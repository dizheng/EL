<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="ENG_NW_001464_20150623_F00100070.nw.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="5649" raw_text_md5="e74e31ab1648ed5efbc97ff677deaa0d">
<TEXT>
<SEG id="segment-0" start_char="0" end_char="37">
<ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
<TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
<TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
</SEG>
<SEG id="segment-1" start_char="39" end_char="81">
<ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001464_20150623_F00100070"&gt;</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
<TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001464_20150623_F00100070"&gt;</TOKEN>
</SEG>
<SEG id="segment-2" start_char="83" end_char="183">
<ORIGINAL_TEXT>&lt;SOURCE&gt;https://www.eff.org/deeplinks/2015/06/how-usa-freedom-impacts-ongoing-nsa-litigation&lt;/SOURCE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="183">&lt;SOURCE&gt;https://www.eff.org/deeplinks/2015/06/how-usa-freedom-impacts-ongoing-nsa-litigation&lt;/SOURCE&gt;</TOKEN>
</SEG>
<SEG id="segment-3" start_char="185" end_char="226">
<ORIGINAL_TEXT>&lt;DATE_TIME&gt;2015-06-23T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="unknown" morph="none" start_char="185" end_char="226">&lt;DATE_TIME&gt;2015-06-23T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
</SEG>
<SEG id="segment-4" start_char="228" end_char="237">
<ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="unknown" morph="none" start_char="228" end_char="237">&lt;HEADLINE&gt;</TOKEN>
</SEG>
<SEG id="segment-5" start_char="239" end_char="284">
<ORIGINAL_TEXT>How USA Freedom Impacts Ongoing NSA Litigation</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="239" end_char="241">How</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="243" end_char="245">USA</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="247" end_char="253">Freedom</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="255" end_char="261">Impacts</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="263" end_char="269">Ongoing</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="271" end_char="273">NSA</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="275" end_char="284">Litigation</TOKEN>
</SEG>
<SEG id="segment-6" start_char="286" end_char="296">
<ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="unknown" morph="none" start_char="286" end_char="296">&lt;/HEADLINE&gt;</TOKEN>
</SEG>
<SEG id="segment-7" start_char="298" end_char="303">
<ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="unknown" morph="none" start_char="298" end_char="303">&lt;TEXT&gt;</TOKEN>
</SEG>
<SEG id="segment-8" start_char="305" end_char="307">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="unknown" morph="none" start_char="305" end_char="307">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-9" start_char="309" end_char="387">
<ORIGINAL_TEXT>Digital liberties groups across the country have both celebrated and criticized</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="309" end_char="315">Digital</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="317" end_char="325">liberties</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="327" end_char="332">groups</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="334" end_char="339">across</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="341" end_char="343">the</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="345" end_char="351">country</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="353" end_char="356">have</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="358" end_char="361">both</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="363" end_char="372">celebrated</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="374" end_char="376">and</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="378" end_char="387">criticized</TOKEN>
</SEG>
<SEG id="segment-10" start_char="389" end_char="466">
<ORIGINAL_TEXT>the recent passage of the USA Freedom Act. Here at EFF, we did a little bit of</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="389" end_char="391">the</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="393" end_char="398">recent</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="400" end_char="406">passage</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="408" end_char="409">of</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="411" end_char="413">the</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="415" end_char="417">USA</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="419" end_char="425">Freedom</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="427" end_char="429">Act</TOKEN>
<TOKEN id="token-10-8" pos="punct" morph="none" start_char="430" end_char="430">.</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="432" end_char="435">Here</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="437" end_char="438">at</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="440" end_char="442">EFF</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="443" end_char="443">,</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="445" end_char="446">we</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="448" end_char="450">did</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="452" end_char="452">a</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="454" end_char="459">little</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="461" end_char="463">bit</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="465" end_char="466">of</TOKEN>
</SEG>
<SEG id="segment-11" start_char="468" end_char="546">
<ORIGINAL_TEXT>both. While USA Freedom will undoubtedly impact the court cases challenging the</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="468" end_char="471">both</TOKEN>
<TOKEN id="token-11-1" pos="punct" morph="none" start_char="472" end_char="472">.</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="474" end_char="478">While</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="480" end_char="482">USA</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="484" end_char="490">Freedom</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="492" end_char="495">will</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="497" end_char="507">undoubtedly</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="509" end_char="514">impact</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="516" end_char="518">the</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="520" end_char="524">court</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="526" end_char="530">cases</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="532" end_char="542">challenging</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="544" end_char="546">the</TOKEN>
</SEG>
<SEG id="segment-12" start_char="548" end_char="626">
<ORIGINAL_TEXT>NSA’s mass surveillance, the full scope of this law and how the courts and even</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="548" end_char="550">NSA</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="551" end_char="551">’</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="552" end_char="552">s</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="554" end_char="557">mass</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="559" end_char="570">surveillance</TOKEN>
<TOKEN id="token-12-5" pos="punct" morph="none" start_char="571" end_char="571">,</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="573" end_char="575">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="577" end_char="580">full</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="582" end_char="586">scope</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="588" end_char="589">of</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="591" end_char="594">this</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="596" end_char="598">law</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="600" end_char="602">and</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="604" end_char="606">how</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="608" end_char="610">the</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="612" end_char="617">courts</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="619" end_char="621">and</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="623" end_char="626">even</TOKEN>
</SEG>
<SEG id="segment-13" start_char="628" end_char="676">
<ORIGINAL_TEXT>the government will interpret it remains unclear.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="628" end_char="630">the</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="632" end_char="641">government</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="643" end_char="646">will</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="648" end_char="656">interpret</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="658" end_char="659">it</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="661" end_char="667">remains</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="669" end_char="675">unclear</TOKEN>
<TOKEN id="token-13-7" pos="punct" morph="none" start_char="676" end_char="676">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="678" end_char="681">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="unknown" morph="none" start_char="678" end_char="681">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-15" start_char="683" end_char="685">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="unknown" morph="none" start_char="683" end_char="685">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-16" start_char="687" end_char="762">
<ORIGINAL_TEXT>However, we do know that the government believes it can renew its daily bulk</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="687" end_char="693">However</TOKEN>
<TOKEN id="token-16-1" pos="punct" morph="none" start_char="694" end_char="694">,</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="696" end_char="697">we</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="699" end_char="700">do</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="702" end_char="705">know</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="707" end_char="710">that</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="712" end_char="714">the</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="716" end_char="725">government</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="727" end_char="734">believes</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="736" end_char="737">it</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="739" end_char="741">can</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="743" end_char="747">renew</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="749" end_char="751">its</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="753" end_char="757">daily</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="759" end_char="762">bulk</TOKEN>
</SEG>
<SEG id="segment-17" start_char="764" end_char="842">
<ORIGINAL_TEXT>collection of telephone records during the 180-day “transition period” in which</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="764" end_char="773">collection</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="775" end_char="776">of</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="778" end_char="786">telephone</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="788" end_char="794">records</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="796" end_char="801">during</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="803" end_char="805">the</TOKEN>
<TOKEN id="token-17-6" pos="number" morph="none" start_char="807" end_char="809">180</TOKEN>
<TOKEN id="token-17-7" pos="punct" morph="none" start_char="810" end_char="810">-</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="811" end_char="813">day</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="815" end_char="815">“</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="816" end_char="825">transition</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="827" end_char="832">period</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="833" end_char="833">”</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="835" end_char="836">in</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="838" end_char="842">which</TOKEN>
</SEG>
<SEG id="segment-18" start_char="844" end_char="921">
<ORIGINAL_TEXT>USA Freedom’s amendments to the phone records authority goes into effect. This</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="844" end_char="846">USA</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="848" end_char="854">Freedom</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="855" end_char="855">’</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="856" end_char="856">s</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="858" end_char="867">amendments</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="869" end_char="870">to</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="872" end_char="874">the</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="876" end_char="880">phone</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="882" end_char="888">records</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="890" end_char="898">authority</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="900" end_char="903">goes</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="905" end_char="908">into</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="910" end_char="915">effect</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="916" end_char="916">.</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="918" end_char="921">This</TOKEN>
</SEG>
<SEG id="segment-19" start_char="923" end_char="1000">
<ORIGINAL_TEXT>is particularly troubling given the Second Circuit’s ruling in ACLU v. Clapper</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="923" end_char="924">is</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="926" end_char="937">particularly</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="939" end_char="947">troubling</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="949" end_char="953">given</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="955" end_char="957">the</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="959" end_char="964">Second</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="966" end_char="972">Circuit</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="973" end_char="973">’</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="974" end_char="974">s</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="976" end_char="981">ruling</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="983" end_char="984">in</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="986" end_char="989">ACLU</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="991" end_char="991">v</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="992" end_char="992">.</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="994" end_char="1000">Clapper</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1002" end_char="1051">
<ORIGINAL_TEXT>that this sort of dragnet surveillance is illegal.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1002" end_char="1005">that</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1007" end_char="1010">this</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1012" end_char="1015">sort</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1017" end_char="1018">of</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1020" end_char="1026">dragnet</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1028" end_char="1039">surveillance</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1041" end_char="1042">is</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1044" end_char="1050">illegal</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="1051" end_char="1051">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1053" end_char="1056">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="unknown" morph="none" start_char="1053" end_char="1056">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1058" end_char="1060">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="unknown" morph="none" start_char="1058" end_char="1060">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1062" end_char="1122">
<ORIGINAL_TEXT>NSA Cases: Smith, First Unitarian, Jewel, Klayman and Clapper</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1062" end_char="1064">NSA</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1066" end_char="1070">Cases</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="1071" end_char="1071">:</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1073" end_char="1077">Smith</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="1078" end_char="1078">,</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="1080" end_char="1084">First</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="1086" end_char="1094">Unitarian</TOKEN>
<TOKEN id="token-23-7" pos="punct" morph="none" start_char="1095" end_char="1095">,</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="1097" end_char="1101">Jewel</TOKEN>
<TOKEN id="token-23-9" pos="punct" morph="none" start_char="1102" end_char="1102">,</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="1104" end_char="1110">Klayman</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="1112" end_char="1114">and</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="1116" end_char="1122">Clapper</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1124" end_char="1127">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="unknown" morph="none" start_char="1124" end_char="1127">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1129" end_char="1131">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="unknown" morph="none" start_char="1129" end_char="1131">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1133" end_char="1203">
<ORIGINAL_TEXT>EFF along with the ACLU had the opportunity to discuss the government’s</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1133" end_char="1135">EFF</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="1137" end_char="1141">along</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="1143" end_char="1146">with</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="1148" end_char="1150">the</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="1152" end_char="1155">ACLU</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="1157" end_char="1159">had</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="1161" end_char="1163">the</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="1165" end_char="1175">opportunity</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="1177" end_char="1178">to</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="1180" end_char="1186">discuss</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="1188" end_char="1190">the</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="1192" end_char="1201">government</TOKEN>
<TOKEN id="token-26-12" pos="punct" morph="none" start_char="1202" end_char="1202">’</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="1203" end_char="1203">s</TOKEN>
</SEG>
<SEG id="segment-27" start_char="1205" end_char="1280">
<ORIGINAL_TEXT>contentions in Smith v. Obama. This past December, the U.S. Court of Appeals</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="1205" end_char="1215">contentions</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="1217" end_char="1218">in</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="1220" end_char="1224">Smith</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="1226" end_char="1226">v</TOKEN>
<TOKEN id="token-27-4" pos="punct" morph="none" start_char="1227" end_char="1227">.</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="1229" end_char="1233">Obama</TOKEN>
<TOKEN id="token-27-6" pos="punct" morph="none" start_char="1234" end_char="1234">.</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="1236" end_char="1239">This</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="1241" end_char="1244">past</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="1246" end_char="1253">December</TOKEN>
<TOKEN id="token-27-10" pos="punct" morph="none" start_char="1254" end_char="1254">,</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="1256" end_char="1258">the</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="1260" end_char="1260">U</TOKEN>
<TOKEN id="token-27-13" pos="punct" morph="none" start_char="1261" end_char="1261">.</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="1262" end_char="1262">S</TOKEN>
<TOKEN id="token-27-15" pos="punct" morph="none" start_char="1263" end_char="1263">.</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="1265" end_char="1269">Court</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="1271" end_char="1272">of</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="1274" end_char="1280">Appeals</TOKEN>
</SEG>
<SEG id="segment-28" start_char="1282" end_char="1353">
<ORIGINAL_TEXT>for the Ninth Circuit heard oral argument on the Smith appeal. After the</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="1282" end_char="1284">for</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="1286" end_char="1288">the</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="1290" end_char="1294">Ninth</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="1296" end_char="1302">Circuit</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="1304" end_char="1308">heard</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="1310" end_char="1313">oral</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="1315" end_char="1322">argument</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="1324" end_char="1325">on</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="1327" end_char="1329">the</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="1331" end_char="1335">Smith</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="1337" end_char="1342">appeal</TOKEN>
<TOKEN id="token-28-11" pos="punct" morph="none" start_char="1343" end_char="1343">.</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="1345" end_char="1349">After</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="1351" end_char="1353">the</TOKEN>
</SEG>
<SEG id="segment-29" start_char="1355" end_char="1431">
<ORIGINAL_TEXT>passage of USA Freedom, the Ninth Circuit quickly requested a briefing by the</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="1355" end_char="1361">passage</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="1363" end_char="1364">of</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="1366" end_char="1368">USA</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="1370" end_char="1376">Freedom</TOKEN>
<TOKEN id="token-29-4" pos="punct" morph="none" start_char="1377" end_char="1377">,</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="1379" end_char="1381">the</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="1383" end_char="1387">Ninth</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="1389" end_char="1395">Circuit</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="1397" end_char="1403">quickly</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="1405" end_char="1413">requested</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="1415" end_char="1415">a</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="1417" end_char="1424">briefing</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="1426" end_char="1427">by</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="1429" end_char="1431">the</TOKEN>
</SEG>
<SEG id="segment-30" start_char="1433" end_char="1510">
<ORIGINAL_TEXT>parties on the impact of USA Freedom on the telephone records program at issue</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="1433" end_char="1439">parties</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="1441" end_char="1442">on</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="1444" end_char="1446">the</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="1448" end_char="1453">impact</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="1455" end_char="1456">of</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="1458" end_char="1460">USA</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="1462" end_char="1468">Freedom</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="1470" end_char="1471">on</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="1473" end_char="1475">the</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="1477" end_char="1485">telephone</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="1487" end_char="1493">records</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="1495" end_char="1501">program</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="1503" end_char="1504">at</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="1506" end_char="1510">issue</TOKEN>
</SEG>
<SEG id="segment-31" start_char="1512" end_char="1568">
<ORIGINAL_TEXT>in Smith. These briefs were submitted on Friday, June 19.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="1512" end_char="1513">in</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="1515" end_char="1519">Smith</TOKEN>
<TOKEN id="token-31-2" pos="punct" morph="none" start_char="1520" end_char="1520">.</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="1522" end_char="1526">These</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="1528" end_char="1533">briefs</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="1535" end_char="1538">were</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="1540" end_char="1548">submitted</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="1550" end_char="1551">on</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="1553" end_char="1558">Friday</TOKEN>
<TOKEN id="token-31-9" pos="punct" morph="none" start_char="1559" end_char="1559">,</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="1561" end_char="1564">June</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="1566" end_char="1567">19</TOKEN>
<TOKEN id="token-31-12" pos="punct" morph="none" start_char="1568" end_char="1568">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="1570" end_char="1573">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="unknown" morph="none" start_char="1570" end_char="1573">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-33" start_char="1575" end_char="1577">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="unknown" morph="none" start_char="1575" end_char="1577">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-34" start_char="1579" end_char="1650">
<ORIGINAL_TEXT>Meanwhile, the United States District Court for the Northern District of</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="1579" end_char="1587">Meanwhile</TOKEN>
<TOKEN id="token-34-1" pos="punct" morph="none" start_char="1588" end_char="1588">,</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="1590" end_char="1592">the</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="1594" end_char="1599">United</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="1601" end_char="1606">States</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="1608" end_char="1615">District</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="1617" end_char="1621">Court</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="1623" end_char="1625">for</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="1627" end_char="1629">the</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="1631" end_char="1638">Northern</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="1640" end_char="1647">District</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="1649" end_char="1650">of</TOKEN>
</SEG>
<SEG id="segment-35" start_char="1652" end_char="1729">
<ORIGINAL_TEXT>California has yet to request briefing on USA Freedom in EFF’s two other cases</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="1652" end_char="1661">California</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="1663" end_char="1665">has</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="1667" end_char="1669">yet</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="1671" end_char="1672">to</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="1674" end_char="1680">request</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="1682" end_char="1689">briefing</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="1691" end_char="1692">on</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="1694" end_char="1696">USA</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="1698" end_char="1704">Freedom</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="1706" end_char="1707">in</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="1709" end_char="1711">EFF</TOKEN>
<TOKEN id="token-35-11" pos="punct" morph="none" start_char="1712" end_char="1712">’</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="1713" end_char="1713">s</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="1715" end_char="1717">two</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="1719" end_char="1723">other</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="1725" end_char="1729">cases</TOKEN>
</SEG>
<SEG id="segment-36" start_char="1731" end_char="1806">
<ORIGINAL_TEXT>challenging the bulk collection of telephone records— First Unitarian v. NSA</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="1731" end_char="1741">challenging</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="1743" end_char="1745">the</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="1747" end_char="1750">bulk</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="1752" end_char="1761">collection</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="1763" end_char="1764">of</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="1766" end_char="1774">telephone</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="1776" end_char="1782">records</TOKEN>
<TOKEN id="token-36-7" pos="punct" morph="none" start_char="1783" end_char="1783">—</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="1785" end_char="1789">First</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="1791" end_char="1799">Unitarian</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="1801" end_char="1801">v</TOKEN>
<TOKEN id="token-36-11" pos="punct" morph="none" start_char="1802" end_char="1802">.</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="1804" end_char="1806">NSA</TOKEN>
</SEG>
<SEG id="segment-37" start_char="1808" end_char="1823">
<ORIGINAL_TEXT>and Jewel v. NSA</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="1808" end_char="1810">and</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="1812" end_char="1816">Jewel</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="1818" end_char="1818">v</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="1819" end_char="1819">.</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="1821" end_char="1823">NSA</TOKEN>
</SEG>
<SEG id="segment-38" start_char="1825" end_char="1828">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="unknown" morph="none" start_char="1825" end_char="1828">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-39" start_char="1830" end_char="1832">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="unknown" morph="none" start_char="1830" end_char="1832">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-40" start_char="1834" end_char="1909">
<ORIGINAL_TEXT>First Unitarian v. NSA solely targets the NSA’s bulk collection of telephone</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="1834" end_char="1838">First</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="1840" end_char="1848">Unitarian</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="1850" end_char="1850">v</TOKEN>
<TOKEN id="token-40-3" pos="punct" morph="none" start_char="1851" end_char="1851">.</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="1853" end_char="1855">NSA</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="1857" end_char="1862">solely</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="1864" end_char="1870">targets</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="1872" end_char="1874">the</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="1876" end_char="1878">NSA</TOKEN>
<TOKEN id="token-40-9" pos="punct" morph="none" start_char="1879" end_char="1879">’</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="1880" end_char="1880">s</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="1882" end_char="1885">bulk</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="1887" end_char="1896">collection</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="1898" end_char="1899">of</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="1901" end_char="1909">telephone</TOKEN>
</SEG>
<SEG id="segment-41" start_char="1911" end_char="1989">
<ORIGINAL_TEXT>records. In First Unitarian, EFF is pursuing First Amendment, Fourth Amendment,</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="1911" end_char="1917">records</TOKEN>
<TOKEN id="token-41-1" pos="punct" morph="none" start_char="1918" end_char="1918">.</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="1920" end_char="1921">In</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="1923" end_char="1927">First</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="1929" end_char="1937">Unitarian</TOKEN>
<TOKEN id="token-41-5" pos="punct" morph="none" start_char="1938" end_char="1938">,</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="1940" end_char="1942">EFF</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="1944" end_char="1945">is</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="1947" end_char="1954">pursuing</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="1956" end_char="1960">First</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="1962" end_char="1970">Amendment</TOKEN>
<TOKEN id="token-41-11" pos="punct" morph="none" start_char="1971" end_char="1971">,</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="1973" end_char="1978">Fourth</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="1980" end_char="1988">Amendment</TOKEN>
<TOKEN id="token-41-14" pos="punct" morph="none" start_char="1989" end_char="1989">,</TOKEN>
</SEG>
<SEG id="segment-42" start_char="1991" end_char="2066">
<ORIGINAL_TEXT>and statutory challenges to this program, so the passage of USA Freedom will</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="1991" end_char="1993">and</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="1995" end_char="2003">statutory</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="2005" end_char="2014">challenges</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="2016" end_char="2017">to</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="2019" end_char="2022">this</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="2024" end_char="2030">program</TOKEN>
<TOKEN id="token-42-6" pos="punct" morph="none" start_char="2031" end_char="2031">,</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="2033" end_char="2034">so</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="2036" end_char="2038">the</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="2040" end_char="2046">passage</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="2048" end_char="2049">of</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="2051" end_char="2053">USA</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="2055" end_char="2061">Freedom</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="2063" end_char="2066">will</TOKEN>
</SEG>
<SEG id="segment-43" start_char="2068" end_char="2145">
<ORIGINAL_TEXT>have an impact on our claims. While the court denied EFF’s most recent request</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="2068" end_char="2071">have</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="2073" end_char="2074">an</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="2076" end_char="2081">impact</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="2083" end_char="2084">on</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="2086" end_char="2088">our</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="2090" end_char="2095">claims</TOKEN>
<TOKEN id="token-43-6" pos="punct" morph="none" start_char="2096" end_char="2096">.</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="2098" end_char="2102">While</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="2104" end_char="2106">the</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="2108" end_char="2112">court</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="2114" end_char="2119">denied</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="2121" end_char="2123">EFF</TOKEN>
<TOKEN id="token-43-12" pos="punct" morph="none" start_char="2124" end_char="2124">’</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="2125" end_char="2125">s</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="2127" end_char="2130">most</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="2132" end_char="2137">recent</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="2139" end_char="2145">request</TOKEN>
</SEG>
<SEG id="segment-44" start_char="2147" end_char="2220">
<ORIGINAL_TEXT>for a hearing, EFF will continue to pursue these claims to ensure that the</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="2147" end_char="2149">for</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="2151" end_char="2151">a</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="2153" end_char="2159">hearing</TOKEN>
<TOKEN id="token-44-3" pos="punct" morph="none" start_char="2160" end_char="2160">,</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="2162" end_char="2164">EFF</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="2166" end_char="2169">will</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="2171" end_char="2178">continue</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="2180" end_char="2181">to</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="2183" end_char="2188">pursue</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="2190" end_char="2194">these</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="2196" end_char="2201">claims</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="2203" end_char="2204">to</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="2206" end_char="2211">ensure</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="2213" end_char="2216">that</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="2218" end_char="2220">the</TOKEN>
</SEG>
<SEG id="segment-45" start_char="2222" end_char="2296">
<ORIGINAL_TEXT>court fully considers the issues raised by the NSA’s phone records program.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="2222" end_char="2226">court</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="2228" end_char="2232">fully</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="2234" end_char="2242">considers</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="2244" end_char="2246">the</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="2248" end_char="2253">issues</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="2255" end_char="2260">raised</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="2262" end_char="2263">by</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="2265" end_char="2267">the</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="2269" end_char="2271">NSA</TOKEN>
<TOKEN id="token-45-9" pos="punct" morph="none" start_char="2272" end_char="2272">’</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="2273" end_char="2273">s</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="2275" end_char="2279">phone</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="2281" end_char="2287">records</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="2289" end_char="2295">program</TOKEN>
<TOKEN id="token-45-14" pos="punct" morph="none" start_char="2296" end_char="2296">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="2298" end_char="2301">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="unknown" morph="none" start_char="2298" end_char="2301">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-47" start_char="2303" end_char="2305">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="unknown" morph="none" start_char="2303" end_char="2305">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-48" start_char="2307" end_char="2375">
<ORIGINAL_TEXT>Jewel v. NSA is EFF’s longest-standing case against the NSA’s dragnet</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="2307" end_char="2311">Jewel</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="2313" end_char="2313">v</TOKEN>
<TOKEN id="token-48-2" pos="punct" morph="none" start_char="2314" end_char="2314">.</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="2316" end_char="2318">NSA</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="2320" end_char="2321">is</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="2323" end_char="2325">EFF</TOKEN>
<TOKEN id="token-48-6" pos="punct" morph="none" start_char="2326" end_char="2326">’</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="2327" end_char="2327">s</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="2329" end_char="2335">longest</TOKEN>
<TOKEN id="token-48-9" pos="punct" morph="none" start_char="2336" end_char="2336">-</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="2337" end_char="2344">standing</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="2346" end_char="2349">case</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="2351" end_char="2357">against</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="2359" end_char="2361">the</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="2363" end_char="2365">NSA</TOKEN>
<TOKEN id="token-48-15" pos="punct" morph="none" start_char="2366" end_char="2366">’</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="2367" end_char="2367">s</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="2369" end_char="2375">dragnet</TOKEN>
</SEG>
<SEG id="segment-49" start_char="2377" end_char="2455">
<ORIGINAL_TEXT>surveillance. Jewel challenges the NSA’s bulk collection of telephony metadata,</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="2377" end_char="2388">surveillance</TOKEN>
<TOKEN id="token-49-1" pos="punct" morph="none" start_char="2389" end_char="2389">.</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="2391" end_char="2395">Jewel</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="2397" end_char="2406">challenges</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="2408" end_char="2410">the</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="2412" end_char="2414">NSA</TOKEN>
<TOKEN id="token-49-6" pos="punct" morph="none" start_char="2415" end_char="2415">’</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="2416" end_char="2416">s</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="2418" end_char="2421">bulk</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="2423" end_char="2432">collection</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="2434" end_char="2435">of</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="2437" end_char="2445">telephony</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="2447" end_char="2454">metadata</TOKEN>
<TOKEN id="token-49-13" pos="punct" morph="none" start_char="2455" end_char="2455">,</TOKEN>
</SEG>
<SEG id="segment-50" start_char="2457" end_char="2531">
<ORIGINAL_TEXT>the collection of Internet metadata, and Internet content surveillance. USA</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="2457" end_char="2459">the</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="2461" end_char="2470">collection</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="2472" end_char="2473">of</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="2475" end_char="2482">Internet</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="2484" end_char="2491">metadata</TOKEN>
<TOKEN id="token-50-5" pos="punct" morph="none" start_char="2492" end_char="2492">,</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="2494" end_char="2496">and</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="2498" end_char="2505">Internet</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="2507" end_char="2513">content</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="2515" end_char="2526">surveillance</TOKEN>
<TOKEN id="token-50-10" pos="punct" morph="none" start_char="2527" end_char="2527">.</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="2529" end_char="2531">USA</TOKEN>
</SEG>
<SEG id="segment-51" start_char="2533" end_char="2607">
<ORIGINAL_TEXT>Freedom addresses the bulk collection of telephony metadata, but it notably</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="2533" end_char="2539">Freedom</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="2541" end_char="2549">addresses</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="2551" end_char="2553">the</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="2555" end_char="2558">bulk</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="2560" end_char="2569">collection</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="2571" end_char="2572">of</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="2574" end_char="2582">telephony</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="2584" end_char="2591">metadata</TOKEN>
<TOKEN id="token-51-8" pos="punct" morph="none" start_char="2592" end_char="2592">,</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="2594" end_char="2596">but</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="2598" end_char="2599">it</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="2601" end_char="2607">notably</TOKEN>
</SEG>
<SEG id="segment-52" start_char="2609" end_char="2683">
<ORIGINAL_TEXT>neglects the collection of Internet communications under Section 702 of the</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="2609" end_char="2616">neglects</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="2618" end_char="2620">the</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="2622" end_char="2631">collection</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="2633" end_char="2634">of</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="2636" end_char="2643">Internet</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="2645" end_char="2658">communications</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="2660" end_char="2664">under</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="2666" end_char="2672">Section</TOKEN>
<TOKEN id="token-52-8" pos="number" morph="none" start_char="2674" end_char="2676">702</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="2678" end_char="2679">of</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="2681" end_char="2683">the</TOKEN>
</SEG>
<SEG id="segment-53" start_char="2685" end_char="2754">
<ORIGINAL_TEXT>FISA Amendment Act. The court ruled for the government on EFF’s Fourth</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="2685" end_char="2688">FISA</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="2690" end_char="2698">Amendment</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="2700" end_char="2702">Act</TOKEN>
<TOKEN id="token-53-3" pos="punct" morph="none" start_char="2703" end_char="2703">.</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="2705" end_char="2707">The</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="2709" end_char="2713">court</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="2715" end_char="2719">ruled</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="2721" end_char="2723">for</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="2725" end_char="2727">the</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="2729" end_char="2738">government</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="2740" end_char="2741">on</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="2743" end_char="2745">EFF</TOKEN>
<TOKEN id="token-53-12" pos="punct" morph="none" start_char="2746" end_char="2746">’</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="2747" end_char="2747">s</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="2749" end_char="2754">Fourth</TOKEN>
</SEG>
<SEG id="segment-54" start_char="2756" end_char="2834">
<ORIGINAL_TEXT>Amendment challenge to the collection of Internet content (and EFF is appealing</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="2756" end_char="2764">Amendment</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="2766" end_char="2774">challenge</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="2776" end_char="2777">to</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="2779" end_char="2781">the</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="2783" end_char="2792">collection</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="2794" end_char="2795">of</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="2797" end_char="2804">Internet</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="2806" end_char="2812">content</TOKEN>
<TOKEN id="token-54-8" pos="punct" morph="none" start_char="2814" end_char="2814">(</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="2815" end_char="2817">and</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="2819" end_char="2821">EFF</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="2823" end_char="2824">is</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="2826" end_char="2834">appealing</TOKEN>
</SEG>
<SEG id="segment-55" start_char="2836" end_char="2908">
<ORIGINAL_TEXT>this decision in the Ninth Circuit), but the court has yet to rule on the</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="2836" end_char="2839">this</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="2841" end_char="2848">decision</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="2850" end_char="2851">in</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="2853" end_char="2855">the</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="2857" end_char="2861">Ninth</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="2863" end_char="2869">Circuit</TOKEN>
<TOKEN id="token-55-6" pos="punct" morph="none" start_char="2870" end_char="2871">),</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="2873" end_char="2875">but</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="2877" end_char="2879">the</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="2881" end_char="2885">court</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="2887" end_char="2889">has</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="2891" end_char="2893">yet</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="2895" end_char="2896">to</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="2898" end_char="2901">rule</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="2903" end_char="2904">on</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="2906" end_char="2908">the</TOKEN>
</SEG>
<SEG id="segment-56" start_char="2910" end_char="2982">
<ORIGINAL_TEXT>constitutionality or permissibility of the mass surveillance of telephone</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="2910" end_char="2926">constitutionality</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="2928" end_char="2929">or</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="2931" end_char="2944">permissibility</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="2946" end_char="2947">of</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="2949" end_char="2951">the</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="2953" end_char="2956">mass</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="2958" end_char="2969">surveillance</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="2971" end_char="2972">of</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="2974" end_char="2982">telephone</TOKEN>
</SEG>
<SEG id="segment-57" start_char="2984" end_char="3057">
<ORIGINAL_TEXT>records. In addition to pursuing our appeal in the Ninth Circuit, EFF will</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="2984" end_char="2990">records</TOKEN>
<TOKEN id="token-57-1" pos="punct" morph="none" start_char="2991" end_char="2991">.</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="2993" end_char="2994">In</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="2996" end_char="3003">addition</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="3005" end_char="3006">to</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="3008" end_char="3015">pursuing</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="3017" end_char="3019">our</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="3021" end_char="3026">appeal</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="3028" end_char="3029">in</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="3031" end_char="3033">the</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="3035" end_char="3039">Ninth</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="3041" end_char="3047">Circuit</TOKEN>
<TOKEN id="token-57-12" pos="punct" morph="none" start_char="3048" end_char="3048">,</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="3050" end_char="3052">EFF</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="3054" end_char="3057">will</TOKEN>
</SEG>
<SEG id="segment-58" start_char="3059" end_char="3125">
<ORIGINAL_TEXT>continue to push forward on our other claims in the district court.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="3059" end_char="3066">continue</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="3068" end_char="3069">to</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="3071" end_char="3074">push</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="3076" end_char="3082">forward</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="3084" end_char="3085">on</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="3087" end_char="3089">our</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="3091" end_char="3095">other</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="3097" end_char="3102">claims</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="3104" end_char="3105">in</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="3107" end_char="3109">the</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="3111" end_char="3118">district</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="3120" end_char="3124">court</TOKEN>
<TOKEN id="token-58-12" pos="punct" morph="none" start_char="3125" end_char="3125">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="3127" end_char="3130">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="unknown" morph="none" start_char="3127" end_char="3130">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-60" start_char="3132" end_char="3134">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="unknown" morph="none" start_char="3132" end_char="3134">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-61" start_char="3136" end_char="3214">
<ORIGINAL_TEXT>Expect similar issues to arise in other NSA spying cases that EFF has supported</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="3136" end_char="3141">Expect</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="3143" end_char="3149">similar</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="3151" end_char="3156">issues</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="3158" end_char="3159">to</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="3161" end_char="3165">arise</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="3167" end_char="3168">in</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="3170" end_char="3174">other</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="3176" end_char="3178">NSA</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="3180" end_char="3185">spying</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="3187" end_char="3191">cases</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="3193" end_char="3196">that</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="3198" end_char="3200">EFF</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="3202" end_char="3204">has</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="3206" end_char="3214">supported</TOKEN>
</SEG>
<SEG id="segment-62" start_char="3216" end_char="3294">
<ORIGINAL_TEXT>as an amicus— Klayman v. Obama and ACLU v. Clapper. Currently, Klayman is under</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="3216" end_char="3217">as</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="3219" end_char="3220">an</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="3222" end_char="3227">amicus</TOKEN>
<TOKEN id="token-62-3" pos="punct" morph="none" start_char="3228" end_char="3228">—</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="3230" end_char="3236">Klayman</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="3238" end_char="3238">v</TOKEN>
<TOKEN id="token-62-6" pos="punct" morph="none" start_char="3239" end_char="3239">.</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="3241" end_char="3245">Obama</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="3247" end_char="3249">and</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="3251" end_char="3254">ACLU</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="3256" end_char="3256">v</TOKEN>
<TOKEN id="token-62-11" pos="punct" morph="none" start_char="3257" end_char="3257">.</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="3259" end_char="3265">Clapper</TOKEN>
<TOKEN id="token-62-13" pos="punct" morph="none" start_char="3266" end_char="3266">.</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="3268" end_char="3276">Currently</TOKEN>
<TOKEN id="token-62-15" pos="punct" morph="none" start_char="3277" end_char="3277">,</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="3279" end_char="3285">Klayman</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="3287" end_char="3288">is</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="3290" end_char="3294">under</TOKEN>
</SEG>
<SEG id="segment-63" start_char="3296" end_char="3371">
<ORIGINAL_TEXT>review following oral argument in the D.C. Circuit, which is considering the</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="3296" end_char="3301">review</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="3303" end_char="3311">following</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="3313" end_char="3316">oral</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="3318" end_char="3325">argument</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="3327" end_char="3328">in</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="3330" end_char="3332">the</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="3334" end_char="3334">D</TOKEN>
<TOKEN id="token-63-7" pos="punct" morph="none" start_char="3335" end_char="3335">.</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="3336" end_char="3336">C</TOKEN>
<TOKEN id="token-63-9" pos="punct" morph="none" start_char="3337" end_char="3337">.</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="3339" end_char="3345">Circuit</TOKEN>
<TOKEN id="token-63-11" pos="punct" morph="none" start_char="3346" end_char="3346">,</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="3348" end_char="3352">which</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="3354" end_char="3355">is</TOKEN>
<TOKEN id="token-63-14" pos="word" morph="none" start_char="3357" end_char="3367">considering</TOKEN>
<TOKEN id="token-63-15" pos="word" morph="none" start_char="3369" end_char="3371">the</TOKEN>
</SEG>
<SEG id="segment-64" start_char="3373" end_char="3451">
<ORIGINAL_TEXT>district court’s ruling that the bulk collection of telephone records is likely</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="3373" end_char="3380">district</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="3382" end_char="3386">court</TOKEN>
<TOKEN id="token-64-2" pos="punct" morph="none" start_char="3387" end_char="3387">’</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="3388" end_char="3388">s</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="3390" end_char="3395">ruling</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="3397" end_char="3400">that</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="3402" end_char="3404">the</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="3406" end_char="3409">bulk</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="3411" end_char="3420">collection</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="3422" end_char="3423">of</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="3425" end_char="3433">telephone</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="3435" end_char="3441">records</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="3443" end_char="3444">is</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="3446" end_char="3451">likely</TOKEN>
</SEG>
<SEG id="segment-65" start_char="3453" end_char="3527">
<ORIGINAL_TEXT>unconstitutional. Klayman recently filed a supplemental brief stressing the</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="3453" end_char="3468">unconstitutional</TOKEN>
<TOKEN id="token-65-1" pos="punct" morph="none" start_char="3469" end_char="3469">.</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="3471" end_char="3477">Klayman</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="3479" end_char="3486">recently</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="3488" end_char="3492">filed</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="3494" end_char="3494">a</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="3496" end_char="3507">supplemental</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="3509" end_char="3513">brief</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="3515" end_char="3523">stressing</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="3525" end_char="3527">the</TOKEN>
</SEG>
<SEG id="segment-66" start_char="3529" end_char="3599">
<ORIGINAL_TEXT>importance of the appeal continuing despite USA Freedom given the NSA’s</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="3529" end_char="3538">importance</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="3540" end_char="3541">of</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="3543" end_char="3545">the</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="3547" end_char="3552">appeal</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="3554" end_char="3563">continuing</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="3565" end_char="3571">despite</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="3573" end_char="3575">USA</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="3577" end_char="3583">Freedom</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="3585" end_char="3589">given</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="3591" end_char="3593">the</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="3595" end_char="3597">NSA</TOKEN>
<TOKEN id="token-66-11" pos="punct" morph="none" start_char="3598" end_char="3598">’</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="3599" end_char="3599">s</TOKEN>
</SEG>
<SEG id="segment-67" start_char="3601" end_char="3678">
<ORIGINAL_TEXT>“pattern of illegal and unconstitutional acts for an extended period of time.”</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="punct" morph="none" start_char="3601" end_char="3601">“</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="3602" end_char="3608">pattern</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="3610" end_char="3611">of</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="3613" end_char="3619">illegal</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="3621" end_char="3623">and</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="3625" end_char="3640">unconstitutional</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="3642" end_char="3645">acts</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="3647" end_char="3649">for</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="3651" end_char="3652">an</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="3654" end_char="3661">extended</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="3663" end_char="3668">period</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="3670" end_char="3671">of</TOKEN>
<TOKEN id="token-67-12" pos="word" morph="none" start_char="3673" end_char="3676">time</TOKEN>
<TOKEN id="token-67-13" pos="punct" morph="none" start_char="3677" end_char="3678">.”</TOKEN>
</SEG>
<SEG id="segment-68" start_char="3680" end_char="3755">
<ORIGINAL_TEXT>Meanwhile, the Second Circuit’s historic ruling in Clapper not only held the</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="3680" end_char="3688">Meanwhile</TOKEN>
<TOKEN id="token-68-1" pos="punct" morph="none" start_char="3689" end_char="3689">,</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="3691" end_char="3693">the</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="3695" end_char="3700">Second</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="3702" end_char="3708">Circuit</TOKEN>
<TOKEN id="token-68-5" pos="punct" morph="none" start_char="3709" end_char="3709">’</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="3710" end_char="3710">s</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="3712" end_char="3719">historic</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="3721" end_char="3726">ruling</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="3728" end_char="3729">in</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="3731" end_char="3737">Clapper</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="3739" end_char="3741">not</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="3743" end_char="3746">only</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="3748" end_char="3751">held</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="3753" end_char="3755">the</TOKEN>
</SEG>
<SEG id="segment-69" start_char="3757" end_char="3833">
<ORIGINAL_TEXT>bulk collection of telephone records exceeded congressional authorization, it</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="3757" end_char="3760">bulk</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="3762" end_char="3771">collection</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="3773" end_char="3774">of</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="3776" end_char="3784">telephone</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="3786" end_char="3792">records</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="3794" end_char="3801">exceeded</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="3803" end_char="3815">congressional</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="3817" end_char="3829">authorization</TOKEN>
<TOKEN id="token-69-8" pos="punct" morph="none" start_char="3830" end_char="3830">,</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="3832" end_char="3833">it</TOKEN>
</SEG>
<SEG id="segment-70" start_char="3835" end_char="3912">
<ORIGINAL_TEXT>also directly raised the possibility of Congress addressing the NSA’s reliance</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="3835" end_char="3838">also</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="3840" end_char="3847">directly</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="3849" end_char="3854">raised</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="3856" end_char="3858">the</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="3860" end_char="3870">possibility</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="3872" end_char="3873">of</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="3875" end_char="3882">Congress</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="3884" end_char="3893">addressing</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="3895" end_char="3897">the</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="3899" end_char="3901">NSA</TOKEN>
<TOKEN id="token-70-10" pos="punct" morph="none" start_char="3902" end_char="3902">’</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="3903" end_char="3903">s</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="3905" end_char="3912">reliance</TOKEN>
</SEG>
<SEG id="segment-71" start_char="3914" end_char="3990">
<ORIGINAL_TEXT>on Section 215 of the Patriot Act for its telephone records program. Congress</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="3914" end_char="3915">on</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="3917" end_char="3923">Section</TOKEN>
<TOKEN id="token-71-2" pos="number" morph="none" start_char="3925" end_char="3927">215</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="3929" end_char="3930">of</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="3932" end_char="3934">the</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="3936" end_char="3942">Patriot</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="3944" end_char="3946">Act</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="3948" end_char="3950">for</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="3952" end_char="3954">its</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="3956" end_char="3964">telephone</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="3966" end_char="3972">records</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="3974" end_char="3980">program</TOKEN>
<TOKEN id="token-71-12" pos="punct" morph="none" start_char="3981" end_char="3981">.</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="3983" end_char="3990">Congress</TOKEN>
</SEG>
<SEG id="segment-72" start_char="3992" end_char="4068">
<ORIGINAL_TEXT>has since spoken with the passage of USA Freedom, so the extent of the Second</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="3992" end_char="3994">has</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="3996" end_char="4000">since</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="4002" end_char="4007">spoken</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="4009" end_char="4012">with</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="4014" end_char="4016">the</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="4018" end_char="4024">passage</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="4026" end_char="4027">of</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="4029" end_char="4031">USA</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="4033" end_char="4039">Freedom</TOKEN>
<TOKEN id="token-72-9" pos="punct" morph="none" start_char="4040" end_char="4040">,</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="4042" end_char="4043">so</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="4045" end_char="4047">the</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="4049" end_char="4054">extent</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="4056" end_char="4057">of</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="4059" end_char="4061">the</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="4063" end_char="4068">Second</TOKEN>
</SEG>
<SEG id="segment-73" start_char="4070" end_char="4147">
<ORIGINAL_TEXT>Circuit’s deference to Congress relating to the 180-day transition period will</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="4070" end_char="4076">Circuit</TOKEN>
<TOKEN id="token-73-1" pos="punct" morph="none" start_char="4077" end_char="4077">’</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="4078" end_char="4078">s</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="4080" end_char="4088">deference</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="4090" end_char="4091">to</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="4093" end_char="4100">Congress</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="4102" end_char="4109">relating</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="4111" end_char="4112">to</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="4114" end_char="4116">the</TOKEN>
<TOKEN id="token-73-9" pos="number" morph="none" start_char="4118" end_char="4120">180</TOKEN>
<TOKEN id="token-73-10" pos="punct" morph="none" start_char="4121" end_char="4121">-</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="4122" end_char="4124">day</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="4126" end_char="4135">transition</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="4137" end_char="4142">period</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="4144" end_char="4147">will</TOKEN>
</SEG>
<SEG id="segment-74" start_char="4149" end_char="4225">
<ORIGINAL_TEXT>be a significant issue as it considers supplemental briefing from the parties</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="4149" end_char="4150">be</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="4152" end_char="4152">a</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="4154" end_char="4164">significant</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="4166" end_char="4170">issue</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="4172" end_char="4173">as</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="4175" end_char="4176">it</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="4178" end_char="4186">considers</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="4188" end_char="4199">supplemental</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="4201" end_char="4208">briefing</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="4210" end_char="4213">from</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="4215" end_char="4217">the</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="4219" end_char="4225">parties</TOKEN>
</SEG>
<SEG id="segment-75" start_char="4227" end_char="4262">
<ORIGINAL_TEXT>on whether the ACLU’s claim is moot.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="4227" end_char="4228">on</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="4230" end_char="4236">whether</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="4238" end_char="4240">the</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="4242" end_char="4245">ACLU</TOKEN>
<TOKEN id="token-75-4" pos="punct" morph="none" start_char="4246" end_char="4246">’</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="4247" end_char="4247">s</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="4249" end_char="4253">claim</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="4255" end_char="4256">is</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="4258" end_char="4261">moot</TOKEN>
<TOKEN id="token-75-9" pos="punct" morph="none" start_char="4262" end_char="4262">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="4264" end_char="4267">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="unknown" morph="none" start_char="4264" end_char="4267">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-77" start_char="4269" end_char="4271">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="unknown" morph="none" start_char="4269" end_char="4271">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-78" start_char="4273" end_char="4297">
<ORIGINAL_TEXT>National Security Letters</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="4273" end_char="4280">National</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="4282" end_char="4289">Security</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="4291" end_char="4297">Letters</TOKEN>
</SEG>
<SEG id="segment-79" start_char="4299" end_char="4302">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="unknown" morph="none" start_char="4299" end_char="4302">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-80" start_char="4304" end_char="4306">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="unknown" morph="none" start_char="4304" end_char="4306">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-81" start_char="4308" end_char="4382">
<ORIGINAL_TEXT>In addition to modifying the requirements for the collection of call detail</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="4308" end_char="4309">In</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="4311" end_char="4318">addition</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="4320" end_char="4321">to</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="4323" end_char="4331">modifying</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="4333" end_char="4335">the</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="4337" end_char="4348">requirements</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="4350" end_char="4352">for</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="4354" end_char="4356">the</TOKEN>
<TOKEN id="token-81-8" pos="word" morph="none" start_char="4358" end_char="4367">collection</TOKEN>
<TOKEN id="token-81-9" pos="word" morph="none" start_char="4369" end_char="4370">of</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="4372" end_char="4375">call</TOKEN>
<TOKEN id="token-81-11" pos="word" morph="none" start_char="4377" end_char="4382">detail</TOKEN>
</SEG>
<SEG id="segment-82" start_char="4384" end_char="4454">
<ORIGINAL_TEXT>records and other tangible things, USA Freedom also amends the statutes</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="4384" end_char="4390">records</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="4392" end_char="4394">and</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="4396" end_char="4400">other</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="4402" end_char="4409">tangible</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="4411" end_char="4416">things</TOKEN>
<TOKEN id="token-82-5" pos="punct" morph="none" start_char="4417" end_char="4417">,</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="4419" end_char="4421">USA</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="4423" end_char="4429">Freedom</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="4431" end_char="4434">also</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="4436" end_char="4441">amends</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="4443" end_char="4445">the</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="4447" end_char="4454">statutes</TOKEN>
</SEG>
<SEG id="segment-83" start_char="4456" end_char="4532">
<ORIGINAL_TEXT>governing national security letters (NSLs). In particular, the NSL amendments</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="4456" end_char="4464">governing</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="4466" end_char="4473">national</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="4475" end_char="4482">security</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="4484" end_char="4490">letters</TOKEN>
<TOKEN id="token-83-4" pos="punct" morph="none" start_char="4492" end_char="4492">(</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="4493" end_char="4496">NSLs</TOKEN>
<TOKEN id="token-83-6" pos="punct" morph="none" start_char="4497" end_char="4498">).</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="4500" end_char="4501">In</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="4503" end_char="4512">particular</TOKEN>
<TOKEN id="token-83-9" pos="punct" morph="none" start_char="4513" end_char="4513">,</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="4515" end_char="4517">the</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="4519" end_char="4521">NSL</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="4523" end_char="4532">amendments</TOKEN>
</SEG>
<SEG id="segment-84" start_char="4534" end_char="4610">
<ORIGINAL_TEXT>attempt to address the constitutional concerns raised in our victory in In re</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="4534" end_char="4540">attempt</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="4542" end_char="4543">to</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="4545" end_char="4551">address</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="4553" end_char="4555">the</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="4557" end_char="4570">constitutional</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="4572" end_char="4579">concerns</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="4581" end_char="4586">raised</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="4588" end_char="4589">in</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="4591" end_char="4593">our</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="4595" end_char="4601">victory</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="4603" end_char="4604">in</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="4606" end_char="4607">In</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="4609" end_char="4610">re</TOKEN>
</SEG>
<SEG id="segment-85" start_char="4612" end_char="4676">
<ORIGINAL_TEXT>NSL by amending the process by which NSL recipients can challenge</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="4612" end_char="4614">NSL</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="4616" end_char="4617">by</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="4619" end_char="4626">amending</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="4628" end_char="4630">the</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="4632" end_char="4638">process</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="4640" end_char="4641">by</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="4643" end_char="4647">which</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="4649" end_char="4651">NSL</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="4653" end_char="4662">recipients</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="4664" end_char="4666">can</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="4668" end_char="4676">challenge</TOKEN>
</SEG>
<SEG id="segment-86" start_char="4678" end_char="4754">
<ORIGINAL_TEXT>non-disclosure orders, but they don’t to go far enough. These amendments will</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="4678" end_char="4680">non</TOKEN>
<TOKEN id="token-86-1" pos="punct" morph="none" start_char="4681" end_char="4681">-</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="4682" end_char="4691">disclosure</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="4693" end_char="4698">orders</TOKEN>
<TOKEN id="token-86-4" pos="punct" morph="none" start_char="4699" end_char="4699">,</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="4701" end_char="4703">but</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="4705" end_char="4708">they</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="4710" end_char="4712">don</TOKEN>
<TOKEN id="token-86-8" pos="punct" morph="none" start_char="4713" end_char="4713">’</TOKEN>
<TOKEN id="token-86-9" pos="word" morph="none" start_char="4714" end_char="4714">t</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="4716" end_char="4717">to</TOKEN>
<TOKEN id="token-86-11" pos="word" morph="none" start_char="4719" end_char="4720">go</TOKEN>
<TOKEN id="token-86-12" pos="word" morph="none" start_char="4722" end_char="4724">far</TOKEN>
<TOKEN id="token-86-13" pos="word" morph="none" start_char="4726" end_char="4731">enough</TOKEN>
<TOKEN id="token-86-14" pos="punct" morph="none" start_char="4732" end_char="4732">.</TOKEN>
<TOKEN id="token-86-15" pos="word" morph="none" start_char="4734" end_char="4738">These</TOKEN>
<TOKEN id="token-86-16" pos="word" morph="none" start_char="4740" end_char="4749">amendments</TOKEN>
<TOKEN id="token-86-17" pos="word" morph="none" start_char="4751" end_char="4754">will</TOKEN>
</SEG>
<SEG id="segment-87" start_char="4756" end_char="4833">
<ORIGINAL_TEXT>certainly be relevant to our work on the appeal of In re NSL, which was argued</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="4756" end_char="4764">certainly</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="4766" end_char="4767">be</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="4769" end_char="4776">relevant</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="4778" end_char="4779">to</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="4781" end_char="4783">our</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="4785" end_char="4788">work</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="4790" end_char="4791">on</TOKEN>
<TOKEN id="token-87-7" pos="word" morph="none" start_char="4793" end_char="4795">the</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="4797" end_char="4802">appeal</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="4804" end_char="4805">of</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="4807" end_char="4808">In</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="4810" end_char="4811">re</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="4813" end_char="4815">NSL</TOKEN>
<TOKEN id="token-87-13" pos="punct" morph="none" start_char="4816" end_char="4816">,</TOKEN>
<TOKEN id="token-87-14" pos="word" morph="none" start_char="4818" end_char="4822">which</TOKEN>
<TOKEN id="token-87-15" pos="word" morph="none" start_char="4824" end_char="4826">was</TOKEN>
<TOKEN id="token-87-16" pos="word" morph="none" start_char="4828" end_char="4833">argued</TOKEN>
</SEG>
<SEG id="segment-88" start_char="4835" end_char="4911">
<ORIGINAL_TEXT>in the Ninth Circuit in October, and as amicus in Twitter v. Holder. In fact,</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="4835" end_char="4836">in</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="4838" end_char="4840">the</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="4842" end_char="4846">Ninth</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="4848" end_char="4854">Circuit</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="4856" end_char="4857">in</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="4859" end_char="4865">October</TOKEN>
<TOKEN id="token-88-6" pos="punct" morph="none" start_char="4866" end_char="4866">,</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="4868" end_char="4870">and</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="4872" end_char="4873">as</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="4875" end_char="4880">amicus</TOKEN>
<TOKEN id="token-88-10" pos="word" morph="none" start_char="4882" end_char="4883">in</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="4885" end_char="4891">Twitter</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="4893" end_char="4893">v</TOKEN>
<TOKEN id="token-88-13" pos="punct" morph="none" start_char="4894" end_char="4894">.</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="4896" end_char="4901">Holder</TOKEN>
<TOKEN id="token-88-15" pos="punct" morph="none" start_char="4902" end_char="4902">.</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="4904" end_char="4905">In</TOKEN>
<TOKEN id="token-88-17" pos="word" morph="none" start_char="4907" end_char="4910">fact</TOKEN>
<TOKEN id="token-88-18" pos="punct" morph="none" start_char="4911" end_char="4911">,</TOKEN>
</SEG>
<SEG id="segment-89" start_char="4913" end_char="4990">
<ORIGINAL_TEXT>the court in the Twitter suit has requested additional briefing by the parties</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="4913" end_char="4915">the</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="4917" end_char="4921">court</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="4923" end_char="4924">in</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="4926" end_char="4928">the</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="4930" end_char="4936">Twitter</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="4938" end_char="4941">suit</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="4943" end_char="4945">has</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="4947" end_char="4955">requested</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="4957" end_char="4966">additional</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="4968" end_char="4975">briefing</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="4977" end_char="4978">by</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="4980" end_char="4982">the</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="4984" end_char="4990">parties</TOKEN>
</SEG>
<SEG id="segment-90" start_char="4992" end_char="5032">
<ORIGINAL_TEXT>on how USA Freedom would impact the case.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="4992" end_char="4993">on</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="4995" end_char="4997">how</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="4999" end_char="5001">USA</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="5003" end_char="5009">Freedom</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="5011" end_char="5015">would</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="5017" end_char="5022">impact</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="5024" end_char="5026">the</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="5028" end_char="5031">case</TOKEN>
<TOKEN id="token-90-8" pos="punct" morph="none" start_char="5032" end_char="5032">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="5034" end_char="5037">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="unknown" morph="none" start_char="5034" end_char="5037">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-92" start_char="5039" end_char="5041">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="unknown" morph="none" start_char="5039" end_char="5041">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-93" start_char="5043" end_char="5052">
<ORIGINAL_TEXT>Next Steps</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="5043" end_char="5046">Next</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="5048" end_char="5052">Steps</TOKEN>
</SEG>
<SEG id="segment-94" start_char="5054" end_char="5057">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="unknown" morph="none" start_char="5054" end_char="5057">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-95" start_char="5059" end_char="5061">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="unknown" morph="none" start_char="5059" end_char="5061">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-96" start_char="5063" end_char="5140">
<ORIGINAL_TEXT>While the short- and long-term implications of USA Freedom may not be as clear</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="5063" end_char="5067">While</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="5069" end_char="5071">the</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="5073" end_char="5077">short</TOKEN>
<TOKEN id="token-96-3" pos="punct" morph="none" start_char="5078" end_char="5078">-</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="5080" end_char="5082">and</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="5084" end_char="5087">long</TOKEN>
<TOKEN id="token-96-6" pos="punct" morph="none" start_char="5088" end_char="5088">-</TOKEN>
<TOKEN id="token-96-7" pos="word" morph="none" start_char="5089" end_char="5092">term</TOKEN>
<TOKEN id="token-96-8" pos="word" morph="none" start_char="5094" end_char="5105">implications</TOKEN>
<TOKEN id="token-96-9" pos="word" morph="none" start_char="5107" end_char="5108">of</TOKEN>
<TOKEN id="token-96-10" pos="word" morph="none" start_char="5110" end_char="5112">USA</TOKEN>
<TOKEN id="token-96-11" pos="word" morph="none" start_char="5114" end_char="5120">Freedom</TOKEN>
<TOKEN id="token-96-12" pos="word" morph="none" start_char="5122" end_char="5124">may</TOKEN>
<TOKEN id="token-96-13" pos="word" morph="none" start_char="5126" end_char="5128">not</TOKEN>
<TOKEN id="token-96-14" pos="word" morph="none" start_char="5130" end_char="5131">be</TOKEN>
<TOKEN id="token-96-15" pos="word" morph="none" start_char="5133" end_char="5134">as</TOKEN>
<TOKEN id="token-96-16" pos="word" morph="none" start_char="5136" end_char="5140">clear</TOKEN>
</SEG>
<SEG id="segment-97" start_char="5142" end_char="5220">
<ORIGINAL_TEXT>as we would like, there is hope. In First Unitarian, Smith, and Jewel, EFF will</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="5142" end_char="5143">as</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="5145" end_char="5146">we</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="5148" end_char="5152">would</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="5154" end_char="5157">like</TOKEN>
<TOKEN id="token-97-4" pos="punct" morph="none" start_char="5158" end_char="5158">,</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="5160" end_char="5164">there</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="5166" end_char="5167">is</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="5169" end_char="5172">hope</TOKEN>
<TOKEN id="token-97-8" pos="punct" morph="none" start_char="5173" end_char="5173">.</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="5175" end_char="5176">In</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="5178" end_char="5182">First</TOKEN>
<TOKEN id="token-97-11" pos="word" morph="none" start_char="5184" end_char="5192">Unitarian</TOKEN>
<TOKEN id="token-97-12" pos="punct" morph="none" start_char="5193" end_char="5193">,</TOKEN>
<TOKEN id="token-97-13" pos="word" morph="none" start_char="5195" end_char="5199">Smith</TOKEN>
<TOKEN id="token-97-14" pos="punct" morph="none" start_char="5200" end_char="5200">,</TOKEN>
<TOKEN id="token-97-15" pos="word" morph="none" start_char="5202" end_char="5204">and</TOKEN>
<TOKEN id="token-97-16" pos="word" morph="none" start_char="5206" end_char="5210">Jewel</TOKEN>
<TOKEN id="token-97-17" pos="punct" morph="none" start_char="5211" end_char="5211">,</TOKEN>
<TOKEN id="token-97-18" pos="word" morph="none" start_char="5213" end_char="5215">EFF</TOKEN>
<TOKEN id="token-97-19" pos="word" morph="none" start_char="5217" end_char="5220">will</TOKEN>
</SEG>
<SEG id="segment-98" start_char="5222" end_char="5293">
<ORIGINAL_TEXT>continue to pursue our challenges to the government’s bulk collection of</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="5222" end_char="5229">continue</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="5231" end_char="5232">to</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="5234" end_char="5239">pursue</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="5241" end_char="5243">our</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="5245" end_char="5254">challenges</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="5256" end_char="5257">to</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="5259" end_char="5261">the</TOKEN>
<TOKEN id="token-98-7" pos="word" morph="none" start_char="5263" end_char="5272">government</TOKEN>
<TOKEN id="token-98-8" pos="punct" morph="none" start_char="5273" end_char="5273">’</TOKEN>
<TOKEN id="token-98-9" pos="word" morph="none" start_char="5274" end_char="5274">s</TOKEN>
<TOKEN id="token-98-10" pos="word" morph="none" start_char="5276" end_char="5279">bulk</TOKEN>
<TOKEN id="token-98-11" pos="word" morph="none" start_char="5281" end_char="5290">collection</TOKEN>
<TOKEN id="token-98-12" pos="word" morph="none" start_char="5292" end_char="5293">of</TOKEN>
</SEG>
<SEG id="segment-99" start_char="5295" end_char="5372">
<ORIGINAL_TEXT>telephone records as well as our other claims before these courts. The Clapper</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="5295" end_char="5303">telephone</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="5305" end_char="5311">records</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="5313" end_char="5314">as</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="5316" end_char="5319">well</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="5321" end_char="5322">as</TOKEN>
<TOKEN id="token-99-5" pos="word" morph="none" start_char="5324" end_char="5326">our</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="5328" end_char="5332">other</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="5334" end_char="5339">claims</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="5341" end_char="5346">before</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="5348" end_char="5352">these</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="5354" end_char="5359">courts</TOKEN>
<TOKEN id="token-99-11" pos="punct" morph="none" start_char="5360" end_char="5360">.</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="5362" end_char="5364">The</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="5366" end_char="5372">Clapper</TOKEN>
</SEG>
<SEG id="segment-100" start_char="5374" end_char="5448">
<ORIGINAL_TEXT>decision certainly provides a great starting point. The next step will be a</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="5374" end_char="5381">decision</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="5383" end_char="5391">certainly</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="5393" end_char="5400">provides</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="5402" end_char="5402">a</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="5404" end_char="5408">great</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="5410" end_char="5417">starting</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="5419" end_char="5423">point</TOKEN>
<TOKEN id="token-100-7" pos="punct" morph="none" start_char="5424" end_char="5424">.</TOKEN>
<TOKEN id="token-100-8" pos="word" morph="none" start_char="5426" end_char="5428">The</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="5430" end_char="5433">next</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="5435" end_char="5438">step</TOKEN>
<TOKEN id="token-100-11" pos="word" morph="none" start_char="5440" end_char="5443">will</TOKEN>
<TOKEN id="token-100-12" pos="word" morph="none" start_char="5445" end_char="5446">be</TOKEN>
<TOKEN id="token-100-13" pos="word" morph="none" start_char="5448" end_char="5448">a</TOKEN>
</SEG>
<SEG id="segment-101" start_char="5450" end_char="5525">
<ORIGINAL_TEXT>decision holding bulk collection to be unconstitutional under both the First</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="5450" end_char="5457">decision</TOKEN>
<TOKEN id="token-101-1" pos="word" morph="none" start_char="5459" end_char="5465">holding</TOKEN>
<TOKEN id="token-101-2" pos="word" morph="none" start_char="5467" end_char="5470">bulk</TOKEN>
<TOKEN id="token-101-3" pos="word" morph="none" start_char="5472" end_char="5481">collection</TOKEN>
<TOKEN id="token-101-4" pos="word" morph="none" start_char="5483" end_char="5484">to</TOKEN>
<TOKEN id="token-101-5" pos="word" morph="none" start_char="5486" end_char="5487">be</TOKEN>
<TOKEN id="token-101-6" pos="word" morph="none" start_char="5489" end_char="5504">unconstitutional</TOKEN>
<TOKEN id="token-101-7" pos="word" morph="none" start_char="5506" end_char="5510">under</TOKEN>
<TOKEN id="token-101-8" pos="word" morph="none" start_char="5512" end_char="5515">both</TOKEN>
<TOKEN id="token-101-9" pos="word" morph="none" start_char="5517" end_char="5519">the</TOKEN>
<TOKEN id="token-101-10" pos="word" morph="none" start_char="5521" end_char="5525">First</TOKEN>
</SEG>
<SEG id="segment-102" start_char="5527" end_char="5605">
<ORIGINAL_TEXT>and Fourth Amendments. Until then, EFF will continue our fight to ensure an end</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="5527" end_char="5529">and</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="5531" end_char="5536">Fourth</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="5538" end_char="5547">Amendments</TOKEN>
<TOKEN id="token-102-3" pos="punct" morph="none" start_char="5548" end_char="5548">.</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="5550" end_char="5554">Until</TOKEN>
<TOKEN id="token-102-5" pos="word" morph="none" start_char="5556" end_char="5559">then</TOKEN>
<TOKEN id="token-102-6" pos="punct" morph="none" start_char="5560" end_char="5560">,</TOKEN>
<TOKEN id="token-102-7" pos="word" morph="none" start_char="5562" end_char="5564">EFF</TOKEN>
<TOKEN id="token-102-8" pos="word" morph="none" start_char="5566" end_char="5569">will</TOKEN>
<TOKEN id="token-102-9" pos="word" morph="none" start_char="5571" end_char="5578">continue</TOKEN>
<TOKEN id="token-102-10" pos="word" morph="none" start_char="5580" end_char="5582">our</TOKEN>
<TOKEN id="token-102-11" pos="word" morph="none" start_char="5584" end_char="5588">fight</TOKEN>
<TOKEN id="token-102-12" pos="word" morph="none" start_char="5590" end_char="5591">to</TOKEN>
<TOKEN id="token-102-13" pos="word" morph="none" start_char="5593" end_char="5598">ensure</TOKEN>
<TOKEN id="token-102-14" pos="word" morph="none" start_char="5600" end_char="5601">an</TOKEN>
<TOKEN id="token-102-15" pos="word" morph="none" start_char="5603" end_char="5605">end</TOKEN>
</SEG>
<SEG id="segment-103" start_char="5607" end_char="5627">
<ORIGINAL_TEXT>to mass surveillance.</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="5607" end_char="5608">to</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="5610" end_char="5613">mass</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="5615" end_char="5626">surveillance</TOKEN>
<TOKEN id="token-103-3" pos="punct" morph="none" start_char="5627" end_char="5627">.</TOKEN>
</SEG>
<SEG id="segment-104" start_char="5629" end_char="5632">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="unknown" morph="none" start_char="5629" end_char="5632">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-105" start_char="5634" end_char="5640">
<ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="unknown" morph="none" start_char="5634" end_char="5640">&lt;/TEXT&gt;</TOKEN>
</SEG>
<SEG id="segment-106" start_char="5642" end_char="5647">
<ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="unknown" morph="none" start_char="5642" end_char="5647">&lt;/DOC&gt;</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
