<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="ENG_NW_001423_20150107_F0010006B.nw.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="5294" raw_text_md5="84c050037c6798f00d0cc052fff0ff22">
<TEXT>
<SEG id="segment-0" start_char="0" end_char="37">
<ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
<TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
<TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
</SEG>
<SEG id="segment-1" start_char="39" end_char="81">
<ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001423_20150107_F0010006B"&gt;</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
<TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001423_20150107_F0010006B"&gt;</TOKEN>
</SEG>
<SEG id="segment-2" start_char="83" end_char="224">
<ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.slate.com/blogs/browbeat/2015/01/07/the_french_cartoonists_killed_at_charlie_hebdo_wolinski_charb_tignous_and.html&lt;/SOURCE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="224">&lt;SOURCE&gt;http://www.slate.com/blogs/browbeat/2015/01/07/the_french_cartoonists_killed_at_charlie_hebdo_wolinski_charb_tignous_and.html&lt;/SOURCE&gt;</TOKEN>
</SEG>
<SEG id="segment-3" start_char="226" end_char="267">
<ORIGINAL_TEXT>&lt;DATE_TIME&gt;2015-01-07T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="unknown" morph="none" start_char="226" end_char="267">&lt;DATE_TIME&gt;2015-01-07T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
</SEG>
<SEG id="segment-4" start_char="269" end_char="278">
<ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="unknown" morph="none" start_char="269" end_char="278">&lt;HEADLINE&gt;</TOKEN>
</SEG>
<SEG id="segment-5" start_char="280" end_char="321">
<ORIGINAL_TEXT>What It Means to Be a Cartoonist in France</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="280" end_char="283">What</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="285" end_char="286">It</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="288" end_char="292">Means</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="294" end_char="295">to</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="297" end_char="298">Be</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="300" end_char="300">a</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="302" end_char="311">Cartoonist</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="313" end_char="314">in</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="316" end_char="321">France</TOKEN>
</SEG>
<SEG id="segment-6" start_char="323" end_char="333">
<ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="unknown" morph="none" start_char="323" end_char="333">&lt;/HEADLINE&gt;</TOKEN>
</SEG>
<SEG id="segment-7" start_char="335" end_char="340">
<ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="unknown" morph="none" start_char="335" end_char="340">&lt;TEXT&gt;</TOKEN>
</SEG>
<SEG id="segment-8" start_char="342" end_char="344">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="unknown" morph="none" start_char="342" end_char="344">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-9" start_char="346" end_char="422">
<ORIGINAL_TEXT>The largest European gathering of comics professionals and fans, the Festival</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="346" end_char="348">The</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="350" end_char="356">largest</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="358" end_char="365">European</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="367" end_char="375">gathering</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="377" end_char="378">of</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="380" end_char="385">comics</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="387" end_char="399">professionals</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="401" end_char="403">and</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="405" end_char="408">fans</TOKEN>
<TOKEN id="token-9-9" pos="punct" morph="none" start_char="409" end_char="409">,</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="411" end_char="413">the</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="415" end_char="422">Festival</TOKEN>
</SEG>
<SEG id="segment-10" start_char="424" end_char="499">
<ORIGINAL_TEXT>International de la Bande Dessinée, has taken place at the end of January in</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="424" end_char="436">International</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="438" end_char="439">de</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="441" end_char="442">la</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="444" end_char="448">Bande</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="450" end_char="457">Dessinée</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="458" end_char="458">,</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="460" end_char="462">has</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="464" end_char="468">taken</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="470" end_char="474">place</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="476" end_char="477">at</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="479" end_char="481">the</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="483" end_char="485">end</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="487" end_char="488">of</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="490" end_char="496">January</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="498" end_char="499">in</TOKEN>
</SEG>
<SEG id="segment-11" start_char="501" end_char="576">
<ORIGINAL_TEXT>the small southwestern French town of Angoulême for 42 years. In contrast to</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="501" end_char="503">the</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="505" end_char="509">small</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="511" end_char="522">southwestern</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="524" end_char="529">French</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="531" end_char="534">town</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="536" end_char="537">of</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="539" end_char="547">Angoulême</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="549" end_char="551">for</TOKEN>
<TOKEN id="token-11-8" pos="number" morph="none" start_char="553" end_char="554">42</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="556" end_char="560">years</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="561" end_char="561">.</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="563" end_char="564">In</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="566" end_char="573">contrast</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="575" end_char="576">to</TOKEN>
</SEG>
<SEG id="segment-12" start_char="578" end_char="651">
<ORIGINAL_TEXT>American comic book conventions like Comic Con International in San Diego,</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="578" end_char="585">American</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="587" end_char="591">comic</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="593" end_char="596">book</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="598" end_char="608">conventions</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="610" end_char="613">like</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="615" end_char="619">Comic</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="621" end_char="623">Con</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="625" end_char="637">International</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="639" end_char="640">in</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="642" end_char="644">San</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="646" end_char="650">Diego</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="651" end_char="651">,</TOKEN>
</SEG>
<SEG id="segment-13" start_char="653" end_char="729">
<ORIGINAL_TEXT>which are dominated by celebrity appearances and announcements of forthcoming</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="653" end_char="657">which</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="659" end_char="661">are</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="663" end_char="671">dominated</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="673" end_char="674">by</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="676" end_char="684">celebrity</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="686" end_char="696">appearances</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="698" end_char="700">and</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="702" end_char="714">announcements</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="716" end_char="717">of</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="719" end_char="729">forthcoming</TOKEN>
</SEG>
<SEG id="segment-14" start_char="731" end_char="808">
<ORIGINAL_TEXT>Hollywood blockbusters, Angoulême still places its emphasis on the cartoonists</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="731" end_char="739">Hollywood</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="741" end_char="752">blockbusters</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="753" end_char="753">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="755" end_char="763">Angoulême</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="765" end_char="769">still</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="771" end_char="776">places</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="778" end_char="780">its</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="782" end_char="789">emphasis</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="791" end_char="792">on</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="794" end_char="796">the</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="798" end_char="808">cartoonists</TOKEN>
</SEG>
<SEG id="segment-15" start_char="810" end_char="887">
<ORIGINAL_TEXT>who come to meet their public. The annual Sunday highlight is the announcement</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="810" end_char="812">who</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="814" end_char="817">come</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="819" end_char="820">to</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="822" end_char="825">meet</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="827" end_char="831">their</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="833" end_char="838">public</TOKEN>
<TOKEN id="token-15-6" pos="punct" morph="none" start_char="839" end_char="839">.</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="841" end_char="843">The</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="845" end_char="850">annual</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="852" end_char="857">Sunday</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="859" end_char="867">highlight</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="869" end_char="870">is</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="872" end_char="874">the</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="876" end_char="887">announcement</TOKEN>
</SEG>
<SEG id="segment-16" start_char="889" end_char="964">
<ORIGINAL_TEXT>of the new Grand Prix de la ville d’Angoulême, the honorary president of the</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="889" end_char="890">of</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="892" end_char="894">the</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="896" end_char="898">new</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="900" end_char="904">Grand</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="906" end_char="909">Prix</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="911" end_char="912">de</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="914" end_char="915">la</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="917" end_char="921">ville</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="923" end_char="923">d</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="924" end_char="924">’</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="925" end_char="933">Angoulême</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="934" end_char="934">,</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="936" end_char="938">the</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="940" end_char="947">honorary</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="949" end_char="957">president</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="959" end_char="960">of</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="962" end_char="964">the</TOKEN>
</SEG>
<SEG id="segment-17" start_char="966" end_char="1033">
<ORIGINAL_TEXT>next Festival, whose career is fêted the following year with a major</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="966" end_char="969">next</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="971" end_char="978">Festival</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="979" end_char="979">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="981" end_char="985">whose</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="987" end_char="992">career</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="994" end_char="995">is</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="997" end_char="1001">fêted</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1003" end_char="1005">the</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1007" end_char="1015">following</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1017" end_char="1020">year</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1022" end_char="1025">with</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1027" end_char="1027">a</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1029" end_char="1033">major</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1035" end_char="1103">
<ORIGINAL_TEXT>retrospective. This is the highest recognition that can be afforded a</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1035" end_char="1047">retrospective</TOKEN>
<TOKEN id="token-18-1" pos="punct" morph="none" start_char="1048" end_char="1048">.</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1050" end_char="1053">This</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1055" end_char="1056">is</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1058" end_char="1060">the</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1062" end_char="1068">highest</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1070" end_char="1080">recognition</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1082" end_char="1085">that</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1087" end_char="1089">can</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1091" end_char="1092">be</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1094" end_char="1101">afforded</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1103" end_char="1103">a</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1105" end_char="1183">
<ORIGINAL_TEXT>cartoonist in France. Wednesday morning, the 2005 winner of this prize, Georges</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1105" end_char="1114">cartoonist</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1116" end_char="1117">in</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1119" end_char="1124">France</TOKEN>
<TOKEN id="token-19-3" pos="punct" morph="none" start_char="1125" end_char="1125">.</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1127" end_char="1135">Wednesday</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1137" end_char="1143">morning</TOKEN>
<TOKEN id="token-19-6" pos="punct" morph="none" start_char="1144" end_char="1144">,</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1146" end_char="1148">the</TOKEN>
<TOKEN id="token-19-8" pos="number" morph="none" start_char="1150" end_char="1153">2005</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1155" end_char="1160">winner</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1162" end_char="1163">of</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1165" end_char="1168">this</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1170" end_char="1174">prize</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="1175" end_char="1175">,</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1177" end_char="1183">Georges</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1185" end_char="1259">
<ORIGINAL_TEXT>Wolinski, was one of four cartoonists killed in a terrorist attack in Paris</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1185" end_char="1192">Wolinski</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="1193" end_char="1193">,</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1195" end_char="1197">was</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1199" end_char="1201">one</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1203" end_char="1204">of</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1206" end_char="1209">four</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1211" end_char="1221">cartoonists</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1223" end_char="1228">killed</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="1230" end_char="1231">in</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1233" end_char="1233">a</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1235" end_char="1243">terrorist</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1245" end_char="1250">attack</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="1252" end_char="1253">in</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1255" end_char="1259">Paris</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1261" end_char="1291">
<ORIGINAL_TEXT>that claimed at least 12 lives.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1261" end_char="1264">that</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1266" end_char="1272">claimed</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1274" end_char="1275">at</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1277" end_char="1281">least</TOKEN>
<TOKEN id="token-21-4" pos="number" morph="none" start_char="1283" end_char="1284">12</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="1286" end_char="1290">lives</TOKEN>
<TOKEN id="token-21-6" pos="punct" morph="none" start_char="1291" end_char="1291">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1293" end_char="1296">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="unknown" morph="none" start_char="1293" end_char="1296">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1298" end_char="1300">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="unknown" morph="none" start_char="1298" end_char="1300">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1302" end_char="1373">
<ORIGINAL_TEXT>As Joshua Keating has noted already today, Charlie Hebdo was born out of</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1302" end_char="1303">As</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1305" end_char="1310">Joshua</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1312" end_char="1318">Keating</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1320" end_char="1322">has</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="1324" end_char="1328">noted</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="1330" end_char="1336">already</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="1338" end_char="1342">today</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="1343" end_char="1343">,</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="1345" end_char="1351">Charlie</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="1353" end_char="1357">Hebdo</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="1359" end_char="1361">was</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="1363" end_char="1366">born</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="1368" end_char="1370">out</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="1372" end_char="1373">of</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1375" end_char="1453">
<ORIGINAL_TEXT>controversy, and has long engaged with confrontational images of all times. The</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="1375" end_char="1385">controversy</TOKEN>
<TOKEN id="token-25-1" pos="punct" morph="none" start_char="1386" end_char="1386">,</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="1388" end_char="1390">and</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="1392" end_char="1394">has</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="1396" end_char="1399">long</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="1401" end_char="1407">engaged</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="1409" end_char="1412">with</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="1414" end_char="1428">confrontational</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="1430" end_char="1435">images</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="1437" end_char="1438">of</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="1440" end_char="1442">all</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="1444" end_char="1448">times</TOKEN>
<TOKEN id="token-25-12" pos="punct" morph="none" start_char="1449" end_char="1449">.</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="1451" end_char="1453">The</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1455" end_char="1531">
<ORIGINAL_TEXT>magazine was resolutely satirical, attacking all comers in the name of humor.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1455" end_char="1462">magazine</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="1464" end_char="1466">was</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="1468" end_char="1477">resolutely</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="1479" end_char="1487">satirical</TOKEN>
<TOKEN id="token-26-4" pos="punct" morph="none" start_char="1488" end_char="1488">,</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="1490" end_char="1498">attacking</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="1500" end_char="1502">all</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="1504" end_char="1509">comers</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="1511" end_char="1512">in</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="1514" end_char="1516">the</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="1518" end_char="1521">name</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="1523" end_char="1524">of</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="1526" end_char="1530">humor</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="1531" end_char="1531">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="1533" end_char="1609">
<ORIGINAL_TEXT>France, of course, has a strong tradition of political satire that dates back</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="1533" end_char="1538">France</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="1539" end_char="1539">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="1541" end_char="1542">of</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="1544" end_char="1549">course</TOKEN>
<TOKEN id="token-27-4" pos="punct" morph="none" start_char="1550" end_char="1550">,</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="1552" end_char="1554">has</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="1556" end_char="1556">a</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="1558" end_char="1563">strong</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="1565" end_char="1573">tradition</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="1575" end_char="1576">of</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="1578" end_char="1586">political</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="1588" end_char="1593">satire</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="1595" end_char="1598">that</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="1600" end_char="1604">dates</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="1606" end_char="1609">back</TOKEN>
</SEG>
<SEG id="segment-28" start_char="1611" end_char="1681">
<ORIGINAL_TEXT>centuries. Honoré Daumier was imprisoned for six months in 1832 for his</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="1611" end_char="1619">centuries</TOKEN>
<TOKEN id="token-28-1" pos="punct" morph="none" start_char="1620" end_char="1620">.</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="1622" end_char="1627">Honoré</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="1629" end_char="1635">Daumier</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="1637" end_char="1639">was</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="1641" end_char="1650">imprisoned</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="1652" end_char="1654">for</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="1656" end_char="1658">six</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="1660" end_char="1665">months</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="1667" end_char="1668">in</TOKEN>
<TOKEN id="token-28-10" pos="number" morph="none" start_char="1670" end_char="1673">1832</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="1675" end_char="1677">for</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="1679" end_char="1681">his</TOKEN>
</SEG>
<SEG id="segment-29" start_char="1683" end_char="1760">
<ORIGINAL_TEXT>depiction of King Louis Philippe as Gargantua, and his later image of the king</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="1683" end_char="1691">depiction</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="1693" end_char="1694">of</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="1696" end_char="1699">King</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="1701" end_char="1705">Louis</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="1707" end_char="1714">Philippe</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="1716" end_char="1717">as</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="1719" end_char="1727">Gargantua</TOKEN>
<TOKEN id="token-29-7" pos="punct" morph="none" start_char="1728" end_char="1728">,</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="1730" end_char="1732">and</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="1734" end_char="1736">his</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="1738" end_char="1742">later</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="1744" end_char="1748">image</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="1750" end_char="1751">of</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="1753" end_char="1755">the</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="1757" end_char="1760">king</TOKEN>
</SEG>
<SEG id="segment-30" start_char="1762" end_char="1836">
<ORIGINAL_TEXT>with the head of a pear is one of the most famous illustrations of the 19th</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="1762" end_char="1765">with</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="1767" end_char="1769">the</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="1771" end_char="1774">head</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="1776" end_char="1777">of</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="1779" end_char="1779">a</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="1781" end_char="1784">pear</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="1786" end_char="1787">is</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="1789" end_char="1791">one</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="1793" end_char="1794">of</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="1796" end_char="1798">the</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="1800" end_char="1803">most</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="1805" end_char="1810">famous</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="1812" end_char="1824">illustrations</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="1826" end_char="1827">of</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="1829" end_char="1831">the</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="1833" end_char="1836">19th</TOKEN>
</SEG>
<SEG id="segment-31" start_char="1838" end_char="1915">
<ORIGINAL_TEXT>century. Yet it is not only the tradition of satire that is revered in France;</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="1838" end_char="1844">century</TOKEN>
<TOKEN id="token-31-1" pos="punct" morph="none" start_char="1845" end_char="1845">.</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="1847" end_char="1849">Yet</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="1851" end_char="1852">it</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="1854" end_char="1855">is</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="1857" end_char="1859">not</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="1861" end_char="1864">only</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="1866" end_char="1868">the</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="1870" end_char="1878">tradition</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="1880" end_char="1881">of</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="1883" end_char="1888">satire</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="1890" end_char="1893">that</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="1895" end_char="1896">is</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="1898" end_char="1904">revered</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="1906" end_char="1907">in</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="1909" end_char="1914">France</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="1915" end_char="1915">;</TOKEN>
</SEG>
<SEG id="segment-32" start_char="1917" end_char="1938">
<ORIGINAL_TEXT>it is also cartooning.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="1917" end_char="1918">it</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="1920" end_char="1921">is</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="1923" end_char="1926">also</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="1928" end_char="1937">cartooning</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="1938" end_char="1938">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="1940" end_char="1943">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="unknown" morph="none" start_char="1940" end_char="1943">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-34" start_char="1945" end_char="1947">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="unknown" morph="none" start_char="1945" end_char="1947">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-35" start_char="1949" end_char="2023">
<ORIGINAL_TEXT>Unlike in the United States, where comic strips, comic books, and editorial</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="1949" end_char="1954">Unlike</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="1956" end_char="1957">in</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="1959" end_char="1961">the</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="1963" end_char="1968">United</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="1970" end_char="1975">States</TOKEN>
<TOKEN id="token-35-5" pos="punct" morph="none" start_char="1976" end_char="1976">,</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="1978" end_char="1982">where</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="1984" end_char="1988">comic</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="1990" end_char="1995">strips</TOKEN>
<TOKEN id="token-35-9" pos="punct" morph="none" start_char="1996" end_char="1996">,</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="1998" end_char="2002">comic</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="2004" end_char="2008">books</TOKEN>
<TOKEN id="token-35-12" pos="punct" morph="none" start_char="2009" end_char="2009">,</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="2011" end_char="2013">and</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="2015" end_char="2023">editorial</TOKEN>
</SEG>
<SEG id="segment-36" start_char="2025" end_char="2103">
<ORIGINAL_TEXT>cartoons are generally regarded as only distantly related wings of the same art</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="2025" end_char="2032">cartoons</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="2034" end_char="2036">are</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="2038" end_char="2046">generally</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="2048" end_char="2055">regarded</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="2057" end_char="2058">as</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="2060" end_char="2063">only</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="2065" end_char="2073">distantly</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="2075" end_char="2081">related</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="2083" end_char="2087">wings</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="2089" end_char="2090">of</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="2092" end_char="2094">the</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="2096" end_char="2099">same</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="2101" end_char="2103">art</TOKEN>
</SEG>
<SEG id="segment-37" start_char="2105" end_char="2181">
<ORIGINAL_TEXT>form, in France the integration of the three is much closer. Each of the four</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="2105" end_char="2108">form</TOKEN>
<TOKEN id="token-37-1" pos="punct" morph="none" start_char="2109" end_char="2109">,</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="2111" end_char="2112">in</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="2114" end_char="2119">France</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="2121" end_char="2123">the</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="2125" end_char="2135">integration</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="2137" end_char="2138">of</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="2140" end_char="2142">the</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="2144" end_char="2148">three</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="2150" end_char="2151">is</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="2153" end_char="2156">much</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="2158" end_char="2163">closer</TOKEN>
<TOKEN id="token-37-12" pos="punct" morph="none" start_char="2164" end_char="2164">.</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="2166" end_char="2169">Each</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="2171" end_char="2172">of</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="2174" end_char="2176">the</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="2178" end_char="2181">four</TOKEN>
</SEG>
<SEG id="segment-38" start_char="2183" end_char="2255">
<ORIGINAL_TEXT>cartoonists killed today worked not only for Charlie Hebdo, but for other</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="2183" end_char="2193">cartoonists</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="2195" end_char="2200">killed</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="2202" end_char="2206">today</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="2208" end_char="2213">worked</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="2215" end_char="2217">not</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="2219" end_char="2222">only</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="2224" end_char="2226">for</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="2228" end_char="2234">Charlie</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="2236" end_char="2240">Hebdo</TOKEN>
<TOKEN id="token-38-9" pos="punct" morph="none" start_char="2241" end_char="2241">,</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="2243" end_char="2245">but</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="2247" end_char="2249">for</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="2251" end_char="2255">other</TOKEN>
</SEG>
<SEG id="segment-39" start_char="2257" end_char="2332">
<ORIGINAL_TEXT>newspapers, and for French comic book publishers. The publishing industry in</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="2257" end_char="2266">newspapers</TOKEN>
<TOKEN id="token-39-1" pos="punct" morph="none" start_char="2267" end_char="2267">,</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="2269" end_char="2271">and</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="2273" end_char="2275">for</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="2277" end_char="2282">French</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="2284" end_char="2288">comic</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="2290" end_char="2293">book</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="2295" end_char="2304">publishers</TOKEN>
<TOKEN id="token-39-8" pos="punct" morph="none" start_char="2305" end_char="2305">.</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="2307" end_char="2309">The</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="2311" end_char="2320">publishing</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="2322" end_char="2329">industry</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="2331" end_char="2332">in</TOKEN>
</SEG>
<SEG id="segment-40" start_char="2334" end_char="2410">
<ORIGINAL_TEXT>France is both smaller and more central than it is in the United States. With</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="2334" end_char="2339">France</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="2341" end_char="2342">is</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="2344" end_char="2347">both</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="2349" end_char="2355">smaller</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="2357" end_char="2359">and</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="2361" end_char="2364">more</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="2366" end_char="2372">central</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="2374" end_char="2377">than</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="2379" end_char="2380">it</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="2382" end_char="2383">is</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="2385" end_char="2386">in</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="2388" end_char="2390">the</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="2392" end_char="2397">United</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="2399" end_char="2404">States</TOKEN>
<TOKEN id="token-40-14" pos="punct" morph="none" start_char="2405" end_char="2405">.</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="2407" end_char="2410">With</TOKEN>
</SEG>
<SEG id="segment-41" start_char="2412" end_char="2488">
<ORIGINAL_TEXT>so many cartoonists living in and around Paris, the overlap between different</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="2412" end_char="2413">so</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="2415" end_char="2418">many</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="2420" end_char="2430">cartoonists</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="2432" end_char="2437">living</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="2439" end_char="2440">in</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="2442" end_char="2444">and</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="2446" end_char="2451">around</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="2453" end_char="2457">Paris</TOKEN>
<TOKEN id="token-41-8" pos="punct" morph="none" start_char="2458" end_char="2458">,</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="2460" end_char="2462">the</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="2464" end_char="2470">overlap</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="2472" end_char="2478">between</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="2480" end_char="2488">different</TOKEN>
</SEG>
<SEG id="segment-42" start_char="2490" end_char="2565">
<ORIGINAL_TEXT>media are quickly eroded in a context where it can sometimes seem that every</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="2490" end_char="2494">media</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="2496" end_char="2498">are</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="2500" end_char="2506">quickly</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="2508" end_char="2513">eroded</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="2515" end_char="2516">in</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="2518" end_char="2518">a</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="2520" end_char="2526">context</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="2528" end_char="2532">where</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="2534" end_char="2535">it</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="2537" end_char="2539">can</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="2541" end_char="2549">sometimes</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="2551" end_char="2554">seem</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="2556" end_char="2559">that</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="2561" end_char="2565">every</TOKEN>
</SEG>
<SEG id="segment-43" start_char="2567" end_char="2645">
<ORIGINAL_TEXT>working cartoonist knows every other one and works across publishing platforms.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="2567" end_char="2573">working</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="2575" end_char="2584">cartoonist</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="2586" end_char="2590">knows</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="2592" end_char="2596">every</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="2598" end_char="2602">other</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="2604" end_char="2606">one</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="2608" end_char="2610">and</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="2612" end_char="2616">works</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="2618" end_char="2623">across</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="2625" end_char="2634">publishing</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="2636" end_char="2644">platforms</TOKEN>
<TOKEN id="token-43-11" pos="punct" morph="none" start_char="2645" end_char="2645">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="2647" end_char="2650">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="unknown" morph="none" start_char="2647" end_char="2650">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-45" start_char="2652" end_char="2654">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="unknown" morph="none" start_char="2652" end_char="2654">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-46" start_char="2656" end_char="2732">
<ORIGINAL_TEXT>Wolinski’s career was symptomatic: He published comics in the daily newspaper</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="2656" end_char="2663">Wolinski</TOKEN>
<TOKEN id="token-46-1" pos="punct" morph="none" start_char="2664" end_char="2664">’</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="2665" end_char="2665">s</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="2667" end_char="2672">career</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="2674" end_char="2676">was</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="2678" end_char="2688">symptomatic</TOKEN>
<TOKEN id="token-46-6" pos="punct" morph="none" start_char="2689" end_char="2689">:</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="2691" end_char="2692">He</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="2694" end_char="2702">published</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="2704" end_char="2709">comics</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="2711" end_char="2712">in</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="2714" end_char="2716">the</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="2718" end_char="2722">daily</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="2724" end_char="2732">newspaper</TOKEN>
</SEG>
<SEG id="segment-47" start_char="2734" end_char="2807">
<ORIGINAL_TEXT>Libération, the weeklies Charlie Hebdo and Paris-Match, and authored, with</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="2734" end_char="2743">Libération</TOKEN>
<TOKEN id="token-47-1" pos="punct" morph="none" start_char="2744" end_char="2744">,</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="2746" end_char="2748">the</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="2750" end_char="2757">weeklies</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="2759" end_char="2765">Charlie</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="2767" end_char="2771">Hebdo</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="2773" end_char="2775">and</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="2777" end_char="2781">Paris</TOKEN>
<TOKEN id="token-47-8" pos="punct" morph="none" start_char="2782" end_char="2782">-</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="2783" end_char="2787">Match</TOKEN>
<TOKEN id="token-47-10" pos="punct" morph="none" start_char="2788" end_char="2788">,</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="2790" end_char="2792">and</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="2794" end_char="2801">authored</TOKEN>
<TOKEN id="token-47-13" pos="punct" morph="none" start_char="2802" end_char="2802">,</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="2804" end_char="2807">with</TOKEN>
</SEG>
<SEG id="segment-48" start_char="2809" end_char="2879">
<ORIGINAL_TEXT>artist Georges Pichard, the comic book series Paulette. The other three</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="2809" end_char="2814">artist</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="2816" end_char="2822">Georges</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="2824" end_char="2830">Pichard</TOKEN>
<TOKEN id="token-48-3" pos="punct" morph="none" start_char="2831" end_char="2831">,</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="2833" end_char="2835">the</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="2837" end_char="2841">comic</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="2843" end_char="2846">book</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="2848" end_char="2853">series</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="2855" end_char="2862">Paulette</TOKEN>
<TOKEN id="token-48-9" pos="punct" morph="none" start_char="2863" end_char="2863">.</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="2865" end_char="2867">The</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="2869" end_char="2873">other</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="2875" end_char="2879">three</TOKEN>
</SEG>
<SEG id="segment-49" start_char="2881" end_char="2950">
<ORIGINAL_TEXT>cartoonists slain today, Stephane Charbonnier (Charb), Bernard Verlhac</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="2881" end_char="2891">cartoonists</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="2893" end_char="2897">slain</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="2899" end_char="2903">today</TOKEN>
<TOKEN id="token-49-3" pos="punct" morph="none" start_char="2904" end_char="2904">,</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="2906" end_char="2913">Stephane</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="2915" end_char="2925">Charbonnier</TOKEN>
<TOKEN id="token-49-6" pos="punct" morph="none" start_char="2927" end_char="2927">(</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="2928" end_char="2932">Charb</TOKEN>
<TOKEN id="token-49-8" pos="punct" morph="none" start_char="2933" end_char="2934">),</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="2936" end_char="2942">Bernard</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="2944" end_char="2950">Verlhac</TOKEN>
</SEG>
<SEG id="segment-50" start_char="2952" end_char="3027">
<ORIGINAL_TEXT>(Tignous), and Jean Cabut (Cabu), had similarly broad profiles. Cabu, one of</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="punct" morph="none" start_char="2952" end_char="2952">(</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="2953" end_char="2959">Tignous</TOKEN>
<TOKEN id="token-50-2" pos="punct" morph="none" start_char="2960" end_char="2961">),</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="2963" end_char="2965">and</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="2967" end_char="2970">Jean</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="2972" end_char="2976">Cabut</TOKEN>
<TOKEN id="token-50-6" pos="punct" morph="none" start_char="2978" end_char="2978">(</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="2979" end_char="2982">Cabu</TOKEN>
<TOKEN id="token-50-8" pos="punct" morph="none" start_char="2983" end_char="2984">),</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="2986" end_char="2988">had</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="2990" end_char="2998">similarly</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="3000" end_char="3004">broad</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="3006" end_char="3013">profiles</TOKEN>
<TOKEN id="token-50-13" pos="punct" morph="none" start_char="3014" end_char="3014">.</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="3016" end_char="3019">Cabu</TOKEN>
<TOKEN id="token-50-15" pos="punct" morph="none" start_char="3020" end_char="3020">,</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="3022" end_char="3024">one</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="3026" end_char="3027">of</TOKEN>
</SEG>
<SEG id="segment-51" start_char="3029" end_char="3107">
<ORIGINAL_TEXT>the founders of Hara-Kiri, the fore-runner of Charlie Hebdo, was the creator of</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="3029" end_char="3031">the</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="3033" end_char="3040">founders</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="3042" end_char="3043">of</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="3045" end_char="3048">Hara</TOKEN>
<TOKEN id="token-51-4" pos="punct" morph="none" start_char="3049" end_char="3049">-</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="3050" end_char="3053">Kiri</TOKEN>
<TOKEN id="token-51-6" pos="punct" morph="none" start_char="3054" end_char="3054">,</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="3056" end_char="3058">the</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="3060" end_char="3063">fore</TOKEN>
<TOKEN id="token-51-9" pos="punct" morph="none" start_char="3064" end_char="3064">-</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="3065" end_char="3070">runner</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="3072" end_char="3073">of</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="3075" end_char="3081">Charlie</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="3083" end_char="3087">Hebdo</TOKEN>
<TOKEN id="token-51-14" pos="punct" morph="none" start_char="3088" end_char="3088">,</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="3090" end_char="3092">was</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="3094" end_char="3096">the</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="3098" end_char="3104">creator</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="3106" end_char="3107">of</TOKEN>
</SEG>
<SEG id="segment-52" start_char="3109" end_char="3185">
<ORIGINAL_TEXT>dozens of comic books, including the long-running series Le grand Duduche. In</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="3109" end_char="3114">dozens</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="3116" end_char="3117">of</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="3119" end_char="3123">comic</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="3125" end_char="3129">books</TOKEN>
<TOKEN id="token-52-4" pos="punct" morph="none" start_char="3130" end_char="3130">,</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="3132" end_char="3140">including</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="3142" end_char="3144">the</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="3146" end_char="3149">long</TOKEN>
<TOKEN id="token-52-8" pos="punct" morph="none" start_char="3150" end_char="3150">-</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="3151" end_char="3157">running</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="3159" end_char="3164">series</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="3166" end_char="3167">Le</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="3169" end_char="3173">grand</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="3175" end_char="3181">Duduche</TOKEN>
<TOKEN id="token-52-14" pos="punct" morph="none" start_char="3182" end_char="3182">.</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="3184" end_char="3185">In</TOKEN>
</SEG>
<SEG id="segment-53" start_char="3187" end_char="3264">
<ORIGINAL_TEXT>2006 he drew the cover illustration when Charlie Hebdo ran the Danish Mohammad</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="number" morph="none" start_char="3187" end_char="3190">2006</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="3192" end_char="3193">he</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="3195" end_char="3198">drew</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="3200" end_char="3202">the</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="3204" end_char="3208">cover</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="3210" end_char="3221">illustration</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="3223" end_char="3226">when</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="3228" end_char="3234">Charlie</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="3236" end_char="3240">Hebdo</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="3242" end_char="3244">ran</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="3246" end_char="3248">the</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="3250" end_char="3255">Danish</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="3257" end_char="3264">Mohammad</TOKEN>
</SEG>
<SEG id="segment-54" start_char="3266" end_char="3339">
<ORIGINAL_TEXT>cartoons. Tignous worked as an illustrator, and he was the author of eight</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="3266" end_char="3273">cartoons</TOKEN>
<TOKEN id="token-54-1" pos="punct" morph="none" start_char="3274" end_char="3274">.</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="3276" end_char="3282">Tignous</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="3284" end_char="3289">worked</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="3291" end_char="3292">as</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="3294" end_char="3295">an</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="3297" end_char="3307">illustrator</TOKEN>
<TOKEN id="token-54-7" pos="punct" morph="none" start_char="3308" end_char="3308">,</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="3310" end_char="3312">and</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="3314" end_char="3315">he</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="3317" end_char="3319">was</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="3321" end_char="3323">the</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="3325" end_char="3330">author</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="3332" end_char="3333">of</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="3335" end_char="3339">eight</TOKEN>
</SEG>
<SEG id="segment-55" start_char="3341" end_char="3417">
<ORIGINAL_TEXT>comic books. Charb, who was the magazine’s editor since 2009, authored dozens</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="3341" end_char="3345">comic</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="3347" end_char="3351">books</TOKEN>
<TOKEN id="token-55-2" pos="punct" morph="none" start_char="3352" end_char="3352">.</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="3354" end_char="3358">Charb</TOKEN>
<TOKEN id="token-55-4" pos="punct" morph="none" start_char="3359" end_char="3359">,</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="3361" end_char="3363">who</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="3365" end_char="3367">was</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="3369" end_char="3371">the</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="3373" end_char="3380">magazine</TOKEN>
<TOKEN id="token-55-9" pos="punct" morph="none" start_char="3381" end_char="3381">’</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="3382" end_char="3382">s</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="3384" end_char="3389">editor</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="3391" end_char="3395">since</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="3397" end_char="3400">2009</TOKEN>
<TOKEN id="token-55-14" pos="punct" morph="none" start_char="3401" end_char="3401">,</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="3403" end_char="3410">authored</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="3412" end_char="3417">dozens</TOKEN>
</SEG>
<SEG id="segment-56" start_char="3419" end_char="3491">
<ORIGINAL_TEXT>of left-wing comic books and contributed to the well-known humor magazine</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="3419" end_char="3420">of</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="3422" end_char="3425">left</TOKEN>
<TOKEN id="token-56-2" pos="punct" morph="none" start_char="3426" end_char="3426">-</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="3427" end_char="3430">wing</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="3432" end_char="3436">comic</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="3438" end_char="3442">books</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="3444" end_char="3446">and</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="3448" end_char="3458">contributed</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="3460" end_char="3461">to</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="3463" end_char="3465">the</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="3467" end_char="3470">well</TOKEN>
<TOKEN id="token-56-11" pos="punct" morph="none" start_char="3471" end_char="3471">-</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="3472" end_char="3476">known</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="3478" end_char="3482">humor</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="3484" end_char="3491">magazine</TOKEN>
</SEG>
<SEG id="segment-57" start_char="3493" end_char="3553">
<ORIGINAL_TEXT>Fluide Glacial and the communist daily newspaper, L’Humanité.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="3493" end_char="3498">Fluide</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="3500" end_char="3506">Glacial</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="3508" end_char="3510">and</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="3512" end_char="3514">the</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="3516" end_char="3524">communist</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="3526" end_char="3530">daily</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="3532" end_char="3540">newspaper</TOKEN>
<TOKEN id="token-57-7" pos="punct" morph="none" start_char="3541" end_char="3541">,</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="3543" end_char="3543">L</TOKEN>
<TOKEN id="token-57-9" pos="punct" morph="none" start_char="3544" end_char="3544">’</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="3545" end_char="3552">Humanité</TOKEN>
<TOKEN id="token-57-11" pos="punct" morph="none" start_char="3553" end_char="3553">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="3555" end_char="3558">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="unknown" morph="none" start_char="3555" end_char="3558">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-59" start_char="3560" end_char="3562">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="unknown" morph="none" start_char="3560" end_char="3562">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-60" start_char="3564" end_char="3641">
<ORIGINAL_TEXT>It’s a durable myth, especially among American cartoonists, that France is the</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="3564" end_char="3565">It</TOKEN>
<TOKEN id="token-60-1" pos="punct" morph="none" start_char="3566" end_char="3566">’</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="3567" end_char="3567">s</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="3569" end_char="3569">a</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="3571" end_char="3577">durable</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="3579" end_char="3582">myth</TOKEN>
<TOKEN id="token-60-6" pos="punct" morph="none" start_char="3583" end_char="3583">,</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="3585" end_char="3594">especially</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="3596" end_char="3600">among</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="3602" end_char="3609">American</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="3611" end_char="3621">cartoonists</TOKEN>
<TOKEN id="token-60-11" pos="punct" morph="none" start_char="3622" end_char="3622">,</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="3624" end_char="3627">that</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="3629" end_char="3634">France</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="3636" end_char="3637">is</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="3639" end_char="3641">the</TOKEN>
</SEG>
<SEG id="segment-61" start_char="3643" end_char="3718">
<ORIGINAL_TEXT>place where comics are given the respect they rarely get on this side of the</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="3643" end_char="3647">place</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="3649" end_char="3653">where</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="3655" end_char="3660">comics</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="3662" end_char="3664">are</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="3666" end_char="3670">given</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="3672" end_char="3674">the</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="3676" end_char="3682">respect</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="3684" end_char="3687">they</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="3689" end_char="3694">rarely</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="3696" end_char="3698">get</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="3700" end_char="3701">on</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="3703" end_char="3706">this</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="3708" end_char="3711">side</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="3713" end_char="3714">of</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="3716" end_char="3718">the</TOKEN>
</SEG>
<SEG id="segment-62" start_char="3720" end_char="3793">
<ORIGINAL_TEXT>Atlantic. While the French comics industry is not without many of the same</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="3720" end_char="3727">Atlantic</TOKEN>
<TOKEN id="token-62-1" pos="punct" morph="none" start_char="3728" end_char="3728">.</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="3730" end_char="3734">While</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="3736" end_char="3738">the</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="3740" end_char="3745">French</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="3747" end_char="3752">comics</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="3754" end_char="3761">industry</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="3763" end_char="3764">is</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="3766" end_char="3768">not</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="3770" end_char="3776">without</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="3778" end_char="3781">many</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="3783" end_char="3784">of</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="3786" end_char="3788">the</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="3790" end_char="3793">same</TOKEN>
</SEG>
<SEG id="segment-63" start_char="3795" end_char="3872">
<ORIGINAL_TEXT>problems that have beset book publishing around the world, there is some truth</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="3795" end_char="3802">problems</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="3804" end_char="3807">that</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="3809" end_char="3812">have</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="3814" end_char="3818">beset</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="3820" end_char="3823">book</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="3825" end_char="3834">publishing</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="3836" end_char="3841">around</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="3843" end_char="3845">the</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="3847" end_char="3851">world</TOKEN>
<TOKEN id="token-63-9" pos="punct" morph="none" start_char="3852" end_char="3852">,</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="3854" end_char="3858">there</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="3860" end_char="3861">is</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="3863" end_char="3866">some</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="3868" end_char="3872">truth</TOKEN>
</SEG>
<SEG id="segment-64" start_char="3874" end_char="3948">
<ORIGINAL_TEXT>to the idea that comics are more central to public life there than they are</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="3874" end_char="3875">to</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="3877" end_char="3879">the</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="3881" end_char="3884">idea</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="3886" end_char="3889">that</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="3891" end_char="3896">comics</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="3898" end_char="3900">are</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="3902" end_char="3905">more</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="3907" end_char="3913">central</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="3915" end_char="3916">to</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="3918" end_char="3923">public</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="3925" end_char="3928">life</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="3930" end_char="3934">there</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="3936" end_char="3939">than</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="3941" end_char="3944">they</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="3946" end_char="3948">are</TOKEN>
</SEG>
<SEG id="segment-65" start_char="3950" end_char="4027">
<ORIGINAL_TEXT>here; it’s notable that Wolinski was the recipient of the Legion of Honor, and</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="3950" end_char="3953">here</TOKEN>
<TOKEN id="token-65-1" pos="punct" morph="none" start_char="3954" end_char="3954">;</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="3956" end_char="3957">it</TOKEN>
<TOKEN id="token-65-3" pos="punct" morph="none" start_char="3958" end_char="3958">’</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="3959" end_char="3959">s</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="3961" end_char="3967">notable</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="3969" end_char="3972">that</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="3974" end_char="3981">Wolinski</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="3983" end_char="3985">was</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="3987" end_char="3989">the</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="3991" end_char="3999">recipient</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="4001" end_char="4002">of</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="4004" end_char="4006">the</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="4008" end_char="4013">Legion</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="4015" end_char="4016">of</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="4018" end_char="4022">Honor</TOKEN>
<TOKEN id="token-65-16" pos="punct" morph="none" start_char="4023" end_char="4023">,</TOKEN>
<TOKEN id="token-65-17" pos="word" morph="none" start_char="4025" end_char="4027">and</TOKEN>
</SEG>
<SEG id="segment-66" start_char="4029" end_char="4096">
<ORIGINAL_TEXT>he is not the only cartoonist to have received his country’s highest</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="4029" end_char="4030">he</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="4032" end_char="4033">is</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="4035" end_char="4037">not</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="4039" end_char="4041">the</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="4043" end_char="4046">only</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="4048" end_char="4057">cartoonist</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="4059" end_char="4060">to</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="4062" end_char="4065">have</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="4067" end_char="4074">received</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="4076" end_char="4078">his</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="4080" end_char="4086">country</TOKEN>
<TOKEN id="token-66-11" pos="punct" morph="none" start_char="4087" end_char="4087">’</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="4088" end_char="4088">s</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="4090" end_char="4096">highest</TOKEN>
</SEG>
<SEG id="segment-67" start_char="4098" end_char="4174">
<ORIGINAL_TEXT>recognition. France integrated comics into the mainstream publishing industry</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="4098" end_char="4108">recognition</TOKEN>
<TOKEN id="token-67-1" pos="punct" morph="none" start_char="4109" end_char="4109">.</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="4111" end_char="4116">France</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="4118" end_char="4127">integrated</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="4129" end_char="4134">comics</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="4136" end_char="4139">into</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="4141" end_char="4143">the</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="4145" end_char="4154">mainstream</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="4156" end_char="4165">publishing</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="4167" end_char="4174">industry</TOKEN>
</SEG>
<SEG id="segment-68" start_char="4176" end_char="4251">
<ORIGINAL_TEXT>much earlier than did the United States. Here, the distinction between comic</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="4176" end_char="4179">much</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="4181" end_char="4187">earlier</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="4189" end_char="4192">than</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="4194" end_char="4196">did</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="4198" end_char="4200">the</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="4202" end_char="4207">United</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="4209" end_char="4214">States</TOKEN>
<TOKEN id="token-68-7" pos="punct" morph="none" start_char="4215" end_char="4215">.</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="4217" end_char="4220">Here</TOKEN>
<TOKEN id="token-68-9" pos="punct" morph="none" start_char="4221" end_char="4221">,</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="4223" end_char="4225">the</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="4227" end_char="4237">distinction</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="4239" end_char="4245">between</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="4247" end_char="4251">comic</TOKEN>
</SEG>
<SEG id="segment-69" start_char="4253" end_char="4331">
<ORIGINAL_TEXT>strips and comic books was sharply drawn for most of the twentieth century, and</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="4253" end_char="4258">strips</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="4260" end_char="4262">and</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="4264" end_char="4268">comic</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="4270" end_char="4274">books</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="4276" end_char="4278">was</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="4280" end_char="4286">sharply</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="4288" end_char="4292">drawn</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="4294" end_char="4296">for</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="4298" end_char="4301">most</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="4303" end_char="4304">of</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="4306" end_char="4308">the</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="4310" end_char="4318">twentieth</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="4320" end_char="4326">century</TOKEN>
<TOKEN id="token-69-13" pos="punct" morph="none" start_char="4327" end_char="4327">,</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="4329" end_char="4331">and</TOKEN>
</SEG>
<SEG id="segment-70" start_char="4333" end_char="4410">
<ORIGINAL_TEXT>comic books were widely regarded as a disposable form of culture for children.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="4333" end_char="4337">comic</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="4339" end_char="4343">books</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="4345" end_char="4348">were</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="4350" end_char="4355">widely</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="4357" end_char="4364">regarded</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="4366" end_char="4367">as</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="4369" end_char="4369">a</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="4371" end_char="4380">disposable</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="4382" end_char="4385">form</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="4387" end_char="4388">of</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="4390" end_char="4396">culture</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="4398" end_char="4400">for</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="4402" end_char="4409">children</TOKEN>
<TOKEN id="token-70-13" pos="punct" morph="none" start_char="4410" end_char="4410">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="4412" end_char="4485">
<ORIGINAL_TEXT>Comics in France—and Belgium—developed differently. Since the most popular</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="4412" end_char="4417">Comics</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="4419" end_char="4420">in</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="4422" end_char="4427">France</TOKEN>
<TOKEN id="token-71-3" pos="punct" morph="none" start_char="4428" end_char="4428">—</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="4429" end_char="4431">and</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="4433" end_char="4439">Belgium</TOKEN>
<TOKEN id="token-71-6" pos="punct" morph="none" start_char="4440" end_char="4440">—</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="4441" end_char="4449">developed</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="4451" end_char="4461">differently</TOKEN>
<TOKEN id="token-71-9" pos="punct" morph="none" start_char="4462" end_char="4462">.</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="4464" end_char="4468">Since</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="4470" end_char="4472">the</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="4474" end_char="4477">most</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="4479" end_char="4485">popular</TOKEN>
</SEG>
<SEG id="segment-72" start_char="4487" end_char="4561">
<ORIGINAL_TEXT>newspaper comics—like Hergé’s Tintin—were collected as hardcover children’s</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="4487" end_char="4495">newspaper</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="4497" end_char="4502">comics</TOKEN>
<TOKEN id="token-72-2" pos="punct" morph="none" start_char="4503" end_char="4503">—</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="4504" end_char="4507">like</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="4509" end_char="4513">Hergé</TOKEN>
<TOKEN id="token-72-5" pos="punct" morph="none" start_char="4514" end_char="4514">’</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="4515" end_char="4515">s</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="4517" end_char="4522">Tintin</TOKEN>
<TOKEN id="token-72-8" pos="punct" morph="none" start_char="4523" end_char="4523">—</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="4524" end_char="4527">were</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="4529" end_char="4537">collected</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="4539" end_char="4540">as</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="4542" end_char="4550">hardcover</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="4552" end_char="4559">children</TOKEN>
<TOKEN id="token-72-14" pos="punct" morph="none" start_char="4560" end_char="4560">’</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="4561" end_char="4561">s</TOKEN>
</SEG>
<SEG id="segment-73" start_char="4563" end_char="4636">
<ORIGINAL_TEXT>books as early as 1930, the medium was viewed as more reputable because it</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="4563" end_char="4567">books</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="4569" end_char="4570">as</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="4572" end_char="4576">early</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="4578" end_char="4579">as</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="4581" end_char="4584">1930</TOKEN>
<TOKEN id="token-73-5" pos="punct" morph="none" start_char="4585" end_char="4585">,</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="4587" end_char="4589">the</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="4591" end_char="4596">medium</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="4598" end_char="4600">was</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="4602" end_char="4607">viewed</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="4609" end_char="4610">as</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="4612" end_char="4615">more</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="4617" end_char="4625">reputable</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="4627" end_char="4633">because</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="4635" end_char="4636">it</TOKEN>
</SEG>
<SEG id="segment-74" start_char="4638" end_char="4711">
<ORIGINAL_TEXT>existed as a part of the regular book trade. In France, cartoonists can be</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="4638" end_char="4644">existed</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="4646" end_char="4647">as</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="4649" end_char="4649">a</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="4651" end_char="4654">part</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="4656" end_char="4657">of</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="4659" end_char="4661">the</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="4663" end_char="4669">regular</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="4671" end_char="4674">book</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="4676" end_char="4680">trade</TOKEN>
<TOKEN id="token-74-9" pos="punct" morph="none" start_char="4681" end_char="4681">.</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="4683" end_char="4684">In</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="4686" end_char="4691">France</TOKEN>
<TOKEN id="token-74-12" pos="punct" morph="none" start_char="4692" end_char="4692">,</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="4694" end_char="4704">cartoonists</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="4706" end_char="4708">can</TOKEN>
<TOKEN id="token-74-15" pos="word" morph="none" start_char="4710" end_char="4711">be</TOKEN>
</SEG>
<SEG id="segment-75" start_char="4713" end_char="4781">
<ORIGINAL_TEXT>genuine cultural celebrites. Cabu, for example, appeared regularly on</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="4713" end_char="4719">genuine</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="4721" end_char="4728">cultural</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="4730" end_char="4739">celebrites</TOKEN>
<TOKEN id="token-75-3" pos="punct" morph="none" start_char="4740" end_char="4740">.</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="4742" end_char="4745">Cabu</TOKEN>
<TOKEN id="token-75-5" pos="punct" morph="none" start_char="4746" end_char="4746">,</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="4748" end_char="4750">for</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="4752" end_char="4758">example</TOKEN>
<TOKEN id="token-75-8" pos="punct" morph="none" start_char="4759" end_char="4759">,</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="4761" end_char="4768">appeared</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="4770" end_char="4778">regularly</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="4780" end_char="4781">on</TOKEN>
</SEG>
<SEG id="segment-76" start_char="4783" end_char="4861">
<ORIGINAL_TEXT>television chat shows where he drew cartoons while discussing the issues of the</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="4783" end_char="4792">television</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="4794" end_char="4797">chat</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="4799" end_char="4803">shows</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="4805" end_char="4809">where</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="4811" end_char="4812">he</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="4814" end_char="4817">drew</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="4819" end_char="4826">cartoons</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="4828" end_char="4832">while</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="4834" end_char="4843">discussing</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="4845" end_char="4847">the</TOKEN>
<TOKEN id="token-76-10" pos="word" morph="none" start_char="4849" end_char="4854">issues</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="4856" end_char="4857">of</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="4859" end_char="4861">the</TOKEN>
</SEG>
<SEG id="segment-77" start_char="4863" end_char="4866">
<ORIGINAL_TEXT>day.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="4863" end_char="4865">day</TOKEN>
<TOKEN id="token-77-1" pos="punct" morph="none" start_char="4866" end_char="4866">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="4868" end_char="4871">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="unknown" morph="none" start_char="4868" end_char="4871">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-79" start_char="4873" end_char="4875">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="unknown" morph="none" start_char="4873" end_char="4875">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-80" start_char="4877" end_char="4954">
<ORIGINAL_TEXT>The attack on Charlie Hebdo is shocking for its brutality and because it is an</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="4877" end_char="4879">The</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="4881" end_char="4886">attack</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="4888" end_char="4889">on</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="4891" end_char="4897">Charlie</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="4899" end_char="4903">Hebdo</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="4905" end_char="4906">is</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="4908" end_char="4915">shocking</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="4917" end_char="4919">for</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="4921" end_char="4923">its</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="4925" end_char="4933">brutality</TOKEN>
<TOKEN id="token-80-10" pos="word" morph="none" start_char="4935" end_char="4937">and</TOKEN>
<TOKEN id="token-80-11" pos="word" morph="none" start_char="4939" end_char="4945">because</TOKEN>
<TOKEN id="token-80-12" pos="word" morph="none" start_char="4947" end_char="4948">it</TOKEN>
<TOKEN id="token-80-13" pos="word" morph="none" start_char="4950" end_char="4951">is</TOKEN>
<TOKEN id="token-80-14" pos="word" morph="none" start_char="4953" end_char="4954">an</TOKEN>
</SEG>
<SEG id="segment-81" start_char="4956" end_char="5031">
<ORIGINAL_TEXT>assault on the very idea of free expression. Yet the target was not just any</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="4956" end_char="4962">assault</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="4964" end_char="4965">on</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="4967" end_char="4969">the</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="4971" end_char="4974">very</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="4976" end_char="4979">idea</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="4981" end_char="4982">of</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="4984" end_char="4987">free</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="4989" end_char="4998">expression</TOKEN>
<TOKEN id="token-81-8" pos="punct" morph="none" start_char="4999" end_char="4999">.</TOKEN>
<TOKEN id="token-81-9" pos="word" morph="none" start_char="5001" end_char="5003">Yet</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="5005" end_char="5007">the</TOKEN>
<TOKEN id="token-81-11" pos="word" morph="none" start_char="5009" end_char="5014">target</TOKEN>
<TOKEN id="token-81-12" pos="word" morph="none" start_char="5016" end_char="5018">was</TOKEN>
<TOKEN id="token-81-13" pos="word" morph="none" start_char="5020" end_char="5022">not</TOKEN>
<TOKEN id="token-81-14" pos="word" morph="none" start_char="5024" end_char="5027">just</TOKEN>
<TOKEN id="token-81-15" pos="word" morph="none" start_char="5029" end_char="5031">any</TOKEN>
</SEG>
<SEG id="segment-82" start_char="5033" end_char="5106">
<ORIGINAL_TEXT>newspaper. Today’s attackers seemed to understand the same thing that King</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="5033" end_char="5041">newspaper</TOKEN>
<TOKEN id="token-82-1" pos="punct" morph="none" start_char="5042" end_char="5042">.</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="5044" end_char="5048">Today</TOKEN>
<TOKEN id="token-82-3" pos="punct" morph="none" start_char="5049" end_char="5049">’</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="5050" end_char="5050">s</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="5052" end_char="5060">attackers</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="5062" end_char="5067">seemed</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="5069" end_char="5070">to</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="5072" end_char="5081">understand</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="5083" end_char="5085">the</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="5087" end_char="5090">same</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="5092" end_char="5096">thing</TOKEN>
<TOKEN id="token-82-12" pos="word" morph="none" start_char="5098" end_char="5101">that</TOKEN>
<TOKEN id="token-82-13" pos="word" morph="none" start_char="5103" end_char="5106">King</TOKEN>
</SEG>
<SEG id="segment-83" start_char="5108" end_char="5186">
<ORIGINAL_TEXT>Louis Philippe recognized in the 1830s: The visual form of the cartoon makes it</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="5108" end_char="5112">Louis</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="5114" end_char="5121">Philippe</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="5123" end_char="5132">recognized</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="5134" end_char="5135">in</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="5137" end_char="5139">the</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="5141" end_char="5145">1830s</TOKEN>
<TOKEN id="token-83-6" pos="punct" morph="none" start_char="5146" end_char="5146">:</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="5148" end_char="5150">The</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="5152" end_char="5157">visual</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="5159" end_char="5162">form</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="5164" end_char="5165">of</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="5167" end_char="5169">the</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="5171" end_char="5177">cartoon</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="5179" end_char="5183">makes</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="5185" end_char="5186">it</TOKEN>
</SEG>
<SEG id="segment-84" start_char="5188" end_char="5262">
<ORIGINAL_TEXT>viscerally powerful, and central to the French conception of caricature and</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="5188" end_char="5197">viscerally</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="5199" end_char="5206">powerful</TOKEN>
<TOKEN id="token-84-2" pos="punct" morph="none" start_char="5207" end_char="5207">,</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="5209" end_char="5211">and</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="5213" end_char="5219">central</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="5221" end_char="5222">to</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="5224" end_char="5226">the</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="5228" end_char="5233">French</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="5235" end_char="5244">conception</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="5246" end_char="5247">of</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="5249" end_char="5258">caricature</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="5260" end_char="5262">and</TOKEN>
</SEG>
<SEG id="segment-85" start_char="5264" end_char="5272">
<ORIGINAL_TEXT>critique.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="5264" end_char="5271">critique</TOKEN>
<TOKEN id="token-85-1" pos="punct" morph="none" start_char="5272" end_char="5272">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="5274" end_char="5277">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="unknown" morph="none" start_char="5274" end_char="5277">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-87" start_char="5279" end_char="5285">
<ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="unknown" morph="none" start_char="5279" end_char="5285">&lt;/TEXT&gt;</TOKEN>
</SEG>
<SEG id="segment-88" start_char="5287" end_char="5292">
<ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="unknown" morph="none" start_char="5287" end_char="5292">&lt;/DOC&gt;</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
