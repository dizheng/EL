<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="SPA_NW_001458_20150620_F0010004F.nw.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="2270" raw_text_md5="3315d1589a5e1b39a665feee2c148d91">
<TEXT>
<SEG id="segment-0" start_char="0" end_char="37">
<ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
<TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
<TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
</SEG>
<SEG id="segment-1" start_char="39" end_char="81">
<ORIGINAL_TEXT>&lt;DOC id="SPA_NW_001458_20150620_F0010004F"&gt;</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
<TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="SPA_NW_001458_20150620_F0010004F"&gt;</TOKEN>
</SEG>
<SEG id="segment-2" start_char="83" end_char="201">
<ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.diariodeibiza.es/internacional/2015/07/31/autor-matanza-charleston-niega-cargos/784435.html&lt;/SOURCE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="201">&lt;SOURCE&gt;http://www.diariodeibiza.es/internacional/2015/07/31/autor-matanza-charleston-niega-cargos/784435.html&lt;/SOURCE&gt;</TOKEN>
</SEG>
<SEG id="segment-3" start_char="203" end_char="244">
<ORIGINAL_TEXT>&lt;DATE_TIME&gt;2015-06-20T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="unknown" morph="none" start_char="203" end_char="244">&lt;DATE_TIME&gt;2015-06-20T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
</SEG>
<SEG id="segment-4" start_char="246" end_char="255">
<ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="unknown" morph="none" start_char="246" end_char="255">&lt;HEADLINE&gt;</TOKEN>
</SEG>
<SEG id="segment-5" start_char="257" end_char="309">
<ORIGINAL_TEXT>El autor de la matanza de Charleston niega los cargos</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="257" end_char="258">El</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="260" end_char="264">autor</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="266" end_char="267">de</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="269" end_char="270">la</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="272" end_char="278">matanza</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="280" end_char="281">de</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="283" end_char="292">Charleston</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="294" end_char="298">niega</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="300" end_char="302">los</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="304" end_char="309">cargos</TOKEN>
</SEG>
<SEG id="segment-6" start_char="311" end_char="321">
<ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="unknown" morph="none" start_char="311" end_char="321">&lt;/HEADLINE&gt;</TOKEN>
</SEG>
<SEG id="segment-7" start_char="323" end_char="328">
<ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="unknown" morph="none" start_char="323" end_char="328">&lt;TEXT&gt;</TOKEN>
</SEG>
<SEG id="segment-8" start_char="330" end_char="332">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="unknown" morph="none" start_char="330" end_char="332">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-9" start_char="334" end_char="410">
<ORIGINAL_TEXT>Dylann Roof quería declararse culpable, pero su abogado le aconsejó esperar a</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="334" end_char="339">Dylann</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="341" end_char="344">Roof</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="346" end_char="351">quería</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="353" end_char="362">declararse</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="364" end_char="371">culpable</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="372" end_char="372">,</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="374" end_char="377">pero</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="379" end_char="380">su</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="382" end_char="388">abogado</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="390" end_char="391">le</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="393" end_char="400">aconsejó</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="402" end_char="408">esperar</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="410" end_char="410">a</TOKEN>
</SEG>
<SEG id="segment-10" start_char="412" end_char="442">
<ORIGINAL_TEXT>conocer si piden pena de muerte</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="412" end_char="418">conocer</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="420" end_char="421">si</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="423" end_char="427">piden</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="429" end_char="432">pena</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="434" end_char="435">de</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="437" end_char="442">muerte</TOKEN>
</SEG>
<SEG id="segment-11" start_char="444" end_char="447">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="unknown" morph="none" start_char="444" end_char="447">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-12" start_char="449" end_char="451">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="unknown" morph="none" start_char="449" end_char="451">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-13" start_char="453" end_char="525">
<ORIGINAL_TEXT>EP/WASHINGTON El autor confeso de la matanza en una iglesia de Charleston</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="453" end_char="454">EP</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="455" end_char="455">/</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="456" end_char="465">WASHINGTON</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="467" end_char="468">El</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="470" end_char="474">autor</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="476" end_char="482">confeso</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="484" end_char="485">de</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="487" end_char="488">la</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="490" end_char="496">matanza</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="498" end_char="499">en</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="501" end_char="503">una</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="505" end_char="511">iglesia</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="513" end_char="514">de</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="516" end_char="525">Charleston</TOKEN>
</SEG>
<SEG id="segment-14" start_char="527" end_char="604">
<ORIGINAL_TEXT>(Carolina del Sur), Dylann Roof, se ha declarado no culpable de los cargos que</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="527" end_char="527">(</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="528" end_char="535">Carolina</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="537" end_char="539">del</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="541" end_char="543">Sur</TOKEN>
<TOKEN id="token-14-4" pos="punct" morph="none" start_char="544" end_char="545">),</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="547" end_char="552">Dylann</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="554" end_char="557">Roof</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="558" end_char="558">,</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="560" end_char="561">se</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="563" end_char="564">ha</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="566" end_char="574">declarado</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="576" end_char="577">no</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="579" end_char="586">culpable</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="588" end_char="589">de</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="591" end_char="593">los</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="595" end_char="600">cargos</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="602" end_char="604">que</TOKEN>
</SEG>
<SEG id="segment-15" start_char="606" end_char="682">
<ORIGINAL_TEXT>se le imputan por la muerte en junio de nueve personas afroamericanas, aunque</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="606" end_char="607">se</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="609" end_char="610">le</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="612" end_char="618">imputan</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="620" end_char="622">por</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="624" end_char="625">la</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="627" end_char="632">muerte</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="634" end_char="635">en</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="637" end_char="641">junio</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="643" end_char="644">de</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="646" end_char="650">nueve</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="652" end_char="659">personas</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="661" end_char="674">afroamericanas</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="675" end_char="675">,</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="677" end_char="682">aunque</TOKEN>
</SEG>
<SEG id="segment-16" start_char="684" end_char="760">
<ORIGINAL_TEXT>su abogado ha asegurado que la intención es asumir las acusaciones una vez se</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="684" end_char="685">su</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="687" end_char="693">abogado</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="695" end_char="696">ha</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="698" end_char="706">asegurado</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="708" end_char="710">que</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="712" end_char="713">la</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="715" end_char="723">intención</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="725" end_char="726">es</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="728" end_char="733">asumir</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="735" end_char="737">las</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="739" end_char="749">acusaciones</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="751" end_char="753">una</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="755" end_char="757">vez</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="759" end_char="760">se</TOKEN>
</SEG>
<SEG id="segment-17" start_char="762" end_char="824">
<ORIGINAL_TEXT>conozca si el Gobierno pide para el detenido la pena de muerte.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="762" end_char="768">conozca</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="770" end_char="771">si</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="773" end_char="774">el</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="776" end_char="783">Gobierno</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="785" end_char="788">pide</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="790" end_char="793">para</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="795" end_char="796">el</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="798" end_char="805">detenido</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="807" end_char="808">la</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="810" end_char="813">pena</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="815" end_char="816">de</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="818" end_char="823">muerte</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="824" end_char="824">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="826" end_char="829">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="unknown" morph="none" start_char="826" end_char="829">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-19" start_char="831" end_char="833">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="unknown" morph="none" start_char="831" end_char="833">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-20" start_char="835" end_char="906">
<ORIGINAL_TEXT>"Hasta que no sepamos si el Gobierno pide la pena de muerte, no podremos</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="punct" morph="none" start_char="835" end_char="835">"</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="836" end_char="840">Hasta</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="842" end_char="844">que</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="846" end_char="847">no</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="849" end_char="855">sepamos</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="857" end_char="858">si</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="860" end_char="861">el</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="863" end_char="870">Gobierno</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="872" end_char="875">pide</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="877" end_char="878">la</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="880" end_char="883">pena</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="885" end_char="886">de</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="888" end_char="893">muerte</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="894" end_char="894">,</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="896" end_char="897">no</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="899" end_char="906">podremos</TOKEN>
</SEG>
<SEG id="segment-21" start_char="908" end_char="979">
<ORIGINAL_TEXT>presentar una declaración de culpabilidad", ha explicado este viernes el</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="908" end_char="916">presentar</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="918" end_char="920">una</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="922" end_char="932">declaración</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="934" end_char="935">de</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="937" end_char="948">culpabilidad</TOKEN>
<TOKEN id="token-21-5" pos="punct" morph="none" start_char="949" end_char="950">",</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="952" end_char="953">ha</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="955" end_char="963">explicado</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="965" end_char="968">este</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="970" end_char="976">viernes</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="978" end_char="979">el</TOKEN>
</SEG>
<SEG id="segment-22" start_char="981" end_char="1058">
<ORIGINAL_TEXT>abogado David Bruck ante el juez Bristow Marchant. "El señor Roof nos ha dicho</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="981" end_char="987">abogado</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="989" end_char="993">David</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="995" end_char="999">Bruck</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1001" end_char="1004">ante</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1006" end_char="1007">el</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1009" end_char="1012">juez</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1014" end_char="1020">Bristow</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="1022" end_char="1029">Marchant</TOKEN>
<TOKEN id="token-22-8" pos="punct" morph="none" start_char="1030" end_char="1030">.</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="1032" end_char="1032">"</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="1033" end_char="1034">El</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="1036" end_char="1040">señor</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="1042" end_char="1045">Roof</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="1047" end_char="1049">nos</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="1051" end_char="1052">ha</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="1054" end_char="1058">dicho</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1060" end_char="1135">
<ORIGINAL_TEXT>que le gustaría declararse culpable", ha añadido el letrado, según NBC News.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1060" end_char="1062">que</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1064" end_char="1065">le</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1067" end_char="1074">gustaría</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1076" end_char="1085">declararse</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="1087" end_char="1094">culpable</TOKEN>
<TOKEN id="token-23-5" pos="punct" morph="none" start_char="1095" end_char="1096">",</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="1098" end_char="1099">ha</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="1101" end_char="1107">añadido</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="1109" end_char="1110">el</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="1112" end_char="1118">letrado</TOKEN>
<TOKEN id="token-23-10" pos="punct" morph="none" start_char="1119" end_char="1119">,</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="1121" end_char="1125">según</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="1127" end_char="1129">NBC</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="1131" end_char="1134">News</TOKEN>
<TOKEN id="token-23-14" pos="punct" morph="none" start_char="1135" end_char="1135">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1137" end_char="1140">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="unknown" morph="none" start_char="1137" end_char="1140">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1142" end_char="1144">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="unknown" morph="none" start_char="1142" end_char="1144">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1146" end_char="1215">
<ORIGINAL_TEXT>El abogado de Roof, David Bruck, dijo que el acusado quería declararse</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1146" end_char="1147">El</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="1149" end_char="1155">abogado</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="1157" end_char="1158">de</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="1160" end_char="1163">Roof</TOKEN>
<TOKEN id="token-26-4" pos="punct" morph="none" start_char="1164" end_char="1164">,</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="1166" end_char="1170">David</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="1172" end_char="1176">Bruck</TOKEN>
<TOKEN id="token-26-7" pos="punct" morph="none" start_char="1177" end_char="1177">,</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="1179" end_char="1182">dijo</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="1184" end_char="1186">que</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="1188" end_char="1189">el</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="1191" end_char="1197">acusado</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="1199" end_char="1204">quería</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="1206" end_char="1215">declararse</TOKEN>
</SEG>
<SEG id="segment-27" start_char="1217" end_char="1294">
<ORIGINAL_TEXT>culpable, pero le aconsejó cambiar la estrategia procesal hasta conocer si los</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="1217" end_char="1224">culpable</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="1225" end_char="1225">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="1227" end_char="1230">pero</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="1232" end_char="1233">le</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="1235" end_char="1242">aconsejó</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="1244" end_char="1250">cambiar</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="1252" end_char="1253">la</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="1255" end_char="1264">estrategia</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="1266" end_char="1273">procesal</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="1275" end_char="1279">hasta</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="1281" end_char="1287">conocer</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="1289" end_char="1290">si</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="1292" end_char="1294">los</TOKEN>
</SEG>
<SEG id="segment-28" start_char="1296" end_char="1330">
<ORIGINAL_TEXT>fiscales pedirán la pena de muerte.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="1296" end_char="1303">fiscales</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="1305" end_char="1311">pedirán</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="1313" end_char="1314">la</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="1316" end_char="1319">pena</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="1321" end_char="1322">de</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="1324" end_char="1329">muerte</TOKEN>
<TOKEN id="token-28-6" pos="punct" morph="none" start_char="1330" end_char="1330">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="1332" end_char="1335">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="unknown" morph="none" start_char="1332" end_char="1335">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-30" start_char="1337" end_char="1339">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="unknown" morph="none" start_char="1337" end_char="1339">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-31" start_char="1341" end_char="1411">
<ORIGINAL_TEXT>Sobre Roof, un presunto supremacista blanco de 21 años, pesan 33 cargos</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="1341" end_char="1345">Sobre</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="1347" end_char="1350">Roof</TOKEN>
<TOKEN id="token-31-2" pos="punct" morph="none" start_char="1351" end_char="1351">,</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="1353" end_char="1354">un</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="1356" end_char="1363">presunto</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="1365" end_char="1376">supremacista</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="1378" end_char="1383">blanco</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="1385" end_char="1386">de</TOKEN>
<TOKEN id="token-31-8" pos="number" morph="none" start_char="1388" end_char="1389">21</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="1391" end_char="1394">años</TOKEN>
<TOKEN id="token-31-10" pos="punct" morph="none" start_char="1395" end_char="1395">,</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="1397" end_char="1401">pesan</TOKEN>
<TOKEN id="token-31-12" pos="number" morph="none" start_char="1403" end_char="1404">33</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="1406" end_char="1411">cargos</TOKEN>
</SEG>
<SEG id="segment-32" start_char="1413" end_char="1487">
<ORIGINAL_TEXT>federales por la masacre, así como nueve cargos de asesinato en un tribunal</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="1413" end_char="1421">federales</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="1423" end_char="1425">por</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="1427" end_char="1428">la</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="1430" end_char="1436">masacre</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="1437" end_char="1437">,</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="1439" end_char="1441">así</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="1443" end_char="1446">como</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="1448" end_char="1452">nueve</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="1454" end_char="1459">cargos</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="1461" end_char="1462">de</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="1464" end_char="1472">asesinato</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="1474" end_char="1475">en</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="1477" end_char="1478">un</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="1480" end_char="1487">tribunal</TOKEN>
</SEG>
<SEG id="segment-33" start_char="1489" end_char="1556">
<ORIGINAL_TEXT>estatal. La pena capital es una opción en ambas jurisdicciones, pero</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="1489" end_char="1495">estatal</TOKEN>
<TOKEN id="token-33-1" pos="punct" morph="none" start_char="1496" end_char="1496">.</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="1498" end_char="1499">La</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="1501" end_char="1504">pena</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="1506" end_char="1512">capital</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="1514" end_char="1515">es</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="1517" end_char="1519">una</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="1521" end_char="1526">opción</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="1528" end_char="1529">en</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="1531" end_char="1535">ambas</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="1537" end_char="1550">jurisdicciones</TOKEN>
<TOKEN id="token-33-11" pos="punct" morph="none" start_char="1551" end_char="1551">,</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="1553" end_char="1556">pero</TOKEN>
</SEG>
<SEG id="segment-34" start_char="1558" end_char="1636">
<ORIGINAL_TEXT>oficialmente la Fiscalía no ha aclarado cuál será su petición y las familias no</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="1558" end_char="1569">oficialmente</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="1571" end_char="1572">la</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="1574" end_char="1581">Fiscalía</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="1583" end_char="1584">no</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="1586" end_char="1587">ha</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="1589" end_char="1596">aclarado</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="1598" end_char="1601">cuál</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="1603" end_char="1606">será</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="1608" end_char="1609">su</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="1611" end_char="1618">petición</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="1620" end_char="1620">y</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="1622" end_char="1624">las</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="1626" end_char="1633">familias</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="1635" end_char="1636">no</TOKEN>
</SEG>
<SEG id="segment-35" start_char="1638" end_char="1671">
<ORIGINAL_TEXT>han expresado opinión al respecto.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="1638" end_char="1640">han</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="1642" end_char="1650">expresado</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="1652" end_char="1658">opinión</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="1660" end_char="1661">al</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="1663" end_char="1670">respecto</TOKEN>
<TOKEN id="token-35-5" pos="punct" morph="none" start_char="1671" end_char="1671">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="1673" end_char="1676">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="unknown" morph="none" start_char="1673" end_char="1676">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-37" start_char="1678" end_char="1680">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="unknown" morph="none" start_char="1678" end_char="1680">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-38" start_char="1682" end_char="1757">
<ORIGINAL_TEXT>Este viernes, varios familiares se han dirigido al tribunal para detallar el</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="1682" end_char="1685">Este</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="1687" end_char="1693">viernes</TOKEN>
<TOKEN id="token-38-2" pos="punct" morph="none" start_char="1694" end_char="1694">,</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="1696" end_char="1701">varios</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="1703" end_char="1712">familiares</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="1714" end_char="1715">se</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="1717" end_char="1719">han</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="1721" end_char="1728">dirigido</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="1730" end_char="1731">al</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="1733" end_char="1740">tribunal</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="1742" end_char="1745">para</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="1747" end_char="1754">detallar</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="1756" end_char="1757">el</TOKEN>
</SEG>
<SEG id="segment-39" start_char="1759" end_char="1836">
<ORIGINAL_TEXT>sufrimiento vivido después de que Roof abriese fuego indiscriminadamente el 17</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="1759" end_char="1769">sufrimiento</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="1771" end_char="1776">vivido</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="1778" end_char="1784">después</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="1786" end_char="1787">de</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="1789" end_char="1791">que</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="1793" end_char="1796">Roof</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="1798" end_char="1804">abriese</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="1806" end_char="1810">fuego</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="1812" end_char="1830">indiscriminadamente</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="1832" end_char="1833">el</TOKEN>
<TOKEN id="token-39-10" pos="number" morph="none" start_char="1835" end_char="1836">17</TOKEN>
</SEG>
<SEG id="segment-40" start_char="1838" end_char="1911">
<ORIGINAL_TEXT>de junio. "No sé lo que le ocurrirá a este joven pero, para el resto de su</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="1838" end_char="1839">de</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="1841" end_char="1845">junio</TOKEN>
<TOKEN id="token-40-2" pos="punct" morph="none" start_char="1846" end_char="1846">.</TOKEN>
<TOKEN id="token-40-3" pos="punct" morph="none" start_char="1848" end_char="1848">"</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="1849" end_char="1850">No</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="1852" end_char="1853">sé</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="1855" end_char="1856">lo</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="1858" end_char="1860">que</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="1862" end_char="1863">le</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="1865" end_char="1872">ocurrirá</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="1874" end_char="1874">a</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="1876" end_char="1879">este</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="1881" end_char="1885">joven</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="1887" end_char="1890">pero</TOKEN>
<TOKEN id="token-40-14" pos="punct" morph="none" start_char="1891" end_char="1891">,</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="1893" end_char="1896">para</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="1898" end_char="1899">el</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="1901" end_char="1905">resto</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="1907" end_char="1908">de</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="1910" end_char="1911">su</TOKEN>
</SEG>
<SEG id="segment-41" start_char="1913" end_char="1988">
<ORIGINAL_TEXT>vida, quiero que sigan pensando" en lo que ocurrió, ha dicho Tyrone Sanders,</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="1913" end_char="1916">vida</TOKEN>
<TOKEN id="token-41-1" pos="punct" morph="none" start_char="1917" end_char="1917">,</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="1919" end_char="1924">quiero</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="1926" end_char="1928">que</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="1930" end_char="1934">sigan</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="1936" end_char="1943">pensando</TOKEN>
<TOKEN id="token-41-6" pos="punct" morph="none" start_char="1944" end_char="1944">"</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="1946" end_char="1947">en</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="1949" end_char="1950">lo</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="1952" end_char="1954">que</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="1956" end_char="1962">ocurrió</TOKEN>
<TOKEN id="token-41-11" pos="punct" morph="none" start_char="1963" end_char="1963">,</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="1965" end_char="1966">ha</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="1968" end_char="1972">dicho</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="1974" end_char="1979">Tyrone</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="1981" end_char="1987">Sanders</TOKEN>
<TOKEN id="token-41-16" pos="punct" morph="none" start_char="1988" end_char="1988">,</TOKEN>
</SEG>
<SEG id="segment-42" start_char="1990" end_char="2018">
<ORIGINAL_TEXT>padre de una de las víctimas.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="1990" end_char="1994">padre</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="1996" end_char="1997">de</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="1999" end_char="2001">una</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="2003" end_char="2004">de</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="2006" end_char="2008">las</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="2010" end_char="2017">víctimas</TOKEN>
<TOKEN id="token-42-6" pos="punct" morph="none" start_char="2018" end_char="2018">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="2020" end_char="2023">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="unknown" morph="none" start_char="2020" end_char="2023">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-44" start_char="2025" end_char="2027">
<ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="unknown" morph="none" start_char="2025" end_char="2027">&lt;P&gt;</TOKEN>
</SEG>
<SEG id="segment-45" start_char="2029" end_char="2100">
<ORIGINAL_TEXT>Malcolm Graham, hermano de otra de las personas que perdió la vida en la</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="2029" end_char="2035">Malcolm</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="2037" end_char="2042">Graham</TOKEN>
<TOKEN id="token-45-2" pos="punct" morph="none" start_char="2043" end_char="2043">,</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="2045" end_char="2051">hermano</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="2053" end_char="2054">de</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="2056" end_char="2059">otra</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="2061" end_char="2062">de</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="2064" end_char="2066">las</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="2068" end_char="2075">personas</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="2077" end_char="2079">que</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="2081" end_char="2086">perdió</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="2088" end_char="2089">la</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="2091" end_char="2094">vida</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="2096" end_char="2097">en</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="2099" end_char="2100">la</TOKEN>
</SEG>
<SEG id="segment-46" start_char="2102" end_char="2180">
<ORIGINAL_TEXT>iglesia, ha asegurado a las puertas del tribunal que "el camino de la Justicia"</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="2102" end_char="2108">iglesia</TOKEN>
<TOKEN id="token-46-1" pos="punct" morph="none" start_char="2109" end_char="2109">,</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="2111" end_char="2112">ha</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="2114" end_char="2122">asegurado</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="2124" end_char="2124">a</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="2126" end_char="2128">las</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="2130" end_char="2136">puertas</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="2138" end_char="2140">del</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="2142" end_char="2149">tribunal</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="2151" end_char="2153">que</TOKEN>
<TOKEN id="token-46-10" pos="punct" morph="none" start_char="2155" end_char="2155">"</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="2156" end_char="2157">el</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="2159" end_char="2164">camino</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="2166" end_char="2167">de</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="2169" end_char="2170">la</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="2172" end_char="2179">Justicia</TOKEN>
<TOKEN id="token-46-16" pos="punct" morph="none" start_char="2180" end_char="2180">"</TOKEN>
</SEG>
<SEG id="segment-47" start_char="2182" end_char="2248">
<ORIGINAL_TEXT>consiste en "dar un paso cada vez" y "hoy se ha dado un buen paso".</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="2182" end_char="2189">consiste</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="2191" end_char="2192">en</TOKEN>
<TOKEN id="token-47-2" pos="punct" morph="none" start_char="2194" end_char="2194">"</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="2195" end_char="2197">dar</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="2199" end_char="2200">un</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="2202" end_char="2205">paso</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="2207" end_char="2210">cada</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="2212" end_char="2214">vez</TOKEN>
<TOKEN id="token-47-8" pos="punct" morph="none" start_char="2215" end_char="2215">"</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="2217" end_char="2217">y</TOKEN>
<TOKEN id="token-47-10" pos="punct" morph="none" start_char="2219" end_char="2219">"</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="2220" end_char="2222">hoy</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="2224" end_char="2225">se</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="2227" end_char="2228">ha</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="2230" end_char="2233">dado</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="2235" end_char="2236">un</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="2238" end_char="2241">buen</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="2243" end_char="2246">paso</TOKEN>
<TOKEN id="token-47-18" pos="punct" morph="none" start_char="2247" end_char="2248">".</TOKEN>
</SEG>
<SEG id="segment-48" start_char="2250" end_char="2253">
<ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="unknown" morph="none" start_char="2250" end_char="2253">&lt;/P&gt;</TOKEN>
</SEG>
<SEG id="segment-49" start_char="2255" end_char="2261">
<ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="unknown" morph="none" start_char="2255" end_char="2261">&lt;/TEXT&gt;</TOKEN>
</SEG>
<SEG id="segment-50" start_char="2263" end_char="2268">
<ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="unknown" morph="none" start_char="2263" end_char="2268">&lt;/DOC&gt;</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
