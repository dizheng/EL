<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="ENG_NW_001039_20141211_F0000001D.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="3591" raw_text_md5="b211a6512ebc5fff20d28bd30bfb56af">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001039_20141211_F0000001D"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001039_20141211_F0000001D"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="176">
        <ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.nzherald.co.nz/world/news/article.cfm?c_id=2&amp;amp;objectid=11372469&lt;/SOURCE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="176">&lt;SOURCE&gt;http://www.nzherald.co.nz/world/news/article.cfm?c_id=2&amp;amp;objectid=11372469&lt;/SOURCE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="178" end_char="219">
        <ORIGINAL_TEXT>&lt;DATE_TIME&gt;2014-12-11T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="unknown" morph="none" start_char="178" end_char="219">&lt;DATE_TIME&gt;2014-12-11T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="221" end_char="230">
        <ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="221" end_char="230">&lt;HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="232" end_char="281">
        <ORIGINAL_TEXT>Oscar Pistorius could still be convicted of murder</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="word" morph="none" start_char="232" end_char="236">Oscar</TOKEN>
        <TOKEN id="token-5-1" pos="word" morph="none" start_char="238" end_char="246">Pistorius</TOKEN>
        <TOKEN id="token-5-2" pos="word" morph="none" start_char="248" end_char="252">could</TOKEN>
        <TOKEN id="token-5-3" pos="word" morph="none" start_char="254" end_char="258">still</TOKEN>
        <TOKEN id="token-5-4" pos="word" morph="none" start_char="260" end_char="261">be</TOKEN>
        <TOKEN id="token-5-5" pos="word" morph="none" start_char="263" end_char="271">convicted</TOKEN>
        <TOKEN id="token-5-6" pos="word" morph="none" start_char="273" end_char="274">of</TOKEN>
        <TOKEN id="token-5-7" pos="word" morph="none" start_char="276" end_char="281">murder</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="283" end_char="293">
        <ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="unknown" morph="none" start_char="283" end_char="293">&lt;/HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="295" end_char="300">
        <ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="295" end_char="300">&lt;TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="302" end_char="304">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="302" end_char="304">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="306" end_char="378">
        <ORIGINAL_TEXT>Judge grants prosecutors leave to appeal, opening the door for Pistorius'</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="306" end_char="310">Judge</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="312" end_char="317">grants</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="319" end_char="329">prosecutors</TOKEN>
        <TOKEN id="token-9-3" pos="word" morph="none" start_char="331" end_char="335">leave</TOKEN>
        <TOKEN id="token-9-4" pos="word" morph="none" start_char="337" end_char="338">to</TOKEN>
        <TOKEN id="token-9-5" pos="word" morph="none" start_char="340" end_char="345">appeal</TOKEN>
        <TOKEN id="token-9-6" pos="punct" morph="none" start_char="346" end_char="346">,</TOKEN>
        <TOKEN id="token-9-7" pos="word" morph="none" start_char="348" end_char="354">opening</TOKEN>
        <TOKEN id="token-9-8" pos="word" morph="none" start_char="356" end_char="358">the</TOKEN>
        <TOKEN id="token-9-9" pos="word" morph="none" start_char="360" end_char="363">door</TOKEN>
        <TOKEN id="token-9-10" pos="word" morph="none" start_char="365" end_char="367">for</TOKEN>
        <TOKEN id="token-9-11" pos="word" morph="none" start_char="369" end_char="377">Pistorius</TOKEN>
        <TOKEN id="token-9-12" pos="punct" morph="none" start_char="378" end_char="378">'</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="380" end_char="414">
        <ORIGINAL_TEXT>conviction to be upgraded to murder</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="word" morph="none" start_char="380" end_char="389">conviction</TOKEN>
        <TOKEN id="token-10-1" pos="word" morph="none" start_char="391" end_char="392">to</TOKEN>
        <TOKEN id="token-10-2" pos="word" morph="none" start_char="394" end_char="395">be</TOKEN>
        <TOKEN id="token-10-3" pos="word" morph="none" start_char="397" end_char="404">upgraded</TOKEN>
        <TOKEN id="token-10-4" pos="word" morph="none" start_char="406" end_char="407">to</TOKEN>
        <TOKEN id="token-10-5" pos="word" morph="none" start_char="409" end_char="414">murder</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="416" end_char="419">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="unknown" morph="none" start_char="416" end_char="419">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="421" end_char="423">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="unknown" morph="none" start_char="421" end_char="423">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="425" end_char="500">
        <ORIGINAL_TEXT>Oscar Pistorius could have his conviction upgraded from culpable homicide to</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="word" morph="none" start_char="425" end_char="429">Oscar</TOKEN>
        <TOKEN id="token-13-1" pos="word" morph="none" start_char="431" end_char="439">Pistorius</TOKEN>
        <TOKEN id="token-13-2" pos="word" morph="none" start_char="441" end_char="445">could</TOKEN>
        <TOKEN id="token-13-3" pos="word" morph="none" start_char="447" end_char="450">have</TOKEN>
        <TOKEN id="token-13-4" pos="word" morph="none" start_char="452" end_char="454">his</TOKEN>
        <TOKEN id="token-13-5" pos="word" morph="none" start_char="456" end_char="465">conviction</TOKEN>
        <TOKEN id="token-13-6" pos="word" morph="none" start_char="467" end_char="474">upgraded</TOKEN>
        <TOKEN id="token-13-7" pos="word" morph="none" start_char="476" end_char="479">from</TOKEN>
        <TOKEN id="token-13-8" pos="word" morph="none" start_char="481" end_char="488">culpable</TOKEN>
        <TOKEN id="token-13-9" pos="word" morph="none" start_char="490" end_char="497">homicide</TOKEN>
        <TOKEN id="token-13-10" pos="word" morph="none" start_char="499" end_char="500">to</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="502" end_char="568">
        <ORIGINAL_TEXT>murder and face a possible 15-year prison sentence, after an appeal</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="word" morph="none" start_char="502" end_char="507">murder</TOKEN>
        <TOKEN id="token-14-1" pos="word" morph="none" start_char="509" end_char="511">and</TOKEN>
        <TOKEN id="token-14-2" pos="word" morph="none" start_char="513" end_char="516">face</TOKEN>
        <TOKEN id="token-14-3" pos="word" morph="none" start_char="518" end_char="518">a</TOKEN>
        <TOKEN id="token-14-4" pos="word" morph="none" start_char="520" end_char="527">possible</TOKEN>
        <TOKEN id="token-14-5" pos="number" morph="none" start_char="529" end_char="530">15</TOKEN>
        <TOKEN id="token-14-6" pos="punct" morph="none" start_char="531" end_char="531">-</TOKEN>
        <TOKEN id="token-14-7" pos="word" morph="none" start_char="532" end_char="535">year</TOKEN>
        <TOKEN id="token-14-8" pos="word" morph="none" start_char="537" end_char="542">prison</TOKEN>
        <TOKEN id="token-14-9" pos="word" morph="none" start_char="544" end_char="551">sentence</TOKEN>
        <TOKEN id="token-14-10" pos="punct" morph="none" start_char="552" end_char="552">,</TOKEN>
        <TOKEN id="token-14-11" pos="word" morph="none" start_char="554" end_char="558">after</TOKEN>
        <TOKEN id="token-14-12" pos="word" morph="none" start_char="560" end_char="561">an</TOKEN>
        <TOKEN id="token-14-13" pos="word" morph="none" start_char="563" end_char="568">appeal</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="570" end_char="619">
        <ORIGINAL_TEXT>application made by state prosecutors was granted.</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="word" morph="none" start_char="570" end_char="580">application</TOKEN>
        <TOKEN id="token-15-1" pos="word" morph="none" start_char="582" end_char="585">made</TOKEN>
        <TOKEN id="token-15-2" pos="word" morph="none" start_char="587" end_char="588">by</TOKEN>
        <TOKEN id="token-15-3" pos="word" morph="none" start_char="590" end_char="594">state</TOKEN>
        <TOKEN id="token-15-4" pos="word" morph="none" start_char="596" end_char="606">prosecutors</TOKEN>
        <TOKEN id="token-15-5" pos="word" morph="none" start_char="608" end_char="610">was</TOKEN>
        <TOKEN id="token-15-6" pos="word" morph="none" start_char="612" end_char="618">granted</TOKEN>
        <TOKEN id="token-15-7" pos="punct" morph="none" start_char="619" end_char="619">.</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="621" end_char="624">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="unknown" morph="none" start_char="621" end_char="624">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="626" end_char="628">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="unknown" morph="none" start_char="626" end_char="628">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="630" end_char="707">
        <ORIGINAL_TEXT>It means the case, ongoing for almost 10 months, will reopen in South Africa's</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="word" morph="none" start_char="630" end_char="631">It</TOKEN>
        <TOKEN id="token-18-1" pos="word" morph="none" start_char="633" end_char="637">means</TOKEN>
        <TOKEN id="token-18-2" pos="word" morph="none" start_char="639" end_char="641">the</TOKEN>
        <TOKEN id="token-18-3" pos="word" morph="none" start_char="643" end_char="646">case</TOKEN>
        <TOKEN id="token-18-4" pos="punct" morph="none" start_char="647" end_char="647">,</TOKEN>
        <TOKEN id="token-18-5" pos="word" morph="none" start_char="649" end_char="655">ongoing</TOKEN>
        <TOKEN id="token-18-6" pos="word" morph="none" start_char="657" end_char="659">for</TOKEN>
        <TOKEN id="token-18-7" pos="word" morph="none" start_char="661" end_char="666">almost</TOKEN>
        <TOKEN id="token-18-8" pos="number" morph="none" start_char="668" end_char="669">10</TOKEN>
        <TOKEN id="token-18-9" pos="word" morph="none" start_char="671" end_char="676">months</TOKEN>
        <TOKEN id="token-18-10" pos="punct" morph="none" start_char="677" end_char="677">,</TOKEN>
        <TOKEN id="token-18-11" pos="word" morph="none" start_char="679" end_char="682">will</TOKEN>
        <TOKEN id="token-18-12" pos="word" morph="none" start_char="684" end_char="689">reopen</TOKEN>
        <TOKEN id="token-18-13" pos="word" morph="none" start_char="691" end_char="692">in</TOKEN>
        <TOKEN id="token-18-14" pos="word" morph="none" start_char="694" end_char="698">South</TOKEN>
        <TOKEN id="token-18-15" pos="word" morph="none" start_char="700" end_char="705">Africa</TOKEN>
        <TOKEN id="token-18-16" pos="punct" morph="none" start_char="706" end_char="706">'</TOKEN>
        <TOKEN id="token-18-17" pos="word" morph="none" start_char="707" end_char="707">s</TOKEN>
      </SEG>
      <SEG id="segment-19" start_char="709" end_char="784">
        <ORIGINAL_TEXT>court of appeal in Bloemfontein, and be heard by a panel of five new judges.</ORIGINAL_TEXT>
        <TOKEN id="token-19-0" pos="word" morph="none" start_char="709" end_char="713">court</TOKEN>
        <TOKEN id="token-19-1" pos="word" morph="none" start_char="715" end_char="716">of</TOKEN>
        <TOKEN id="token-19-2" pos="word" morph="none" start_char="718" end_char="723">appeal</TOKEN>
        <TOKEN id="token-19-3" pos="word" morph="none" start_char="725" end_char="726">in</TOKEN>
        <TOKEN id="token-19-4" pos="word" morph="none" start_char="728" end_char="739">Bloemfontein</TOKEN>
        <TOKEN id="token-19-5" pos="punct" morph="none" start_char="740" end_char="740">,</TOKEN>
        <TOKEN id="token-19-6" pos="word" morph="none" start_char="742" end_char="744">and</TOKEN>
        <TOKEN id="token-19-7" pos="word" morph="none" start_char="746" end_char="747">be</TOKEN>
        <TOKEN id="token-19-8" pos="word" morph="none" start_char="749" end_char="753">heard</TOKEN>
        <TOKEN id="token-19-9" pos="word" morph="none" start_char="755" end_char="756">by</TOKEN>
        <TOKEN id="token-19-10" pos="word" morph="none" start_char="758" end_char="758">a</TOKEN>
        <TOKEN id="token-19-11" pos="word" morph="none" start_char="760" end_char="764">panel</TOKEN>
        <TOKEN id="token-19-12" pos="word" morph="none" start_char="766" end_char="767">of</TOKEN>
        <TOKEN id="token-19-13" pos="word" morph="none" start_char="769" end_char="772">five</TOKEN>
        <TOKEN id="token-19-14" pos="word" morph="none" start_char="774" end_char="776">new</TOKEN>
        <TOKEN id="token-19-15" pos="word" morph="none" start_char="778" end_char="783">judges</TOKEN>
        <TOKEN id="token-19-16" pos="punct" morph="none" start_char="784" end_char="784">.</TOKEN>
      </SEG>
      <SEG id="segment-20" start_char="786" end_char="789">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-20-0" pos="unknown" morph="none" start_char="786" end_char="789">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-21" start_char="791" end_char="793">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-21-0" pos="unknown" morph="none" start_char="791" end_char="793">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-22" start_char="795" end_char="872">
        <ORIGINAL_TEXT>Granting the application, Judge Thokozile Masipa, who heard the original case,</ORIGINAL_TEXT>
        <TOKEN id="token-22-0" pos="word" morph="none" start_char="795" end_char="802">Granting</TOKEN>
        <TOKEN id="token-22-1" pos="word" morph="none" start_char="804" end_char="806">the</TOKEN>
        <TOKEN id="token-22-2" pos="word" morph="none" start_char="808" end_char="818">application</TOKEN>
        <TOKEN id="token-22-3" pos="punct" morph="none" start_char="819" end_char="819">,</TOKEN>
        <TOKEN id="token-22-4" pos="word" morph="none" start_char="821" end_char="825">Judge</TOKEN>
        <TOKEN id="token-22-5" pos="word" morph="none" start_char="827" end_char="835">Thokozile</TOKEN>
        <TOKEN id="token-22-6" pos="word" morph="none" start_char="837" end_char="842">Masipa</TOKEN>
        <TOKEN id="token-22-7" pos="punct" morph="none" start_char="843" end_char="843">,</TOKEN>
        <TOKEN id="token-22-8" pos="word" morph="none" start_char="845" end_char="847">who</TOKEN>
        <TOKEN id="token-22-9" pos="word" morph="none" start_char="849" end_char="853">heard</TOKEN>
        <TOKEN id="token-22-10" pos="word" morph="none" start_char="855" end_char="857">the</TOKEN>
        <TOKEN id="token-22-11" pos="word" morph="none" start_char="859" end_char="866">original</TOKEN>
        <TOKEN id="token-22-12" pos="word" morph="none" start_char="868" end_char="871">case</TOKEN>
        <TOKEN id="token-22-13" pos="punct" morph="none" start_char="872" end_char="872">,</TOKEN>
      </SEG>
      <SEG id="segment-23" start_char="874" end_char="944">
        <ORIGINAL_TEXT>said the appeal made by state prosecutor Gerrie Nel showed that the law</ORIGINAL_TEXT>
        <TOKEN id="token-23-0" pos="word" morph="none" start_char="874" end_char="877">said</TOKEN>
        <TOKEN id="token-23-1" pos="word" morph="none" start_char="879" end_char="881">the</TOKEN>
        <TOKEN id="token-23-2" pos="word" morph="none" start_char="883" end_char="888">appeal</TOKEN>
        <TOKEN id="token-23-3" pos="word" morph="none" start_char="890" end_char="893">made</TOKEN>
        <TOKEN id="token-23-4" pos="word" morph="none" start_char="895" end_char="896">by</TOKEN>
        <TOKEN id="token-23-5" pos="word" morph="none" start_char="898" end_char="902">state</TOKEN>
        <TOKEN id="token-23-6" pos="word" morph="none" start_char="904" end_char="913">prosecutor</TOKEN>
        <TOKEN id="token-23-7" pos="word" morph="none" start_char="915" end_char="920">Gerrie</TOKEN>
        <TOKEN id="token-23-8" pos="word" morph="none" start_char="922" end_char="924">Nel</TOKEN>
        <TOKEN id="token-23-9" pos="word" morph="none" start_char="926" end_char="931">showed</TOKEN>
        <TOKEN id="token-23-10" pos="word" morph="none" start_char="933" end_char="936">that</TOKEN>
        <TOKEN id="token-23-11" pos="word" morph="none" start_char="938" end_char="940">the</TOKEN>
        <TOKEN id="token-23-12" pos="word" morph="none" start_char="942" end_char="944">law</TOKEN>
      </SEG>
      <SEG id="segment-24" start_char="946" end_char="1009">
        <ORIGINAL_TEXT>applied to the case could be open to a different interpretation.</ORIGINAL_TEXT>
        <TOKEN id="token-24-0" pos="word" morph="none" start_char="946" end_char="952">applied</TOKEN>
        <TOKEN id="token-24-1" pos="word" morph="none" start_char="954" end_char="955">to</TOKEN>
        <TOKEN id="token-24-2" pos="word" morph="none" start_char="957" end_char="959">the</TOKEN>
        <TOKEN id="token-24-3" pos="word" morph="none" start_char="961" end_char="964">case</TOKEN>
        <TOKEN id="token-24-4" pos="word" morph="none" start_char="966" end_char="970">could</TOKEN>
        <TOKEN id="token-24-5" pos="word" morph="none" start_char="972" end_char="973">be</TOKEN>
        <TOKEN id="token-24-6" pos="word" morph="none" start_char="975" end_char="978">open</TOKEN>
        <TOKEN id="token-24-7" pos="word" morph="none" start_char="980" end_char="981">to</TOKEN>
        <TOKEN id="token-24-8" pos="word" morph="none" start_char="983" end_char="983">a</TOKEN>
        <TOKEN id="token-24-9" pos="word" morph="none" start_char="985" end_char="993">different</TOKEN>
        <TOKEN id="token-24-10" pos="word" morph="none" start_char="995" end_char="1008">interpretation</TOKEN>
        <TOKEN id="token-24-11" pos="punct" morph="none" start_char="1009" end_char="1009">.</TOKEN>
      </SEG>
      <SEG id="segment-25" start_char="1011" end_char="1014">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-25-0" pos="unknown" morph="none" start_char="1011" end_char="1014">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-26" start_char="1016" end_char="1018">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-26-0" pos="unknown" morph="none" start_char="1016" end_char="1018">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-27" start_char="1020" end_char="1096">
        <ORIGINAL_TEXT>"I cannot say ... that the prospect of success at the supreme court of appeal</ORIGINAL_TEXT>
        <TOKEN id="token-27-0" pos="punct" morph="none" start_char="1020" end_char="1020">"</TOKEN>
        <TOKEN id="token-27-1" pos="word" morph="none" start_char="1021" end_char="1021">I</TOKEN>
        <TOKEN id="token-27-2" pos="word" morph="none" start_char="1023" end_char="1028">cannot</TOKEN>
        <TOKEN id="token-27-3" pos="word" morph="none" start_char="1030" end_char="1032">say</TOKEN>
        <TOKEN id="token-27-4" pos="unknown" morph="none" start_char="1034" end_char="1036">...</TOKEN>
        <TOKEN id="token-27-5" pos="word" morph="none" start_char="1038" end_char="1041">that</TOKEN>
        <TOKEN id="token-27-6" pos="word" morph="none" start_char="1043" end_char="1045">the</TOKEN>
        <TOKEN id="token-27-7" pos="word" morph="none" start_char="1047" end_char="1054">prospect</TOKEN>
        <TOKEN id="token-27-8" pos="word" morph="none" start_char="1056" end_char="1057">of</TOKEN>
        <TOKEN id="token-27-9" pos="word" morph="none" start_char="1059" end_char="1065">success</TOKEN>
        <TOKEN id="token-27-10" pos="word" morph="none" start_char="1067" end_char="1068">at</TOKEN>
        <TOKEN id="token-27-11" pos="word" morph="none" start_char="1070" end_char="1072">the</TOKEN>
        <TOKEN id="token-27-12" pos="word" morph="none" start_char="1074" end_char="1080">supreme</TOKEN>
        <TOKEN id="token-27-13" pos="word" morph="none" start_char="1082" end_char="1086">court</TOKEN>
        <TOKEN id="token-27-14" pos="word" morph="none" start_char="1088" end_char="1089">of</TOKEN>
        <TOKEN id="token-27-15" pos="word" morph="none" start_char="1091" end_char="1096">appeal</TOKEN>
      </SEG>
      <SEG id="segment-28" start_char="1098" end_char="1158">
        <ORIGINAL_TEXT>is remote," Judge Masipa ruled at the High Court in Pretoria.</ORIGINAL_TEXT>
        <TOKEN id="token-28-0" pos="word" morph="none" start_char="1098" end_char="1099">is</TOKEN>
        <TOKEN id="token-28-1" pos="word" morph="none" start_char="1101" end_char="1106">remote</TOKEN>
        <TOKEN id="token-28-2" pos="punct" morph="none" start_char="1107" end_char="1108">,"</TOKEN>
        <TOKEN id="token-28-3" pos="word" morph="none" start_char="1110" end_char="1114">Judge</TOKEN>
        <TOKEN id="token-28-4" pos="word" morph="none" start_char="1116" end_char="1121">Masipa</TOKEN>
        <TOKEN id="token-28-5" pos="word" morph="none" start_char="1123" end_char="1127">ruled</TOKEN>
        <TOKEN id="token-28-6" pos="word" morph="none" start_char="1129" end_char="1130">at</TOKEN>
        <TOKEN id="token-28-7" pos="word" morph="none" start_char="1132" end_char="1134">the</TOKEN>
        <TOKEN id="token-28-8" pos="word" morph="none" start_char="1136" end_char="1139">High</TOKEN>
        <TOKEN id="token-28-9" pos="word" morph="none" start_char="1141" end_char="1145">Court</TOKEN>
        <TOKEN id="token-28-10" pos="word" morph="none" start_char="1147" end_char="1148">in</TOKEN>
        <TOKEN id="token-28-11" pos="word" morph="none" start_char="1150" end_char="1157">Pretoria</TOKEN>
        <TOKEN id="token-28-12" pos="punct" morph="none" start_char="1158" end_char="1158">.</TOKEN>
      </SEG>
      <SEG id="segment-29" start_char="1160" end_char="1163">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-29-0" pos="unknown" morph="none" start_char="1160" end_char="1163">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-30" start_char="1165" end_char="1167">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-30-0" pos="unknown" morph="none" start_char="1165" end_char="1167">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-31" start_char="1169" end_char="1244">
        <ORIGINAL_TEXT>"The application, therefore, in respect of count one is decided in favour of</ORIGINAL_TEXT>
        <TOKEN id="token-31-0" pos="punct" morph="none" start_char="1169" end_char="1169">"</TOKEN>
        <TOKEN id="token-31-1" pos="word" morph="none" start_char="1170" end_char="1172">The</TOKEN>
        <TOKEN id="token-31-2" pos="word" morph="none" start_char="1174" end_char="1184">application</TOKEN>
        <TOKEN id="token-31-3" pos="punct" morph="none" start_char="1185" end_char="1185">,</TOKEN>
        <TOKEN id="token-31-4" pos="word" morph="none" start_char="1187" end_char="1195">therefore</TOKEN>
        <TOKEN id="token-31-5" pos="punct" morph="none" start_char="1196" end_char="1196">,</TOKEN>
        <TOKEN id="token-31-6" pos="word" morph="none" start_char="1198" end_char="1199">in</TOKEN>
        <TOKEN id="token-31-7" pos="word" morph="none" start_char="1201" end_char="1207">respect</TOKEN>
        <TOKEN id="token-31-8" pos="word" morph="none" start_char="1209" end_char="1210">of</TOKEN>
        <TOKEN id="token-31-9" pos="word" morph="none" start_char="1212" end_char="1216">count</TOKEN>
        <TOKEN id="token-31-10" pos="word" morph="none" start_char="1218" end_char="1220">one</TOKEN>
        <TOKEN id="token-31-11" pos="word" morph="none" start_char="1222" end_char="1223">is</TOKEN>
        <TOKEN id="token-31-12" pos="word" morph="none" start_char="1225" end_char="1231">decided</TOKEN>
        <TOKEN id="token-31-13" pos="word" morph="none" start_char="1233" end_char="1234">in</TOKEN>
        <TOKEN id="token-31-14" pos="word" morph="none" start_char="1236" end_char="1241">favour</TOKEN>
        <TOKEN id="token-31-15" pos="word" morph="none" start_char="1243" end_char="1244">of</TOKEN>
      </SEG>
      <SEG id="segment-32" start_char="1246" end_char="1260">
        <ORIGINAL_TEXT>the applicant."</ORIGINAL_TEXT>
        <TOKEN id="token-32-0" pos="word" morph="none" start_char="1246" end_char="1248">the</TOKEN>
        <TOKEN id="token-32-1" pos="word" morph="none" start_char="1250" end_char="1258">applicant</TOKEN>
        <TOKEN id="token-32-2" pos="punct" morph="none" start_char="1259" end_char="1260">."</TOKEN>
      </SEG>
      <SEG id="segment-33" start_char="1262" end_char="1265">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-33-0" pos="unknown" morph="none" start_char="1262" end_char="1265">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-34" start_char="1267" end_char="1269">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-34-0" pos="unknown" morph="none" start_char="1267" end_char="1269">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-35" start_char="1271" end_char="1348">
        <ORIGINAL_TEXT>Oscar Pistorius himself was not present to hear the application. He remains in</ORIGINAL_TEXT>
        <TOKEN id="token-35-0" pos="word" morph="none" start_char="1271" end_char="1275">Oscar</TOKEN>
        <TOKEN id="token-35-1" pos="word" morph="none" start_char="1277" end_char="1285">Pistorius</TOKEN>
        <TOKEN id="token-35-2" pos="word" morph="none" start_char="1287" end_char="1293">himself</TOKEN>
        <TOKEN id="token-35-3" pos="word" morph="none" start_char="1295" end_char="1297">was</TOKEN>
        <TOKEN id="token-35-4" pos="word" morph="none" start_char="1299" end_char="1301">not</TOKEN>
        <TOKEN id="token-35-5" pos="word" morph="none" start_char="1303" end_char="1309">present</TOKEN>
        <TOKEN id="token-35-6" pos="word" morph="none" start_char="1311" end_char="1312">to</TOKEN>
        <TOKEN id="token-35-7" pos="word" morph="none" start_char="1314" end_char="1317">hear</TOKEN>
        <TOKEN id="token-35-8" pos="word" morph="none" start_char="1319" end_char="1321">the</TOKEN>
        <TOKEN id="token-35-9" pos="word" morph="none" start_char="1323" end_char="1333">application</TOKEN>
        <TOKEN id="token-35-10" pos="punct" morph="none" start_char="1334" end_char="1334">.</TOKEN>
        <TOKEN id="token-35-11" pos="word" morph="none" start_char="1336" end_char="1337">He</TOKEN>
        <TOKEN id="token-35-12" pos="word" morph="none" start_char="1339" end_char="1345">remains</TOKEN>
        <TOKEN id="token-35-13" pos="word" morph="none" start_char="1347" end_char="1348">in</TOKEN>
      </SEG>
      <SEG id="segment-36" start_char="1350" end_char="1427">
        <ORIGINAL_TEXT>prison in Pretoria, and will do so for at least another eight months, at which</ORIGINAL_TEXT>
        <TOKEN id="token-36-0" pos="word" morph="none" start_char="1350" end_char="1355">prison</TOKEN>
        <TOKEN id="token-36-1" pos="word" morph="none" start_char="1357" end_char="1358">in</TOKEN>
        <TOKEN id="token-36-2" pos="word" morph="none" start_char="1360" end_char="1367">Pretoria</TOKEN>
        <TOKEN id="token-36-3" pos="punct" morph="none" start_char="1368" end_char="1368">,</TOKEN>
        <TOKEN id="token-36-4" pos="word" morph="none" start_char="1370" end_char="1372">and</TOKEN>
        <TOKEN id="token-36-5" pos="word" morph="none" start_char="1374" end_char="1377">will</TOKEN>
        <TOKEN id="token-36-6" pos="word" morph="none" start_char="1379" end_char="1380">do</TOKEN>
        <TOKEN id="token-36-7" pos="word" morph="none" start_char="1382" end_char="1383">so</TOKEN>
        <TOKEN id="token-36-8" pos="word" morph="none" start_char="1385" end_char="1387">for</TOKEN>
        <TOKEN id="token-36-9" pos="word" morph="none" start_char="1389" end_char="1390">at</TOKEN>
        <TOKEN id="token-36-10" pos="word" morph="none" start_char="1392" end_char="1396">least</TOKEN>
        <TOKEN id="token-36-11" pos="word" morph="none" start_char="1398" end_char="1404">another</TOKEN>
        <TOKEN id="token-36-12" pos="word" morph="none" start_char="1406" end_char="1410">eight</TOKEN>
        <TOKEN id="token-36-13" pos="word" morph="none" start_char="1412" end_char="1417">months</TOKEN>
        <TOKEN id="token-36-14" pos="punct" morph="none" start_char="1418" end_char="1418">,</TOKEN>
        <TOKEN id="token-36-15" pos="word" morph="none" start_char="1420" end_char="1421">at</TOKEN>
        <TOKEN id="token-36-16" pos="word" morph="none" start_char="1423" end_char="1427">which</TOKEN>
      </SEG>
      <SEG id="segment-37" start_char="1429" end_char="1469">
        <ORIGINAL_TEXT>point he will become eligible for parole.</ORIGINAL_TEXT>
        <TOKEN id="token-37-0" pos="word" morph="none" start_char="1429" end_char="1433">point</TOKEN>
        <TOKEN id="token-37-1" pos="word" morph="none" start_char="1435" end_char="1436">he</TOKEN>
        <TOKEN id="token-37-2" pos="word" morph="none" start_char="1438" end_char="1441">will</TOKEN>
        <TOKEN id="token-37-3" pos="word" morph="none" start_char="1443" end_char="1448">become</TOKEN>
        <TOKEN id="token-37-4" pos="word" morph="none" start_char="1450" end_char="1457">eligible</TOKEN>
        <TOKEN id="token-37-5" pos="word" morph="none" start_char="1459" end_char="1461">for</TOKEN>
        <TOKEN id="token-37-6" pos="word" morph="none" start_char="1463" end_char="1468">parole</TOKEN>
        <TOKEN id="token-37-7" pos="punct" morph="none" start_char="1469" end_char="1469">.</TOKEN>
      </SEG>
      <SEG id="segment-38" start_char="1471" end_char="1474">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-38-0" pos="unknown" morph="none" start_char="1471" end_char="1474">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-39" start_char="1476" end_char="1478">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-39-0" pos="unknown" morph="none" start_char="1476" end_char="1478">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-40" start_char="1480" end_char="1555">
        <ORIGINAL_TEXT>South Africa's Supreme Court will not be asked to decide whether the athlete</ORIGINAL_TEXT>
        <TOKEN id="token-40-0" pos="word" morph="none" start_char="1480" end_char="1484">South</TOKEN>
        <TOKEN id="token-40-1" pos="word" morph="none" start_char="1486" end_char="1491">Africa</TOKEN>
        <TOKEN id="token-40-2" pos="punct" morph="none" start_char="1492" end_char="1492">'</TOKEN>
        <TOKEN id="token-40-3" pos="word" morph="none" start_char="1493" end_char="1493">s</TOKEN>
        <TOKEN id="token-40-4" pos="word" morph="none" start_char="1495" end_char="1501">Supreme</TOKEN>
        <TOKEN id="token-40-5" pos="word" morph="none" start_char="1503" end_char="1507">Court</TOKEN>
        <TOKEN id="token-40-6" pos="word" morph="none" start_char="1509" end_char="1512">will</TOKEN>
        <TOKEN id="token-40-7" pos="word" morph="none" start_char="1514" end_char="1516">not</TOKEN>
        <TOKEN id="token-40-8" pos="word" morph="none" start_char="1518" end_char="1519">be</TOKEN>
        <TOKEN id="token-40-9" pos="word" morph="none" start_char="1521" end_char="1525">asked</TOKEN>
        <TOKEN id="token-40-10" pos="word" morph="none" start_char="1527" end_char="1528">to</TOKEN>
        <TOKEN id="token-40-11" pos="word" morph="none" start_char="1530" end_char="1535">decide</TOKEN>
        <TOKEN id="token-40-12" pos="word" morph="none" start_char="1537" end_char="1543">whether</TOKEN>
        <TOKEN id="token-40-13" pos="word" morph="none" start_char="1545" end_char="1547">the</TOKEN>
        <TOKEN id="token-40-14" pos="word" morph="none" start_char="1549" end_char="1555">athlete</TOKEN>
      </SEG>
      <SEG id="segment-41" start_char="1557" end_char="1634">
        <ORIGINAL_TEXT>knew his girlfriend Reeva Steenkamp was behind the bathroom door when he fired</ORIGINAL_TEXT>
        <TOKEN id="token-41-0" pos="word" morph="none" start_char="1557" end_char="1560">knew</TOKEN>
        <TOKEN id="token-41-1" pos="word" morph="none" start_char="1562" end_char="1564">his</TOKEN>
        <TOKEN id="token-41-2" pos="word" morph="none" start_char="1566" end_char="1575">girlfriend</TOKEN>
        <TOKEN id="token-41-3" pos="word" morph="none" start_char="1577" end_char="1581">Reeva</TOKEN>
        <TOKEN id="token-41-4" pos="word" morph="none" start_char="1583" end_char="1591">Steenkamp</TOKEN>
        <TOKEN id="token-41-5" pos="word" morph="none" start_char="1593" end_char="1595">was</TOKEN>
        <TOKEN id="token-41-6" pos="word" morph="none" start_char="1597" end_char="1602">behind</TOKEN>
        <TOKEN id="token-41-7" pos="word" morph="none" start_char="1604" end_char="1606">the</TOKEN>
        <TOKEN id="token-41-8" pos="word" morph="none" start_char="1608" end_char="1615">bathroom</TOKEN>
        <TOKEN id="token-41-9" pos="word" morph="none" start_char="1617" end_char="1620">door</TOKEN>
        <TOKEN id="token-41-10" pos="word" morph="none" start_char="1622" end_char="1625">when</TOKEN>
        <TOKEN id="token-41-11" pos="word" morph="none" start_char="1627" end_char="1628">he</TOKEN>
        <TOKEN id="token-41-12" pos="word" morph="none" start_char="1630" end_char="1634">fired</TOKEN>
      </SEG>
      <SEG id="segment-42" start_char="1636" end_char="1713">
        <ORIGINAL_TEXT>four shots through it in the early hours of Valentine's Day morning last year.</ORIGINAL_TEXT>
        <TOKEN id="token-42-0" pos="word" morph="none" start_char="1636" end_char="1639">four</TOKEN>
        <TOKEN id="token-42-1" pos="word" morph="none" start_char="1641" end_char="1645">shots</TOKEN>
        <TOKEN id="token-42-2" pos="word" morph="none" start_char="1647" end_char="1653">through</TOKEN>
        <TOKEN id="token-42-3" pos="word" morph="none" start_char="1655" end_char="1656">it</TOKEN>
        <TOKEN id="token-42-4" pos="word" morph="none" start_char="1658" end_char="1659">in</TOKEN>
        <TOKEN id="token-42-5" pos="word" morph="none" start_char="1661" end_char="1663">the</TOKEN>
        <TOKEN id="token-42-6" pos="word" morph="none" start_char="1665" end_char="1669">early</TOKEN>
        <TOKEN id="token-42-7" pos="word" morph="none" start_char="1671" end_char="1675">hours</TOKEN>
        <TOKEN id="token-42-8" pos="word" morph="none" start_char="1677" end_char="1678">of</TOKEN>
        <TOKEN id="token-42-9" pos="word" morph="none" start_char="1680" end_char="1688">Valentine</TOKEN>
        <TOKEN id="token-42-10" pos="punct" morph="none" start_char="1689" end_char="1689">'</TOKEN>
        <TOKEN id="token-42-11" pos="word" morph="none" start_char="1690" end_char="1690">s</TOKEN>
        <TOKEN id="token-42-12" pos="word" morph="none" start_char="1692" end_char="1694">Day</TOKEN>
        <TOKEN id="token-42-13" pos="word" morph="none" start_char="1696" end_char="1702">morning</TOKEN>
        <TOKEN id="token-42-14" pos="word" morph="none" start_char="1704" end_char="1707">last</TOKEN>
        <TOKEN id="token-42-15" pos="word" morph="none" start_char="1709" end_char="1712">year</TOKEN>
        <TOKEN id="token-42-16" pos="punct" morph="none" start_char="1713" end_char="1713">.</TOKEN>
      </SEG>
      <SEG id="segment-43" start_char="1715" end_char="1718">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-43-0" pos="unknown" morph="none" start_char="1715" end_char="1718">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-44" start_char="1720" end_char="1722">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-44-0" pos="unknown" morph="none" start_char="1720" end_char="1722">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-45" start_char="1724" end_char="1800">
        <ORIGINAL_TEXT>By his own admission, Pistorius believed an intruder was behind the door, and</ORIGINAL_TEXT>
        <TOKEN id="token-45-0" pos="word" morph="none" start_char="1724" end_char="1725">By</TOKEN>
        <TOKEN id="token-45-1" pos="word" morph="none" start_char="1727" end_char="1729">his</TOKEN>
        <TOKEN id="token-45-2" pos="word" morph="none" start_char="1731" end_char="1733">own</TOKEN>
        <TOKEN id="token-45-3" pos="word" morph="none" start_char="1735" end_char="1743">admission</TOKEN>
        <TOKEN id="token-45-4" pos="punct" morph="none" start_char="1744" end_char="1744">,</TOKEN>
        <TOKEN id="token-45-5" pos="word" morph="none" start_char="1746" end_char="1754">Pistorius</TOKEN>
        <TOKEN id="token-45-6" pos="word" morph="none" start_char="1756" end_char="1763">believed</TOKEN>
        <TOKEN id="token-45-7" pos="word" morph="none" start_char="1765" end_char="1766">an</TOKEN>
        <TOKEN id="token-45-8" pos="word" morph="none" start_char="1768" end_char="1775">intruder</TOKEN>
        <TOKEN id="token-45-9" pos="word" morph="none" start_char="1777" end_char="1779">was</TOKEN>
        <TOKEN id="token-45-10" pos="word" morph="none" start_char="1781" end_char="1786">behind</TOKEN>
        <TOKEN id="token-45-11" pos="word" morph="none" start_char="1788" end_char="1790">the</TOKEN>
        <TOKEN id="token-45-12" pos="word" morph="none" start_char="1792" end_char="1795">door</TOKEN>
        <TOKEN id="token-45-13" pos="punct" morph="none" start_char="1796" end_char="1796">,</TOKEN>
        <TOKEN id="token-45-14" pos="word" morph="none" start_char="1798" end_char="1800">and</TOKEN>
      </SEG>
      <SEG id="segment-46" start_char="1802" end_char="1879">
        <ORIGINAL_TEXT>the case will hinge on whether the athlete foresaw that his actions would kill</ORIGINAL_TEXT>
        <TOKEN id="token-46-0" pos="word" morph="none" start_char="1802" end_char="1804">the</TOKEN>
        <TOKEN id="token-46-1" pos="word" morph="none" start_char="1806" end_char="1809">case</TOKEN>
        <TOKEN id="token-46-2" pos="word" morph="none" start_char="1811" end_char="1814">will</TOKEN>
        <TOKEN id="token-46-3" pos="word" morph="none" start_char="1816" end_char="1820">hinge</TOKEN>
        <TOKEN id="token-46-4" pos="word" morph="none" start_char="1822" end_char="1823">on</TOKEN>
        <TOKEN id="token-46-5" pos="word" morph="none" start_char="1825" end_char="1831">whether</TOKEN>
        <TOKEN id="token-46-6" pos="word" morph="none" start_char="1833" end_char="1835">the</TOKEN>
        <TOKEN id="token-46-7" pos="word" morph="none" start_char="1837" end_char="1843">athlete</TOKEN>
        <TOKEN id="token-46-8" pos="word" morph="none" start_char="1845" end_char="1851">foresaw</TOKEN>
        <TOKEN id="token-46-9" pos="word" morph="none" start_char="1853" end_char="1856">that</TOKEN>
        <TOKEN id="token-46-10" pos="word" morph="none" start_char="1858" end_char="1860">his</TOKEN>
        <TOKEN id="token-46-11" pos="word" morph="none" start_char="1862" end_char="1868">actions</TOKEN>
        <TOKEN id="token-46-12" pos="word" morph="none" start_char="1870" end_char="1874">would</TOKEN>
        <TOKEN id="token-46-13" pos="word" morph="none" start_char="1876" end_char="1879">kill</TOKEN>
      </SEG>
      <SEG id="segment-47" start_char="1881" end_char="1892">
        <ORIGINAL_TEXT>that person.</ORIGINAL_TEXT>
        <TOKEN id="token-47-0" pos="word" morph="none" start_char="1881" end_char="1884">that</TOKEN>
        <TOKEN id="token-47-1" pos="word" morph="none" start_char="1886" end_char="1891">person</TOKEN>
        <TOKEN id="token-47-2" pos="punct" morph="none" start_char="1892" end_char="1892">.</TOKEN>
      </SEG>
      <SEG id="segment-48" start_char="1894" end_char="1897">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-48-0" pos="unknown" morph="none" start_char="1894" end_char="1897">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-49" start_char="1899" end_char="1901">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-49-0" pos="unknown" morph="none" start_char="1899" end_char="1901">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-50" start_char="1903" end_char="1976">
        <ORIGINAL_TEXT>In her sentencing, Judge Masipa decided that while he should have foreseen</ORIGINAL_TEXT>
        <TOKEN id="token-50-0" pos="word" morph="none" start_char="1903" end_char="1904">In</TOKEN>
        <TOKEN id="token-50-1" pos="word" morph="none" start_char="1906" end_char="1908">her</TOKEN>
        <TOKEN id="token-50-2" pos="word" morph="none" start_char="1910" end_char="1919">sentencing</TOKEN>
        <TOKEN id="token-50-3" pos="punct" morph="none" start_char="1920" end_char="1920">,</TOKEN>
        <TOKEN id="token-50-4" pos="word" morph="none" start_char="1922" end_char="1926">Judge</TOKEN>
        <TOKEN id="token-50-5" pos="word" morph="none" start_char="1928" end_char="1933">Masipa</TOKEN>
        <TOKEN id="token-50-6" pos="word" morph="none" start_char="1935" end_char="1941">decided</TOKEN>
        <TOKEN id="token-50-7" pos="word" morph="none" start_char="1943" end_char="1946">that</TOKEN>
        <TOKEN id="token-50-8" pos="word" morph="none" start_char="1948" end_char="1952">while</TOKEN>
        <TOKEN id="token-50-9" pos="word" morph="none" start_char="1954" end_char="1955">he</TOKEN>
        <TOKEN id="token-50-10" pos="word" morph="none" start_char="1957" end_char="1962">should</TOKEN>
        <TOKEN id="token-50-11" pos="word" morph="none" start_char="1964" end_char="1967">have</TOKEN>
        <TOKEN id="token-50-12" pos="word" morph="none" start_char="1969" end_char="1976">foreseen</TOKEN>
      </SEG>
      <SEG id="segment-51" start_char="1978" end_char="1993">
        <ORIGINAL_TEXT>this, he didn't.</ORIGINAL_TEXT>
        <TOKEN id="token-51-0" pos="word" morph="none" start_char="1978" end_char="1981">this</TOKEN>
        <TOKEN id="token-51-1" pos="punct" morph="none" start_char="1982" end_char="1982">,</TOKEN>
        <TOKEN id="token-51-2" pos="word" morph="none" start_char="1984" end_char="1985">he</TOKEN>
        <TOKEN id="token-51-3" pos="word" morph="none" start_char="1987" end_char="1990">didn</TOKEN>
        <TOKEN id="token-51-4" pos="punct" morph="none" start_char="1991" end_char="1991">'</TOKEN>
        <TOKEN id="token-51-5" pos="word" morph="none" start_char="1992" end_char="1992">t</TOKEN>
        <TOKEN id="token-51-6" pos="punct" morph="none" start_char="1993" end_char="1993">.</TOKEN>
      </SEG>
      <SEG id="segment-52" start_char="1995" end_char="1998">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-52-0" pos="unknown" morph="none" start_char="1995" end_char="1998">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-53" start_char="2000" end_char="2002">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-53-0" pos="unknown" morph="none" start_char="2000" end_char="2002">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-54" start_char="2004" end_char="2081">
        <ORIGINAL_TEXT>If the Supreme Court decides otherwise, he could be convicted of second-degree</ORIGINAL_TEXT>
        <TOKEN id="token-54-0" pos="word" morph="none" start_char="2004" end_char="2005">If</TOKEN>
        <TOKEN id="token-54-1" pos="word" morph="none" start_char="2007" end_char="2009">the</TOKEN>
        <TOKEN id="token-54-2" pos="word" morph="none" start_char="2011" end_char="2017">Supreme</TOKEN>
        <TOKEN id="token-54-3" pos="word" morph="none" start_char="2019" end_char="2023">Court</TOKEN>
        <TOKEN id="token-54-4" pos="word" morph="none" start_char="2025" end_char="2031">decides</TOKEN>
        <TOKEN id="token-54-5" pos="word" morph="none" start_char="2033" end_char="2041">otherwise</TOKEN>
        <TOKEN id="token-54-6" pos="punct" morph="none" start_char="2042" end_char="2042">,</TOKEN>
        <TOKEN id="token-54-7" pos="word" morph="none" start_char="2044" end_char="2045">he</TOKEN>
        <TOKEN id="token-54-8" pos="word" morph="none" start_char="2047" end_char="2051">could</TOKEN>
        <TOKEN id="token-54-9" pos="word" morph="none" start_char="2053" end_char="2054">be</TOKEN>
        <TOKEN id="token-54-10" pos="word" morph="none" start_char="2056" end_char="2064">convicted</TOKEN>
        <TOKEN id="token-54-11" pos="word" morph="none" start_char="2066" end_char="2067">of</TOKEN>
        <TOKEN id="token-54-12" pos="word" morph="none" start_char="2069" end_char="2074">second</TOKEN>
        <TOKEN id="token-54-13" pos="punct" morph="none" start_char="2075" end_char="2075">-</TOKEN>
        <TOKEN id="token-54-14" pos="word" morph="none" start_char="2076" end_char="2081">degree</TOKEN>
      </SEG>
      <SEG id="segment-55" start_char="2083" end_char="2159">
        <ORIGINAL_TEXT>murder, on the principle of dolus eventualis, the Latin term that has hovered</ORIGINAL_TEXT>
        <TOKEN id="token-55-0" pos="word" morph="none" start_char="2083" end_char="2088">murder</TOKEN>
        <TOKEN id="token-55-1" pos="punct" morph="none" start_char="2089" end_char="2089">,</TOKEN>
        <TOKEN id="token-55-2" pos="word" morph="none" start_char="2091" end_char="2092">on</TOKEN>
        <TOKEN id="token-55-3" pos="word" morph="none" start_char="2094" end_char="2096">the</TOKEN>
        <TOKEN id="token-55-4" pos="word" morph="none" start_char="2098" end_char="2106">principle</TOKEN>
        <TOKEN id="token-55-5" pos="word" morph="none" start_char="2108" end_char="2109">of</TOKEN>
        <TOKEN id="token-55-6" pos="word" morph="none" start_char="2111" end_char="2115">dolus</TOKEN>
        <TOKEN id="token-55-7" pos="word" morph="none" start_char="2117" end_char="2126">eventualis</TOKEN>
        <TOKEN id="token-55-8" pos="punct" morph="none" start_char="2127" end_char="2127">,</TOKEN>
        <TOKEN id="token-55-9" pos="word" morph="none" start_char="2129" end_char="2131">the</TOKEN>
        <TOKEN id="token-55-10" pos="word" morph="none" start_char="2133" end_char="2137">Latin</TOKEN>
        <TOKEN id="token-55-11" pos="word" morph="none" start_char="2139" end_char="2142">term</TOKEN>
        <TOKEN id="token-55-12" pos="word" morph="none" start_char="2144" end_char="2147">that</TOKEN>
        <TOKEN id="token-55-13" pos="word" morph="none" start_char="2149" end_char="2151">has</TOKEN>
        <TOKEN id="token-55-14" pos="word" morph="none" start_char="2153" end_char="2159">hovered</TOKEN>
      </SEG>
      <SEG id="segment-56" start_char="2161" end_char="2198">
        <ORIGINAL_TEXT>over this incredibly protracted trial.</ORIGINAL_TEXT>
        <TOKEN id="token-56-0" pos="word" morph="none" start_char="2161" end_char="2164">over</TOKEN>
        <TOKEN id="token-56-1" pos="word" morph="none" start_char="2166" end_char="2169">this</TOKEN>
        <TOKEN id="token-56-2" pos="word" morph="none" start_char="2171" end_char="2180">incredibly</TOKEN>
        <TOKEN id="token-56-3" pos="word" morph="none" start_char="2182" end_char="2191">protracted</TOKEN>
        <TOKEN id="token-56-4" pos="word" morph="none" start_char="2193" end_char="2197">trial</TOKEN>
        <TOKEN id="token-56-5" pos="punct" morph="none" start_char="2198" end_char="2198">.</TOKEN>
      </SEG>
      <SEG id="segment-57" start_char="2200" end_char="2203">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-57-0" pos="unknown" morph="none" start_char="2200" end_char="2203">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-58" start_char="2205" end_char="2207">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-58-0" pos="unknown" morph="none" start_char="2205" end_char="2207">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-59" start_char="2209" end_char="2278">
        <ORIGINAL_TEXT>Judge Masipa rejected the prosecution's application also to appeal the</ORIGINAL_TEXT>
        <TOKEN id="token-59-0" pos="word" morph="none" start_char="2209" end_char="2213">Judge</TOKEN>
        <TOKEN id="token-59-1" pos="word" morph="none" start_char="2215" end_char="2220">Masipa</TOKEN>
        <TOKEN id="token-59-2" pos="word" morph="none" start_char="2222" end_char="2229">rejected</TOKEN>
        <TOKEN id="token-59-3" pos="word" morph="none" start_char="2231" end_char="2233">the</TOKEN>
        <TOKEN id="token-59-4" pos="word" morph="none" start_char="2235" end_char="2245">prosecution</TOKEN>
        <TOKEN id="token-59-5" pos="punct" morph="none" start_char="2246" end_char="2246">'</TOKEN>
        <TOKEN id="token-59-6" pos="word" morph="none" start_char="2247" end_char="2247">s</TOKEN>
        <TOKEN id="token-59-7" pos="word" morph="none" start_char="2249" end_char="2259">application</TOKEN>
        <TOKEN id="token-59-8" pos="word" morph="none" start_char="2261" end_char="2264">also</TOKEN>
        <TOKEN id="token-59-9" pos="word" morph="none" start_char="2266" end_char="2267">to</TOKEN>
        <TOKEN id="token-59-10" pos="word" morph="none" start_char="2269" end_char="2274">appeal</TOKEN>
        <TOKEN id="token-59-11" pos="word" morph="none" start_char="2276" end_char="2278">the</TOKEN>
      </SEG>
      <SEG id="segment-60" start_char="2280" end_char="2349">
        <ORIGINAL_TEXT>sentence she laid down, of five years, which Mr Nel called "shockingly</ORIGINAL_TEXT>
        <TOKEN id="token-60-0" pos="word" morph="none" start_char="2280" end_char="2287">sentence</TOKEN>
        <TOKEN id="token-60-1" pos="word" morph="none" start_char="2289" end_char="2291">she</TOKEN>
        <TOKEN id="token-60-2" pos="word" morph="none" start_char="2293" end_char="2296">laid</TOKEN>
        <TOKEN id="token-60-3" pos="word" morph="none" start_char="2298" end_char="2301">down</TOKEN>
        <TOKEN id="token-60-4" pos="punct" morph="none" start_char="2302" end_char="2302">,</TOKEN>
        <TOKEN id="token-60-5" pos="word" morph="none" start_char="2304" end_char="2305">of</TOKEN>
        <TOKEN id="token-60-6" pos="word" morph="none" start_char="2307" end_char="2310">five</TOKEN>
        <TOKEN id="token-60-7" pos="word" morph="none" start_char="2312" end_char="2316">years</TOKEN>
        <TOKEN id="token-60-8" pos="punct" morph="none" start_char="2317" end_char="2317">,</TOKEN>
        <TOKEN id="token-60-9" pos="word" morph="none" start_char="2319" end_char="2323">which</TOKEN>
        <TOKEN id="token-60-10" pos="word" morph="none" start_char="2325" end_char="2326">Mr</TOKEN>
        <TOKEN id="token-60-11" pos="word" morph="none" start_char="2328" end_char="2330">Nel</TOKEN>
        <TOKEN id="token-60-12" pos="word" morph="none" start_char="2332" end_char="2337">called</TOKEN>
        <TOKEN id="token-60-13" pos="punct" morph="none" start_char="2339" end_char="2339">"</TOKEN>
        <TOKEN id="token-60-14" pos="word" morph="none" start_char="2340" end_char="2349">shockingly</TOKEN>
      </SEG>
      <SEG id="segment-61" start_char="2351" end_char="2365">
        <ORIGINAL_TEXT>inappropriate".</ORIGINAL_TEXT>
        <TOKEN id="token-61-0" pos="word" morph="none" start_char="2351" end_char="2363">inappropriate</TOKEN>
        <TOKEN id="token-61-1" pos="punct" morph="none" start_char="2364" end_char="2365">".</TOKEN>
      </SEG>
      <SEG id="segment-62" start_char="2367" end_char="2370">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-62-0" pos="unknown" morph="none" start_char="2367" end_char="2370">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-63" start_char="2372" end_char="2374">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-63-0" pos="unknown" morph="none" start_char="2372" end_char="2374">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-64" start_char="2376" end_char="2452">
        <ORIGINAL_TEXT>But in practice, once the matter is in the hands of the Supreme Court, it can</ORIGINAL_TEXT>
        <TOKEN id="token-64-0" pos="word" morph="none" start_char="2376" end_char="2378">But</TOKEN>
        <TOKEN id="token-64-1" pos="word" morph="none" start_char="2380" end_char="2381">in</TOKEN>
        <TOKEN id="token-64-2" pos="word" morph="none" start_char="2383" end_char="2390">practice</TOKEN>
        <TOKEN id="token-64-3" pos="punct" morph="none" start_char="2391" end_char="2391">,</TOKEN>
        <TOKEN id="token-64-4" pos="word" morph="none" start_char="2393" end_char="2396">once</TOKEN>
        <TOKEN id="token-64-5" pos="word" morph="none" start_char="2398" end_char="2400">the</TOKEN>
        <TOKEN id="token-64-6" pos="word" morph="none" start_char="2402" end_char="2407">matter</TOKEN>
        <TOKEN id="token-64-7" pos="word" morph="none" start_char="2409" end_char="2410">is</TOKEN>
        <TOKEN id="token-64-8" pos="word" morph="none" start_char="2412" end_char="2413">in</TOKEN>
        <TOKEN id="token-64-9" pos="word" morph="none" start_char="2415" end_char="2417">the</TOKEN>
        <TOKEN id="token-64-10" pos="word" morph="none" start_char="2419" end_char="2423">hands</TOKEN>
        <TOKEN id="token-64-11" pos="word" morph="none" start_char="2425" end_char="2426">of</TOKEN>
        <TOKEN id="token-64-12" pos="word" morph="none" start_char="2428" end_char="2430">the</TOKEN>
        <TOKEN id="token-64-13" pos="word" morph="none" start_char="2432" end_char="2438">Supreme</TOKEN>
        <TOKEN id="token-64-14" pos="word" morph="none" start_char="2440" end_char="2444">Court</TOKEN>
        <TOKEN id="token-64-15" pos="punct" morph="none" start_char="2445" end_char="2445">,</TOKEN>
        <TOKEN id="token-64-16" pos="word" morph="none" start_char="2447" end_char="2448">it</TOKEN>
        <TOKEN id="token-64-17" pos="word" morph="none" start_char="2450" end_char="2452">can</TOKEN>
      </SEG>
      <SEG id="segment-65" start_char="2454" end_char="2489">
        <ORIGINAL_TEXT>decide to overturn this in any case.</ORIGINAL_TEXT>
        <TOKEN id="token-65-0" pos="word" morph="none" start_char="2454" end_char="2459">decide</TOKEN>
        <TOKEN id="token-65-1" pos="word" morph="none" start_char="2461" end_char="2462">to</TOKEN>
        <TOKEN id="token-65-2" pos="word" morph="none" start_char="2464" end_char="2471">overturn</TOKEN>
        <TOKEN id="token-65-3" pos="word" morph="none" start_char="2473" end_char="2476">this</TOKEN>
        <TOKEN id="token-65-4" pos="word" morph="none" start_char="2478" end_char="2479">in</TOKEN>
        <TOKEN id="token-65-5" pos="word" morph="none" start_char="2481" end_char="2483">any</TOKEN>
        <TOKEN id="token-65-6" pos="word" morph="none" start_char="2485" end_char="2488">case</TOKEN>
        <TOKEN id="token-65-7" pos="punct" morph="none" start_char="2489" end_char="2489">.</TOKEN>
      </SEG>
      <SEG id="segment-66" start_char="2491" end_char="2494">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-66-0" pos="unknown" morph="none" start_char="2491" end_char="2494">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-67" start_char="2496" end_char="2498">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-67-0" pos="unknown" morph="none" start_char="2496" end_char="2498">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-68" start_char="2500" end_char="2573">
        <ORIGINAL_TEXT>Reeva Steenkamp's parents had previously said they were satisfied with the</ORIGINAL_TEXT>
        <TOKEN id="token-68-0" pos="word" morph="none" start_char="2500" end_char="2504">Reeva</TOKEN>
        <TOKEN id="token-68-1" pos="word" morph="none" start_char="2506" end_char="2514">Steenkamp</TOKEN>
        <TOKEN id="token-68-2" pos="punct" morph="none" start_char="2515" end_char="2515">'</TOKEN>
        <TOKEN id="token-68-3" pos="word" morph="none" start_char="2516" end_char="2516">s</TOKEN>
        <TOKEN id="token-68-4" pos="word" morph="none" start_char="2518" end_char="2524">parents</TOKEN>
        <TOKEN id="token-68-5" pos="word" morph="none" start_char="2526" end_char="2528">had</TOKEN>
        <TOKEN id="token-68-6" pos="word" morph="none" start_char="2530" end_char="2539">previously</TOKEN>
        <TOKEN id="token-68-7" pos="word" morph="none" start_char="2541" end_char="2544">said</TOKEN>
        <TOKEN id="token-68-8" pos="word" morph="none" start_char="2546" end_char="2549">they</TOKEN>
        <TOKEN id="token-68-9" pos="word" morph="none" start_char="2551" end_char="2554">were</TOKEN>
        <TOKEN id="token-68-10" pos="word" morph="none" start_char="2556" end_char="2564">satisfied</TOKEN>
        <TOKEN id="token-68-11" pos="word" morph="none" start_char="2566" end_char="2569">with</TOKEN>
        <TOKEN id="token-68-12" pos="word" morph="none" start_char="2571" end_char="2573">the</TOKEN>
      </SEG>
      <SEG id="segment-69" start_char="2575" end_char="2620">
        <ORIGINAL_TEXT>verdict and sentence handed down to Pistorius.</ORIGINAL_TEXT>
        <TOKEN id="token-69-0" pos="word" morph="none" start_char="2575" end_char="2581">verdict</TOKEN>
        <TOKEN id="token-69-1" pos="word" morph="none" start_char="2583" end_char="2585">and</TOKEN>
        <TOKEN id="token-69-2" pos="word" morph="none" start_char="2587" end_char="2594">sentence</TOKEN>
        <TOKEN id="token-69-3" pos="word" morph="none" start_char="2596" end_char="2601">handed</TOKEN>
        <TOKEN id="token-69-4" pos="word" morph="none" start_char="2603" end_char="2606">down</TOKEN>
        <TOKEN id="token-69-5" pos="word" morph="none" start_char="2608" end_char="2609">to</TOKEN>
        <TOKEN id="token-69-6" pos="word" morph="none" start_char="2611" end_char="2619">Pistorius</TOKEN>
        <TOKEN id="token-69-7" pos="punct" morph="none" start_char="2620" end_char="2620">.</TOKEN>
      </SEG>
      <SEG id="segment-70" start_char="2622" end_char="2625">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-70-0" pos="unknown" morph="none" start_char="2622" end_char="2625">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-71" start_char="2627" end_char="2629">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-71-0" pos="unknown" morph="none" start_char="2627" end_char="2629">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-72" start_char="2631" end_char="2706">
        <ORIGINAL_TEXT>The family's lawyer, Dup de Bruyn, said: "All they're saying is justice must</ORIGINAL_TEXT>
        <TOKEN id="token-72-0" pos="word" morph="none" start_char="2631" end_char="2633">The</TOKEN>
        <TOKEN id="token-72-1" pos="word" morph="none" start_char="2635" end_char="2640">family</TOKEN>
        <TOKEN id="token-72-2" pos="punct" morph="none" start_char="2641" end_char="2641">'</TOKEN>
        <TOKEN id="token-72-3" pos="word" morph="none" start_char="2642" end_char="2642">s</TOKEN>
        <TOKEN id="token-72-4" pos="word" morph="none" start_char="2644" end_char="2649">lawyer</TOKEN>
        <TOKEN id="token-72-5" pos="punct" morph="none" start_char="2650" end_char="2650">,</TOKEN>
        <TOKEN id="token-72-6" pos="word" morph="none" start_char="2652" end_char="2654">Dup</TOKEN>
        <TOKEN id="token-72-7" pos="word" morph="none" start_char="2656" end_char="2657">de</TOKEN>
        <TOKEN id="token-72-8" pos="word" morph="none" start_char="2659" end_char="2663">Bruyn</TOKEN>
        <TOKEN id="token-72-9" pos="punct" morph="none" start_char="2664" end_char="2664">,</TOKEN>
        <TOKEN id="token-72-10" pos="word" morph="none" start_char="2666" end_char="2669">said</TOKEN>
        <TOKEN id="token-72-11" pos="punct" morph="none" start_char="2670" end_char="2670">:</TOKEN>
        <TOKEN id="token-72-12" pos="punct" morph="none" start_char="2672" end_char="2672">"</TOKEN>
        <TOKEN id="token-72-13" pos="word" morph="none" start_char="2673" end_char="2675">All</TOKEN>
        <TOKEN id="token-72-14" pos="word" morph="none" start_char="2677" end_char="2680">they</TOKEN>
        <TOKEN id="token-72-15" pos="punct" morph="none" start_char="2681" end_char="2681">'</TOKEN>
        <TOKEN id="token-72-16" pos="word" morph="none" start_char="2682" end_char="2683">re</TOKEN>
        <TOKEN id="token-72-17" pos="word" morph="none" start_char="2685" end_char="2690">saying</TOKEN>
        <TOKEN id="token-72-18" pos="word" morph="none" start_char="2692" end_char="2693">is</TOKEN>
        <TOKEN id="token-72-19" pos="word" morph="none" start_char="2695" end_char="2701">justice</TOKEN>
        <TOKEN id="token-72-20" pos="word" morph="none" start_char="2703" end_char="2706">must</TOKEN>
      </SEG>
      <SEG id="segment-73" start_char="2708" end_char="2764">
        <ORIGINAL_TEXT>run its course and they want to get on with their lives."</ORIGINAL_TEXT>
        <TOKEN id="token-73-0" pos="word" morph="none" start_char="2708" end_char="2710">run</TOKEN>
        <TOKEN id="token-73-1" pos="word" morph="none" start_char="2712" end_char="2714">its</TOKEN>
        <TOKEN id="token-73-2" pos="word" morph="none" start_char="2716" end_char="2721">course</TOKEN>
        <TOKEN id="token-73-3" pos="word" morph="none" start_char="2723" end_char="2725">and</TOKEN>
        <TOKEN id="token-73-4" pos="word" morph="none" start_char="2727" end_char="2730">they</TOKEN>
        <TOKEN id="token-73-5" pos="word" morph="none" start_char="2732" end_char="2735">want</TOKEN>
        <TOKEN id="token-73-6" pos="word" morph="none" start_char="2737" end_char="2738">to</TOKEN>
        <TOKEN id="token-73-7" pos="word" morph="none" start_char="2740" end_char="2742">get</TOKEN>
        <TOKEN id="token-73-8" pos="word" morph="none" start_char="2744" end_char="2745">on</TOKEN>
        <TOKEN id="token-73-9" pos="word" morph="none" start_char="2747" end_char="2750">with</TOKEN>
        <TOKEN id="token-73-10" pos="word" morph="none" start_char="2752" end_char="2756">their</TOKEN>
        <TOKEN id="token-73-11" pos="word" morph="none" start_char="2758" end_char="2762">lives</TOKEN>
        <TOKEN id="token-73-12" pos="punct" morph="none" start_char="2763" end_char="2764">."</TOKEN>
      </SEG>
      <SEG id="segment-74" start_char="2766" end_char="2769">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-74-0" pos="unknown" morph="none" start_char="2766" end_char="2769">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-75" start_char="2771" end_char="2773">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-75-0" pos="unknown" morph="none" start_char="2771" end_char="2773">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-76" start_char="2775" end_char="2851">
        <ORIGINAL_TEXT>Typically, cases take more than a year to appear before the Supreme Court, by</ORIGINAL_TEXT>
        <TOKEN id="token-76-0" pos="word" morph="none" start_char="2775" end_char="2783">Typically</TOKEN>
        <TOKEN id="token-76-1" pos="punct" morph="none" start_char="2784" end_char="2784">,</TOKEN>
        <TOKEN id="token-76-2" pos="word" morph="none" start_char="2786" end_char="2790">cases</TOKEN>
        <TOKEN id="token-76-3" pos="word" morph="none" start_char="2792" end_char="2795">take</TOKEN>
        <TOKEN id="token-76-4" pos="word" morph="none" start_char="2797" end_char="2800">more</TOKEN>
        <TOKEN id="token-76-5" pos="word" morph="none" start_char="2802" end_char="2805">than</TOKEN>
        <TOKEN id="token-76-6" pos="word" morph="none" start_char="2807" end_char="2807">a</TOKEN>
        <TOKEN id="token-76-7" pos="word" morph="none" start_char="2809" end_char="2812">year</TOKEN>
        <TOKEN id="token-76-8" pos="word" morph="none" start_char="2814" end_char="2815">to</TOKEN>
        <TOKEN id="token-76-9" pos="word" morph="none" start_char="2817" end_char="2822">appear</TOKEN>
        <TOKEN id="token-76-10" pos="word" morph="none" start_char="2824" end_char="2829">before</TOKEN>
        <TOKEN id="token-76-11" pos="word" morph="none" start_char="2831" end_char="2833">the</TOKEN>
        <TOKEN id="token-76-12" pos="word" morph="none" start_char="2835" end_char="2841">Supreme</TOKEN>
        <TOKEN id="token-76-13" pos="word" morph="none" start_char="2843" end_char="2847">Court</TOKEN>
        <TOKEN id="token-76-14" pos="punct" morph="none" start_char="2848" end_char="2848">,</TOKEN>
        <TOKEN id="token-76-15" pos="word" morph="none" start_char="2850" end_char="2851">by</TOKEN>
      </SEG>
      <SEG id="segment-77" start_char="2853" end_char="2927">
        <ORIGINAL_TEXT>which point Pistorius is likely to be out of prison and serving the rest of</ORIGINAL_TEXT>
        <TOKEN id="token-77-0" pos="word" morph="none" start_char="2853" end_char="2857">which</TOKEN>
        <TOKEN id="token-77-1" pos="word" morph="none" start_char="2859" end_char="2863">point</TOKEN>
        <TOKEN id="token-77-2" pos="word" morph="none" start_char="2865" end_char="2873">Pistorius</TOKEN>
        <TOKEN id="token-77-3" pos="word" morph="none" start_char="2875" end_char="2876">is</TOKEN>
        <TOKEN id="token-77-4" pos="word" morph="none" start_char="2878" end_char="2883">likely</TOKEN>
        <TOKEN id="token-77-5" pos="word" morph="none" start_char="2885" end_char="2886">to</TOKEN>
        <TOKEN id="token-77-6" pos="word" morph="none" start_char="2888" end_char="2889">be</TOKEN>
        <TOKEN id="token-77-7" pos="word" morph="none" start_char="2891" end_char="2893">out</TOKEN>
        <TOKEN id="token-77-8" pos="word" morph="none" start_char="2895" end_char="2896">of</TOKEN>
        <TOKEN id="token-77-9" pos="word" morph="none" start_char="2898" end_char="2903">prison</TOKEN>
        <TOKEN id="token-77-10" pos="word" morph="none" start_char="2905" end_char="2907">and</TOKEN>
        <TOKEN id="token-77-11" pos="word" morph="none" start_char="2909" end_char="2915">serving</TOKEN>
        <TOKEN id="token-77-12" pos="word" morph="none" start_char="2917" end_char="2919">the</TOKEN>
        <TOKEN id="token-77-13" pos="word" morph="none" start_char="2921" end_char="2924">rest</TOKEN>
        <TOKEN id="token-77-14" pos="word" morph="none" start_char="2926" end_char="2927">of</TOKEN>
      </SEG>
      <SEG id="segment-78" start_char="2929" end_char="2960">
        <ORIGINAL_TEXT>his sentence under house arrest.</ORIGINAL_TEXT>
        <TOKEN id="token-78-0" pos="word" morph="none" start_char="2929" end_char="2931">his</TOKEN>
        <TOKEN id="token-78-1" pos="word" morph="none" start_char="2933" end_char="2940">sentence</TOKEN>
        <TOKEN id="token-78-2" pos="word" morph="none" start_char="2942" end_char="2946">under</TOKEN>
        <TOKEN id="token-78-3" pos="word" morph="none" start_char="2948" end_char="2952">house</TOKEN>
        <TOKEN id="token-78-4" pos="word" morph="none" start_char="2954" end_char="2959">arrest</TOKEN>
        <TOKEN id="token-78-5" pos="punct" morph="none" start_char="2960" end_char="2960">.</TOKEN>
      </SEG>
      <SEG id="segment-79" start_char="2962" end_char="2965">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-79-0" pos="unknown" morph="none" start_char="2962" end_char="2965">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-80" start_char="2967" end_char="2969">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-80-0" pos="unknown" morph="none" start_char="2967" end_char="2969">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-81" start_char="2971" end_char="3045">
        <ORIGINAL_TEXT>He would be unlikely to attend the trial, which would in the most part be a</ORIGINAL_TEXT>
        <TOKEN id="token-81-0" pos="word" morph="none" start_char="2971" end_char="2972">He</TOKEN>
        <TOKEN id="token-81-1" pos="word" morph="none" start_char="2974" end_char="2978">would</TOKEN>
        <TOKEN id="token-81-2" pos="word" morph="none" start_char="2980" end_char="2981">be</TOKEN>
        <TOKEN id="token-81-3" pos="word" morph="none" start_char="2983" end_char="2990">unlikely</TOKEN>
        <TOKEN id="token-81-4" pos="word" morph="none" start_char="2992" end_char="2993">to</TOKEN>
        <TOKEN id="token-81-5" pos="word" morph="none" start_char="2995" end_char="3000">attend</TOKEN>
        <TOKEN id="token-81-6" pos="word" morph="none" start_char="3002" end_char="3004">the</TOKEN>
        <TOKEN id="token-81-7" pos="word" morph="none" start_char="3006" end_char="3010">trial</TOKEN>
        <TOKEN id="token-81-8" pos="punct" morph="none" start_char="3011" end_char="3011">,</TOKEN>
        <TOKEN id="token-81-9" pos="word" morph="none" start_char="3013" end_char="3017">which</TOKEN>
        <TOKEN id="token-81-10" pos="word" morph="none" start_char="3019" end_char="3023">would</TOKEN>
        <TOKEN id="token-81-11" pos="word" morph="none" start_char="3025" end_char="3026">in</TOKEN>
        <TOKEN id="token-81-12" pos="word" morph="none" start_char="3028" end_char="3030">the</TOKEN>
        <TOKEN id="token-81-13" pos="word" morph="none" start_char="3032" end_char="3035">most</TOKEN>
        <TOKEN id="token-81-14" pos="word" morph="none" start_char="3037" end_char="3040">part</TOKEN>
        <TOKEN id="token-81-15" pos="word" morph="none" start_char="3042" end_char="3043">be</TOKEN>
        <TOKEN id="token-81-16" pos="word" morph="none" start_char="3045" end_char="3045">a</TOKEN>
      </SEG>
      <SEG id="segment-82" start_char="3047" end_char="3123">
        <ORIGINAL_TEXT>matter of arguing over whether the law had been correctly applied rather than</ORIGINAL_TEXT>
        <TOKEN id="token-82-0" pos="word" morph="none" start_char="3047" end_char="3052">matter</TOKEN>
        <TOKEN id="token-82-1" pos="word" morph="none" start_char="3054" end_char="3055">of</TOKEN>
        <TOKEN id="token-82-2" pos="word" morph="none" start_char="3057" end_char="3063">arguing</TOKEN>
        <TOKEN id="token-82-3" pos="word" morph="none" start_char="3065" end_char="3068">over</TOKEN>
        <TOKEN id="token-82-4" pos="word" morph="none" start_char="3070" end_char="3076">whether</TOKEN>
        <TOKEN id="token-82-5" pos="word" morph="none" start_char="3078" end_char="3080">the</TOKEN>
        <TOKEN id="token-82-6" pos="word" morph="none" start_char="3082" end_char="3084">law</TOKEN>
        <TOKEN id="token-82-7" pos="word" morph="none" start_char="3086" end_char="3088">had</TOKEN>
        <TOKEN id="token-82-8" pos="word" morph="none" start_char="3090" end_char="3093">been</TOKEN>
        <TOKEN id="token-82-9" pos="word" morph="none" start_char="3095" end_char="3103">correctly</TOKEN>
        <TOKEN id="token-82-10" pos="word" morph="none" start_char="3105" end_char="3111">applied</TOKEN>
        <TOKEN id="token-82-11" pos="word" morph="none" start_char="3113" end_char="3118">rather</TOKEN>
        <TOKEN id="token-82-12" pos="word" morph="none" start_char="3120" end_char="3123">than</TOKEN>
      </SEG>
      <SEG id="segment-83" start_char="3125" end_char="3145">
        <ORIGINAL_TEXT>hearing new evidence.</ORIGINAL_TEXT>
        <TOKEN id="token-83-0" pos="word" morph="none" start_char="3125" end_char="3131">hearing</TOKEN>
        <TOKEN id="token-83-1" pos="word" morph="none" start_char="3133" end_char="3135">new</TOKEN>
        <TOKEN id="token-83-2" pos="word" morph="none" start_char="3137" end_char="3144">evidence</TOKEN>
        <TOKEN id="token-83-3" pos="punct" morph="none" start_char="3145" end_char="3145">.</TOKEN>
      </SEG>
      <SEG id="segment-84" start_char="3147" end_char="3150">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-84-0" pos="unknown" morph="none" start_char="3147" end_char="3150">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-85" start_char="3152" end_char="3154">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-85-0" pos="unknown" morph="none" start_char="3152" end_char="3154">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-86" start_char="3156" end_char="3231">
        <ORIGINAL_TEXT>It is a victory for the National Prosecuting Authority (NPA), which has been</ORIGINAL_TEXT>
        <TOKEN id="token-86-0" pos="word" morph="none" start_char="3156" end_char="3157">It</TOKEN>
        <TOKEN id="token-86-1" pos="word" morph="none" start_char="3159" end_char="3160">is</TOKEN>
        <TOKEN id="token-86-2" pos="word" morph="none" start_char="3162" end_char="3162">a</TOKEN>
        <TOKEN id="token-86-3" pos="word" morph="none" start_char="3164" end_char="3170">victory</TOKEN>
        <TOKEN id="token-86-4" pos="word" morph="none" start_char="3172" end_char="3174">for</TOKEN>
        <TOKEN id="token-86-5" pos="word" morph="none" start_char="3176" end_char="3178">the</TOKEN>
        <TOKEN id="token-86-6" pos="word" morph="none" start_char="3180" end_char="3187">National</TOKEN>
        <TOKEN id="token-86-7" pos="word" morph="none" start_char="3189" end_char="3199">Prosecuting</TOKEN>
        <TOKEN id="token-86-8" pos="word" morph="none" start_char="3201" end_char="3209">Authority</TOKEN>
        <TOKEN id="token-86-9" pos="punct" morph="none" start_char="3211" end_char="3211">(</TOKEN>
        <TOKEN id="token-86-10" pos="word" morph="none" start_char="3212" end_char="3214">NPA</TOKEN>
        <TOKEN id="token-86-11" pos="punct" morph="none" start_char="3215" end_char="3216">),</TOKEN>
        <TOKEN id="token-86-12" pos="word" morph="none" start_char="3218" end_char="3222">which</TOKEN>
        <TOKEN id="token-86-13" pos="word" morph="none" start_char="3224" end_char="3226">has</TOKEN>
        <TOKEN id="token-86-14" pos="word" morph="none" start_char="3228" end_char="3231">been</TOKEN>
      </SEG>
      <SEG id="segment-87" start_char="3233" end_char="3308">
        <ORIGINAL_TEXT>humiliated both by the Pistorius case and by the acquittal of Shrien Dewani,</ORIGINAL_TEXT>
        <TOKEN id="token-87-0" pos="word" morph="none" start_char="3233" end_char="3242">humiliated</TOKEN>
        <TOKEN id="token-87-1" pos="word" morph="none" start_char="3244" end_char="3247">both</TOKEN>
        <TOKEN id="token-87-2" pos="word" morph="none" start_char="3249" end_char="3250">by</TOKEN>
        <TOKEN id="token-87-3" pos="word" morph="none" start_char="3252" end_char="3254">the</TOKEN>
        <TOKEN id="token-87-4" pos="word" morph="none" start_char="3256" end_char="3264">Pistorius</TOKEN>
        <TOKEN id="token-87-5" pos="word" morph="none" start_char="3266" end_char="3269">case</TOKEN>
        <TOKEN id="token-87-6" pos="word" morph="none" start_char="3271" end_char="3273">and</TOKEN>
        <TOKEN id="token-87-7" pos="word" morph="none" start_char="3275" end_char="3276">by</TOKEN>
        <TOKEN id="token-87-8" pos="word" morph="none" start_char="3278" end_char="3280">the</TOKEN>
        <TOKEN id="token-87-9" pos="word" morph="none" start_char="3282" end_char="3290">acquittal</TOKEN>
        <TOKEN id="token-87-10" pos="word" morph="none" start_char="3292" end_char="3293">of</TOKEN>
        <TOKEN id="token-87-11" pos="word" morph="none" start_char="3295" end_char="3300">Shrien</TOKEN>
        <TOKEN id="token-87-12" pos="word" morph="none" start_char="3302" end_char="3307">Dewani</TOKEN>
        <TOKEN id="token-87-13" pos="punct" morph="none" start_char="3308" end_char="3308">,</TOKEN>
      </SEG>
      <SEG id="segment-88" start_char="3310" end_char="3385">
        <ORIGINAL_TEXT>after seeking his extradition for the supposed contract killing of his wife.</ORIGINAL_TEXT>
        <TOKEN id="token-88-0" pos="word" morph="none" start_char="3310" end_char="3314">after</TOKEN>
        <TOKEN id="token-88-1" pos="word" morph="none" start_char="3316" end_char="3322">seeking</TOKEN>
        <TOKEN id="token-88-2" pos="word" morph="none" start_char="3324" end_char="3326">his</TOKEN>
        <TOKEN id="token-88-3" pos="word" morph="none" start_char="3328" end_char="3338">extradition</TOKEN>
        <TOKEN id="token-88-4" pos="word" morph="none" start_char="3340" end_char="3342">for</TOKEN>
        <TOKEN id="token-88-5" pos="word" morph="none" start_char="3344" end_char="3346">the</TOKEN>
        <TOKEN id="token-88-6" pos="word" morph="none" start_char="3348" end_char="3355">supposed</TOKEN>
        <TOKEN id="token-88-7" pos="word" morph="none" start_char="3357" end_char="3364">contract</TOKEN>
        <TOKEN id="token-88-8" pos="word" morph="none" start_char="3366" end_char="3372">killing</TOKEN>
        <TOKEN id="token-88-9" pos="word" morph="none" start_char="3374" end_char="3375">of</TOKEN>
        <TOKEN id="token-88-10" pos="word" morph="none" start_char="3377" end_char="3379">his</TOKEN>
        <TOKEN id="token-88-11" pos="word" morph="none" start_char="3381" end_char="3384">wife</TOKEN>
        <TOKEN id="token-88-12" pos="punct" morph="none" start_char="3385" end_char="3385">.</TOKEN>
      </SEG>
      <SEG id="segment-89" start_char="3387" end_char="3390">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-89-0" pos="unknown" morph="none" start_char="3387" end_char="3390">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-90" start_char="3392" end_char="3394">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-90-0" pos="unknown" morph="none" start_char="3392" end_char="3394">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-91" start_char="3396" end_char="3469">
        <ORIGINAL_TEXT>Nathi Mncube, the NPA's spokesman said: "Our argument was that [Pistorius]</ORIGINAL_TEXT>
        <TOKEN id="token-91-0" pos="word" morph="none" start_char="3396" end_char="3400">Nathi</TOKEN>
        <TOKEN id="token-91-1" pos="word" morph="none" start_char="3402" end_char="3407">Mncube</TOKEN>
        <TOKEN id="token-91-2" pos="punct" morph="none" start_char="3408" end_char="3408">,</TOKEN>
        <TOKEN id="token-91-3" pos="word" morph="none" start_char="3410" end_char="3412">the</TOKEN>
        <TOKEN id="token-91-4" pos="word" morph="none" start_char="3414" end_char="3416">NPA</TOKEN>
        <TOKEN id="token-91-5" pos="punct" morph="none" start_char="3417" end_char="3417">'</TOKEN>
        <TOKEN id="token-91-6" pos="word" morph="none" start_char="3418" end_char="3418">s</TOKEN>
        <TOKEN id="token-91-7" pos="word" morph="none" start_char="3420" end_char="3428">spokesman</TOKEN>
        <TOKEN id="token-91-8" pos="word" morph="none" start_char="3430" end_char="3433">said</TOKEN>
        <TOKEN id="token-91-9" pos="punct" morph="none" start_char="3434" end_char="3434">:</TOKEN>
        <TOKEN id="token-91-10" pos="punct" morph="none" start_char="3436" end_char="3436">"</TOKEN>
        <TOKEN id="token-91-11" pos="word" morph="none" start_char="3437" end_char="3439">Our</TOKEN>
        <TOKEN id="token-91-12" pos="word" morph="none" start_char="3441" end_char="3448">argument</TOKEN>
        <TOKEN id="token-91-13" pos="word" morph="none" start_char="3450" end_char="3452">was</TOKEN>
        <TOKEN id="token-91-14" pos="word" morph="none" start_char="3454" end_char="3457">that</TOKEN>
        <TOKEN id="token-91-15" pos="punct" morph="none" start_char="3459" end_char="3459">[</TOKEN>
        <TOKEN id="token-91-16" pos="word" morph="none" start_char="3460" end_char="3468">Pistorius</TOKEN>
        <TOKEN id="token-91-17" pos="punct" morph="none" start_char="3469" end_char="3469">]</TOKEN>
      </SEG>
      <SEG id="segment-92" start_char="3471" end_char="3547">
        <ORIGINAL_TEXT>should have been convicted of murder, and then would have been sentenced to a</ORIGINAL_TEXT>
        <TOKEN id="token-92-0" pos="word" morph="none" start_char="3471" end_char="3476">should</TOKEN>
        <TOKEN id="token-92-1" pos="word" morph="none" start_char="3478" end_char="3481">have</TOKEN>
        <TOKEN id="token-92-2" pos="word" morph="none" start_char="3483" end_char="3486">been</TOKEN>
        <TOKEN id="token-92-3" pos="word" morph="none" start_char="3488" end_char="3496">convicted</TOKEN>
        <TOKEN id="token-92-4" pos="word" morph="none" start_char="3498" end_char="3499">of</TOKEN>
        <TOKEN id="token-92-5" pos="word" morph="none" start_char="3501" end_char="3506">murder</TOKEN>
        <TOKEN id="token-92-6" pos="punct" morph="none" start_char="3507" end_char="3507">,</TOKEN>
        <TOKEN id="token-92-7" pos="word" morph="none" start_char="3509" end_char="3511">and</TOKEN>
        <TOKEN id="token-92-8" pos="word" morph="none" start_char="3513" end_char="3516">then</TOKEN>
        <TOKEN id="token-92-9" pos="word" morph="none" start_char="3518" end_char="3522">would</TOKEN>
        <TOKEN id="token-92-10" pos="word" morph="none" start_char="3524" end_char="3527">have</TOKEN>
        <TOKEN id="token-92-11" pos="word" morph="none" start_char="3529" end_char="3532">been</TOKEN>
        <TOKEN id="token-92-12" pos="word" morph="none" start_char="3534" end_char="3542">sentenced</TOKEN>
        <TOKEN id="token-92-13" pos="word" morph="none" start_char="3544" end_char="3545">to</TOKEN>
        <TOKEN id="token-92-14" pos="word" morph="none" start_char="3547" end_char="3547">a</TOKEN>
      </SEG>
      <SEG id="segment-93" start_char="3549" end_char="3569">
        <ORIGINAL_TEXT>minimum of 15 years."</ORIGINAL_TEXT>
        <TOKEN id="token-93-0" pos="word" morph="none" start_char="3549" end_char="3555">minimum</TOKEN>
        <TOKEN id="token-93-1" pos="word" morph="none" start_char="3557" end_char="3558">of</TOKEN>
        <TOKEN id="token-93-2" pos="number" morph="none" start_char="3560" end_char="3561">15</TOKEN>
        <TOKEN id="token-93-3" pos="word" morph="none" start_char="3563" end_char="3567">years</TOKEN>
        <TOKEN id="token-93-4" pos="punct" morph="none" start_char="3568" end_char="3569">."</TOKEN>
      </SEG>
      <SEG id="segment-94" start_char="3571" end_char="3574">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-94-0" pos="unknown" morph="none" start_char="3571" end_char="3574">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-95" start_char="3576" end_char="3582">
        <ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-95-0" pos="unknown" morph="none" start_char="3576" end_char="3582">&lt;/TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-96" start_char="3584" end_char="3589">
        <ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-96-0" pos="unknown" morph="none" start_char="3584" end_char="3589">&lt;/DOC&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
