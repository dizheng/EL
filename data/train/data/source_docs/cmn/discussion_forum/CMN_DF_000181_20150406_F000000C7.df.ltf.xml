<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="CMN_DF_000181_20150406_F000000C7.df.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="574" raw_text_md5="d56f1e0ecf6f71c9c821da4046199e30">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;doc id="CMN_DF_000181_20150406_F000000C7"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;doc</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="CMN_DF_000181_20150406_F000000C7"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="92">
        <ORIGINAL_TEXT>&lt;headline&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="92">&lt;headline&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="94" end_char="112">
        <ORIGINAL_TEXT>美国首次同意 古巴参加美洲峰会(转载)</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="word" morph="none" start_char="94" end_char="99">美国首次同意</TOKEN>
        <TOKEN id="token-3-1" pos="word" morph="none" start_char="101" end_char="108">古巴参加美洲峰会</TOKEN>
        <TOKEN id="token-3-2" pos="punct" morph="none" start_char="109" end_char="109">(</TOKEN>
        <TOKEN id="token-3-3" pos="word" morph="none" start_char="110" end_char="111">转载</TOKEN>
        <TOKEN id="token-3-4" pos="punct" morph="none" start_char="112" end_char="112">)</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="114" end_char="124">
        <ORIGINAL_TEXT>&lt;/headline&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="114" end_char="124">&lt;/headline&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="126" end_char="188">
        <ORIGINAL_TEXT>&lt;post id="p1" author="weinis12" datetime="2015-04-06T00:50:00"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="unknown" morph="none" start_char="126" end_char="130">&lt;post</TOKEN>
        <TOKEN id="token-5-1" pos="unknown" morph="none" start_char="132" end_char="138">id="p1"</TOKEN>
        <TOKEN id="token-5-2" pos="unknown" morph="none" start_char="140" end_char="156">author="weinis12"</TOKEN>
        <TOKEN id="token-5-3" pos="unknown" morph="none" start_char="158" end_char="188">datetime="2015-04-06T00:50:00"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="190" end_char="253">
        <ORIGINAL_TEXT>http://china.cnr.cn/NewsFeeds/20150405/t20150405_518235773.shtml</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="url" morph="none" start_char="190" end_char="253">http://china.cnr.cn/NewsFeeds/20150405/t20150405_518235773.shtml</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="255" end_char="261">
        <ORIGINAL_TEXT>&lt;/post&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="255" end_char="261">&lt;/post&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="263" end_char="329">
        <ORIGINAL_TEXT>&lt;post id="p2" author="ylqingluan1 " datetime="2015-04-06T00:51:00"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="263" end_char="267">&lt;post</TOKEN>
        <TOKEN id="token-8-1" pos="unknown" morph="none" start_char="269" end_char="275">id="p2"</TOKEN>
        <TOKEN id="token-8-2" pos="unknown" morph="none" start_char="277" end_char="295">author="ylqingluan1</TOKEN>
        <TOKEN id="token-8-3" pos="unknown" morph="none" start_char="297" end_char="297">"</TOKEN>
        <TOKEN id="token-8-4" pos="unknown" morph="none" start_char="299" end_char="329">datetime="2015-04-06T00:51:00"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="331" end_char="347">
        <ORIGINAL_TEXT>美国最逗比的是 制裁这个 制裁那个</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="331" end_char="337">美国最逗比的是</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="339" end_char="342">制裁这个</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="344" end_char="347">制裁那个</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="350" end_char="372">
        <ORIGINAL_TEXT>所有的人他都要制裁 制裁到最后 一看就剩自己了</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="word" morph="none" start_char="350" end_char="358">所有的人他都要制裁</TOKEN>
        <TOKEN id="token-10-1" pos="word" morph="none" start_char="360" end_char="364">制裁到最后</TOKEN>
        <TOKEN id="token-10-2" pos="word" morph="none" start_char="366" end_char="372">一看就剩自己了</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="374" end_char="380">
        <ORIGINAL_TEXT>&lt;/post&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="unknown" morph="none" start_char="374" end_char="380">&lt;/post&gt;</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="382" end_char="441">
        <ORIGINAL_TEXT>&lt;post id="p3" author="拖后退的 " datetime="2015-04-06T01:04:00"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="unknown" morph="none" start_char="382" end_char="386">&lt;post</TOKEN>
        <TOKEN id="token-12-1" pos="unknown" morph="none" start_char="388" end_char="394">id="p3"</TOKEN>
        <TOKEN id="token-12-2" pos="unknown" morph="none" start_char="396" end_char="407">author="拖后退的</TOKEN>
        <TOKEN id="token-12-3" pos="unknown" morph="none" start_char="409" end_char="409">"</TOKEN>
        <TOKEN id="token-12-4" pos="unknown" morph="none" start_char="411" end_char="441">datetime="2015-04-06T01:04:00"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="443" end_char="472">
        <ORIGINAL_TEXT>凡是反美坚持到底的人都活过来了, 半途而废被美国忽悠的都死了</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="word" morph="none" start_char="443" end_char="457">凡是反美坚持到底的人都活过来了</TOKEN>
        <TOKEN id="token-13-1" pos="punct" morph="none" start_char="458" end_char="458">,</TOKEN>
        <TOKEN id="token-13-2" pos="word" morph="none" start_char="460" end_char="472">半途而废被美国忽悠的都死了</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="474" end_char="480">
        <ORIGINAL_TEXT>&lt;/post&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="unknown" morph="none" start_char="474" end_char="480">&lt;/post&gt;</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="482" end_char="541">
        <ORIGINAL_TEXT>&lt;post id="p4" author="拖后退的 " datetime="2015-04-06T01:05:00"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="unknown" morph="none" start_char="482" end_char="486">&lt;post</TOKEN>
        <TOKEN id="token-15-1" pos="unknown" morph="none" start_char="488" end_char="494">id="p4"</TOKEN>
        <TOKEN id="token-15-2" pos="unknown" morph="none" start_char="496" end_char="507">author="拖后退的</TOKEN>
        <TOKEN id="token-15-3" pos="unknown" morph="none" start_char="509" end_char="509">"</TOKEN>
        <TOKEN id="token-15-4" pos="unknown" morph="none" start_char="511" end_char="541">datetime="2015-04-06T01:05:00"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="543" end_char="557">
        <ORIGINAL_TEXT>这个时候肿么不讲人权和民主了?</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="word" morph="none" start_char="543" end_char="556">这个时候肿么不讲人权和民主了</TOKEN>
        <TOKEN id="token-16-1" pos="punct" morph="none" start_char="557" end_char="557">?</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="559" end_char="565">
        <ORIGINAL_TEXT>&lt;/post&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="unknown" morph="none" start_char="559" end_char="565">&lt;/post&gt;</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="567" end_char="572">
        <ORIGINAL_TEXT>&lt;/doc&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="unknown" morph="none" start_char="567" end_char="572">&lt;/doc&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
