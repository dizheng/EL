<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="SPA_NW_001095_20141026_F0000003M.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="1811" raw_text_md5="33ec9e345cb7330bba9f1b6079e6e6c6">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;DOC id="SPA_NW_001095_20141026_F0000003M"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="SPA_NW_001095_20141026_F0000003M"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="170">
        <ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.elmundo.es/deportes/2014/10/26/544cd662268e3ee3188b4576.html&lt;/SOURCE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="170">&lt;SOURCE&gt;http://www.elmundo.es/deportes/2014/10/26/544cd662268e3ee3188b4576.html&lt;/SOURCE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="172" end_char="213">
        <ORIGINAL_TEXT>&lt;DATE_TIME&gt;2014-10-26T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="unknown" morph="none" start_char="172" end_char="213">&lt;DATE_TIME&gt;2014-10-26T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="215" end_char="224">
        <ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="215" end_char="224">&lt;HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="226" end_char="344">
        <ORIGINAL_TEXT>La madre de la novia de Pistorius asegura que ella había decidido abandonarle la noche que el atleta la mató a disparos</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="word" morph="none" start_char="226" end_char="227">La</TOKEN>
        <TOKEN id="token-5-1" pos="word" morph="none" start_char="229" end_char="233">madre</TOKEN>
        <TOKEN id="token-5-2" pos="word" morph="none" start_char="235" end_char="236">de</TOKEN>
        <TOKEN id="token-5-3" pos="word" morph="none" start_char="238" end_char="239">la</TOKEN>
        <TOKEN id="token-5-4" pos="word" morph="none" start_char="241" end_char="245">novia</TOKEN>
        <TOKEN id="token-5-5" pos="word" morph="none" start_char="247" end_char="248">de</TOKEN>
        <TOKEN id="token-5-6" pos="word" morph="none" start_char="250" end_char="258">Pistorius</TOKEN>
        <TOKEN id="token-5-7" pos="word" morph="none" start_char="260" end_char="266">asegura</TOKEN>
        <TOKEN id="token-5-8" pos="word" morph="none" start_char="268" end_char="270">que</TOKEN>
        <TOKEN id="token-5-9" pos="word" morph="none" start_char="272" end_char="275">ella</TOKEN>
        <TOKEN id="token-5-10" pos="word" morph="none" start_char="277" end_char="281">había</TOKEN>
        <TOKEN id="token-5-11" pos="word" morph="none" start_char="283" end_char="290">decidido</TOKEN>
        <TOKEN id="token-5-12" pos="word" morph="none" start_char="292" end_char="302">abandonarle</TOKEN>
        <TOKEN id="token-5-13" pos="word" morph="none" start_char="304" end_char="305">la</TOKEN>
        <TOKEN id="token-5-14" pos="word" morph="none" start_char="307" end_char="311">noche</TOKEN>
        <TOKEN id="token-5-15" pos="word" morph="none" start_char="313" end_char="315">que</TOKEN>
        <TOKEN id="token-5-16" pos="word" morph="none" start_char="317" end_char="318">el</TOKEN>
        <TOKEN id="token-5-17" pos="word" morph="none" start_char="320" end_char="325">atleta</TOKEN>
        <TOKEN id="token-5-18" pos="word" morph="none" start_char="327" end_char="328">la</TOKEN>
        <TOKEN id="token-5-19" pos="word" morph="none" start_char="330" end_char="333">mató</TOKEN>
        <TOKEN id="token-5-20" pos="word" morph="none" start_char="335" end_char="335">a</TOKEN>
        <TOKEN id="token-5-21" pos="word" morph="none" start_char="337" end_char="344">disparos</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="346" end_char="356">
        <ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="unknown" morph="none" start_char="346" end_char="356">&lt;/HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="358" end_char="363">
        <ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="358" end_char="363">&lt;TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="365" end_char="367">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="365" end_char="367">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="369" end_char="441">
        <ORIGINAL_TEXT>La madre de Reeva Steenkamp, disparada en 2013 por el campeón paralímpico</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="369" end_char="370">La</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="372" end_char="376">madre</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="378" end_char="379">de</TOKEN>
        <TOKEN id="token-9-3" pos="word" morph="none" start_char="381" end_char="385">Reeva</TOKEN>
        <TOKEN id="token-9-4" pos="word" morph="none" start_char="387" end_char="395">Steenkamp</TOKEN>
        <TOKEN id="token-9-5" pos="punct" morph="none" start_char="396" end_char="396">,</TOKEN>
        <TOKEN id="token-9-6" pos="word" morph="none" start_char="398" end_char="406">disparada</TOKEN>
        <TOKEN id="token-9-7" pos="word" morph="none" start_char="408" end_char="409">en</TOKEN>
        <TOKEN id="token-9-8" pos="number" morph="none" start_char="411" end_char="414">2013</TOKEN>
        <TOKEN id="token-9-9" pos="word" morph="none" start_char="416" end_char="418">por</TOKEN>
        <TOKEN id="token-9-10" pos="word" morph="none" start_char="420" end_char="421">el</TOKEN>
        <TOKEN id="token-9-11" pos="word" morph="none" start_char="423" end_char="429">campeón</TOKEN>
        <TOKEN id="token-9-12" pos="word" morph="none" start_char="431" end_char="441">paralímpico</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="443" end_char="520">
        <ORIGINAL_TEXT>Oscar Pistorius, asegura en una entrevista exclusiva a la revista Times que su</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="word" morph="none" start_char="443" end_char="447">Oscar</TOKEN>
        <TOKEN id="token-10-1" pos="word" morph="none" start_char="449" end_char="457">Pistorius</TOKEN>
        <TOKEN id="token-10-2" pos="punct" morph="none" start_char="458" end_char="458">,</TOKEN>
        <TOKEN id="token-10-3" pos="word" morph="none" start_char="460" end_char="466">asegura</TOKEN>
        <TOKEN id="token-10-4" pos="word" morph="none" start_char="468" end_char="469">en</TOKEN>
        <TOKEN id="token-10-5" pos="word" morph="none" start_char="471" end_char="473">una</TOKEN>
        <TOKEN id="token-10-6" pos="word" morph="none" start_char="475" end_char="484">entrevista</TOKEN>
        <TOKEN id="token-10-7" pos="word" morph="none" start_char="486" end_char="494">exclusiva</TOKEN>
        <TOKEN id="token-10-8" pos="word" morph="none" start_char="496" end_char="496">a</TOKEN>
        <TOKEN id="token-10-9" pos="word" morph="none" start_char="498" end_char="499">la</TOKEN>
        <TOKEN id="token-10-10" pos="word" morph="none" start_char="501" end_char="507">revista</TOKEN>
        <TOKEN id="token-10-11" pos="word" morph="none" start_char="509" end_char="513">Times</TOKEN>
        <TOKEN id="token-10-12" pos="word" morph="none" start_char="515" end_char="517">que</TOKEN>
        <TOKEN id="token-10-13" pos="word" morph="none" start_char="519" end_char="520">su</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="522" end_char="596">
        <ORIGINAL_TEXT>hija "había decidido abandonarle esa noche". "Su ropa estaba en maletas. No</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="word" morph="none" start_char="522" end_char="525">hija</TOKEN>
        <TOKEN id="token-11-1" pos="punct" morph="none" start_char="527" end_char="527">"</TOKEN>
        <TOKEN id="token-11-2" pos="word" morph="none" start_char="528" end_char="532">había</TOKEN>
        <TOKEN id="token-11-3" pos="word" morph="none" start_char="534" end_char="541">decidido</TOKEN>
        <TOKEN id="token-11-4" pos="word" morph="none" start_char="543" end_char="553">abandonarle</TOKEN>
        <TOKEN id="token-11-5" pos="word" morph="none" start_char="555" end_char="557">esa</TOKEN>
        <TOKEN id="token-11-6" pos="word" morph="none" start_char="559" end_char="563">noche</TOKEN>
        <TOKEN id="token-11-7" pos="punct" morph="none" start_char="564" end_char="565">".</TOKEN>
        <TOKEN id="token-11-8" pos="punct" morph="none" start_char="567" end_char="567">"</TOKEN>
        <TOKEN id="token-11-9" pos="word" morph="none" start_char="568" end_char="569">Su</TOKEN>
        <TOKEN id="token-11-10" pos="word" morph="none" start_char="571" end_char="574">ropa</TOKEN>
        <TOKEN id="token-11-11" pos="word" morph="none" start_char="576" end_char="581">estaba</TOKEN>
        <TOKEN id="token-11-12" pos="word" morph="none" start_char="583" end_char="584">en</TOKEN>
        <TOKEN id="token-11-13" pos="word" morph="none" start_char="586" end_char="592">maletas</TOKEN>
        <TOKEN id="token-11-14" pos="punct" morph="none" start_char="593" end_char="593">.</TOKEN>
        <TOKEN id="token-11-15" pos="word" morph="none" start_char="595" end_char="596">No</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="598" end_char="671">
        <ORIGINAL_TEXT>tenemos ninguna duda de que había decidido dejarle esa noche", afirma June</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="word" morph="none" start_char="598" end_char="604">tenemos</TOKEN>
        <TOKEN id="token-12-1" pos="word" morph="none" start_char="606" end_char="612">ninguna</TOKEN>
        <TOKEN id="token-12-2" pos="word" morph="none" start_char="614" end_char="617">duda</TOKEN>
        <TOKEN id="token-12-3" pos="word" morph="none" start_char="619" end_char="620">de</TOKEN>
        <TOKEN id="token-12-4" pos="word" morph="none" start_char="622" end_char="624">que</TOKEN>
        <TOKEN id="token-12-5" pos="word" morph="none" start_char="626" end_char="630">había</TOKEN>
        <TOKEN id="token-12-6" pos="word" morph="none" start_char="632" end_char="639">decidido</TOKEN>
        <TOKEN id="token-12-7" pos="word" morph="none" start_char="641" end_char="647">dejarle</TOKEN>
        <TOKEN id="token-12-8" pos="word" morph="none" start_char="649" end_char="651">esa</TOKEN>
        <TOKEN id="token-12-9" pos="word" morph="none" start_char="653" end_char="657">noche</TOKEN>
        <TOKEN id="token-12-10" pos="punct" morph="none" start_char="658" end_char="659">",</TOKEN>
        <TOKEN id="token-12-11" pos="word" morph="none" start_char="661" end_char="666">afirma</TOKEN>
        <TOKEN id="token-12-12" pos="word" morph="none" start_char="668" end_char="671">June</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="673" end_char="682">
        <ORIGINAL_TEXT>Steenkamp.</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="word" morph="none" start_char="673" end_char="681">Steenkamp</TOKEN>
        <TOKEN id="token-13-1" pos="punct" morph="none" start_char="682" end_char="682">.</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="684" end_char="687">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="unknown" morph="none" start_char="684" end_char="687">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="689" end_char="691">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="unknown" morph="none" start_char="689" end_char="691">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="693" end_char="763">
        <ORIGINAL_TEXT>El primer atleta olímpico paralímpico ha sido condenado a cinco años de</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="word" morph="none" start_char="693" end_char="694">El</TOKEN>
        <TOKEN id="token-16-1" pos="word" morph="none" start_char="696" end_char="701">primer</TOKEN>
        <TOKEN id="token-16-2" pos="word" morph="none" start_char="703" end_char="708">atleta</TOKEN>
        <TOKEN id="token-16-3" pos="word" morph="none" start_char="710" end_char="717">olímpico</TOKEN>
        <TOKEN id="token-16-4" pos="word" morph="none" start_char="719" end_char="729">paralímpico</TOKEN>
        <TOKEN id="token-16-5" pos="word" morph="none" start_char="731" end_char="732">ha</TOKEN>
        <TOKEN id="token-16-6" pos="word" morph="none" start_char="734" end_char="737">sido</TOKEN>
        <TOKEN id="token-16-7" pos="word" morph="none" start_char="739" end_char="747">condenado</TOKEN>
        <TOKEN id="token-16-8" pos="word" morph="none" start_char="749" end_char="749">a</TOKEN>
        <TOKEN id="token-16-9" pos="word" morph="none" start_char="751" end_char="755">cinco</TOKEN>
        <TOKEN id="token-16-10" pos="word" morph="none" start_char="757" end_char="760">años</TOKEN>
        <TOKEN id="token-16-11" pos="word" morph="none" start_char="762" end_char="763">de</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="765" end_char="832">
        <ORIGINAL_TEXT>prisión por el homicidio involuntario de su novia la víspera del San</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="word" morph="none" start_char="765" end_char="771">prisión</TOKEN>
        <TOKEN id="token-17-1" pos="word" morph="none" start_char="773" end_char="775">por</TOKEN>
        <TOKEN id="token-17-2" pos="word" morph="none" start_char="777" end_char="778">el</TOKEN>
        <TOKEN id="token-17-3" pos="word" morph="none" start_char="780" end_char="788">homicidio</TOKEN>
        <TOKEN id="token-17-4" pos="word" morph="none" start_char="790" end_char="801">involuntario</TOKEN>
        <TOKEN id="token-17-5" pos="word" morph="none" start_char="803" end_char="804">de</TOKEN>
        <TOKEN id="token-17-6" pos="word" morph="none" start_char="806" end_char="807">su</TOKEN>
        <TOKEN id="token-17-7" pos="word" morph="none" start_char="809" end_char="813">novia</TOKEN>
        <TOKEN id="token-17-8" pos="word" morph="none" start_char="815" end_char="816">la</TOKEN>
        <TOKEN id="token-17-9" pos="word" morph="none" start_char="818" end_char="824">víspera</TOKEN>
        <TOKEN id="token-17-10" pos="word" morph="none" start_char="826" end_char="828">del</TOKEN>
        <TOKEN id="token-17-11" pos="word" morph="none" start_char="830" end_char="832">San</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="834" end_char="907">
        <ORIGINAL_TEXT>Valentín de 2013. "No tenemos ninguna duda de que algo salió terriblemente</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="word" morph="none" start_char="834" end_char="841">Valentín</TOKEN>
        <TOKEN id="token-18-1" pos="word" morph="none" start_char="843" end_char="844">de</TOKEN>
        <TOKEN id="token-18-2" pos="word" morph="none" start_char="846" end_char="849">2013</TOKEN>
        <TOKEN id="token-18-3" pos="punct" morph="none" start_char="850" end_char="850">.</TOKEN>
        <TOKEN id="token-18-4" pos="punct" morph="none" start_char="852" end_char="852">"</TOKEN>
        <TOKEN id="token-18-5" pos="word" morph="none" start_char="853" end_char="854">No</TOKEN>
        <TOKEN id="token-18-6" pos="word" morph="none" start_char="856" end_char="862">tenemos</TOKEN>
        <TOKEN id="token-18-7" pos="word" morph="none" start_char="864" end_char="870">ninguna</TOKEN>
        <TOKEN id="token-18-8" pos="word" morph="none" start_char="872" end_char="875">duda</TOKEN>
        <TOKEN id="token-18-9" pos="word" morph="none" start_char="877" end_char="878">de</TOKEN>
        <TOKEN id="token-18-10" pos="word" morph="none" start_char="880" end_char="882">que</TOKEN>
        <TOKEN id="token-18-11" pos="word" morph="none" start_char="884" end_char="887">algo</TOKEN>
        <TOKEN id="token-18-12" pos="word" morph="none" start_char="889" end_char="893">salió</TOKEN>
        <TOKEN id="token-18-13" pos="word" morph="none" start_char="895" end_char="907">terriblemente</TOKEN>
      </SEG>
      <SEG id="segment-19" start_char="909" end_char="984">
        <ORIGINAL_TEXT>mal" escribe la madre de la joven en su libro 'Reeva', que saldrá el próximo</ORIGINAL_TEXT>
        <TOKEN id="token-19-0" pos="word" morph="none" start_char="909" end_char="911">mal</TOKEN>
        <TOKEN id="token-19-1" pos="punct" morph="none" start_char="912" end_char="912">"</TOKEN>
        <TOKEN id="token-19-2" pos="word" morph="none" start_char="914" end_char="920">escribe</TOKEN>
        <TOKEN id="token-19-3" pos="word" morph="none" start_char="922" end_char="923">la</TOKEN>
        <TOKEN id="token-19-4" pos="word" morph="none" start_char="925" end_char="929">madre</TOKEN>
        <TOKEN id="token-19-5" pos="word" morph="none" start_char="931" end_char="932">de</TOKEN>
        <TOKEN id="token-19-6" pos="word" morph="none" start_char="934" end_char="935">la</TOKEN>
        <TOKEN id="token-19-7" pos="word" morph="none" start_char="937" end_char="941">joven</TOKEN>
        <TOKEN id="token-19-8" pos="word" morph="none" start_char="943" end_char="944">en</TOKEN>
        <TOKEN id="token-19-9" pos="word" morph="none" start_char="946" end_char="947">su</TOKEN>
        <TOKEN id="token-19-10" pos="word" morph="none" start_char="949" end_char="953">libro</TOKEN>
        <TOKEN id="token-19-11" pos="punct" morph="none" start_char="955" end_char="955">'</TOKEN>
        <TOKEN id="token-19-12" pos="word" morph="none" start_char="956" end_char="960">Reeva</TOKEN>
        <TOKEN id="token-19-13" pos="punct" morph="none" start_char="961" end_char="962">',</TOKEN>
        <TOKEN id="token-19-14" pos="word" morph="none" start_char="964" end_char="966">que</TOKEN>
        <TOKEN id="token-19-15" pos="word" morph="none" start_char="968" end_char="973">saldrá</TOKEN>
        <TOKEN id="token-19-16" pos="word" morph="none" start_char="975" end_char="976">el</TOKEN>
        <TOKEN id="token-19-17" pos="word" morph="none" start_char="978" end_char="984">próximo</TOKEN>
      </SEG>
      <SEG id="segment-20" start_char="986" end_char="1061">
        <ORIGINAL_TEXT>6 de noviembre a las librerías británicas y del que la revista Times publica</ORIGINAL_TEXT>
        <TOKEN id="token-20-0" pos="number" morph="none" start_char="986" end_char="986">6</TOKEN>
        <TOKEN id="token-20-1" pos="word" morph="none" start_char="988" end_char="989">de</TOKEN>
        <TOKEN id="token-20-2" pos="word" morph="none" start_char="991" end_char="999">noviembre</TOKEN>
        <TOKEN id="token-20-3" pos="word" morph="none" start_char="1001" end_char="1001">a</TOKEN>
        <TOKEN id="token-20-4" pos="word" morph="none" start_char="1003" end_char="1005">las</TOKEN>
        <TOKEN id="token-20-5" pos="word" morph="none" start_char="1007" end_char="1015">librerías</TOKEN>
        <TOKEN id="token-20-6" pos="word" morph="none" start_char="1017" end_char="1026">británicas</TOKEN>
        <TOKEN id="token-20-7" pos="word" morph="none" start_char="1028" end_char="1028">y</TOKEN>
        <TOKEN id="token-20-8" pos="word" morph="none" start_char="1030" end_char="1032">del</TOKEN>
        <TOKEN id="token-20-9" pos="word" morph="none" start_char="1034" end_char="1036">que</TOKEN>
        <TOKEN id="token-20-10" pos="word" morph="none" start_char="1038" end_char="1039">la</TOKEN>
        <TOKEN id="token-20-11" pos="word" morph="none" start_char="1041" end_char="1047">revista</TOKEN>
        <TOKEN id="token-20-12" pos="word" morph="none" start_char="1049" end_char="1053">Times</TOKEN>
        <TOKEN id="token-20-13" pos="word" morph="none" start_char="1055" end_char="1061">publica</TOKEN>
      </SEG>
      <SEG id="segment-21" start_char="1063" end_char="1080">
        <ORIGINAL_TEXT>varios fragmentos.</ORIGINAL_TEXT>
        <TOKEN id="token-21-0" pos="word" morph="none" start_char="1063" end_char="1068">varios</TOKEN>
        <TOKEN id="token-21-1" pos="word" morph="none" start_char="1070" end_char="1079">fragmentos</TOKEN>
        <TOKEN id="token-21-2" pos="punct" morph="none" start_char="1080" end_char="1080">.</TOKEN>
      </SEG>
      <SEG id="segment-22" start_char="1082" end_char="1085">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-22-0" pos="unknown" morph="none" start_char="1082" end_char="1085">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-23" start_char="1087" end_char="1089">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-23-0" pos="unknown" morph="none" start_char="1087" end_char="1089">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-24" start_char="1091" end_char="1165">
        <ORIGINAL_TEXT>June Steenkamp describe a Pistorius como alguien "arrogante", "caprichoso",</ORIGINAL_TEXT>
        <TOKEN id="token-24-0" pos="word" morph="none" start_char="1091" end_char="1094">June</TOKEN>
        <TOKEN id="token-24-1" pos="word" morph="none" start_char="1096" end_char="1104">Steenkamp</TOKEN>
        <TOKEN id="token-24-2" pos="word" morph="none" start_char="1106" end_char="1113">describe</TOKEN>
        <TOKEN id="token-24-3" pos="word" morph="none" start_char="1115" end_char="1115">a</TOKEN>
        <TOKEN id="token-24-4" pos="word" morph="none" start_char="1117" end_char="1125">Pistorius</TOKEN>
        <TOKEN id="token-24-5" pos="word" morph="none" start_char="1127" end_char="1130">como</TOKEN>
        <TOKEN id="token-24-6" pos="word" morph="none" start_char="1132" end_char="1138">alguien</TOKEN>
        <TOKEN id="token-24-7" pos="punct" morph="none" start_char="1140" end_char="1140">"</TOKEN>
        <TOKEN id="token-24-8" pos="word" morph="none" start_char="1141" end_char="1149">arrogante</TOKEN>
        <TOKEN id="token-24-9" pos="punct" morph="none" start_char="1150" end_char="1151">",</TOKEN>
        <TOKEN id="token-24-10" pos="punct" morph="none" start_char="1153" end_char="1153">"</TOKEN>
        <TOKEN id="token-24-11" pos="word" morph="none" start_char="1154" end_char="1163">caprichoso</TOKEN>
        <TOKEN id="token-24-12" pos="punct" morph="none" start_char="1164" end_char="1165">",</TOKEN>
      </SEG>
      <SEG id="segment-25" start_char="1167" end_char="1234">
        <ORIGINAL_TEXT>"versátil", "explosivo", "posesivo", "distraído" y "escurridizo". Le</ORIGINAL_TEXT>
        <TOKEN id="token-25-0" pos="punct" morph="none" start_char="1167" end_char="1167">"</TOKEN>
        <TOKEN id="token-25-1" pos="word" morph="none" start_char="1168" end_char="1175">versátil</TOKEN>
        <TOKEN id="token-25-2" pos="punct" morph="none" start_char="1176" end_char="1177">",</TOKEN>
        <TOKEN id="token-25-3" pos="punct" morph="none" start_char="1179" end_char="1179">"</TOKEN>
        <TOKEN id="token-25-4" pos="word" morph="none" start_char="1180" end_char="1188">explosivo</TOKEN>
        <TOKEN id="token-25-5" pos="punct" morph="none" start_char="1189" end_char="1190">",</TOKEN>
        <TOKEN id="token-25-6" pos="punct" morph="none" start_char="1192" end_char="1192">"</TOKEN>
        <TOKEN id="token-25-7" pos="word" morph="none" start_char="1193" end_char="1200">posesivo</TOKEN>
        <TOKEN id="token-25-8" pos="punct" morph="none" start_char="1201" end_char="1202">",</TOKEN>
        <TOKEN id="token-25-9" pos="punct" morph="none" start_char="1204" end_char="1204">"</TOKEN>
        <TOKEN id="token-25-10" pos="word" morph="none" start_char="1205" end_char="1213">distraído</TOKEN>
        <TOKEN id="token-25-11" pos="punct" morph="none" start_char="1214" end_char="1214">"</TOKEN>
        <TOKEN id="token-25-12" pos="word" morph="none" start_char="1216" end_char="1216">y</TOKEN>
        <TOKEN id="token-25-13" pos="punct" morph="none" start_char="1218" end_char="1218">"</TOKEN>
        <TOKEN id="token-25-14" pos="word" morph="none" start_char="1219" end_char="1229">escurridizo</TOKEN>
        <TOKEN id="token-25-15" pos="punct" morph="none" start_char="1230" end_char="1231">".</TOKEN>
        <TOKEN id="token-25-16" pos="word" morph="none" start_char="1233" end_char="1234">Le</TOKEN>
      </SEG>
      <SEG id="segment-26" start_char="1236" end_char="1312">
        <ORIGINAL_TEXT>presenta como "armados hasta los dientes" y de "gatillo fácil". "La desgracia</ORIGINAL_TEXT>
        <TOKEN id="token-26-0" pos="word" morph="none" start_char="1236" end_char="1243">presenta</TOKEN>
        <TOKEN id="token-26-1" pos="word" morph="none" start_char="1245" end_char="1248">como</TOKEN>
        <TOKEN id="token-26-2" pos="punct" morph="none" start_char="1250" end_char="1250">"</TOKEN>
        <TOKEN id="token-26-3" pos="word" morph="none" start_char="1251" end_char="1257">armados</TOKEN>
        <TOKEN id="token-26-4" pos="word" morph="none" start_char="1259" end_char="1263">hasta</TOKEN>
        <TOKEN id="token-26-5" pos="word" morph="none" start_char="1265" end_char="1267">los</TOKEN>
        <TOKEN id="token-26-6" pos="word" morph="none" start_char="1269" end_char="1275">dientes</TOKEN>
        <TOKEN id="token-26-7" pos="punct" morph="none" start_char="1276" end_char="1276">"</TOKEN>
        <TOKEN id="token-26-8" pos="word" morph="none" start_char="1278" end_char="1278">y</TOKEN>
        <TOKEN id="token-26-9" pos="word" morph="none" start_char="1280" end_char="1281">de</TOKEN>
        <TOKEN id="token-26-10" pos="punct" morph="none" start_char="1283" end_char="1283">"</TOKEN>
        <TOKEN id="token-26-11" pos="word" morph="none" start_char="1284" end_char="1290">gatillo</TOKEN>
        <TOKEN id="token-26-12" pos="word" morph="none" start_char="1292" end_char="1296">fácil</TOKEN>
        <TOKEN id="token-26-13" pos="punct" morph="none" start_char="1297" end_char="1298">".</TOKEN>
        <TOKEN id="token-26-14" pos="punct" morph="none" start_char="1300" end_char="1300">"</TOKEN>
        <TOKEN id="token-26-15" pos="word" morph="none" start_char="1301" end_char="1302">La</TOKEN>
        <TOKEN id="token-26-16" pos="word" morph="none" start_char="1304" end_char="1312">desgracia</TOKEN>
      </SEG>
      <SEG id="segment-27" start_char="1314" end_char="1388">
        <ORIGINAL_TEXT>de Reeva fue unirse con él, porque tarde o temprano iba a matar a alguien",</ORIGINAL_TEXT>
        <TOKEN id="token-27-0" pos="word" morph="none" start_char="1314" end_char="1315">de</TOKEN>
        <TOKEN id="token-27-1" pos="word" morph="none" start_char="1317" end_char="1321">Reeva</TOKEN>
        <TOKEN id="token-27-2" pos="word" morph="none" start_char="1323" end_char="1325">fue</TOKEN>
        <TOKEN id="token-27-3" pos="word" morph="none" start_char="1327" end_char="1332">unirse</TOKEN>
        <TOKEN id="token-27-4" pos="word" morph="none" start_char="1334" end_char="1336">con</TOKEN>
        <TOKEN id="token-27-5" pos="word" morph="none" start_char="1338" end_char="1339">él</TOKEN>
        <TOKEN id="token-27-6" pos="punct" morph="none" start_char="1340" end_char="1340">,</TOKEN>
        <TOKEN id="token-27-7" pos="word" morph="none" start_char="1342" end_char="1347">porque</TOKEN>
        <TOKEN id="token-27-8" pos="word" morph="none" start_char="1349" end_char="1353">tarde</TOKEN>
        <TOKEN id="token-27-9" pos="word" morph="none" start_char="1355" end_char="1355">o</TOKEN>
        <TOKEN id="token-27-10" pos="word" morph="none" start_char="1357" end_char="1364">temprano</TOKEN>
        <TOKEN id="token-27-11" pos="word" morph="none" start_char="1366" end_char="1368">iba</TOKEN>
        <TOKEN id="token-27-12" pos="word" morph="none" start_char="1370" end_char="1370">a</TOKEN>
        <TOKEN id="token-27-13" pos="word" morph="none" start_char="1372" end_char="1376">matar</TOKEN>
        <TOKEN id="token-27-14" pos="word" morph="none" start_char="1378" end_char="1378">a</TOKEN>
        <TOKEN id="token-27-15" pos="word" morph="none" start_char="1380" end_char="1386">alguien</TOKEN>
        <TOKEN id="token-27-16" pos="punct" morph="none" start_char="1387" end_char="1388">",</TOKEN>
      </SEG>
      <SEG id="segment-28" start_char="1390" end_char="1462">
        <ORIGINAL_TEXT>añade en el libro. Y añade que su hija tenía "persistentes dudas sobre su</ORIGINAL_TEXT>
        <TOKEN id="token-28-0" pos="word" morph="none" start_char="1390" end_char="1394">añade</TOKEN>
        <TOKEN id="token-28-1" pos="word" morph="none" start_char="1396" end_char="1397">en</TOKEN>
        <TOKEN id="token-28-2" pos="word" morph="none" start_char="1399" end_char="1400">el</TOKEN>
        <TOKEN id="token-28-3" pos="word" morph="none" start_char="1402" end_char="1406">libro</TOKEN>
        <TOKEN id="token-28-4" pos="punct" morph="none" start_char="1407" end_char="1407">.</TOKEN>
        <TOKEN id="token-28-5" pos="word" morph="none" start_char="1409" end_char="1409">Y</TOKEN>
        <TOKEN id="token-28-6" pos="word" morph="none" start_char="1411" end_char="1415">añade</TOKEN>
        <TOKEN id="token-28-7" pos="word" morph="none" start_char="1417" end_char="1419">que</TOKEN>
        <TOKEN id="token-28-8" pos="word" morph="none" start_char="1421" end_char="1422">su</TOKEN>
        <TOKEN id="token-28-9" pos="word" morph="none" start_char="1424" end_char="1427">hija</TOKEN>
        <TOKEN id="token-28-10" pos="word" morph="none" start_char="1429" end_char="1433">tenía</TOKEN>
        <TOKEN id="token-28-11" pos="punct" morph="none" start_char="1435" end_char="1435">"</TOKEN>
        <TOKEN id="token-28-12" pos="word" morph="none" start_char="1436" end_char="1447">persistentes</TOKEN>
        <TOKEN id="token-28-13" pos="word" morph="none" start_char="1449" end_char="1453">dudas</TOKEN>
        <TOKEN id="token-28-14" pos="word" morph="none" start_char="1455" end_char="1459">sobre</TOKEN>
        <TOKEN id="token-28-15" pos="word" morph="none" start_char="1461" end_char="1462">su</TOKEN>
      </SEG>
      <SEG id="segment-29" start_char="1464" end_char="1479">
        <ORIGINAL_TEXT>compatibilidad".</ORIGINAL_TEXT>
        <TOKEN id="token-29-0" pos="word" morph="none" start_char="1464" end_char="1477">compatibilidad</TOKEN>
        <TOKEN id="token-29-1" pos="punct" morph="none" start_char="1478" end_char="1479">".</TOKEN>
      </SEG>
      <SEG id="segment-30" start_char="1481" end_char="1484">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-30-0" pos="unknown" morph="none" start_char="1481" end_char="1484">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-31" start_char="1486" end_char="1488">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-31-0" pos="unknown" morph="none" start_char="1486" end_char="1488">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-32" start_char="1490" end_char="1560">
        <ORIGINAL_TEXT>"Ella me dijo que no había consumado la relación. Compartieron la misma</ORIGINAL_TEXT>
        <TOKEN id="token-32-0" pos="punct" morph="none" start_char="1490" end_char="1490">"</TOKEN>
        <TOKEN id="token-32-1" pos="word" morph="none" start_char="1491" end_char="1494">Ella</TOKEN>
        <TOKEN id="token-32-2" pos="word" morph="none" start_char="1496" end_char="1497">me</TOKEN>
        <TOKEN id="token-32-3" pos="word" morph="none" start_char="1499" end_char="1502">dijo</TOKEN>
        <TOKEN id="token-32-4" pos="word" morph="none" start_char="1504" end_char="1506">que</TOKEN>
        <TOKEN id="token-32-5" pos="word" morph="none" start_char="1508" end_char="1509">no</TOKEN>
        <TOKEN id="token-32-6" pos="word" morph="none" start_char="1511" end_char="1515">había</TOKEN>
        <TOKEN id="token-32-7" pos="word" morph="none" start_char="1517" end_char="1525">consumado</TOKEN>
        <TOKEN id="token-32-8" pos="word" morph="none" start_char="1527" end_char="1528">la</TOKEN>
        <TOKEN id="token-32-9" pos="word" morph="none" start_char="1530" end_char="1537">relación</TOKEN>
        <TOKEN id="token-32-10" pos="punct" morph="none" start_char="1538" end_char="1538">.</TOKEN>
        <TOKEN id="token-32-11" pos="word" morph="none" start_char="1540" end_char="1551">Compartieron</TOKEN>
        <TOKEN id="token-32-12" pos="word" morph="none" start_char="1553" end_char="1554">la</TOKEN>
        <TOKEN id="token-32-13" pos="word" morph="none" start_char="1556" end_char="1560">misma</TOKEN>
      </SEG>
      <SEG id="segment-33" start_char="1562" end_char="1636">
        <ORIGINAL_TEXT>cama, pero tenía miedo de llevar su relación a este nivel... Ella no estaba</ORIGINAL_TEXT>
        <TOKEN id="token-33-0" pos="word" morph="none" start_char="1562" end_char="1565">cama</TOKEN>
        <TOKEN id="token-33-1" pos="punct" morph="none" start_char="1566" end_char="1566">,</TOKEN>
        <TOKEN id="token-33-2" pos="word" morph="none" start_char="1568" end_char="1571">pero</TOKEN>
        <TOKEN id="token-33-3" pos="word" morph="none" start_char="1573" end_char="1577">tenía</TOKEN>
        <TOKEN id="token-33-4" pos="word" morph="none" start_char="1579" end_char="1583">miedo</TOKEN>
        <TOKEN id="token-33-5" pos="word" morph="none" start_char="1585" end_char="1586">de</TOKEN>
        <TOKEN id="token-33-6" pos="word" morph="none" start_char="1588" end_char="1593">llevar</TOKEN>
        <TOKEN id="token-33-7" pos="word" morph="none" start_char="1595" end_char="1596">su</TOKEN>
        <TOKEN id="token-33-8" pos="word" morph="none" start_char="1598" end_char="1605">relación</TOKEN>
        <TOKEN id="token-33-9" pos="word" morph="none" start_char="1607" end_char="1607">a</TOKEN>
        <TOKEN id="token-33-10" pos="word" morph="none" start_char="1609" end_char="1612">este</TOKEN>
        <TOKEN id="token-33-11" pos="word" morph="none" start_char="1614" end_char="1618">nivel</TOKEN>
        <TOKEN id="token-33-12" pos="punct" morph="none" start_char="1619" end_char="1621">...</TOKEN>
        <TOKEN id="token-33-13" pos="word" morph="none" start_char="1623" end_char="1626">Ella</TOKEN>
        <TOKEN id="token-33-14" pos="word" morph="none" start_char="1628" end_char="1629">no</TOKEN>
        <TOKEN id="token-33-15" pos="word" morph="none" start_char="1631" end_char="1636">estaba</TOKEN>
      </SEG>
      <SEG id="segment-34" start_char="1638" end_char="1692">
        <ORIGINAL_TEXT>segura, creo que quería terminar su relación", escribe.</ORIGINAL_TEXT>
        <TOKEN id="token-34-0" pos="word" morph="none" start_char="1638" end_char="1643">segura</TOKEN>
        <TOKEN id="token-34-1" pos="punct" morph="none" start_char="1644" end_char="1644">,</TOKEN>
        <TOKEN id="token-34-2" pos="word" morph="none" start_char="1646" end_char="1649">creo</TOKEN>
        <TOKEN id="token-34-3" pos="word" morph="none" start_char="1651" end_char="1653">que</TOKEN>
        <TOKEN id="token-34-4" pos="word" morph="none" start_char="1655" end_char="1660">quería</TOKEN>
        <TOKEN id="token-34-5" pos="word" morph="none" start_char="1662" end_char="1669">terminar</TOKEN>
        <TOKEN id="token-34-6" pos="word" morph="none" start_char="1671" end_char="1672">su</TOKEN>
        <TOKEN id="token-34-7" pos="word" morph="none" start_char="1674" end_char="1681">relación</TOKEN>
        <TOKEN id="token-34-8" pos="punct" morph="none" start_char="1682" end_char="1683">",</TOKEN>
        <TOKEN id="token-34-9" pos="word" morph="none" start_char="1685" end_char="1691">escribe</TOKEN>
        <TOKEN id="token-34-10" pos="punct" morph="none" start_char="1692" end_char="1692">.</TOKEN>
      </SEG>
      <SEG id="segment-35" start_char="1694" end_char="1697">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-35-0" pos="unknown" morph="none" start_char="1694" end_char="1697">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-36" start_char="1699" end_char="1701">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-36-0" pos="unknown" morph="none" start_char="1699" end_char="1701">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-37" start_char="1703" end_char="1777">
        <ORIGINAL_TEXT>El deportista ya ha pasado sus primeros días en la prisión de Kgosi Mapuru,</ORIGINAL_TEXT>
        <TOKEN id="token-37-0" pos="word" morph="none" start_char="1703" end_char="1704">El</TOKEN>
        <TOKEN id="token-37-1" pos="word" morph="none" start_char="1706" end_char="1715">deportista</TOKEN>
        <TOKEN id="token-37-2" pos="word" morph="none" start_char="1717" end_char="1718">ya</TOKEN>
        <TOKEN id="token-37-3" pos="word" morph="none" start_char="1720" end_char="1721">ha</TOKEN>
        <TOKEN id="token-37-4" pos="word" morph="none" start_char="1723" end_char="1728">pasado</TOKEN>
        <TOKEN id="token-37-5" pos="word" morph="none" start_char="1730" end_char="1732">sus</TOKEN>
        <TOKEN id="token-37-6" pos="word" morph="none" start_char="1734" end_char="1741">primeros</TOKEN>
        <TOKEN id="token-37-7" pos="word" morph="none" start_char="1743" end_char="1746">días</TOKEN>
        <TOKEN id="token-37-8" pos="word" morph="none" start_char="1748" end_char="1749">en</TOKEN>
        <TOKEN id="token-37-9" pos="word" morph="none" start_char="1751" end_char="1752">la</TOKEN>
        <TOKEN id="token-37-10" pos="word" morph="none" start_char="1754" end_char="1760">prisión</TOKEN>
        <TOKEN id="token-37-11" pos="word" morph="none" start_char="1762" end_char="1763">de</TOKEN>
        <TOKEN id="token-37-12" pos="word" morph="none" start_char="1765" end_char="1769">Kgosi</TOKEN>
        <TOKEN id="token-37-13" pos="word" morph="none" start_char="1771" end_char="1776">Mapuru</TOKEN>
        <TOKEN id="token-37-14" pos="punct" morph="none" start_char="1777" end_char="1777">,</TOKEN>
      </SEG>
      <SEG id="segment-38" start_char="1779" end_char="1789">
        <ORIGINAL_TEXT>en Pretoria</ORIGINAL_TEXT>
        <TOKEN id="token-38-0" pos="word" morph="none" start_char="1779" end_char="1780">en</TOKEN>
        <TOKEN id="token-38-1" pos="word" morph="none" start_char="1782" end_char="1789">Pretoria</TOKEN>
      </SEG>
      <SEG id="segment-39" start_char="1791" end_char="1794">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-39-0" pos="unknown" morph="none" start_char="1791" end_char="1794">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-40" start_char="1796" end_char="1802">
        <ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-40-0" pos="unknown" morph="none" start_char="1796" end_char="1802">&lt;/TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-41" start_char="1804" end_char="1809">
        <ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-41-0" pos="unknown" morph="none" start_char="1804" end_char="1809">&lt;/DOC&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
