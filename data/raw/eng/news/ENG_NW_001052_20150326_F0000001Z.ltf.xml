<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="ENG_NW_001052_20150326_F0000001Z.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="5713" raw_text_md5="c7b254f15bbaf40d48e2eca50de5b333">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001052_20150326_F0000001Z"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001052_20150326_F0000001Z"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="194">
        <ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.thestar.com/life/2015/03/26/monica-lewinskys-story-needs-to-begin-a-new-chapter.html&lt;/SOURCE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="194">&lt;SOURCE&gt;http://www.thestar.com/life/2015/03/26/monica-lewinskys-story-needs-to-begin-a-new-chapter.html&lt;/SOURCE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="196" end_char="237">
        <ORIGINAL_TEXT>&lt;DATE_TIME&gt;2015-03-26T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="unknown" morph="none" start_char="196" end_char="237">&lt;DATE_TIME&gt;2015-03-26T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="239" end_char="248">
        <ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="239" end_char="248">&lt;HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="250" end_char="309">
        <ORIGINAL_TEXT>Monica Lewinsky’s story needs to begin a new chapter: Timson</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="word" morph="none" start_char="250" end_char="255">Monica</TOKEN>
        <TOKEN id="token-5-1" pos="word" morph="none" start_char="257" end_char="264">Lewinsky</TOKEN>
        <TOKEN id="token-5-2" pos="punct" morph="none" start_char="265" end_char="265">’</TOKEN>
        <TOKEN id="token-5-3" pos="word" morph="none" start_char="266" end_char="266">s</TOKEN>
        <TOKEN id="token-5-4" pos="word" morph="none" start_char="268" end_char="272">story</TOKEN>
        <TOKEN id="token-5-5" pos="word" morph="none" start_char="274" end_char="278">needs</TOKEN>
        <TOKEN id="token-5-6" pos="word" morph="none" start_char="280" end_char="281">to</TOKEN>
        <TOKEN id="token-5-7" pos="word" morph="none" start_char="283" end_char="287">begin</TOKEN>
        <TOKEN id="token-5-8" pos="word" morph="none" start_char="289" end_char="289">a</TOKEN>
        <TOKEN id="token-5-9" pos="word" morph="none" start_char="291" end_char="293">new</TOKEN>
        <TOKEN id="token-5-10" pos="word" morph="none" start_char="295" end_char="301">chapter</TOKEN>
        <TOKEN id="token-5-11" pos="punct" morph="none" start_char="302" end_char="302">:</TOKEN>
        <TOKEN id="token-5-12" pos="word" morph="none" start_char="304" end_char="309">Timson</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="311" end_char="321">
        <ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="unknown" morph="none" start_char="311" end_char="321">&lt;/HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="323" end_char="328">
        <ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="323" end_char="328">&lt;TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="330" end_char="332">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="330" end_char="332">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="334" end_char="384">
        <ORIGINAL_TEXT>I still don’t know what to make of Monica Lewinsky.</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="334" end_char="334">I</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="336" end_char="340">still</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="342" end_char="344">don</TOKEN>
        <TOKEN id="token-9-3" pos="punct" morph="none" start_char="345" end_char="345">’</TOKEN>
        <TOKEN id="token-9-4" pos="word" morph="none" start_char="346" end_char="346">t</TOKEN>
        <TOKEN id="token-9-5" pos="word" morph="none" start_char="348" end_char="351">know</TOKEN>
        <TOKEN id="token-9-6" pos="word" morph="none" start_char="353" end_char="356">what</TOKEN>
        <TOKEN id="token-9-7" pos="word" morph="none" start_char="358" end_char="359">to</TOKEN>
        <TOKEN id="token-9-8" pos="word" morph="none" start_char="361" end_char="364">make</TOKEN>
        <TOKEN id="token-9-9" pos="word" morph="none" start_char="366" end_char="367">of</TOKEN>
        <TOKEN id="token-9-10" pos="word" morph="none" start_char="369" end_char="374">Monica</TOKEN>
        <TOKEN id="token-9-11" pos="word" morph="none" start_char="376" end_char="383">Lewinsky</TOKEN>
        <TOKEN id="token-9-12" pos="punct" morph="none" start_char="384" end_char="384">.</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="386" end_char="389">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="unknown" morph="none" start_char="386" end_char="389">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="391" end_char="393">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="unknown" morph="none" start_char="391" end_char="393">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="395" end_char="469">
        <ORIGINAL_TEXT>The former White House intern whose name, at 24, became worldwide shorthand</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="word" morph="none" start_char="395" end_char="397">The</TOKEN>
        <TOKEN id="token-12-1" pos="word" morph="none" start_char="399" end_char="404">former</TOKEN>
        <TOKEN id="token-12-2" pos="word" morph="none" start_char="406" end_char="410">White</TOKEN>
        <TOKEN id="token-12-3" pos="word" morph="none" start_char="412" end_char="416">House</TOKEN>
        <TOKEN id="token-12-4" pos="word" morph="none" start_char="418" end_char="423">intern</TOKEN>
        <TOKEN id="token-12-5" pos="word" morph="none" start_char="425" end_char="429">whose</TOKEN>
        <TOKEN id="token-12-6" pos="word" morph="none" start_char="431" end_char="434">name</TOKEN>
        <TOKEN id="token-12-7" pos="punct" morph="none" start_char="435" end_char="435">,</TOKEN>
        <TOKEN id="token-12-8" pos="word" morph="none" start_char="437" end_char="438">at</TOKEN>
        <TOKEN id="token-12-9" pos="word" morph="none" start_char="440" end_char="441">24</TOKEN>
        <TOKEN id="token-12-10" pos="punct" morph="none" start_char="442" end_char="442">,</TOKEN>
        <TOKEN id="token-12-11" pos="word" morph="none" start_char="444" end_char="449">became</TOKEN>
        <TOKEN id="token-12-12" pos="word" morph="none" start_char="451" end_char="459">worldwide</TOKEN>
        <TOKEN id="token-12-13" pos="word" morph="none" start_char="461" end_char="469">shorthand</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="471" end_char="543">
        <ORIGINAL_TEXT>for, as she said recently, “tramp, tart, slut, whore, bimbo and of course</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="word" morph="none" start_char="471" end_char="473">for</TOKEN>
        <TOKEN id="token-13-1" pos="punct" morph="none" start_char="474" end_char="474">,</TOKEN>
        <TOKEN id="token-13-2" pos="word" morph="none" start_char="476" end_char="477">as</TOKEN>
        <TOKEN id="token-13-3" pos="word" morph="none" start_char="479" end_char="481">she</TOKEN>
        <TOKEN id="token-13-4" pos="word" morph="none" start_char="483" end_char="486">said</TOKEN>
        <TOKEN id="token-13-5" pos="word" morph="none" start_char="488" end_char="495">recently</TOKEN>
        <TOKEN id="token-13-6" pos="punct" morph="none" start_char="496" end_char="496">,</TOKEN>
        <TOKEN id="token-13-7" pos="punct" morph="none" start_char="498" end_char="498">“</TOKEN>
        <TOKEN id="token-13-8" pos="word" morph="none" start_char="499" end_char="503">tramp</TOKEN>
        <TOKEN id="token-13-9" pos="punct" morph="none" start_char="504" end_char="504">,</TOKEN>
        <TOKEN id="token-13-10" pos="word" morph="none" start_char="506" end_char="509">tart</TOKEN>
        <TOKEN id="token-13-11" pos="punct" morph="none" start_char="510" end_char="510">,</TOKEN>
        <TOKEN id="token-13-12" pos="word" morph="none" start_char="512" end_char="515">slut</TOKEN>
        <TOKEN id="token-13-13" pos="punct" morph="none" start_char="516" end_char="516">,</TOKEN>
        <TOKEN id="token-13-14" pos="word" morph="none" start_char="518" end_char="522">whore</TOKEN>
        <TOKEN id="token-13-15" pos="punct" morph="none" start_char="523" end_char="523">,</TOKEN>
        <TOKEN id="token-13-16" pos="word" morph="none" start_char="525" end_char="529">bimbo</TOKEN>
        <TOKEN id="token-13-17" pos="word" morph="none" start_char="531" end_char="533">and</TOKEN>
        <TOKEN id="token-13-18" pos="word" morph="none" start_char="535" end_char="536">of</TOKEN>
        <TOKEN id="token-13-19" pos="word" morph="none" start_char="538" end_char="543">course</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="545" end_char="618">
        <ORIGINAL_TEXT>That Woman” after her sexual relationship with then President Bill Clinton</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="word" morph="none" start_char="545" end_char="548">That</TOKEN>
        <TOKEN id="token-14-1" pos="word" morph="none" start_char="550" end_char="554">Woman</TOKEN>
        <TOKEN id="token-14-2" pos="punct" morph="none" start_char="555" end_char="555">”</TOKEN>
        <TOKEN id="token-14-3" pos="word" morph="none" start_char="557" end_char="561">after</TOKEN>
        <TOKEN id="token-14-4" pos="word" morph="none" start_char="563" end_char="565">her</TOKEN>
        <TOKEN id="token-14-5" pos="word" morph="none" start_char="567" end_char="572">sexual</TOKEN>
        <TOKEN id="token-14-6" pos="word" morph="none" start_char="574" end_char="585">relationship</TOKEN>
        <TOKEN id="token-14-7" pos="word" morph="none" start_char="587" end_char="590">with</TOKEN>
        <TOKEN id="token-14-8" pos="word" morph="none" start_char="592" end_char="595">then</TOKEN>
        <TOKEN id="token-14-9" pos="word" morph="none" start_char="597" end_char="605">President</TOKEN>
        <TOKEN id="token-14-10" pos="word" morph="none" start_char="607" end_char="610">Bill</TOKEN>
        <TOKEN id="token-14-11" pos="word" morph="none" start_char="612" end_char="618">Clinton</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="620" end_char="693">
        <ORIGINAL_TEXT>resulted in his impeachment (spoiler alert, he survived nicely) is now 41,</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="word" morph="none" start_char="620" end_char="627">resulted</TOKEN>
        <TOKEN id="token-15-1" pos="word" morph="none" start_char="629" end_char="630">in</TOKEN>
        <TOKEN id="token-15-2" pos="word" morph="none" start_char="632" end_char="634">his</TOKEN>
        <TOKEN id="token-15-3" pos="word" morph="none" start_char="636" end_char="646">impeachment</TOKEN>
        <TOKEN id="token-15-4" pos="punct" morph="none" start_char="648" end_char="648">(</TOKEN>
        <TOKEN id="token-15-5" pos="word" morph="none" start_char="649" end_char="655">spoiler</TOKEN>
        <TOKEN id="token-15-6" pos="word" morph="none" start_char="657" end_char="661">alert</TOKEN>
        <TOKEN id="token-15-7" pos="punct" morph="none" start_char="662" end_char="662">,</TOKEN>
        <TOKEN id="token-15-8" pos="word" morph="none" start_char="664" end_char="665">he</TOKEN>
        <TOKEN id="token-15-9" pos="word" morph="none" start_char="667" end_char="674">survived</TOKEN>
        <TOKEN id="token-15-10" pos="word" morph="none" start_char="676" end_char="681">nicely</TOKEN>
        <TOKEN id="token-15-11" pos="punct" morph="none" start_char="682" end_char="682">)</TOKEN>
        <TOKEN id="token-15-12" pos="word" morph="none" start_char="684" end_char="685">is</TOKEN>
        <TOKEN id="token-15-13" pos="word" morph="none" start_char="687" end_char="689">now</TOKEN>
        <TOKEN id="token-15-14" pos="word" morph="none" start_char="691" end_char="692">41</TOKEN>
        <TOKEN id="token-15-15" pos="punct" morph="none" start_char="693" end_char="693">,</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="695" end_char="745">
        <ORIGINAL_TEXT>back in the spotlight, and saying some wise things.</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="word" morph="none" start_char="695" end_char="698">back</TOKEN>
        <TOKEN id="token-16-1" pos="word" morph="none" start_char="700" end_char="701">in</TOKEN>
        <TOKEN id="token-16-2" pos="word" morph="none" start_char="703" end_char="705">the</TOKEN>
        <TOKEN id="token-16-3" pos="word" morph="none" start_char="707" end_char="715">spotlight</TOKEN>
        <TOKEN id="token-16-4" pos="punct" morph="none" start_char="716" end_char="716">,</TOKEN>
        <TOKEN id="token-16-5" pos="word" morph="none" start_char="718" end_char="720">and</TOKEN>
        <TOKEN id="token-16-6" pos="word" morph="none" start_char="722" end_char="727">saying</TOKEN>
        <TOKEN id="token-16-7" pos="word" morph="none" start_char="729" end_char="732">some</TOKEN>
        <TOKEN id="token-16-8" pos="word" morph="none" start_char="734" end_char="737">wise</TOKEN>
        <TOKEN id="token-16-9" pos="word" morph="none" start_char="739" end_char="744">things</TOKEN>
        <TOKEN id="token-16-10" pos="punct" morph="none" start_char="745" end_char="745">.</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="747" end_char="750">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="unknown" morph="none" start_char="747" end_char="750">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="752" end_char="754">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="unknown" morph="none" start_char="752" end_char="754">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-19" start_char="756" end_char="829">
        <ORIGINAL_TEXT>“Insist on a different ending to your story,” Lewinsky said last week in a</ORIGINAL_TEXT>
        <TOKEN id="token-19-0" pos="punct" morph="none" start_char="756" end_char="756">“</TOKEN>
        <TOKEN id="token-19-1" pos="word" morph="none" start_char="757" end_char="762">Insist</TOKEN>
        <TOKEN id="token-19-2" pos="word" morph="none" start_char="764" end_char="765">on</TOKEN>
        <TOKEN id="token-19-3" pos="word" morph="none" start_char="767" end_char="767">a</TOKEN>
        <TOKEN id="token-19-4" pos="word" morph="none" start_char="769" end_char="777">different</TOKEN>
        <TOKEN id="token-19-5" pos="word" morph="none" start_char="779" end_char="784">ending</TOKEN>
        <TOKEN id="token-19-6" pos="word" morph="none" start_char="786" end_char="787">to</TOKEN>
        <TOKEN id="token-19-7" pos="word" morph="none" start_char="789" end_char="792">your</TOKEN>
        <TOKEN id="token-19-8" pos="word" morph="none" start_char="794" end_char="798">story</TOKEN>
        <TOKEN id="token-19-9" pos="punct" morph="none" start_char="799" end_char="800">,”</TOKEN>
        <TOKEN id="token-19-10" pos="word" morph="none" start_char="802" end_char="809">Lewinsky</TOKEN>
        <TOKEN id="token-19-11" pos="word" morph="none" start_char="811" end_char="814">said</TOKEN>
        <TOKEN id="token-19-12" pos="word" morph="none" start_char="816" end_char="819">last</TOKEN>
        <TOKEN id="token-19-13" pos="word" morph="none" start_char="821" end_char="824">week</TOKEN>
        <TOKEN id="token-19-14" pos="word" morph="none" start_char="826" end_char="827">in</TOKEN>
        <TOKEN id="token-19-15" pos="word" morph="none" start_char="829" end_char="829">a</TOKEN>
      </SEG>
      <SEG id="segment-20" start_char="831" end_char="898">
        <ORIGINAL_TEXT>universally acclaimed TED Talk condemning “public shaming as a blood</ORIGINAL_TEXT>
        <TOKEN id="token-20-0" pos="word" morph="none" start_char="831" end_char="841">universally</TOKEN>
        <TOKEN id="token-20-1" pos="word" morph="none" start_char="843" end_char="851">acclaimed</TOKEN>
        <TOKEN id="token-20-2" pos="word" morph="none" start_char="853" end_char="855">TED</TOKEN>
        <TOKEN id="token-20-3" pos="word" morph="none" start_char="857" end_char="860">Talk</TOKEN>
        <TOKEN id="token-20-4" pos="word" morph="none" start_char="862" end_char="871">condemning</TOKEN>
        <TOKEN id="token-20-5" pos="punct" morph="none" start_char="873" end_char="873">“</TOKEN>
        <TOKEN id="token-20-6" pos="word" morph="none" start_char="874" end_char="879">public</TOKEN>
        <TOKEN id="token-20-7" pos="word" morph="none" start_char="881" end_char="887">shaming</TOKEN>
        <TOKEN id="token-20-8" pos="word" morph="none" start_char="889" end_char="890">as</TOKEN>
        <TOKEN id="token-20-9" pos="word" morph="none" start_char="892" end_char="892">a</TOKEN>
        <TOKEN id="token-20-10" pos="word" morph="none" start_char="894" end_char="898">blood</TOKEN>
      </SEG>
      <SEG id="segment-21" start_char="900" end_char="906">
        <ORIGINAL_TEXT>sport.”</ORIGINAL_TEXT>
        <TOKEN id="token-21-0" pos="word" morph="none" start_char="900" end_char="904">sport</TOKEN>
        <TOKEN id="token-21-1" pos="punct" morph="none" start_char="905" end_char="906">.”</TOKEN>
      </SEG>
      <SEG id="segment-22" start_char="908" end_char="911">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-22-0" pos="unknown" morph="none" start_char="908" end_char="911">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-23" start_char="913" end_char="915">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-23-0" pos="unknown" morph="none" start_char="913" end_char="915">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-24" start_char="917" end_char="987">
        <ORIGINAL_TEXT>Describing herself as “patient zero” in internet shaming — there was no</ORIGINAL_TEXT>
        <TOKEN id="token-24-0" pos="word" morph="none" start_char="917" end_char="926">Describing</TOKEN>
        <TOKEN id="token-24-1" pos="word" morph="none" start_char="928" end_char="934">herself</TOKEN>
        <TOKEN id="token-24-2" pos="word" morph="none" start_char="936" end_char="937">as</TOKEN>
        <TOKEN id="token-24-3" pos="punct" morph="none" start_char="939" end_char="939">“</TOKEN>
        <TOKEN id="token-24-4" pos="word" morph="none" start_char="940" end_char="946">patient</TOKEN>
        <TOKEN id="token-24-5" pos="word" morph="none" start_char="948" end_char="951">zero</TOKEN>
        <TOKEN id="token-24-6" pos="punct" morph="none" start_char="952" end_char="952">”</TOKEN>
        <TOKEN id="token-24-7" pos="word" morph="none" start_char="954" end_char="955">in</TOKEN>
        <TOKEN id="token-24-8" pos="word" morph="none" start_char="957" end_char="964">internet</TOKEN>
        <TOKEN id="token-24-9" pos="word" morph="none" start_char="966" end_char="972">shaming</TOKEN>
        <TOKEN id="token-24-10" pos="unknown" morph="none" start_char="974" end_char="974">—</TOKEN>
        <TOKEN id="token-24-11" pos="word" morph="none" start_char="976" end_char="980">there</TOKEN>
        <TOKEN id="token-24-12" pos="word" morph="none" start_char="982" end_char="984">was</TOKEN>
        <TOKEN id="token-24-13" pos="word" morph="none" start_char="986" end_char="987">no</TOKEN>
      </SEG>
      <SEG id="segment-25" start_char="989" end_char="1062">
        <ORIGINAL_TEXT>social media in 1998, but news of her affair with Clinton as a young woman</ORIGINAL_TEXT>
        <TOKEN id="token-25-0" pos="word" morph="none" start_char="989" end_char="994">social</TOKEN>
        <TOKEN id="token-25-1" pos="word" morph="none" start_char="996" end_char="1000">media</TOKEN>
        <TOKEN id="token-25-2" pos="word" morph="none" start_char="1002" end_char="1003">in</TOKEN>
        <TOKEN id="token-25-3" pos="word" morph="none" start_char="1005" end_char="1008">1998</TOKEN>
        <TOKEN id="token-25-4" pos="punct" morph="none" start_char="1009" end_char="1009">,</TOKEN>
        <TOKEN id="token-25-5" pos="word" morph="none" start_char="1011" end_char="1013">but</TOKEN>
        <TOKEN id="token-25-6" pos="word" morph="none" start_char="1015" end_char="1018">news</TOKEN>
        <TOKEN id="token-25-7" pos="word" morph="none" start_char="1020" end_char="1021">of</TOKEN>
        <TOKEN id="token-25-8" pos="word" morph="none" start_char="1023" end_char="1025">her</TOKEN>
        <TOKEN id="token-25-9" pos="word" morph="none" start_char="1027" end_char="1032">affair</TOKEN>
        <TOKEN id="token-25-10" pos="word" morph="none" start_char="1034" end_char="1037">with</TOKEN>
        <TOKEN id="token-25-11" pos="word" morph="none" start_char="1039" end_char="1045">Clinton</TOKEN>
        <TOKEN id="token-25-12" pos="word" morph="none" start_char="1047" end_char="1048">as</TOKEN>
        <TOKEN id="token-25-13" pos="word" morph="none" start_char="1050" end_char="1050">a</TOKEN>
        <TOKEN id="token-25-14" pos="word" morph="none" start_char="1052" end_char="1056">young</TOKEN>
        <TOKEN id="token-25-15" pos="word" morph="none" start_char="1058" end_char="1062">woman</TOKEN>
      </SEG>
      <SEG id="segment-26" start_char="1064" end_char="1134">
        <ORIGINAL_TEXT>first broke on the gossipy online Drudge Report — Lewinsky called for a</ORIGINAL_TEXT>
        <TOKEN id="token-26-0" pos="word" morph="none" start_char="1064" end_char="1068">first</TOKEN>
        <TOKEN id="token-26-1" pos="word" morph="none" start_char="1070" end_char="1074">broke</TOKEN>
        <TOKEN id="token-26-2" pos="word" morph="none" start_char="1076" end_char="1077">on</TOKEN>
        <TOKEN id="token-26-3" pos="word" morph="none" start_char="1079" end_char="1081">the</TOKEN>
        <TOKEN id="token-26-4" pos="word" morph="none" start_char="1083" end_char="1089">gossipy</TOKEN>
        <TOKEN id="token-26-5" pos="word" morph="none" start_char="1091" end_char="1096">online</TOKEN>
        <TOKEN id="token-26-6" pos="word" morph="none" start_char="1098" end_char="1103">Drudge</TOKEN>
        <TOKEN id="token-26-7" pos="word" morph="none" start_char="1105" end_char="1110">Report</TOKEN>
        <TOKEN id="token-26-8" pos="unknown" morph="none" start_char="1112" end_char="1112">—</TOKEN>
        <TOKEN id="token-26-9" pos="word" morph="none" start_char="1114" end_char="1121">Lewinsky</TOKEN>
        <TOKEN id="token-26-10" pos="word" morph="none" start_char="1123" end_char="1128">called</TOKEN>
        <TOKEN id="token-26-11" pos="word" morph="none" start_char="1130" end_char="1132">for</TOKEN>
        <TOKEN id="token-26-12" pos="word" morph="none" start_char="1134" end_char="1134">a</TOKEN>
      </SEG>
      <SEG id="segment-27" start_char="1136" end_char="1174">
        <ORIGINAL_TEXT>revolution in “compassion and empathy”.</ORIGINAL_TEXT>
        <TOKEN id="token-27-0" pos="word" morph="none" start_char="1136" end_char="1145">revolution</TOKEN>
        <TOKEN id="token-27-1" pos="word" morph="none" start_char="1147" end_char="1148">in</TOKEN>
        <TOKEN id="token-27-2" pos="punct" morph="none" start_char="1150" end_char="1150">“</TOKEN>
        <TOKEN id="token-27-3" pos="word" morph="none" start_char="1151" end_char="1160">compassion</TOKEN>
        <TOKEN id="token-27-4" pos="word" morph="none" start_char="1162" end_char="1164">and</TOKEN>
        <TOKEN id="token-27-5" pos="word" morph="none" start_char="1166" end_char="1172">empathy</TOKEN>
        <TOKEN id="token-27-6" pos="punct" morph="none" start_char="1173" end_char="1174">”.</TOKEN>
      </SEG>
      <SEG id="segment-28" start_char="1176" end_char="1179">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-28-0" pos="unknown" morph="none" start_char="1176" end_char="1179">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-29" start_char="1181" end_char="1183">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-29-0" pos="unknown" morph="none" start_char="1181" end_char="1183">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-30" start_char="1185" end_char="1255">
        <ORIGINAL_TEXT>She described how humiliated she had been when salacious details became</ORIGINAL_TEXT>
        <TOKEN id="token-30-0" pos="word" morph="none" start_char="1185" end_char="1187">She</TOKEN>
        <TOKEN id="token-30-1" pos="word" morph="none" start_char="1189" end_char="1197">described</TOKEN>
        <TOKEN id="token-30-2" pos="word" morph="none" start_char="1199" end_char="1201">how</TOKEN>
        <TOKEN id="token-30-3" pos="word" morph="none" start_char="1203" end_char="1212">humiliated</TOKEN>
        <TOKEN id="token-30-4" pos="word" morph="none" start_char="1214" end_char="1216">she</TOKEN>
        <TOKEN id="token-30-5" pos="word" morph="none" start_char="1218" end_char="1220">had</TOKEN>
        <TOKEN id="token-30-6" pos="word" morph="none" start_char="1222" end_char="1225">been</TOKEN>
        <TOKEN id="token-30-7" pos="word" morph="none" start_char="1227" end_char="1230">when</TOKEN>
        <TOKEN id="token-30-8" pos="word" morph="none" start_char="1232" end_char="1240">salacious</TOKEN>
        <TOKEN id="token-30-9" pos="word" morph="none" start_char="1242" end_char="1248">details</TOKEN>
        <TOKEN id="token-30-10" pos="word" morph="none" start_char="1250" end_char="1255">became</TOKEN>
      </SEG>
      <SEG id="segment-31" start_char="1257" end_char="1322">
        <ORIGINAL_TEXT>public: “I lost my reputation, my dignity, I almost lost my life.”</ORIGINAL_TEXT>
        <TOKEN id="token-31-0" pos="word" morph="none" start_char="1257" end_char="1262">public</TOKEN>
        <TOKEN id="token-31-1" pos="punct" morph="none" start_char="1263" end_char="1263">:</TOKEN>
        <TOKEN id="token-31-2" pos="punct" morph="none" start_char="1265" end_char="1265">“</TOKEN>
        <TOKEN id="token-31-3" pos="word" morph="none" start_char="1266" end_char="1266">I</TOKEN>
        <TOKEN id="token-31-4" pos="word" morph="none" start_char="1268" end_char="1271">lost</TOKEN>
        <TOKEN id="token-31-5" pos="word" morph="none" start_char="1273" end_char="1274">my</TOKEN>
        <TOKEN id="token-31-6" pos="word" morph="none" start_char="1276" end_char="1285">reputation</TOKEN>
        <TOKEN id="token-31-7" pos="punct" morph="none" start_char="1286" end_char="1286">,</TOKEN>
        <TOKEN id="token-31-8" pos="word" morph="none" start_char="1288" end_char="1289">my</TOKEN>
        <TOKEN id="token-31-9" pos="word" morph="none" start_char="1291" end_char="1297">dignity</TOKEN>
        <TOKEN id="token-31-10" pos="punct" morph="none" start_char="1298" end_char="1298">,</TOKEN>
        <TOKEN id="token-31-11" pos="word" morph="none" start_char="1300" end_char="1300">I</TOKEN>
        <TOKEN id="token-31-12" pos="word" morph="none" start_char="1302" end_char="1307">almost</TOKEN>
        <TOKEN id="token-31-13" pos="word" morph="none" start_char="1309" end_char="1312">lost</TOKEN>
        <TOKEN id="token-31-14" pos="word" morph="none" start_char="1314" end_char="1315">my</TOKEN>
        <TOKEN id="token-31-15" pos="word" morph="none" start_char="1317" end_char="1320">life</TOKEN>
        <TOKEN id="token-31-16" pos="punct" morph="none" start_char="1321" end_char="1322">.”</TOKEN>
      </SEG>
      <SEG id="segment-32" start_char="1324" end_char="1327">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-32-0" pos="unknown" morph="none" start_char="1324" end_char="1327">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-33" start_char="1329" end_char="1331">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-33-0" pos="unknown" morph="none" start_char="1329" end_char="1331">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-34" start_char="1333" end_char="1405">
        <ORIGINAL_TEXT>Those details included snapping her thong at the pathetically weak-willed</ORIGINAL_TEXT>
        <TOKEN id="token-34-0" pos="word" morph="none" start_char="1333" end_char="1337">Those</TOKEN>
        <TOKEN id="token-34-1" pos="word" morph="none" start_char="1339" end_char="1345">details</TOKEN>
        <TOKEN id="token-34-2" pos="word" morph="none" start_char="1347" end_char="1354">included</TOKEN>
        <TOKEN id="token-34-3" pos="word" morph="none" start_char="1356" end_char="1363">snapping</TOKEN>
        <TOKEN id="token-34-4" pos="word" morph="none" start_char="1365" end_char="1367">her</TOKEN>
        <TOKEN id="token-34-5" pos="word" morph="none" start_char="1369" end_char="1373">thong</TOKEN>
        <TOKEN id="token-34-6" pos="word" morph="none" start_char="1375" end_char="1376">at</TOKEN>
        <TOKEN id="token-34-7" pos="word" morph="none" start_char="1378" end_char="1380">the</TOKEN>
        <TOKEN id="token-34-8" pos="word" morph="none" start_char="1382" end_char="1393">pathetically</TOKEN>
        <TOKEN id="token-34-9" pos="word" morph="none" start_char="1395" end_char="1398">weak</TOKEN>
        <TOKEN id="token-34-10" pos="punct" morph="none" start_char="1399" end_char="1399">-</TOKEN>
        <TOKEN id="token-34-11" pos="word" morph="none" start_char="1400" end_char="1405">willed</TOKEN>
      </SEG>
      <SEG id="segment-35" start_char="1407" end_char="1484">
        <ORIGINAL_TEXT>president to get his attention, administering oral sex to him beneath his desk</ORIGINAL_TEXT>
        <TOKEN id="token-35-0" pos="word" morph="none" start_char="1407" end_char="1415">president</TOKEN>
        <TOKEN id="token-35-1" pos="word" morph="none" start_char="1417" end_char="1418">to</TOKEN>
        <TOKEN id="token-35-2" pos="word" morph="none" start_char="1420" end_char="1422">get</TOKEN>
        <TOKEN id="token-35-3" pos="word" morph="none" start_char="1424" end_char="1426">his</TOKEN>
        <TOKEN id="token-35-4" pos="word" morph="none" start_char="1428" end_char="1436">attention</TOKEN>
        <TOKEN id="token-35-5" pos="punct" morph="none" start_char="1437" end_char="1437">,</TOKEN>
        <TOKEN id="token-35-6" pos="word" morph="none" start_char="1439" end_char="1451">administering</TOKEN>
        <TOKEN id="token-35-7" pos="word" morph="none" start_char="1453" end_char="1456">oral</TOKEN>
        <TOKEN id="token-35-8" pos="word" morph="none" start_char="1458" end_char="1460">sex</TOKEN>
        <TOKEN id="token-35-9" pos="word" morph="none" start_char="1462" end_char="1463">to</TOKEN>
        <TOKEN id="token-35-10" pos="word" morph="none" start_char="1465" end_char="1467">him</TOKEN>
        <TOKEN id="token-35-11" pos="word" morph="none" start_char="1469" end_char="1475">beneath</TOKEN>
        <TOKEN id="token-35-12" pos="word" morph="none" start_char="1477" end_char="1479">his</TOKEN>
        <TOKEN id="token-35-13" pos="word" morph="none" start_char="1481" end_char="1484">desk</TOKEN>
      </SEG>
      <SEG id="segment-36" start_char="1486" end_char="1560">
        <ORIGINAL_TEXT>as he talked to congressional leaders, and that infamous blue dress stained</ORIGINAL_TEXT>
        <TOKEN id="token-36-0" pos="word" morph="none" start_char="1486" end_char="1487">as</TOKEN>
        <TOKEN id="token-36-1" pos="word" morph="none" start_char="1489" end_char="1490">he</TOKEN>
        <TOKEN id="token-36-2" pos="word" morph="none" start_char="1492" end_char="1497">talked</TOKEN>
        <TOKEN id="token-36-3" pos="word" morph="none" start_char="1499" end_char="1500">to</TOKEN>
        <TOKEN id="token-36-4" pos="word" morph="none" start_char="1502" end_char="1514">congressional</TOKEN>
        <TOKEN id="token-36-5" pos="word" morph="none" start_char="1516" end_char="1522">leaders</TOKEN>
        <TOKEN id="token-36-6" pos="punct" morph="none" start_char="1523" end_char="1523">,</TOKEN>
        <TOKEN id="token-36-7" pos="word" morph="none" start_char="1525" end_char="1527">and</TOKEN>
        <TOKEN id="token-36-8" pos="word" morph="none" start_char="1529" end_char="1532">that</TOKEN>
        <TOKEN id="token-36-9" pos="word" morph="none" start_char="1534" end_char="1541">infamous</TOKEN>
        <TOKEN id="token-36-10" pos="word" morph="none" start_char="1543" end_char="1546">blue</TOKEN>
        <TOKEN id="token-36-11" pos="word" morph="none" start_char="1548" end_char="1552">dress</TOKEN>
        <TOKEN id="token-36-12" pos="word" morph="none" start_char="1554" end_char="1560">stained</TOKEN>
      </SEG>
      <SEG id="segment-37" start_char="1562" end_char="1616">
        <ORIGINAL_TEXT>with his bodily fluids that made its way into rap songs</ORIGINAL_TEXT>
        <TOKEN id="token-37-0" pos="word" morph="none" start_char="1562" end_char="1565">with</TOKEN>
        <TOKEN id="token-37-1" pos="word" morph="none" start_char="1567" end_char="1569">his</TOKEN>
        <TOKEN id="token-37-2" pos="word" morph="none" start_char="1571" end_char="1576">bodily</TOKEN>
        <TOKEN id="token-37-3" pos="word" morph="none" start_char="1578" end_char="1583">fluids</TOKEN>
        <TOKEN id="token-37-4" pos="word" morph="none" start_char="1585" end_char="1588">that</TOKEN>
        <TOKEN id="token-37-5" pos="word" morph="none" start_char="1590" end_char="1593">made</TOKEN>
        <TOKEN id="token-37-6" pos="word" morph="none" start_char="1595" end_char="1597">its</TOKEN>
        <TOKEN id="token-37-7" pos="word" morph="none" start_char="1599" end_char="1601">way</TOKEN>
        <TOKEN id="token-37-8" pos="word" morph="none" start_char="1603" end_char="1606">into</TOKEN>
        <TOKEN id="token-37-9" pos="word" morph="none" start_char="1608" end_char="1610">rap</TOKEN>
        <TOKEN id="token-37-10" pos="word" morph="none" start_char="1612" end_char="1616">songs</TOKEN>
      </SEG>
      <SEG id="segment-38" start_char="1618" end_char="1621">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-38-0" pos="unknown" morph="none" start_char="1618" end_char="1621">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-39" start_char="1623" end_char="1625">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-39-0" pos="unknown" morph="none" start_char="1623" end_char="1625">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-40" start_char="1627" end_char="1693">
        <ORIGINAL_TEXT>She was fat shamed — one paper called her “the portly pepper pot” —</ORIGINAL_TEXT>
        <TOKEN id="token-40-0" pos="word" morph="none" start_char="1627" end_char="1629">She</TOKEN>
        <TOKEN id="token-40-1" pos="word" morph="none" start_char="1631" end_char="1633">was</TOKEN>
        <TOKEN id="token-40-2" pos="word" morph="none" start_char="1635" end_char="1637">fat</TOKEN>
        <TOKEN id="token-40-3" pos="word" morph="none" start_char="1639" end_char="1644">shamed</TOKEN>
        <TOKEN id="token-40-4" pos="unknown" morph="none" start_char="1646" end_char="1646">—</TOKEN>
        <TOKEN id="token-40-5" pos="word" morph="none" start_char="1648" end_char="1650">one</TOKEN>
        <TOKEN id="token-40-6" pos="word" morph="none" start_char="1652" end_char="1656">paper</TOKEN>
        <TOKEN id="token-40-7" pos="word" morph="none" start_char="1658" end_char="1663">called</TOKEN>
        <TOKEN id="token-40-8" pos="word" morph="none" start_char="1665" end_char="1667">her</TOKEN>
        <TOKEN id="token-40-9" pos="punct" morph="none" start_char="1669" end_char="1669">“</TOKEN>
        <TOKEN id="token-40-10" pos="word" morph="none" start_char="1670" end_char="1672">the</TOKEN>
        <TOKEN id="token-40-11" pos="word" morph="none" start_char="1674" end_char="1679">portly</TOKEN>
        <TOKEN id="token-40-12" pos="word" morph="none" start_char="1681" end_char="1686">pepper</TOKEN>
        <TOKEN id="token-40-13" pos="word" morph="none" start_char="1688" end_char="1690">pot</TOKEN>
        <TOKEN id="token-40-14" pos="punct" morph="none" start_char="1691" end_char="1691">”</TOKEN>
        <TOKEN id="token-40-15" pos="unknown" morph="none" start_char="1693" end_char="1693">—</TOKEN>
      </SEG>
      <SEG id="segment-41" start_char="1695" end_char="1769">
        <ORIGINAL_TEXT>slut shamed, and portrayed as an opportunistic sexual predator — albeit one</ORIGINAL_TEXT>
        <TOKEN id="token-41-0" pos="word" morph="none" start_char="1695" end_char="1698">slut</TOKEN>
        <TOKEN id="token-41-1" pos="word" morph="none" start_char="1700" end_char="1705">shamed</TOKEN>
        <TOKEN id="token-41-2" pos="punct" morph="none" start_char="1706" end_char="1706">,</TOKEN>
        <TOKEN id="token-41-3" pos="word" morph="none" start_char="1708" end_char="1710">and</TOKEN>
        <TOKEN id="token-41-4" pos="word" morph="none" start_char="1712" end_char="1720">portrayed</TOKEN>
        <TOKEN id="token-41-5" pos="word" morph="none" start_char="1722" end_char="1723">as</TOKEN>
        <TOKEN id="token-41-6" pos="word" morph="none" start_char="1725" end_char="1726">an</TOKEN>
        <TOKEN id="token-41-7" pos="word" morph="none" start_char="1728" end_char="1740">opportunistic</TOKEN>
        <TOKEN id="token-41-8" pos="word" morph="none" start_char="1742" end_char="1747">sexual</TOKEN>
        <TOKEN id="token-41-9" pos="word" morph="none" start_char="1749" end_char="1756">predator</TOKEN>
        <TOKEN id="token-41-10" pos="unknown" morph="none" start_char="1758" end_char="1758">—</TOKEN>
        <TOKEN id="token-41-11" pos="word" morph="none" start_char="1760" end_char="1765">albeit</TOKEN>
        <TOKEN id="token-41-12" pos="word" morph="none" start_char="1767" end_char="1769">one</TOKEN>
      </SEG>
      <SEG id="segment-42" start_char="1771" end_char="1810">
        <ORIGINAL_TEXT>who snagged the biggest predator of all.</ORIGINAL_TEXT>
        <TOKEN id="token-42-0" pos="word" morph="none" start_char="1771" end_char="1773">who</TOKEN>
        <TOKEN id="token-42-1" pos="word" morph="none" start_char="1775" end_char="1781">snagged</TOKEN>
        <TOKEN id="token-42-2" pos="word" morph="none" start_char="1783" end_char="1785">the</TOKEN>
        <TOKEN id="token-42-3" pos="word" morph="none" start_char="1787" end_char="1793">biggest</TOKEN>
        <TOKEN id="token-42-4" pos="word" morph="none" start_char="1795" end_char="1802">predator</TOKEN>
        <TOKEN id="token-42-5" pos="word" morph="none" start_char="1804" end_char="1805">of</TOKEN>
        <TOKEN id="token-42-6" pos="word" morph="none" start_char="1807" end_char="1809">all</TOKEN>
        <TOKEN id="token-42-7" pos="punct" morph="none" start_char="1810" end_char="1810">.</TOKEN>
      </SEG>
      <SEG id="segment-43" start_char="1812" end_char="1815">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-43-0" pos="unknown" morph="none" start_char="1812" end_char="1815">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-44" start_char="1817" end_char="1819">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-44-0" pos="unknown" morph="none" start_char="1817" end_char="1819">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-45" start_char="1821" end_char="1893">
        <ORIGINAL_TEXT>Lewinsky’s TED Talk was beautifully rendered, as was her earlier essay in</ORIGINAL_TEXT>
        <TOKEN id="token-45-0" pos="word" morph="none" start_char="1821" end_char="1828">Lewinsky</TOKEN>
        <TOKEN id="token-45-1" pos="punct" morph="none" start_char="1829" end_char="1829">’</TOKEN>
        <TOKEN id="token-45-2" pos="word" morph="none" start_char="1830" end_char="1830">s</TOKEN>
        <TOKEN id="token-45-3" pos="word" morph="none" start_char="1832" end_char="1834">TED</TOKEN>
        <TOKEN id="token-45-4" pos="word" morph="none" start_char="1836" end_char="1839">Talk</TOKEN>
        <TOKEN id="token-45-5" pos="word" morph="none" start_char="1841" end_char="1843">was</TOKEN>
        <TOKEN id="token-45-6" pos="word" morph="none" start_char="1845" end_char="1855">beautifully</TOKEN>
        <TOKEN id="token-45-7" pos="word" morph="none" start_char="1857" end_char="1864">rendered</TOKEN>
        <TOKEN id="token-45-8" pos="punct" morph="none" start_char="1865" end_char="1865">,</TOKEN>
        <TOKEN id="token-45-9" pos="word" morph="none" start_char="1867" end_char="1868">as</TOKEN>
        <TOKEN id="token-45-10" pos="word" morph="none" start_char="1870" end_char="1872">was</TOKEN>
        <TOKEN id="token-45-11" pos="word" morph="none" start_char="1874" end_char="1876">her</TOKEN>
        <TOKEN id="token-45-12" pos="word" morph="none" start_char="1878" end_char="1884">earlier</TOKEN>
        <TOKEN id="token-45-13" pos="word" morph="none" start_char="1886" end_char="1890">essay</TOKEN>
        <TOKEN id="token-45-14" pos="word" morph="none" start_char="1892" end_char="1893">in</TOKEN>
      </SEG>
      <SEG id="segment-46" start_char="1895" end_char="1968">
        <ORIGINAL_TEXT>Vanity Fair magazine in which she had a sharp message for feminist thought</ORIGINAL_TEXT>
        <TOKEN id="token-46-0" pos="word" morph="none" start_char="1895" end_char="1900">Vanity</TOKEN>
        <TOKEN id="token-46-1" pos="word" morph="none" start_char="1902" end_char="1905">Fair</TOKEN>
        <TOKEN id="token-46-2" pos="word" morph="none" start_char="1907" end_char="1914">magazine</TOKEN>
        <TOKEN id="token-46-3" pos="word" morph="none" start_char="1916" end_char="1917">in</TOKEN>
        <TOKEN id="token-46-4" pos="word" morph="none" start_char="1919" end_char="1923">which</TOKEN>
        <TOKEN id="token-46-5" pos="word" morph="none" start_char="1925" end_char="1927">she</TOKEN>
        <TOKEN id="token-46-6" pos="word" morph="none" start_char="1929" end_char="1931">had</TOKEN>
        <TOKEN id="token-46-7" pos="word" morph="none" start_char="1933" end_char="1933">a</TOKEN>
        <TOKEN id="token-46-8" pos="word" morph="none" start_char="1935" end_char="1939">sharp</TOKEN>
        <TOKEN id="token-46-9" pos="word" morph="none" start_char="1941" end_char="1947">message</TOKEN>
        <TOKEN id="token-46-10" pos="word" morph="none" start_char="1949" end_char="1951">for</TOKEN>
        <TOKEN id="token-46-11" pos="word" morph="none" start_char="1953" end_char="1960">feminist</TOKEN>
        <TOKEN id="token-46-12" pos="word" morph="none" start_char="1962" end_char="1968">thought</TOKEN>
      </SEG>
      <SEG id="segment-47" start_char="1970" end_char="2044">
        <ORIGINAL_TEXT>leaders who were so desperate to keep a Democratic president in office they</ORIGINAL_TEXT>
        <TOKEN id="token-47-0" pos="word" morph="none" start_char="1970" end_char="1976">leaders</TOKEN>
        <TOKEN id="token-47-1" pos="word" morph="none" start_char="1978" end_char="1980">who</TOKEN>
        <TOKEN id="token-47-2" pos="word" morph="none" start_char="1982" end_char="1985">were</TOKEN>
        <TOKEN id="token-47-3" pos="word" morph="none" start_char="1987" end_char="1988">so</TOKEN>
        <TOKEN id="token-47-4" pos="word" morph="none" start_char="1990" end_char="1998">desperate</TOKEN>
        <TOKEN id="token-47-5" pos="word" morph="none" start_char="2000" end_char="2001">to</TOKEN>
        <TOKEN id="token-47-6" pos="word" morph="none" start_char="2003" end_char="2006">keep</TOKEN>
        <TOKEN id="token-47-7" pos="word" morph="none" start_char="2008" end_char="2008">a</TOKEN>
        <TOKEN id="token-47-8" pos="word" morph="none" start_char="2010" end_char="2019">Democratic</TOKEN>
        <TOKEN id="token-47-9" pos="word" morph="none" start_char="2021" end_char="2029">president</TOKEN>
        <TOKEN id="token-47-10" pos="word" morph="none" start_char="2031" end_char="2032">in</TOKEN>
        <TOKEN id="token-47-11" pos="word" morph="none" start_char="2034" end_char="2039">office</TOKEN>
        <TOKEN id="token-47-12" pos="word" morph="none" start_char="2041" end_char="2044">they</TOKEN>
      </SEG>
      <SEG id="segment-48" start_char="2046" end_char="2118">
        <ORIGINAL_TEXT>formed a mean girls club of their own, cackling about everything from her</ORIGINAL_TEXT>
        <TOKEN id="token-48-0" pos="word" morph="none" start_char="2046" end_char="2051">formed</TOKEN>
        <TOKEN id="token-48-1" pos="word" morph="none" start_char="2053" end_char="2053">a</TOKEN>
        <TOKEN id="token-48-2" pos="word" morph="none" start_char="2055" end_char="2058">mean</TOKEN>
        <TOKEN id="token-48-3" pos="word" morph="none" start_char="2060" end_char="2064">girls</TOKEN>
        <TOKEN id="token-48-4" pos="word" morph="none" start_char="2066" end_char="2069">club</TOKEN>
        <TOKEN id="token-48-5" pos="word" morph="none" start_char="2071" end_char="2072">of</TOKEN>
        <TOKEN id="token-48-6" pos="word" morph="none" start_char="2074" end_char="2078">their</TOKEN>
        <TOKEN id="token-48-7" pos="word" morph="none" start_char="2080" end_char="2082">own</TOKEN>
        <TOKEN id="token-48-8" pos="punct" morph="none" start_char="2083" end_char="2083">,</TOKEN>
        <TOKEN id="token-48-9" pos="word" morph="none" start_char="2085" end_char="2092">cackling</TOKEN>
        <TOKEN id="token-48-10" pos="word" morph="none" start_char="2094" end_char="2098">about</TOKEN>
        <TOKEN id="token-48-11" pos="word" morph="none" start_char="2100" end_char="2109">everything</TOKEN>
        <TOKEN id="token-48-12" pos="word" morph="none" start_char="2111" end_char="2114">from</TOKEN>
        <TOKEN id="token-48-13" pos="word" morph="none" start_char="2116" end_char="2118">her</TOKEN>
      </SEG>
      <SEG id="segment-49" start_char="2120" end_char="2190">
        <ORIGINAL_TEXT>“third stage gum disease” to whether other men would go after what Bill</ORIGINAL_TEXT>
        <TOKEN id="token-49-0" pos="punct" morph="none" start_char="2120" end_char="2120">“</TOKEN>
        <TOKEN id="token-49-1" pos="word" morph="none" start_char="2121" end_char="2125">third</TOKEN>
        <TOKEN id="token-49-2" pos="word" morph="none" start_char="2127" end_char="2131">stage</TOKEN>
        <TOKEN id="token-49-3" pos="word" morph="none" start_char="2133" end_char="2135">gum</TOKEN>
        <TOKEN id="token-49-4" pos="word" morph="none" start_char="2137" end_char="2143">disease</TOKEN>
        <TOKEN id="token-49-5" pos="punct" morph="none" start_char="2144" end_char="2144">”</TOKEN>
        <TOKEN id="token-49-6" pos="word" morph="none" start_char="2146" end_char="2147">to</TOKEN>
        <TOKEN id="token-49-7" pos="word" morph="none" start_char="2149" end_char="2155">whether</TOKEN>
        <TOKEN id="token-49-8" pos="word" morph="none" start_char="2157" end_char="2161">other</TOKEN>
        <TOKEN id="token-49-9" pos="word" morph="none" start_char="2163" end_char="2165">men</TOKEN>
        <TOKEN id="token-49-10" pos="word" morph="none" start_char="2167" end_char="2171">would</TOKEN>
        <TOKEN id="token-49-11" pos="word" morph="none" start_char="2173" end_char="2174">go</TOKEN>
        <TOKEN id="token-49-12" pos="word" morph="none" start_char="2176" end_char="2180">after</TOKEN>
        <TOKEN id="token-49-13" pos="word" morph="none" start_char="2182" end_char="2185">what</TOKEN>
        <TOKEN id="token-49-14" pos="word" morph="none" start_char="2187" end_char="2190">Bill</TOKEN>
      </SEG>
      <SEG id="segment-50" start_char="2192" end_char="2264">
        <ORIGINAL_TEXT>Clinton had enjoyed: “I sorely wished for some sign of understanding from</ORIGINAL_TEXT>
        <TOKEN id="token-50-0" pos="word" morph="none" start_char="2192" end_char="2198">Clinton</TOKEN>
        <TOKEN id="token-50-1" pos="word" morph="none" start_char="2200" end_char="2202">had</TOKEN>
        <TOKEN id="token-50-2" pos="word" morph="none" start_char="2204" end_char="2210">enjoyed</TOKEN>
        <TOKEN id="token-50-3" pos="punct" morph="none" start_char="2211" end_char="2211">:</TOKEN>
        <TOKEN id="token-50-4" pos="punct" morph="none" start_char="2213" end_char="2213">“</TOKEN>
        <TOKEN id="token-50-5" pos="word" morph="none" start_char="2214" end_char="2214">I</TOKEN>
        <TOKEN id="token-50-6" pos="word" morph="none" start_char="2216" end_char="2221">sorely</TOKEN>
        <TOKEN id="token-50-7" pos="word" morph="none" start_char="2223" end_char="2228">wished</TOKEN>
        <TOKEN id="token-50-8" pos="word" morph="none" start_char="2230" end_char="2232">for</TOKEN>
        <TOKEN id="token-50-9" pos="word" morph="none" start_char="2234" end_char="2237">some</TOKEN>
        <TOKEN id="token-50-10" pos="word" morph="none" start_char="2239" end_char="2242">sign</TOKEN>
        <TOKEN id="token-50-11" pos="word" morph="none" start_char="2244" end_char="2245">of</TOKEN>
        <TOKEN id="token-50-12" pos="word" morph="none" start_char="2247" end_char="2259">understanding</TOKEN>
        <TOKEN id="token-50-13" pos="word" morph="none" start_char="2261" end_char="2264">from</TOKEN>
      </SEG>
      <SEG id="segment-51" start_char="2266" end_char="2341">
        <ORIGINAL_TEXT>the feminist camp ... Given the issues at play — gender politics, sex in the</ORIGINAL_TEXT>
        <TOKEN id="token-51-0" pos="word" morph="none" start_char="2266" end_char="2268">the</TOKEN>
        <TOKEN id="token-51-1" pos="word" morph="none" start_char="2270" end_char="2277">feminist</TOKEN>
        <TOKEN id="token-51-2" pos="word" morph="none" start_char="2279" end_char="2282">camp</TOKEN>
        <TOKEN id="token-51-3" pos="unknown" morph="none" start_char="2284" end_char="2286">...</TOKEN>
        <TOKEN id="token-51-4" pos="word" morph="none" start_char="2288" end_char="2292">Given</TOKEN>
        <TOKEN id="token-51-5" pos="word" morph="none" start_char="2294" end_char="2296">the</TOKEN>
        <TOKEN id="token-51-6" pos="word" morph="none" start_char="2298" end_char="2303">issues</TOKEN>
        <TOKEN id="token-51-7" pos="word" morph="none" start_char="2305" end_char="2306">at</TOKEN>
        <TOKEN id="token-51-8" pos="word" morph="none" start_char="2308" end_char="2311">play</TOKEN>
        <TOKEN id="token-51-9" pos="unknown" morph="none" start_char="2313" end_char="2313">—</TOKEN>
        <TOKEN id="token-51-10" pos="word" morph="none" start_char="2315" end_char="2320">gender</TOKEN>
        <TOKEN id="token-51-11" pos="word" morph="none" start_char="2322" end_char="2329">politics</TOKEN>
        <TOKEN id="token-51-12" pos="punct" morph="none" start_char="2330" end_char="2330">,</TOKEN>
        <TOKEN id="token-51-13" pos="word" morph="none" start_char="2332" end_char="2334">sex</TOKEN>
        <TOKEN id="token-51-14" pos="word" morph="none" start_char="2336" end_char="2337">in</TOKEN>
        <TOKEN id="token-51-15" pos="word" morph="none" start_char="2339" end_char="2341">the</TOKEN>
      </SEG>
      <SEG id="segment-52" start_char="2343" end_char="2393">
        <ORIGINAL_TEXT>workplace — you’d think they would have spoken up.”</ORIGINAL_TEXT>
        <TOKEN id="token-52-0" pos="word" morph="none" start_char="2343" end_char="2351">workplace</TOKEN>
        <TOKEN id="token-52-1" pos="unknown" morph="none" start_char="2353" end_char="2353">—</TOKEN>
        <TOKEN id="token-52-2" pos="word" morph="none" start_char="2355" end_char="2357">you</TOKEN>
        <TOKEN id="token-52-3" pos="punct" morph="none" start_char="2358" end_char="2358">’</TOKEN>
        <TOKEN id="token-52-4" pos="word" morph="none" start_char="2359" end_char="2359">d</TOKEN>
        <TOKEN id="token-52-5" pos="word" morph="none" start_char="2361" end_char="2365">think</TOKEN>
        <TOKEN id="token-52-6" pos="word" morph="none" start_char="2367" end_char="2370">they</TOKEN>
        <TOKEN id="token-52-7" pos="word" morph="none" start_char="2372" end_char="2376">would</TOKEN>
        <TOKEN id="token-52-8" pos="word" morph="none" start_char="2378" end_char="2381">have</TOKEN>
        <TOKEN id="token-52-9" pos="word" morph="none" start_char="2383" end_char="2388">spoken</TOKEN>
        <TOKEN id="token-52-10" pos="word" morph="none" start_char="2390" end_char="2391">up</TOKEN>
        <TOKEN id="token-52-11" pos="punct" morph="none" start_char="2392" end_char="2393">.”</TOKEN>
      </SEG>
      <SEG id="segment-53" start_char="2395" end_char="2398">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-53-0" pos="unknown" morph="none" start_char="2395" end_char="2398">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-54" start_char="2400" end_char="2402">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-54-0" pos="unknown" morph="none" start_char="2400" end_char="2402">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-55" start_char="2404" end_char="2477">
        <ORIGINAL_TEXT>Lewinsky did lose much of her life. With a graduate degree from the London</ORIGINAL_TEXT>
        <TOKEN id="token-55-0" pos="word" morph="none" start_char="2404" end_char="2411">Lewinsky</TOKEN>
        <TOKEN id="token-55-1" pos="word" morph="none" start_char="2413" end_char="2415">did</TOKEN>
        <TOKEN id="token-55-2" pos="word" morph="none" start_char="2417" end_char="2420">lose</TOKEN>
        <TOKEN id="token-55-3" pos="word" morph="none" start_char="2422" end_char="2425">much</TOKEN>
        <TOKEN id="token-55-4" pos="word" morph="none" start_char="2427" end_char="2428">of</TOKEN>
        <TOKEN id="token-55-5" pos="word" morph="none" start_char="2430" end_char="2432">her</TOKEN>
        <TOKEN id="token-55-6" pos="word" morph="none" start_char="2434" end_char="2437">life</TOKEN>
        <TOKEN id="token-55-7" pos="punct" morph="none" start_char="2438" end_char="2438">.</TOKEN>
        <TOKEN id="token-55-8" pos="word" morph="none" start_char="2440" end_char="2443">With</TOKEN>
        <TOKEN id="token-55-9" pos="word" morph="none" start_char="2445" end_char="2445">a</TOKEN>
        <TOKEN id="token-55-10" pos="word" morph="none" start_char="2447" end_char="2454">graduate</TOKEN>
        <TOKEN id="token-55-11" pos="word" morph="none" start_char="2456" end_char="2461">degree</TOKEN>
        <TOKEN id="token-55-12" pos="word" morph="none" start_char="2463" end_char="2466">from</TOKEN>
        <TOKEN id="token-55-13" pos="word" morph="none" start_char="2468" end_char="2470">the</TOKEN>
        <TOKEN id="token-55-14" pos="word" morph="none" start_char="2472" end_char="2477">London</TOKEN>
      </SEG>
      <SEG id="segment-56" start_char="2479" end_char="2552">
        <ORIGINAL_TEXT>School of Economics, she seems not to have achieved any of the personal or</ORIGINAL_TEXT>
        <TOKEN id="token-56-0" pos="word" morph="none" start_char="2479" end_char="2484">School</TOKEN>
        <TOKEN id="token-56-1" pos="word" morph="none" start_char="2486" end_char="2487">of</TOKEN>
        <TOKEN id="token-56-2" pos="word" morph="none" start_char="2489" end_char="2497">Economics</TOKEN>
        <TOKEN id="token-56-3" pos="punct" morph="none" start_char="2498" end_char="2498">,</TOKEN>
        <TOKEN id="token-56-4" pos="word" morph="none" start_char="2500" end_char="2502">she</TOKEN>
        <TOKEN id="token-56-5" pos="word" morph="none" start_char="2504" end_char="2508">seems</TOKEN>
        <TOKEN id="token-56-6" pos="word" morph="none" start_char="2510" end_char="2512">not</TOKEN>
        <TOKEN id="token-56-7" pos="word" morph="none" start_char="2514" end_char="2515">to</TOKEN>
        <TOKEN id="token-56-8" pos="word" morph="none" start_char="2517" end_char="2520">have</TOKEN>
        <TOKEN id="token-56-9" pos="word" morph="none" start_char="2522" end_char="2529">achieved</TOKEN>
        <TOKEN id="token-56-10" pos="word" morph="none" start_char="2531" end_char="2533">any</TOKEN>
        <TOKEN id="token-56-11" pos="word" morph="none" start_char="2535" end_char="2536">of</TOKEN>
        <TOKEN id="token-56-12" pos="word" morph="none" start_char="2538" end_char="2540">the</TOKEN>
        <TOKEN id="token-56-13" pos="word" morph="none" start_char="2542" end_char="2549">personal</TOKEN>
        <TOKEN id="token-56-14" pos="word" morph="none" start_char="2551" end_char="2552">or</TOKEN>
      </SEG>
      <SEG id="segment-57" start_char="2554" end_char="2628">
        <ORIGINAL_TEXT>professional milestones a smart, personable woman of her age normally would</ORIGINAL_TEXT>
        <TOKEN id="token-57-0" pos="word" morph="none" start_char="2554" end_char="2565">professional</TOKEN>
        <TOKEN id="token-57-1" pos="word" morph="none" start_char="2567" end_char="2576">milestones</TOKEN>
        <TOKEN id="token-57-2" pos="word" morph="none" start_char="2578" end_char="2578">a</TOKEN>
        <TOKEN id="token-57-3" pos="word" morph="none" start_char="2580" end_char="2584">smart</TOKEN>
        <TOKEN id="token-57-4" pos="punct" morph="none" start_char="2585" end_char="2585">,</TOKEN>
        <TOKEN id="token-57-5" pos="word" morph="none" start_char="2587" end_char="2596">personable</TOKEN>
        <TOKEN id="token-57-6" pos="word" morph="none" start_char="2598" end_char="2602">woman</TOKEN>
        <TOKEN id="token-57-7" pos="word" morph="none" start_char="2604" end_char="2605">of</TOKEN>
        <TOKEN id="token-57-8" pos="word" morph="none" start_char="2607" end_char="2609">her</TOKEN>
        <TOKEN id="token-57-9" pos="word" morph="none" start_char="2611" end_char="2613">age</TOKEN>
        <TOKEN id="token-57-10" pos="word" morph="none" start_char="2615" end_char="2622">normally</TOKEN>
        <TOKEN id="token-57-11" pos="word" morph="none" start_char="2624" end_char="2628">would</TOKEN>
      </SEG>
      <SEG id="segment-58" start_char="2630" end_char="2693">
        <ORIGINAL_TEXT>have—no career, no permanent relationship, no family of her own.</ORIGINAL_TEXT>
        <TOKEN id="token-58-0" pos="word" morph="none" start_char="2630" end_char="2633">have</TOKEN>
        <TOKEN id="token-58-1" pos="punct" morph="none" start_char="2634" end_char="2634">—</TOKEN>
        <TOKEN id="token-58-2" pos="word" morph="none" start_char="2635" end_char="2636">no</TOKEN>
        <TOKEN id="token-58-3" pos="word" morph="none" start_char="2638" end_char="2643">career</TOKEN>
        <TOKEN id="token-58-4" pos="punct" morph="none" start_char="2644" end_char="2644">,</TOKEN>
        <TOKEN id="token-58-5" pos="word" morph="none" start_char="2646" end_char="2647">no</TOKEN>
        <TOKEN id="token-58-6" pos="word" morph="none" start_char="2649" end_char="2657">permanent</TOKEN>
        <TOKEN id="token-58-7" pos="word" morph="none" start_char="2659" end_char="2670">relationship</TOKEN>
        <TOKEN id="token-58-8" pos="punct" morph="none" start_char="2671" end_char="2671">,</TOKEN>
        <TOKEN id="token-58-9" pos="word" morph="none" start_char="2673" end_char="2674">no</TOKEN>
        <TOKEN id="token-58-10" pos="word" morph="none" start_char="2676" end_char="2681">family</TOKEN>
        <TOKEN id="token-58-11" pos="word" morph="none" start_char="2683" end_char="2684">of</TOKEN>
        <TOKEN id="token-58-12" pos="word" morph="none" start_char="2686" end_char="2688">her</TOKEN>
        <TOKEN id="token-58-13" pos="word" morph="none" start_char="2690" end_char="2692">own</TOKEN>
        <TOKEN id="token-58-14" pos="punct" morph="none" start_char="2693" end_char="2693">.</TOKEN>
      </SEG>
      <SEG id="segment-59" start_char="2695" end_char="2698">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-59-0" pos="unknown" morph="none" start_char="2695" end_char="2698">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-60" start_char="2700" end_char="2702">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-60-0" pos="unknown" morph="none" start_char="2700" end_char="2702">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-61" start_char="2704" end_char="2775">
        <ORIGINAL_TEXT>She puts it down to the outpouring of ridicule and opprobrium that first</ORIGINAL_TEXT>
        <TOKEN id="token-61-0" pos="word" morph="none" start_char="2704" end_char="2706">She</TOKEN>
        <TOKEN id="token-61-1" pos="word" morph="none" start_char="2708" end_char="2711">puts</TOKEN>
        <TOKEN id="token-61-2" pos="word" morph="none" start_char="2713" end_char="2714">it</TOKEN>
        <TOKEN id="token-61-3" pos="word" morph="none" start_char="2716" end_char="2719">down</TOKEN>
        <TOKEN id="token-61-4" pos="word" morph="none" start_char="2721" end_char="2722">to</TOKEN>
        <TOKEN id="token-61-5" pos="word" morph="none" start_char="2724" end_char="2726">the</TOKEN>
        <TOKEN id="token-61-6" pos="word" morph="none" start_char="2728" end_char="2737">outpouring</TOKEN>
        <TOKEN id="token-61-7" pos="word" morph="none" start_char="2739" end_char="2740">of</TOKEN>
        <TOKEN id="token-61-8" pos="word" morph="none" start_char="2742" end_char="2749">ridicule</TOKEN>
        <TOKEN id="token-61-9" pos="word" morph="none" start_char="2751" end_char="2753">and</TOKEN>
        <TOKEN id="token-61-10" pos="word" morph="none" start_char="2755" end_char="2764">opprobrium</TOKEN>
        <TOKEN id="token-61-11" pos="word" morph="none" start_char="2766" end_char="2769">that</TOKEN>
        <TOKEN id="token-61-12" pos="word" morph="none" start_char="2771" end_char="2775">first</TOKEN>
      </SEG>
      <SEG id="segment-62" start_char="2777" end_char="2854">
        <ORIGINAL_TEXT>paralyzed her, and then to the ongoing prurience that never let people see her</ORIGINAL_TEXT>
        <TOKEN id="token-62-0" pos="word" morph="none" start_char="2777" end_char="2785">paralyzed</TOKEN>
        <TOKEN id="token-62-1" pos="word" morph="none" start_char="2787" end_char="2789">her</TOKEN>
        <TOKEN id="token-62-2" pos="punct" morph="none" start_char="2790" end_char="2790">,</TOKEN>
        <TOKEN id="token-62-3" pos="word" morph="none" start_char="2792" end_char="2794">and</TOKEN>
        <TOKEN id="token-62-4" pos="word" morph="none" start_char="2796" end_char="2799">then</TOKEN>
        <TOKEN id="token-62-5" pos="word" morph="none" start_char="2801" end_char="2802">to</TOKEN>
        <TOKEN id="token-62-6" pos="word" morph="none" start_char="2804" end_char="2806">the</TOKEN>
        <TOKEN id="token-62-7" pos="word" morph="none" start_char="2808" end_char="2814">ongoing</TOKEN>
        <TOKEN id="token-62-8" pos="word" morph="none" start_char="2816" end_char="2824">prurience</TOKEN>
        <TOKEN id="token-62-9" pos="word" morph="none" start_char="2826" end_char="2829">that</TOKEN>
        <TOKEN id="token-62-10" pos="word" morph="none" start_char="2831" end_char="2835">never</TOKEN>
        <TOKEN id="token-62-11" pos="word" morph="none" start_char="2837" end_char="2839">let</TOKEN>
        <TOKEN id="token-62-12" pos="word" morph="none" start_char="2841" end_char="2846">people</TOKEN>
        <TOKEN id="token-62-13" pos="word" morph="none" start_char="2848" end_char="2850">see</TOKEN>
        <TOKEN id="token-62-14" pos="word" morph="none" start_char="2852" end_char="2854">her</TOKEN>
      </SEG>
      <SEG id="segment-63" start_char="2856" end_char="2877">
        <ORIGINAL_TEXT>as a real human being.</ORIGINAL_TEXT>
        <TOKEN id="token-63-0" pos="word" morph="none" start_char="2856" end_char="2857">as</TOKEN>
        <TOKEN id="token-63-1" pos="word" morph="none" start_char="2859" end_char="2859">a</TOKEN>
        <TOKEN id="token-63-2" pos="word" morph="none" start_char="2861" end_char="2864">real</TOKEN>
        <TOKEN id="token-63-3" pos="word" morph="none" start_char="2866" end_char="2870">human</TOKEN>
        <TOKEN id="token-63-4" pos="word" morph="none" start_char="2872" end_char="2876">being</TOKEN>
        <TOKEN id="token-63-5" pos="punct" morph="none" start_char="2877" end_char="2877">.</TOKEN>
      </SEG>
      <SEG id="segment-64" start_char="2879" end_char="2882">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-64-0" pos="unknown" morph="none" start_char="2879" end_char="2882">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-65" start_char="2884" end_char="2886">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-65-0" pos="unknown" morph="none" start_char="2884" end_char="2886">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-66" start_char="2888" end_char="2965">
        <ORIGINAL_TEXT>Yet 17 years is a long time to wander in the wilderness of shame. I know women</ORIGINAL_TEXT>
        <TOKEN id="token-66-0" pos="word" morph="none" start_char="2888" end_char="2890">Yet</TOKEN>
        <TOKEN id="token-66-1" pos="number" morph="none" start_char="2892" end_char="2893">17</TOKEN>
        <TOKEN id="token-66-2" pos="word" morph="none" start_char="2895" end_char="2899">years</TOKEN>
        <TOKEN id="token-66-3" pos="word" morph="none" start_char="2901" end_char="2902">is</TOKEN>
        <TOKEN id="token-66-4" pos="word" morph="none" start_char="2904" end_char="2904">a</TOKEN>
        <TOKEN id="token-66-5" pos="word" morph="none" start_char="2906" end_char="2909">long</TOKEN>
        <TOKEN id="token-66-6" pos="word" morph="none" start_char="2911" end_char="2914">time</TOKEN>
        <TOKEN id="token-66-7" pos="word" morph="none" start_char="2916" end_char="2917">to</TOKEN>
        <TOKEN id="token-66-8" pos="word" morph="none" start_char="2919" end_char="2924">wander</TOKEN>
        <TOKEN id="token-66-9" pos="word" morph="none" start_char="2926" end_char="2927">in</TOKEN>
        <TOKEN id="token-66-10" pos="word" morph="none" start_char="2929" end_char="2931">the</TOKEN>
        <TOKEN id="token-66-11" pos="word" morph="none" start_char="2933" end_char="2942">wilderness</TOKEN>
        <TOKEN id="token-66-12" pos="word" morph="none" start_char="2944" end_char="2945">of</TOKEN>
        <TOKEN id="token-66-13" pos="word" morph="none" start_char="2947" end_char="2951">shame</TOKEN>
        <TOKEN id="token-66-14" pos="punct" morph="none" start_char="2952" end_char="2952">.</TOKEN>
        <TOKEN id="token-66-15" pos="word" morph="none" start_char="2954" end_char="2954">I</TOKEN>
        <TOKEN id="token-66-16" pos="word" morph="none" start_char="2956" end_char="2959">know</TOKEN>
        <TOKEN id="token-66-17" pos="word" morph="none" start_char="2961" end_char="2965">women</TOKEN>
      </SEG>
      <SEG id="segment-67" start_char="2967" end_char="3041">
        <ORIGINAL_TEXT>who have recovered from deep personal trauma and gone on to have productive</ORIGINAL_TEXT>
        <TOKEN id="token-67-0" pos="word" morph="none" start_char="2967" end_char="2969">who</TOKEN>
        <TOKEN id="token-67-1" pos="word" morph="none" start_char="2971" end_char="2974">have</TOKEN>
        <TOKEN id="token-67-2" pos="word" morph="none" start_char="2976" end_char="2984">recovered</TOKEN>
        <TOKEN id="token-67-3" pos="word" morph="none" start_char="2986" end_char="2989">from</TOKEN>
        <TOKEN id="token-67-4" pos="word" morph="none" start_char="2991" end_char="2994">deep</TOKEN>
        <TOKEN id="token-67-5" pos="word" morph="none" start_char="2996" end_char="3003">personal</TOKEN>
        <TOKEN id="token-67-6" pos="word" morph="none" start_char="3005" end_char="3010">trauma</TOKEN>
        <TOKEN id="token-67-7" pos="word" morph="none" start_char="3012" end_char="3014">and</TOKEN>
        <TOKEN id="token-67-8" pos="word" morph="none" start_char="3016" end_char="3019">gone</TOKEN>
        <TOKEN id="token-67-9" pos="word" morph="none" start_char="3021" end_char="3022">on</TOKEN>
        <TOKEN id="token-67-10" pos="word" morph="none" start_char="3024" end_char="3025">to</TOKEN>
        <TOKEN id="token-67-11" pos="word" morph="none" start_char="3027" end_char="3030">have</TOKEN>
        <TOKEN id="token-67-12" pos="word" morph="none" start_char="3032" end_char="3041">productive</TOKEN>
      </SEG>
      <SEG id="segment-68" start_char="3043" end_char="3073">
        <ORIGINAL_TEXT>lives. Why not Monica Lewinsky?</ORIGINAL_TEXT>
        <TOKEN id="token-68-0" pos="word" morph="none" start_char="3043" end_char="3047">lives</TOKEN>
        <TOKEN id="token-68-1" pos="punct" morph="none" start_char="3048" end_char="3048">.</TOKEN>
        <TOKEN id="token-68-2" pos="word" morph="none" start_char="3050" end_char="3052">Why</TOKEN>
        <TOKEN id="token-68-3" pos="word" morph="none" start_char="3054" end_char="3056">not</TOKEN>
        <TOKEN id="token-68-4" pos="word" morph="none" start_char="3058" end_char="3063">Monica</TOKEN>
        <TOKEN id="token-68-5" pos="word" morph="none" start_char="3065" end_char="3072">Lewinsky</TOKEN>
        <TOKEN id="token-68-6" pos="punct" morph="none" start_char="3073" end_char="3073">?</TOKEN>
      </SEG>
      <SEG id="segment-69" start_char="3075" end_char="3078">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-69-0" pos="unknown" morph="none" start_char="3075" end_char="3078">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-70" start_char="3080" end_char="3082">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-70-0" pos="unknown" morph="none" start_char="3080" end_char="3082">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-71" start_char="3084" end_char="3157">
        <ORIGINAL_TEXT>Thankfully, she does not paint herself totally as a victim—she laments her</ORIGINAL_TEXT>
        <TOKEN id="token-71-0" pos="word" morph="none" start_char="3084" end_char="3093">Thankfully</TOKEN>
        <TOKEN id="token-71-1" pos="punct" morph="none" start_char="3094" end_char="3094">,</TOKEN>
        <TOKEN id="token-71-2" pos="word" morph="none" start_char="3096" end_char="3098">she</TOKEN>
        <TOKEN id="token-71-3" pos="word" morph="none" start_char="3100" end_char="3103">does</TOKEN>
        <TOKEN id="token-71-4" pos="word" morph="none" start_char="3105" end_char="3107">not</TOKEN>
        <TOKEN id="token-71-5" pos="word" morph="none" start_char="3109" end_char="3113">paint</TOKEN>
        <TOKEN id="token-71-6" pos="word" morph="none" start_char="3115" end_char="3121">herself</TOKEN>
        <TOKEN id="token-71-7" pos="word" morph="none" start_char="3123" end_char="3129">totally</TOKEN>
        <TOKEN id="token-71-8" pos="word" morph="none" start_char="3131" end_char="3132">as</TOKEN>
        <TOKEN id="token-71-9" pos="word" morph="none" start_char="3134" end_char="3134">a</TOKEN>
        <TOKEN id="token-71-10" pos="word" morph="none" start_char="3136" end_char="3141">victim</TOKEN>
        <TOKEN id="token-71-11" pos="punct" morph="none" start_char="3142" end_char="3142">—</TOKEN>
        <TOKEN id="token-71-12" pos="word" morph="none" start_char="3143" end_char="3145">she</TOKEN>
        <TOKEN id="token-71-13" pos="word" morph="none" start_char="3147" end_char="3153">laments</TOKEN>
        <TOKEN id="token-71-14" pos="word" morph="none" start_char="3155" end_char="3157">her</TOKEN>
      </SEG>
      <SEG id="segment-72" start_char="3159" end_char="3173">
        <ORIGINAL_TEXT>“poor choices”.</ORIGINAL_TEXT>
        <TOKEN id="token-72-0" pos="punct" morph="none" start_char="3159" end_char="3159">“</TOKEN>
        <TOKEN id="token-72-1" pos="word" morph="none" start_char="3160" end_char="3163">poor</TOKEN>
        <TOKEN id="token-72-2" pos="word" morph="none" start_char="3165" end_char="3171">choices</TOKEN>
        <TOKEN id="token-72-3" pos="punct" morph="none" start_char="3172" end_char="3173">”.</TOKEN>
      </SEG>
      <SEG id="segment-73" start_char="3175" end_char="3178">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-73-0" pos="unknown" morph="none" start_char="3175" end_char="3178">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-74" start_char="3180" end_char="3182">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-74-0" pos="unknown" morph="none" start_char="3180" end_char="3182">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-75" start_char="3184" end_char="3257">
        <ORIGINAL_TEXT>But she is disingenuous in saying her big mistake was “I fell in love with</ORIGINAL_TEXT>
        <TOKEN id="token-75-0" pos="word" morph="none" start_char="3184" end_char="3186">But</TOKEN>
        <TOKEN id="token-75-1" pos="word" morph="none" start_char="3188" end_char="3190">she</TOKEN>
        <TOKEN id="token-75-2" pos="word" morph="none" start_char="3192" end_char="3193">is</TOKEN>
        <TOKEN id="token-75-3" pos="word" morph="none" start_char="3195" end_char="3206">disingenuous</TOKEN>
        <TOKEN id="token-75-4" pos="word" morph="none" start_char="3208" end_char="3209">in</TOKEN>
        <TOKEN id="token-75-5" pos="word" morph="none" start_char="3211" end_char="3216">saying</TOKEN>
        <TOKEN id="token-75-6" pos="word" morph="none" start_char="3218" end_char="3220">her</TOKEN>
        <TOKEN id="token-75-7" pos="word" morph="none" start_char="3222" end_char="3224">big</TOKEN>
        <TOKEN id="token-75-8" pos="word" morph="none" start_char="3226" end_char="3232">mistake</TOKEN>
        <TOKEN id="token-75-9" pos="word" morph="none" start_char="3234" end_char="3236">was</TOKEN>
        <TOKEN id="token-75-10" pos="punct" morph="none" start_char="3238" end_char="3238">“</TOKEN>
        <TOKEN id="token-75-11" pos="word" morph="none" start_char="3239" end_char="3239">I</TOKEN>
        <TOKEN id="token-75-12" pos="word" morph="none" start_char="3241" end_char="3244">fell</TOKEN>
        <TOKEN id="token-75-13" pos="word" morph="none" start_char="3246" end_char="3247">in</TOKEN>
        <TOKEN id="token-75-14" pos="word" morph="none" start_char="3249" end_char="3252">love</TOKEN>
        <TOKEN id="token-75-15" pos="word" morph="none" start_char="3254" end_char="3257">with</TOKEN>
      </SEG>
      <SEG id="segment-76" start_char="3259" end_char="3334">
        <ORIGINAL_TEXT>my boss.” That makes her sound like everywoman in an office, instead of what</ORIGINAL_TEXT>
        <TOKEN id="token-76-0" pos="word" morph="none" start_char="3259" end_char="3260">my</TOKEN>
        <TOKEN id="token-76-1" pos="word" morph="none" start_char="3262" end_char="3265">boss</TOKEN>
        <TOKEN id="token-76-2" pos="punct" morph="none" start_char="3266" end_char="3267">.”</TOKEN>
        <TOKEN id="token-76-3" pos="word" morph="none" start_char="3269" end_char="3272">That</TOKEN>
        <TOKEN id="token-76-4" pos="word" morph="none" start_char="3274" end_char="3278">makes</TOKEN>
        <TOKEN id="token-76-5" pos="word" morph="none" start_char="3280" end_char="3282">her</TOKEN>
        <TOKEN id="token-76-6" pos="word" morph="none" start_char="3284" end_char="3288">sound</TOKEN>
        <TOKEN id="token-76-7" pos="word" morph="none" start_char="3290" end_char="3293">like</TOKEN>
        <TOKEN id="token-76-8" pos="word" morph="none" start_char="3295" end_char="3304">everywoman</TOKEN>
        <TOKEN id="token-76-9" pos="word" morph="none" start_char="3306" end_char="3307">in</TOKEN>
        <TOKEN id="token-76-10" pos="word" morph="none" start_char="3309" end_char="3310">an</TOKEN>
        <TOKEN id="token-76-11" pos="word" morph="none" start_char="3312" end_char="3317">office</TOKEN>
        <TOKEN id="token-76-12" pos="punct" morph="none" start_char="3318" end_char="3318">,</TOKEN>
        <TOKEN id="token-76-13" pos="word" morph="none" start_char="3320" end_char="3326">instead</TOKEN>
        <TOKEN id="token-76-14" pos="word" morph="none" start_char="3328" end_char="3329">of</TOKEN>
        <TOKEN id="token-76-15" pos="word" morph="none" start_char="3331" end_char="3334">what</TOKEN>
      </SEG>
      <SEG id="segment-77" start_char="3336" end_char="3408">
        <ORIGINAL_TEXT>she was—attention seeking, foolhardy, and very proactive in pursuing what</ORIGINAL_TEXT>
        <TOKEN id="token-77-0" pos="word" morph="none" start_char="3336" end_char="3338">she</TOKEN>
        <TOKEN id="token-77-1" pos="word" morph="none" start_char="3340" end_char="3342">was</TOKEN>
        <TOKEN id="token-77-2" pos="punct" morph="none" start_char="3343" end_char="3343">—</TOKEN>
        <TOKEN id="token-77-3" pos="word" morph="none" start_char="3344" end_char="3352">attention</TOKEN>
        <TOKEN id="token-77-4" pos="word" morph="none" start_char="3354" end_char="3360">seeking</TOKEN>
        <TOKEN id="token-77-5" pos="punct" morph="none" start_char="3361" end_char="3361">,</TOKEN>
        <TOKEN id="token-77-6" pos="word" morph="none" start_char="3363" end_char="3371">foolhardy</TOKEN>
        <TOKEN id="token-77-7" pos="punct" morph="none" start_char="3372" end_char="3372">,</TOKEN>
        <TOKEN id="token-77-8" pos="word" morph="none" start_char="3374" end_char="3376">and</TOKEN>
        <TOKEN id="token-77-9" pos="word" morph="none" start_char="3378" end_char="3381">very</TOKEN>
        <TOKEN id="token-77-10" pos="word" morph="none" start_char="3383" end_char="3391">proactive</TOKEN>
        <TOKEN id="token-77-11" pos="word" morph="none" start_char="3393" end_char="3394">in</TOKEN>
        <TOKEN id="token-77-12" pos="word" morph="none" start_char="3396" end_char="3403">pursuing</TOKEN>
        <TOKEN id="token-77-13" pos="word" morph="none" start_char="3405" end_char="3408">what</TOKEN>
      </SEG>
      <SEG id="segment-78" start_char="3410" end_char="3483">
        <ORIGINAL_TEXT>she calls “a consensual” relationship with a powerful man whose roving eye</ORIGINAL_TEXT>
        <TOKEN id="token-78-0" pos="word" morph="none" start_char="3410" end_char="3412">she</TOKEN>
        <TOKEN id="token-78-1" pos="word" morph="none" start_char="3414" end_char="3418">calls</TOKEN>
        <TOKEN id="token-78-2" pos="punct" morph="none" start_char="3420" end_char="3420">“</TOKEN>
        <TOKEN id="token-78-3" pos="word" morph="none" start_char="3421" end_char="3421">a</TOKEN>
        <TOKEN id="token-78-4" pos="word" morph="none" start_char="3423" end_char="3432">consensual</TOKEN>
        <TOKEN id="token-78-5" pos="punct" morph="none" start_char="3433" end_char="3433">”</TOKEN>
        <TOKEN id="token-78-6" pos="word" morph="none" start_char="3435" end_char="3446">relationship</TOKEN>
        <TOKEN id="token-78-7" pos="word" morph="none" start_char="3448" end_char="3451">with</TOKEN>
        <TOKEN id="token-78-8" pos="word" morph="none" start_char="3453" end_char="3453">a</TOKEN>
        <TOKEN id="token-78-9" pos="word" morph="none" start_char="3455" end_char="3462">powerful</TOKEN>
        <TOKEN id="token-78-10" pos="word" morph="none" start_char="3464" end_char="3466">man</TOKEN>
        <TOKEN id="token-78-11" pos="word" morph="none" start_char="3468" end_char="3472">whose</TOKEN>
        <TOKEN id="token-78-12" pos="word" morph="none" start_char="3474" end_char="3479">roving</TOKEN>
        <TOKEN id="token-78-13" pos="word" morph="none" start_char="3481" end_char="3483">eye</TOKEN>
      </SEG>
      <SEG id="segment-79" start_char="3485" end_char="3499">
        <ORIGINAL_TEXT>was well known.</ORIGINAL_TEXT>
        <TOKEN id="token-79-0" pos="word" morph="none" start_char="3485" end_char="3487">was</TOKEN>
        <TOKEN id="token-79-1" pos="word" morph="none" start_char="3489" end_char="3492">well</TOKEN>
        <TOKEN id="token-79-2" pos="word" morph="none" start_char="3494" end_char="3498">known</TOKEN>
        <TOKEN id="token-79-3" pos="punct" morph="none" start_char="3499" end_char="3499">.</TOKEN>
      </SEG>
      <SEG id="segment-80" start_char="3501" end_char="3504">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-80-0" pos="unknown" morph="none" start_char="3501" end_char="3504">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-81" start_char="3506" end_char="3508">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-81-0" pos="unknown" morph="none" start_char="3506" end_char="3508">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-82" start_char="3510" end_char="3582">
        <ORIGINAL_TEXT>I’ve never understood why she kept that incriminating blue dress, stained</ORIGINAL_TEXT>
        <TOKEN id="token-82-0" pos="word" morph="none" start_char="3510" end_char="3510">I</TOKEN>
        <TOKEN id="token-82-1" pos="punct" morph="none" start_char="3511" end_char="3511">’</TOKEN>
        <TOKEN id="token-82-2" pos="word" morph="none" start_char="3512" end_char="3513">ve</TOKEN>
        <TOKEN id="token-82-3" pos="word" morph="none" start_char="3515" end_char="3519">never</TOKEN>
        <TOKEN id="token-82-4" pos="word" morph="none" start_char="3521" end_char="3530">understood</TOKEN>
        <TOKEN id="token-82-5" pos="word" morph="none" start_char="3532" end_char="3534">why</TOKEN>
        <TOKEN id="token-82-6" pos="word" morph="none" start_char="3536" end_char="3538">she</TOKEN>
        <TOKEN id="token-82-7" pos="word" morph="none" start_char="3540" end_char="3543">kept</TOKEN>
        <TOKEN id="token-82-8" pos="word" morph="none" start_char="3545" end_char="3548">that</TOKEN>
        <TOKEN id="token-82-9" pos="word" morph="none" start_char="3550" end_char="3562">incriminating</TOKEN>
        <TOKEN id="token-82-10" pos="word" morph="none" start_char="3564" end_char="3567">blue</TOKEN>
        <TOKEN id="token-82-11" pos="word" morph="none" start_char="3569" end_char="3573">dress</TOKEN>
        <TOKEN id="token-82-12" pos="punct" morph="none" start_char="3574" end_char="3574">,</TOKEN>
        <TOKEN id="token-82-13" pos="word" morph="none" start_char="3576" end_char="3582">stained</TOKEN>
      </SEG>
      <SEG id="segment-83" start_char="3584" end_char="3659">
        <ORIGINAL_TEXT>with the semen of the most powerful man in the world. She testified that her</ORIGINAL_TEXT>
        <TOKEN id="token-83-0" pos="word" morph="none" start_char="3584" end_char="3587">with</TOKEN>
        <TOKEN id="token-83-1" pos="word" morph="none" start_char="3589" end_char="3591">the</TOKEN>
        <TOKEN id="token-83-2" pos="word" morph="none" start_char="3593" end_char="3597">semen</TOKEN>
        <TOKEN id="token-83-3" pos="word" morph="none" start_char="3599" end_char="3600">of</TOKEN>
        <TOKEN id="token-83-4" pos="word" morph="none" start_char="3602" end_char="3604">the</TOKEN>
        <TOKEN id="token-83-5" pos="word" morph="none" start_char="3606" end_char="3609">most</TOKEN>
        <TOKEN id="token-83-6" pos="word" morph="none" start_char="3611" end_char="3618">powerful</TOKEN>
        <TOKEN id="token-83-7" pos="word" morph="none" start_char="3620" end_char="3622">man</TOKEN>
        <TOKEN id="token-83-8" pos="word" morph="none" start_char="3624" end_char="3625">in</TOKEN>
        <TOKEN id="token-83-9" pos="word" morph="none" start_char="3627" end_char="3629">the</TOKEN>
        <TOKEN id="token-83-10" pos="word" morph="none" start_char="3631" end_char="3635">world</TOKEN>
        <TOKEN id="token-83-11" pos="punct" morph="none" start_char="3636" end_char="3636">.</TOKEN>
        <TOKEN id="token-83-12" pos="word" morph="none" start_char="3638" end_char="3640">She</TOKEN>
        <TOKEN id="token-83-13" pos="word" morph="none" start_char="3642" end_char="3650">testified</TOKEN>
        <TOKEN id="token-83-14" pos="word" morph="none" start_char="3652" end_char="3655">that</TOKEN>
        <TOKEN id="token-83-15" pos="word" morph="none" start_char="3657" end_char="3659">her</TOKEN>
      </SEG>
      <SEG id="segment-84" start_char="3661" end_char="3729">
        <ORIGINAL_TEXT>“frenemy,” government employee Linda Tripp, who ultimately outed her,</ORIGINAL_TEXT>
        <TOKEN id="token-84-0" pos="punct" morph="none" start_char="3661" end_char="3661">“</TOKEN>
        <TOKEN id="token-84-1" pos="word" morph="none" start_char="3662" end_char="3668">frenemy</TOKEN>
        <TOKEN id="token-84-2" pos="punct" morph="none" start_char="3669" end_char="3670">,”</TOKEN>
        <TOKEN id="token-84-3" pos="word" morph="none" start_char="3672" end_char="3681">government</TOKEN>
        <TOKEN id="token-84-4" pos="word" morph="none" start_char="3683" end_char="3690">employee</TOKEN>
        <TOKEN id="token-84-5" pos="word" morph="none" start_char="3692" end_char="3696">Linda</TOKEN>
        <TOKEN id="token-84-6" pos="word" morph="none" start_char="3698" end_char="3702">Tripp</TOKEN>
        <TOKEN id="token-84-7" pos="punct" morph="none" start_char="3703" end_char="3703">,</TOKEN>
        <TOKEN id="token-84-8" pos="word" morph="none" start_char="3705" end_char="3707">who</TOKEN>
        <TOKEN id="token-84-9" pos="word" morph="none" start_char="3709" end_char="3718">ultimately</TOKEN>
        <TOKEN id="token-84-10" pos="word" morph="none" start_char="3720" end_char="3724">outed</TOKEN>
        <TOKEN id="token-84-11" pos="word" morph="none" start_char="3726" end_char="3728">her</TOKEN>
        <TOKEN id="token-84-12" pos="punct" morph="none" start_char="3729" end_char="3729">,</TOKEN>
      </SEG>
      <SEG id="segment-85" start_char="3731" end_char="3801">
        <ORIGINAL_TEXT>“told me that I should put it in a safe-deposit box because it could be</ORIGINAL_TEXT>
        <TOKEN id="token-85-0" pos="punct" morph="none" start_char="3731" end_char="3731">“</TOKEN>
        <TOKEN id="token-85-1" pos="word" morph="none" start_char="3732" end_char="3735">told</TOKEN>
        <TOKEN id="token-85-2" pos="word" morph="none" start_char="3737" end_char="3738">me</TOKEN>
        <TOKEN id="token-85-3" pos="word" morph="none" start_char="3740" end_char="3743">that</TOKEN>
        <TOKEN id="token-85-4" pos="word" morph="none" start_char="3745" end_char="3745">I</TOKEN>
        <TOKEN id="token-85-5" pos="word" morph="none" start_char="3747" end_char="3752">should</TOKEN>
        <TOKEN id="token-85-6" pos="word" morph="none" start_char="3754" end_char="3756">put</TOKEN>
        <TOKEN id="token-85-7" pos="word" morph="none" start_char="3758" end_char="3759">it</TOKEN>
        <TOKEN id="token-85-8" pos="word" morph="none" start_char="3761" end_char="3762">in</TOKEN>
        <TOKEN id="token-85-9" pos="word" morph="none" start_char="3764" end_char="3764">a</TOKEN>
        <TOKEN id="token-85-10" pos="word" morph="none" start_char="3766" end_char="3769">safe</TOKEN>
        <TOKEN id="token-85-11" pos="punct" morph="none" start_char="3770" end_char="3770">-</TOKEN>
        <TOKEN id="token-85-12" pos="word" morph="none" start_char="3771" end_char="3777">deposit</TOKEN>
        <TOKEN id="token-85-13" pos="word" morph="none" start_char="3779" end_char="3781">box</TOKEN>
        <TOKEN id="token-85-14" pos="word" morph="none" start_char="3783" end_char="3789">because</TOKEN>
        <TOKEN id="token-85-15" pos="word" morph="none" start_char="3791" end_char="3792">it</TOKEN>
        <TOKEN id="token-85-16" pos="word" morph="none" start_char="3794" end_char="3798">could</TOKEN>
        <TOKEN id="token-85-17" pos="word" morph="none" start_char="3800" end_char="3801">be</TOKEN>
      </SEG>
      <SEG id="segment-86" start_char="3803" end_char="3875">
        <ORIGINAL_TEXT>evidence one day. And I said that was ludicrous because I would never — I</ORIGINAL_TEXT>
        <TOKEN id="token-86-0" pos="word" morph="none" start_char="3803" end_char="3810">evidence</TOKEN>
        <TOKEN id="token-86-1" pos="word" morph="none" start_char="3812" end_char="3814">one</TOKEN>
        <TOKEN id="token-86-2" pos="word" morph="none" start_char="3816" end_char="3818">day</TOKEN>
        <TOKEN id="token-86-3" pos="punct" morph="none" start_char="3819" end_char="3819">.</TOKEN>
        <TOKEN id="token-86-4" pos="word" morph="none" start_char="3821" end_char="3823">And</TOKEN>
        <TOKEN id="token-86-5" pos="word" morph="none" start_char="3825" end_char="3825">I</TOKEN>
        <TOKEN id="token-86-6" pos="word" morph="none" start_char="3827" end_char="3830">said</TOKEN>
        <TOKEN id="token-86-7" pos="word" morph="none" start_char="3832" end_char="3835">that</TOKEN>
        <TOKEN id="token-86-8" pos="word" morph="none" start_char="3837" end_char="3839">was</TOKEN>
        <TOKEN id="token-86-9" pos="word" morph="none" start_char="3841" end_char="3849">ludicrous</TOKEN>
        <TOKEN id="token-86-10" pos="word" morph="none" start_char="3851" end_char="3857">because</TOKEN>
        <TOKEN id="token-86-11" pos="word" morph="none" start_char="3859" end_char="3859">I</TOKEN>
        <TOKEN id="token-86-12" pos="word" morph="none" start_char="3861" end_char="3865">would</TOKEN>
        <TOKEN id="token-86-13" pos="word" morph="none" start_char="3867" end_char="3871">never</TOKEN>
        <TOKEN id="token-86-14" pos="unknown" morph="none" start_char="3873" end_char="3873">—</TOKEN>
        <TOKEN id="token-86-15" pos="word" morph="none" start_char="3875" end_char="3875">I</TOKEN>
      </SEG>
      <SEG id="segment-87" start_char="3877" end_char="3943">
        <ORIGINAL_TEXT>would never disclose that I had a relationship with the president.”</ORIGINAL_TEXT>
        <TOKEN id="token-87-0" pos="word" morph="none" start_char="3877" end_char="3881">would</TOKEN>
        <TOKEN id="token-87-1" pos="word" morph="none" start_char="3883" end_char="3887">never</TOKEN>
        <TOKEN id="token-87-2" pos="word" morph="none" start_char="3889" end_char="3896">disclose</TOKEN>
        <TOKEN id="token-87-3" pos="word" morph="none" start_char="3898" end_char="3901">that</TOKEN>
        <TOKEN id="token-87-4" pos="word" morph="none" start_char="3903" end_char="3903">I</TOKEN>
        <TOKEN id="token-87-5" pos="word" morph="none" start_char="3905" end_char="3907">had</TOKEN>
        <TOKEN id="token-87-6" pos="word" morph="none" start_char="3909" end_char="3909">a</TOKEN>
        <TOKEN id="token-87-7" pos="word" morph="none" start_char="3911" end_char="3922">relationship</TOKEN>
        <TOKEN id="token-87-8" pos="word" morph="none" start_char="3924" end_char="3927">with</TOKEN>
        <TOKEN id="token-87-9" pos="word" morph="none" start_char="3929" end_char="3931">the</TOKEN>
        <TOKEN id="token-87-10" pos="word" morph="none" start_char="3933" end_char="3941">president</TOKEN>
        <TOKEN id="token-87-11" pos="punct" morph="none" start_char="3942" end_char="3943">.”</TOKEN>
      </SEG>
      <SEG id="segment-88" start_char="3945" end_char="3948">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-88-0" pos="unknown" morph="none" start_char="3945" end_char="3948">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-89" start_char="3950" end_char="3952">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-89-0" pos="unknown" morph="none" start_char="3950" end_char="3952">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-90" start_char="3954" end_char="4030">
        <ORIGINAL_TEXT>She was forced to do just that under oath by very scary men, including odious</ORIGINAL_TEXT>
        <TOKEN id="token-90-0" pos="word" morph="none" start_char="3954" end_char="3956">She</TOKEN>
        <TOKEN id="token-90-1" pos="word" morph="none" start_char="3958" end_char="3960">was</TOKEN>
        <TOKEN id="token-90-2" pos="word" morph="none" start_char="3962" end_char="3967">forced</TOKEN>
        <TOKEN id="token-90-3" pos="word" morph="none" start_char="3969" end_char="3970">to</TOKEN>
        <TOKEN id="token-90-4" pos="word" morph="none" start_char="3972" end_char="3973">do</TOKEN>
        <TOKEN id="token-90-5" pos="word" morph="none" start_char="3975" end_char="3978">just</TOKEN>
        <TOKEN id="token-90-6" pos="word" morph="none" start_char="3980" end_char="3983">that</TOKEN>
        <TOKEN id="token-90-7" pos="word" morph="none" start_char="3985" end_char="3989">under</TOKEN>
        <TOKEN id="token-90-8" pos="word" morph="none" start_char="3991" end_char="3994">oath</TOKEN>
        <TOKEN id="token-90-9" pos="word" morph="none" start_char="3996" end_char="3997">by</TOKEN>
        <TOKEN id="token-90-10" pos="word" morph="none" start_char="3999" end_char="4002">very</TOKEN>
        <TOKEN id="token-90-11" pos="word" morph="none" start_char="4004" end_char="4008">scary</TOKEN>
        <TOKEN id="token-90-12" pos="word" morph="none" start_char="4010" end_char="4012">men</TOKEN>
        <TOKEN id="token-90-13" pos="punct" morph="none" start_char="4013" end_char="4013">,</TOKEN>
        <TOKEN id="token-90-14" pos="word" morph="none" start_char="4015" end_char="4023">including</TOKEN>
        <TOKEN id="token-90-15" pos="word" morph="none" start_char="4025" end_char="4030">odious</TOKEN>
      </SEG>
      <SEG id="segment-91" start_char="4032" end_char="4102">
        <ORIGINAL_TEXT>prosecutor Ken Starr, who admitted he “loved the narrative” of shame he</ORIGINAL_TEXT>
        <TOKEN id="token-91-0" pos="word" morph="none" start_char="4032" end_char="4041">prosecutor</TOKEN>
        <TOKEN id="token-91-1" pos="word" morph="none" start_char="4043" end_char="4045">Ken</TOKEN>
        <TOKEN id="token-91-2" pos="word" morph="none" start_char="4047" end_char="4051">Starr</TOKEN>
        <TOKEN id="token-91-3" pos="punct" morph="none" start_char="4052" end_char="4052">,</TOKEN>
        <TOKEN id="token-91-4" pos="word" morph="none" start_char="4054" end_char="4056">who</TOKEN>
        <TOKEN id="token-91-5" pos="word" morph="none" start_char="4058" end_char="4065">admitted</TOKEN>
        <TOKEN id="token-91-6" pos="word" morph="none" start_char="4067" end_char="4068">he</TOKEN>
        <TOKEN id="token-91-7" pos="punct" morph="none" start_char="4070" end_char="4070">“</TOKEN>
        <TOKEN id="token-91-8" pos="word" morph="none" start_char="4071" end_char="4075">loved</TOKEN>
        <TOKEN id="token-91-9" pos="word" morph="none" start_char="4077" end_char="4079">the</TOKEN>
        <TOKEN id="token-91-10" pos="word" morph="none" start_char="4081" end_char="4089">narrative</TOKEN>
        <TOKEN id="token-91-11" pos="punct" morph="none" start_char="4090" end_char="4090">”</TOKEN>
        <TOKEN id="token-91-12" pos="word" morph="none" start_char="4092" end_char="4093">of</TOKEN>
        <TOKEN id="token-91-13" pos="word" morph="none" start_char="4095" end_char="4099">shame</TOKEN>
        <TOKEN id="token-91-14" pos="word" morph="none" start_char="4101" end_char="4102">he</TOKEN>
      </SEG>
      <SEG id="segment-92" start_char="4104" end_char="4176">
        <ORIGINAL_TEXT>had uncovered. The result was a moral and political cataclysm in America.</ORIGINAL_TEXT>
        <TOKEN id="token-92-0" pos="word" morph="none" start_char="4104" end_char="4106">had</TOKEN>
        <TOKEN id="token-92-1" pos="word" morph="none" start_char="4108" end_char="4116">uncovered</TOKEN>
        <TOKEN id="token-92-2" pos="punct" morph="none" start_char="4117" end_char="4117">.</TOKEN>
        <TOKEN id="token-92-3" pos="word" morph="none" start_char="4119" end_char="4121">The</TOKEN>
        <TOKEN id="token-92-4" pos="word" morph="none" start_char="4123" end_char="4128">result</TOKEN>
        <TOKEN id="token-92-5" pos="word" morph="none" start_char="4130" end_char="4132">was</TOKEN>
        <TOKEN id="token-92-6" pos="word" morph="none" start_char="4134" end_char="4134">a</TOKEN>
        <TOKEN id="token-92-7" pos="word" morph="none" start_char="4136" end_char="4140">moral</TOKEN>
        <TOKEN id="token-92-8" pos="word" morph="none" start_char="4142" end_char="4144">and</TOKEN>
        <TOKEN id="token-92-9" pos="word" morph="none" start_char="4146" end_char="4154">political</TOKEN>
        <TOKEN id="token-92-10" pos="word" morph="none" start_char="4156" end_char="4164">cataclysm</TOKEN>
        <TOKEN id="token-92-11" pos="word" morph="none" start_char="4166" end_char="4167">in</TOKEN>
        <TOKEN id="token-92-12" pos="word" morph="none" start_char="4169" end_char="4175">America</TOKEN>
        <TOKEN id="token-92-13" pos="punct" morph="none" start_char="4176" end_char="4176">.</TOKEN>
      </SEG>
      <SEG id="segment-93" start_char="4178" end_char="4181">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-93-0" pos="unknown" morph="none" start_char="4178" end_char="4181">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-94" start_char="4183" end_char="4185">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-94-0" pos="unknown" morph="none" start_char="4183" end_char="4185">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-95" start_char="4187" end_char="4263">
        <ORIGINAL_TEXT>And now, just as Hillary Clinton, who in wifely frustration once called her a</ORIGINAL_TEXT>
        <TOKEN id="token-95-0" pos="word" morph="none" start_char="4187" end_char="4189">And</TOKEN>
        <TOKEN id="token-95-1" pos="word" morph="none" start_char="4191" end_char="4193">now</TOKEN>
        <TOKEN id="token-95-2" pos="punct" morph="none" start_char="4194" end_char="4194">,</TOKEN>
        <TOKEN id="token-95-3" pos="word" morph="none" start_char="4196" end_char="4199">just</TOKEN>
        <TOKEN id="token-95-4" pos="word" morph="none" start_char="4201" end_char="4202">as</TOKEN>
        <TOKEN id="token-95-5" pos="word" morph="none" start_char="4204" end_char="4210">Hillary</TOKEN>
        <TOKEN id="token-95-6" pos="word" morph="none" start_char="4212" end_char="4218">Clinton</TOKEN>
        <TOKEN id="token-95-7" pos="punct" morph="none" start_char="4219" end_char="4219">,</TOKEN>
        <TOKEN id="token-95-8" pos="word" morph="none" start_char="4221" end_char="4223">who</TOKEN>
        <TOKEN id="token-95-9" pos="word" morph="none" start_char="4225" end_char="4226">in</TOKEN>
        <TOKEN id="token-95-10" pos="word" morph="none" start_char="4228" end_char="4233">wifely</TOKEN>
        <TOKEN id="token-95-11" pos="word" morph="none" start_char="4235" end_char="4245">frustration</TOKEN>
        <TOKEN id="token-95-12" pos="word" morph="none" start_char="4247" end_char="4250">once</TOKEN>
        <TOKEN id="token-95-13" pos="word" morph="none" start_char="4252" end_char="4257">called</TOKEN>
        <TOKEN id="token-95-14" pos="word" morph="none" start_char="4259" end_char="4261">her</TOKEN>
        <TOKEN id="token-95-15" pos="word" morph="none" start_char="4263" end_char="4263">a</TOKEN>
      </SEG>
      <SEG id="segment-96" start_char="4265" end_char="4337">
        <ORIGINAL_TEXT>“narcissistic loony tune,” is embarking on her presidential bid, Lewinsky</ORIGINAL_TEXT>
        <TOKEN id="token-96-0" pos="punct" morph="none" start_char="4265" end_char="4265">“</TOKEN>
        <TOKEN id="token-96-1" pos="word" morph="none" start_char="4266" end_char="4277">narcissistic</TOKEN>
        <TOKEN id="token-96-2" pos="word" morph="none" start_char="4279" end_char="4283">loony</TOKEN>
        <TOKEN id="token-96-3" pos="word" morph="none" start_char="4285" end_char="4288">tune</TOKEN>
        <TOKEN id="token-96-4" pos="punct" morph="none" start_char="4289" end_char="4290">,”</TOKEN>
        <TOKEN id="token-96-5" pos="word" morph="none" start_char="4292" end_char="4293">is</TOKEN>
        <TOKEN id="token-96-6" pos="word" morph="none" start_char="4295" end_char="4303">embarking</TOKEN>
        <TOKEN id="token-96-7" pos="word" morph="none" start_char="4305" end_char="4306">on</TOKEN>
        <TOKEN id="token-96-8" pos="word" morph="none" start_char="4308" end_char="4310">her</TOKEN>
        <TOKEN id="token-96-9" pos="word" morph="none" start_char="4312" end_char="4323">presidential</TOKEN>
        <TOKEN id="token-96-10" pos="word" morph="none" start_char="4325" end_char="4327">bid</TOKEN>
        <TOKEN id="token-96-11" pos="punct" morph="none" start_char="4328" end_char="4328">,</TOKEN>
        <TOKEN id="token-96-12" pos="word" morph="none" start_char="4330" end_char="4337">Lewinsky</TOKEN>
      </SEG>
      <SEG id="segment-97" start_char="4339" end_char="4408">
        <ORIGINAL_TEXT>is back, declaring she has been “stuck” for too long, and it’s time to</ORIGINAL_TEXT>
        <TOKEN id="token-97-0" pos="word" morph="none" start_char="4339" end_char="4340">is</TOKEN>
        <TOKEN id="token-97-1" pos="word" morph="none" start_char="4342" end_char="4345">back</TOKEN>
        <TOKEN id="token-97-2" pos="punct" morph="none" start_char="4346" end_char="4346">,</TOKEN>
        <TOKEN id="token-97-3" pos="word" morph="none" start_char="4348" end_char="4356">declaring</TOKEN>
        <TOKEN id="token-97-4" pos="word" morph="none" start_char="4358" end_char="4360">she</TOKEN>
        <TOKEN id="token-97-5" pos="word" morph="none" start_char="4362" end_char="4364">has</TOKEN>
        <TOKEN id="token-97-6" pos="word" morph="none" start_char="4366" end_char="4369">been</TOKEN>
        <TOKEN id="token-97-7" pos="punct" morph="none" start_char="4371" end_char="4371">“</TOKEN>
        <TOKEN id="token-97-8" pos="word" morph="none" start_char="4372" end_char="4376">stuck</TOKEN>
        <TOKEN id="token-97-9" pos="punct" morph="none" start_char="4377" end_char="4377">”</TOKEN>
        <TOKEN id="token-97-10" pos="word" morph="none" start_char="4379" end_char="4381">for</TOKEN>
        <TOKEN id="token-97-11" pos="word" morph="none" start_char="4383" end_char="4385">too</TOKEN>
        <TOKEN id="token-97-12" pos="word" morph="none" start_char="4387" end_char="4390">long</TOKEN>
        <TOKEN id="token-97-13" pos="punct" morph="none" start_char="4391" end_char="4391">,</TOKEN>
        <TOKEN id="token-97-14" pos="word" morph="none" start_char="4393" end_char="4395">and</TOKEN>
        <TOKEN id="token-97-15" pos="word" morph="none" start_char="4397" end_char="4398">it</TOKEN>
        <TOKEN id="token-97-16" pos="punct" morph="none" start_char="4399" end_char="4399">’</TOKEN>
        <TOKEN id="token-97-17" pos="word" morph="none" start_char="4400" end_char="4400">s</TOKEN>
        <TOKEN id="token-97-18" pos="word" morph="none" start_char="4402" end_char="4405">time</TOKEN>
        <TOKEN id="token-97-19" pos="word" morph="none" start_char="4407" end_char="4408">to</TOKEN>
      </SEG>
      <SEG id="segment-98" start_char="4410" end_char="4448">
        <ORIGINAL_TEXT>“bury the blue dress and move forward.”</ORIGINAL_TEXT>
        <TOKEN id="token-98-0" pos="punct" morph="none" start_char="4410" end_char="4410">“</TOKEN>
        <TOKEN id="token-98-1" pos="word" morph="none" start_char="4411" end_char="4414">bury</TOKEN>
        <TOKEN id="token-98-2" pos="word" morph="none" start_char="4416" end_char="4418">the</TOKEN>
        <TOKEN id="token-98-3" pos="word" morph="none" start_char="4420" end_char="4423">blue</TOKEN>
        <TOKEN id="token-98-4" pos="word" morph="none" start_char="4425" end_char="4429">dress</TOKEN>
        <TOKEN id="token-98-5" pos="word" morph="none" start_char="4431" end_char="4433">and</TOKEN>
        <TOKEN id="token-98-6" pos="word" morph="none" start_char="4435" end_char="4438">move</TOKEN>
        <TOKEN id="token-98-7" pos="word" morph="none" start_char="4440" end_char="4446">forward</TOKEN>
        <TOKEN id="token-98-8" pos="punct" morph="none" start_char="4447" end_char="4448">.”</TOKEN>
      </SEG>
      <SEG id="segment-99" start_char="4450" end_char="4453">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-99-0" pos="unknown" morph="none" start_char="4450" end_char="4453">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-100" start_char="4455" end_char="4457">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-100-0" pos="unknown" morph="none" start_char="4455" end_char="4457">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-101" start_char="4459" end_char="4529">
        <ORIGINAL_TEXT>Timing is everything. Would people have paid this much attention if the</ORIGINAL_TEXT>
        <TOKEN id="token-101-0" pos="word" morph="none" start_char="4459" end_char="4464">Timing</TOKEN>
        <TOKEN id="token-101-1" pos="word" morph="none" start_char="4466" end_char="4467">is</TOKEN>
        <TOKEN id="token-101-2" pos="word" morph="none" start_char="4469" end_char="4478">everything</TOKEN>
        <TOKEN id="token-101-3" pos="punct" morph="none" start_char="4479" end_char="4479">.</TOKEN>
        <TOKEN id="token-101-4" pos="word" morph="none" start_char="4481" end_char="4485">Would</TOKEN>
        <TOKEN id="token-101-5" pos="word" morph="none" start_char="4487" end_char="4492">people</TOKEN>
        <TOKEN id="token-101-6" pos="word" morph="none" start_char="4494" end_char="4497">have</TOKEN>
        <TOKEN id="token-101-7" pos="word" morph="none" start_char="4499" end_char="4502">paid</TOKEN>
        <TOKEN id="token-101-8" pos="word" morph="none" start_char="4504" end_char="4507">this</TOKEN>
        <TOKEN id="token-101-9" pos="word" morph="none" start_char="4509" end_char="4512">much</TOKEN>
        <TOKEN id="token-101-10" pos="word" morph="none" start_char="4514" end_char="4522">attention</TOKEN>
        <TOKEN id="token-101-11" pos="word" morph="none" start_char="4524" end_char="4525">if</TOKEN>
        <TOKEN id="token-101-12" pos="word" morph="none" start_char="4527" end_char="4529">the</TOKEN>
      </SEG>
      <SEG id="segment-102" start_char="4531" end_char="4580">
        <ORIGINAL_TEXT>Clintons were not still dominating the news cycle?</ORIGINAL_TEXT>
        <TOKEN id="token-102-0" pos="word" morph="none" start_char="4531" end_char="4538">Clintons</TOKEN>
        <TOKEN id="token-102-1" pos="word" morph="none" start_char="4540" end_char="4543">were</TOKEN>
        <TOKEN id="token-102-2" pos="word" morph="none" start_char="4545" end_char="4547">not</TOKEN>
        <TOKEN id="token-102-3" pos="word" morph="none" start_char="4549" end_char="4553">still</TOKEN>
        <TOKEN id="token-102-4" pos="word" morph="none" start_char="4555" end_char="4564">dominating</TOKEN>
        <TOKEN id="token-102-5" pos="word" morph="none" start_char="4566" end_char="4568">the</TOKEN>
        <TOKEN id="token-102-6" pos="word" morph="none" start_char="4570" end_char="4573">news</TOKEN>
        <TOKEN id="token-102-7" pos="word" morph="none" start_char="4575" end_char="4579">cycle</TOKEN>
        <TOKEN id="token-102-8" pos="punct" morph="none" start_char="4580" end_char="4580">?</TOKEN>
      </SEG>
      <SEG id="segment-103" start_char="4582" end_char="4585">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-103-0" pos="unknown" morph="none" start_char="4582" end_char="4585">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-104" start_char="4587" end_char="4589">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-104-0" pos="unknown" morph="none" start_char="4587" end_char="4589">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-105" start_char="4591" end_char="4663">
        <ORIGINAL_TEXT>Here’s a startling thought. Monica Lewinsky may ultimately be credited as</ORIGINAL_TEXT>
        <TOKEN id="token-105-0" pos="word" morph="none" start_char="4591" end_char="4594">Here</TOKEN>
        <TOKEN id="token-105-1" pos="punct" morph="none" start_char="4595" end_char="4595">’</TOKEN>
        <TOKEN id="token-105-2" pos="word" morph="none" start_char="4596" end_char="4596">s</TOKEN>
        <TOKEN id="token-105-3" pos="word" morph="none" start_char="4598" end_char="4598">a</TOKEN>
        <TOKEN id="token-105-4" pos="word" morph="none" start_char="4600" end_char="4608">startling</TOKEN>
        <TOKEN id="token-105-5" pos="word" morph="none" start_char="4610" end_char="4616">thought</TOKEN>
        <TOKEN id="token-105-6" pos="punct" morph="none" start_char="4617" end_char="4617">.</TOKEN>
        <TOKEN id="token-105-7" pos="word" morph="none" start_char="4619" end_char="4624">Monica</TOKEN>
        <TOKEN id="token-105-8" pos="word" morph="none" start_char="4626" end_char="4633">Lewinsky</TOKEN>
        <TOKEN id="token-105-9" pos="word" morph="none" start_char="4635" end_char="4637">may</TOKEN>
        <TOKEN id="token-105-10" pos="word" morph="none" start_char="4639" end_char="4648">ultimately</TOKEN>
        <TOKEN id="token-105-11" pos="word" morph="none" start_char="4650" end_char="4651">be</TOKEN>
        <TOKEN id="token-105-12" pos="word" morph="none" start_char="4653" end_char="4660">credited</TOKEN>
        <TOKEN id="token-105-13" pos="word" morph="none" start_char="4662" end_char="4663">as</TOKEN>
      </SEG>
      <SEG id="segment-106" start_char="4665" end_char="4717">
        <ORIGINAL_TEXT>the catalyst for the first female American president.</ORIGINAL_TEXT>
        <TOKEN id="token-106-0" pos="word" morph="none" start_char="4665" end_char="4667">the</TOKEN>
        <TOKEN id="token-106-1" pos="word" morph="none" start_char="4669" end_char="4676">catalyst</TOKEN>
        <TOKEN id="token-106-2" pos="word" morph="none" start_char="4678" end_char="4680">for</TOKEN>
        <TOKEN id="token-106-3" pos="word" morph="none" start_char="4682" end_char="4684">the</TOKEN>
        <TOKEN id="token-106-4" pos="word" morph="none" start_char="4686" end_char="4690">first</TOKEN>
        <TOKEN id="token-106-5" pos="word" morph="none" start_char="4692" end_char="4697">female</TOKEN>
        <TOKEN id="token-106-6" pos="word" morph="none" start_char="4699" end_char="4706">American</TOKEN>
        <TOKEN id="token-106-7" pos="word" morph="none" start_char="4708" end_char="4716">president</TOKEN>
        <TOKEN id="token-106-8" pos="punct" morph="none" start_char="4717" end_char="4717">.</TOKEN>
      </SEG>
      <SEG id="segment-107" start_char="4719" end_char="4722">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-107-0" pos="unknown" morph="none" start_char="4719" end_char="4722">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-108" start_char="4724" end_char="4726">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-108-0" pos="unknown" morph="none" start_char="4724" end_char="4726">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-109" start_char="4728" end_char="4799">
        <ORIGINAL_TEXT>In Carl Bernstein’s excellent 2007 Hillary Clinton biography, A Woman in</ORIGINAL_TEXT>
        <TOKEN id="token-109-0" pos="word" morph="none" start_char="4728" end_char="4729">In</TOKEN>
        <TOKEN id="token-109-1" pos="word" morph="none" start_char="4731" end_char="4734">Carl</TOKEN>
        <TOKEN id="token-109-2" pos="word" morph="none" start_char="4736" end_char="4744">Bernstein</TOKEN>
        <TOKEN id="token-109-3" pos="punct" morph="none" start_char="4745" end_char="4745">’</TOKEN>
        <TOKEN id="token-109-4" pos="word" morph="none" start_char="4746" end_char="4746">s</TOKEN>
        <TOKEN id="token-109-5" pos="word" morph="none" start_char="4748" end_char="4756">excellent</TOKEN>
        <TOKEN id="token-109-6" pos="number" morph="none" start_char="4758" end_char="4761">2007</TOKEN>
        <TOKEN id="token-109-7" pos="word" morph="none" start_char="4763" end_char="4769">Hillary</TOKEN>
        <TOKEN id="token-109-8" pos="word" morph="none" start_char="4771" end_char="4777">Clinton</TOKEN>
        <TOKEN id="token-109-9" pos="word" morph="none" start_char="4779" end_char="4787">biography</TOKEN>
        <TOKEN id="token-109-10" pos="punct" morph="none" start_char="4788" end_char="4788">,</TOKEN>
        <TOKEN id="token-109-11" pos="word" morph="none" start_char="4790" end_char="4790">A</TOKEN>
        <TOKEN id="token-109-12" pos="word" morph="none" start_char="4792" end_char="4796">Woman</TOKEN>
        <TOKEN id="token-109-13" pos="word" morph="none" start_char="4798" end_char="4799">in</TOKEN>
      </SEG>
      <SEG id="segment-110" start_char="4801" end_char="4877">
        <ORIGINAL_TEXT>Charge, he argues it was shortly after the devastating Lewinsky scandal, that</ORIGINAL_TEXT>
        <TOKEN id="token-110-0" pos="word" morph="none" start_char="4801" end_char="4806">Charge</TOKEN>
        <TOKEN id="token-110-1" pos="punct" morph="none" start_char="4807" end_char="4807">,</TOKEN>
        <TOKEN id="token-110-2" pos="word" morph="none" start_char="4809" end_char="4810">he</TOKEN>
        <TOKEN id="token-110-3" pos="word" morph="none" start_char="4812" end_char="4817">argues</TOKEN>
        <TOKEN id="token-110-4" pos="word" morph="none" start_char="4819" end_char="4820">it</TOKEN>
        <TOKEN id="token-110-5" pos="word" morph="none" start_char="4822" end_char="4824">was</TOKEN>
        <TOKEN id="token-110-6" pos="word" morph="none" start_char="4826" end_char="4832">shortly</TOKEN>
        <TOKEN id="token-110-7" pos="word" morph="none" start_char="4834" end_char="4838">after</TOKEN>
        <TOKEN id="token-110-8" pos="word" morph="none" start_char="4840" end_char="4842">the</TOKEN>
        <TOKEN id="token-110-9" pos="word" morph="none" start_char="4844" end_char="4854">devastating</TOKEN>
        <TOKEN id="token-110-10" pos="word" morph="none" start_char="4856" end_char="4863">Lewinsky</TOKEN>
        <TOKEN id="token-110-11" pos="word" morph="none" start_char="4865" end_char="4871">scandal</TOKEN>
        <TOKEN id="token-110-12" pos="punct" morph="none" start_char="4872" end_char="4872">,</TOKEN>
        <TOKEN id="token-110-13" pos="word" morph="none" start_char="4874" end_char="4877">that</TOKEN>
      </SEG>
      <SEG id="segment-111" start_char="4879" end_char="4952">
        <ORIGINAL_TEXT>Clinton made up her mind to separate herself from her husband’s agenda and</ORIGINAL_TEXT>
        <TOKEN id="token-111-0" pos="word" morph="none" start_char="4879" end_char="4885">Clinton</TOKEN>
        <TOKEN id="token-111-1" pos="word" morph="none" start_char="4887" end_char="4890">made</TOKEN>
        <TOKEN id="token-111-2" pos="word" morph="none" start_char="4892" end_char="4893">up</TOKEN>
        <TOKEN id="token-111-3" pos="word" morph="none" start_char="4895" end_char="4897">her</TOKEN>
        <TOKEN id="token-111-4" pos="word" morph="none" start_char="4899" end_char="4902">mind</TOKEN>
        <TOKEN id="token-111-5" pos="word" morph="none" start_char="4904" end_char="4905">to</TOKEN>
        <TOKEN id="token-111-6" pos="word" morph="none" start_char="4907" end_char="4914">separate</TOKEN>
        <TOKEN id="token-111-7" pos="word" morph="none" start_char="4916" end_char="4922">herself</TOKEN>
        <TOKEN id="token-111-8" pos="word" morph="none" start_char="4924" end_char="4927">from</TOKEN>
        <TOKEN id="token-111-9" pos="word" morph="none" start_char="4929" end_char="4931">her</TOKEN>
        <TOKEN id="token-111-10" pos="word" morph="none" start_char="4933" end_char="4939">husband</TOKEN>
        <TOKEN id="token-111-11" pos="punct" morph="none" start_char="4940" end_char="4940">’</TOKEN>
        <TOKEN id="token-111-12" pos="word" morph="none" start_char="4941" end_char="4941">s</TOKEN>
        <TOKEN id="token-111-13" pos="word" morph="none" start_char="4943" end_char="4948">agenda</TOKEN>
        <TOKEN id="token-111-14" pos="word" morph="none" start_char="4950" end_char="4952">and</TOKEN>
      </SEG>
      <SEG id="segment-112" start_char="4954" end_char="5030">
        <ORIGINAL_TEXT>run for the Senate. Without her successful tenure as a senator, Clinton could</ORIGINAL_TEXT>
        <TOKEN id="token-112-0" pos="word" morph="none" start_char="4954" end_char="4956">run</TOKEN>
        <TOKEN id="token-112-1" pos="word" morph="none" start_char="4958" end_char="4960">for</TOKEN>
        <TOKEN id="token-112-2" pos="word" morph="none" start_char="4962" end_char="4964">the</TOKEN>
        <TOKEN id="token-112-3" pos="word" morph="none" start_char="4966" end_char="4971">Senate</TOKEN>
        <TOKEN id="token-112-4" pos="punct" morph="none" start_char="4972" end_char="4972">.</TOKEN>
        <TOKEN id="token-112-5" pos="word" morph="none" start_char="4974" end_char="4980">Without</TOKEN>
        <TOKEN id="token-112-6" pos="word" morph="none" start_char="4982" end_char="4984">her</TOKEN>
        <TOKEN id="token-112-7" pos="word" morph="none" start_char="4986" end_char="4995">successful</TOKEN>
        <TOKEN id="token-112-8" pos="word" morph="none" start_char="4997" end_char="5002">tenure</TOKEN>
        <TOKEN id="token-112-9" pos="word" morph="none" start_char="5004" end_char="5005">as</TOKEN>
        <TOKEN id="token-112-10" pos="word" morph="none" start_char="5007" end_char="5007">a</TOKEN>
        <TOKEN id="token-112-11" pos="word" morph="none" start_char="5009" end_char="5015">senator</TOKEN>
        <TOKEN id="token-112-12" pos="punct" morph="none" start_char="5016" end_char="5016">,</TOKEN>
        <TOKEN id="token-112-13" pos="word" morph="none" start_char="5018" end_char="5024">Clinton</TOKEN>
        <TOKEN id="token-112-14" pos="word" morph="none" start_char="5026" end_char="5030">could</TOKEN>
      </SEG>
      <SEG id="segment-113" start_char="5032" end_char="5053">
        <ORIGINAL_TEXT>not run for president.</ORIGINAL_TEXT>
        <TOKEN id="token-113-0" pos="word" morph="none" start_char="5032" end_char="5034">not</TOKEN>
        <TOKEN id="token-113-1" pos="word" morph="none" start_char="5036" end_char="5038">run</TOKEN>
        <TOKEN id="token-113-2" pos="word" morph="none" start_char="5040" end_char="5042">for</TOKEN>
        <TOKEN id="token-113-3" pos="word" morph="none" start_char="5044" end_char="5052">president</TOKEN>
        <TOKEN id="token-113-4" pos="punct" morph="none" start_char="5053" end_char="5053">.</TOKEN>
      </SEG>
      <SEG id="segment-114" start_char="5055" end_char="5058">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-114-0" pos="unknown" morph="none" start_char="5055" end_char="5058">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-115" start_char="5060" end_char="5062">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-115-0" pos="unknown" morph="none" start_char="5060" end_char="5062">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-116" start_char="5064" end_char="5136">
        <ORIGINAL_TEXT>Hah. F. Scott Fitzgerald got it seriously wrong when he argued there were</ORIGINAL_TEXT>
        <TOKEN id="token-116-0" pos="word" morph="none" start_char="5064" end_char="5066">Hah</TOKEN>
        <TOKEN id="token-116-1" pos="punct" morph="none" start_char="5067" end_char="5067">.</TOKEN>
        <TOKEN id="token-116-2" pos="word" morph="none" start_char="5069" end_char="5069">F</TOKEN>
        <TOKEN id="token-116-3" pos="punct" morph="none" start_char="5070" end_char="5070">.</TOKEN>
        <TOKEN id="token-116-4" pos="word" morph="none" start_char="5072" end_char="5076">Scott</TOKEN>
        <TOKEN id="token-116-5" pos="word" morph="none" start_char="5078" end_char="5087">Fitzgerald</TOKEN>
        <TOKEN id="token-116-6" pos="word" morph="none" start_char="5089" end_char="5091">got</TOKEN>
        <TOKEN id="token-116-7" pos="word" morph="none" start_char="5093" end_char="5094">it</TOKEN>
        <TOKEN id="token-116-8" pos="word" morph="none" start_char="5096" end_char="5104">seriously</TOKEN>
        <TOKEN id="token-116-9" pos="word" morph="none" start_char="5106" end_char="5110">wrong</TOKEN>
        <TOKEN id="token-116-10" pos="word" morph="none" start_char="5112" end_char="5115">when</TOKEN>
        <TOKEN id="token-116-11" pos="word" morph="none" start_char="5117" end_char="5118">he</TOKEN>
        <TOKEN id="token-116-12" pos="word" morph="none" start_char="5120" end_char="5125">argued</TOKEN>
        <TOKEN id="token-116-13" pos="word" morph="none" start_char="5127" end_char="5131">there</TOKEN>
        <TOKEN id="token-116-14" pos="word" morph="none" start_char="5133" end_char="5136">were</TOKEN>
      </SEG>
      <SEG id="segment-117" start_char="5138" end_char="5208">
        <ORIGINAL_TEXT>“no second acts” in American life. The Clintons and now Monica Lewinsky</ORIGINAL_TEXT>
        <TOKEN id="token-117-0" pos="punct" morph="none" start_char="5138" end_char="5138">“</TOKEN>
        <TOKEN id="token-117-1" pos="word" morph="none" start_char="5139" end_char="5140">no</TOKEN>
        <TOKEN id="token-117-2" pos="word" morph="none" start_char="5142" end_char="5147">second</TOKEN>
        <TOKEN id="token-117-3" pos="word" morph="none" start_char="5149" end_char="5152">acts</TOKEN>
        <TOKEN id="token-117-4" pos="punct" morph="none" start_char="5153" end_char="5153">”</TOKEN>
        <TOKEN id="token-117-5" pos="word" morph="none" start_char="5155" end_char="5156">in</TOKEN>
        <TOKEN id="token-117-6" pos="word" morph="none" start_char="5158" end_char="5165">American</TOKEN>
        <TOKEN id="token-117-7" pos="word" morph="none" start_char="5167" end_char="5170">life</TOKEN>
        <TOKEN id="token-117-8" pos="punct" morph="none" start_char="5171" end_char="5171">.</TOKEN>
        <TOKEN id="token-117-9" pos="word" morph="none" start_char="5173" end_char="5175">The</TOKEN>
        <TOKEN id="token-117-10" pos="word" morph="none" start_char="5177" end_char="5184">Clintons</TOKEN>
        <TOKEN id="token-117-11" pos="word" morph="none" start_char="5186" end_char="5188">and</TOKEN>
        <TOKEN id="token-117-12" pos="word" morph="none" start_char="5190" end_char="5192">now</TOKEN>
        <TOKEN id="token-117-13" pos="word" morph="none" start_char="5194" end_char="5199">Monica</TOKEN>
        <TOKEN id="token-117-14" pos="word" morph="none" start_char="5201" end_char="5208">Lewinsky</TOKEN>
      </SEG>
      <SEG id="segment-118" start_char="5210" end_char="5244">
        <ORIGINAL_TEXT>are having spectacular second acts.</ORIGINAL_TEXT>
        <TOKEN id="token-118-0" pos="word" morph="none" start_char="5210" end_char="5212">are</TOKEN>
        <TOKEN id="token-118-1" pos="word" morph="none" start_char="5214" end_char="5219">having</TOKEN>
        <TOKEN id="token-118-2" pos="word" morph="none" start_char="5221" end_char="5231">spectacular</TOKEN>
        <TOKEN id="token-118-3" pos="word" morph="none" start_char="5233" end_char="5238">second</TOKEN>
        <TOKEN id="token-118-4" pos="word" morph="none" start_char="5240" end_char="5243">acts</TOKEN>
        <TOKEN id="token-118-5" pos="punct" morph="none" start_char="5244" end_char="5244">.</TOKEN>
      </SEG>
      <SEG id="segment-119" start_char="5246" end_char="5249">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-119-0" pos="unknown" morph="none" start_char="5246" end_char="5249">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-120" start_char="5251" end_char="5253">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-120-0" pos="unknown" morph="none" start_char="5251" end_char="5253">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-121" start_char="5255" end_char="5328">
        <ORIGINAL_TEXT>But I hope for her sake that Lewinsky, after contributing profoundly to an</ORIGINAL_TEXT>
        <TOKEN id="token-121-0" pos="word" morph="none" start_char="5255" end_char="5257">But</TOKEN>
        <TOKEN id="token-121-1" pos="word" morph="none" start_char="5259" end_char="5259">I</TOKEN>
        <TOKEN id="token-121-2" pos="word" morph="none" start_char="5261" end_char="5264">hope</TOKEN>
        <TOKEN id="token-121-3" pos="word" morph="none" start_char="5266" end_char="5268">for</TOKEN>
        <TOKEN id="token-121-4" pos="word" morph="none" start_char="5270" end_char="5272">her</TOKEN>
        <TOKEN id="token-121-5" pos="word" morph="none" start_char="5274" end_char="5277">sake</TOKEN>
        <TOKEN id="token-121-6" pos="word" morph="none" start_char="5279" end_char="5282">that</TOKEN>
        <TOKEN id="token-121-7" pos="word" morph="none" start_char="5284" end_char="5291">Lewinsky</TOKEN>
        <TOKEN id="token-121-8" pos="punct" morph="none" start_char="5292" end_char="5292">,</TOKEN>
        <TOKEN id="token-121-9" pos="word" morph="none" start_char="5294" end_char="5298">after</TOKEN>
        <TOKEN id="token-121-10" pos="word" morph="none" start_char="5300" end_char="5311">contributing</TOKEN>
        <TOKEN id="token-121-11" pos="word" morph="none" start_char="5313" end_char="5322">profoundly</TOKEN>
        <TOKEN id="token-121-12" pos="word" morph="none" start_char="5324" end_char="5325">to</TOKEN>
        <TOKEN id="token-121-13" pos="word" morph="none" start_char="5327" end_char="5328">an</TOKEN>
      </SEG>
      <SEG id="segment-122" start_char="5330" end_char="5407">
        <ORIGINAL_TEXT>urgent conversation about how badly we treat each other online, can stop using</ORIGINAL_TEXT>
        <TOKEN id="token-122-0" pos="word" morph="none" start_char="5330" end_char="5335">urgent</TOKEN>
        <TOKEN id="token-122-1" pos="word" morph="none" start_char="5337" end_char="5348">conversation</TOKEN>
        <TOKEN id="token-122-2" pos="word" morph="none" start_char="5350" end_char="5354">about</TOKEN>
        <TOKEN id="token-122-3" pos="word" morph="none" start_char="5356" end_char="5358">how</TOKEN>
        <TOKEN id="token-122-4" pos="word" morph="none" start_char="5360" end_char="5364">badly</TOKEN>
        <TOKEN id="token-122-5" pos="word" morph="none" start_char="5366" end_char="5367">we</TOKEN>
        <TOKEN id="token-122-6" pos="word" morph="none" start_char="5369" end_char="5373">treat</TOKEN>
        <TOKEN id="token-122-7" pos="word" morph="none" start_char="5375" end_char="5378">each</TOKEN>
        <TOKEN id="token-122-8" pos="word" morph="none" start_char="5380" end_char="5384">other</TOKEN>
        <TOKEN id="token-122-9" pos="word" morph="none" start_char="5386" end_char="5391">online</TOKEN>
        <TOKEN id="token-122-10" pos="punct" morph="none" start_char="5392" end_char="5392">,</TOKEN>
        <TOKEN id="token-122-11" pos="word" morph="none" start_char="5394" end_char="5396">can</TOKEN>
        <TOKEN id="token-122-12" pos="word" morph="none" start_char="5398" end_char="5401">stop</TOKEN>
        <TOKEN id="token-122-13" pos="word" morph="none" start_char="5403" end_char="5407">using</TOKEN>
      </SEG>
      <SEG id="segment-123" start_char="5409" end_char="5483">
        <ORIGINAL_TEXT>her beleaguered past and get on with living a life complete with meaningful</ORIGINAL_TEXT>
        <TOKEN id="token-123-0" pos="word" morph="none" start_char="5409" end_char="5411">her</TOKEN>
        <TOKEN id="token-123-1" pos="word" morph="none" start_char="5413" end_char="5423">beleaguered</TOKEN>
        <TOKEN id="token-123-2" pos="word" morph="none" start_char="5425" end_char="5428">past</TOKEN>
        <TOKEN id="token-123-3" pos="word" morph="none" start_char="5430" end_char="5432">and</TOKEN>
        <TOKEN id="token-123-4" pos="word" morph="none" start_char="5434" end_char="5436">get</TOKEN>
        <TOKEN id="token-123-5" pos="word" morph="none" start_char="5438" end_char="5439">on</TOKEN>
        <TOKEN id="token-123-6" pos="word" morph="none" start_char="5441" end_char="5444">with</TOKEN>
        <TOKEN id="token-123-7" pos="word" morph="none" start_char="5446" end_char="5451">living</TOKEN>
        <TOKEN id="token-123-8" pos="word" morph="none" start_char="5453" end_char="5453">a</TOKEN>
        <TOKEN id="token-123-9" pos="word" morph="none" start_char="5455" end_char="5458">life</TOKEN>
        <TOKEN id="token-123-10" pos="word" morph="none" start_char="5460" end_char="5467">complete</TOKEN>
        <TOKEN id="token-123-11" pos="word" morph="none" start_char="5469" end_char="5472">with</TOKEN>
        <TOKEN id="token-123-12" pos="word" morph="none" start_char="5474" end_char="5483">meaningful</TOKEN>
      </SEG>
      <SEG id="segment-124" start_char="5485" end_char="5507">
        <ORIGINAL_TEXT>work and relationships.</ORIGINAL_TEXT>
        <TOKEN id="token-124-0" pos="word" morph="none" start_char="5485" end_char="5488">work</TOKEN>
        <TOKEN id="token-124-1" pos="word" morph="none" start_char="5490" end_char="5492">and</TOKEN>
        <TOKEN id="token-124-2" pos="word" morph="none" start_char="5494" end_char="5506">relationships</TOKEN>
        <TOKEN id="token-124-3" pos="punct" morph="none" start_char="5507" end_char="5507">.</TOKEN>
      </SEG>
      <SEG id="segment-125" start_char="5509" end_char="5512">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-125-0" pos="unknown" morph="none" start_char="5509" end_char="5512">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-126" start_char="5514" end_char="5516">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-126-0" pos="unknown" morph="none" start_char="5514" end_char="5516">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-127" start_char="5518" end_char="5592">
        <ORIGINAL_TEXT>Lewinsky can’t change or deny the past but the really triumphant ending she</ORIGINAL_TEXT>
        <TOKEN id="token-127-0" pos="word" morph="none" start_char="5518" end_char="5525">Lewinsky</TOKEN>
        <TOKEN id="token-127-1" pos="word" morph="none" start_char="5527" end_char="5529">can</TOKEN>
        <TOKEN id="token-127-2" pos="punct" morph="none" start_char="5530" end_char="5530">’</TOKEN>
        <TOKEN id="token-127-3" pos="word" morph="none" start_char="5531" end_char="5531">t</TOKEN>
        <TOKEN id="token-127-4" pos="word" morph="none" start_char="5533" end_char="5538">change</TOKEN>
        <TOKEN id="token-127-5" pos="word" morph="none" start_char="5540" end_char="5541">or</TOKEN>
        <TOKEN id="token-127-6" pos="word" morph="none" start_char="5543" end_char="5546">deny</TOKEN>
        <TOKEN id="token-127-7" pos="word" morph="none" start_char="5548" end_char="5550">the</TOKEN>
        <TOKEN id="token-127-8" pos="word" morph="none" start_char="5552" end_char="5555">past</TOKEN>
        <TOKEN id="token-127-9" pos="word" morph="none" start_char="5557" end_char="5559">but</TOKEN>
        <TOKEN id="token-127-10" pos="word" morph="none" start_char="5561" end_char="5563">the</TOKEN>
        <TOKEN id="token-127-11" pos="word" morph="none" start_char="5565" end_char="5570">really</TOKEN>
        <TOKEN id="token-127-12" pos="word" morph="none" start_char="5572" end_char="5581">triumphant</TOKEN>
        <TOKEN id="token-127-13" pos="word" morph="none" start_char="5583" end_char="5588">ending</TOKEN>
        <TOKEN id="token-127-14" pos="word" morph="none" start_char="5590" end_char="5592">she</TOKEN>
      </SEG>
      <SEG id="segment-128" start_char="5594" end_char="5656">
        <ORIGINAL_TEXT>should insist on would be in not letting it—in bad or even good</ORIGINAL_TEXT>
        <TOKEN id="token-128-0" pos="word" morph="none" start_char="5594" end_char="5599">should</TOKEN>
        <TOKEN id="token-128-1" pos="word" morph="none" start_char="5601" end_char="5606">insist</TOKEN>
        <TOKEN id="token-128-2" pos="word" morph="none" start_char="5608" end_char="5609">on</TOKEN>
        <TOKEN id="token-128-3" pos="word" morph="none" start_char="5611" end_char="5615">would</TOKEN>
        <TOKEN id="token-128-4" pos="word" morph="none" start_char="5617" end_char="5618">be</TOKEN>
        <TOKEN id="token-128-5" pos="word" morph="none" start_char="5620" end_char="5621">in</TOKEN>
        <TOKEN id="token-128-6" pos="word" morph="none" start_char="5623" end_char="5625">not</TOKEN>
        <TOKEN id="token-128-7" pos="word" morph="none" start_char="5627" end_char="5633">letting</TOKEN>
        <TOKEN id="token-128-8" pos="word" morph="none" start_char="5635" end_char="5636">it</TOKEN>
        <TOKEN id="token-128-9" pos="punct" morph="none" start_char="5637" end_char="5637">—</TOKEN>
        <TOKEN id="token-128-10" pos="word" morph="none" start_char="5638" end_char="5639">in</TOKEN>
        <TOKEN id="token-128-11" pos="word" morph="none" start_char="5641" end_char="5643">bad</TOKEN>
        <TOKEN id="token-128-12" pos="word" morph="none" start_char="5645" end_char="5646">or</TOKEN>
        <TOKEN id="token-128-13" pos="word" morph="none" start_char="5648" end_char="5651">even</TOKEN>
        <TOKEN id="token-128-14" pos="word" morph="none" start_char="5653" end_char="5656">good</TOKEN>
      </SEG>
      <SEG id="segment-129" start_char="5658" end_char="5691">
        <ORIGINAL_TEXT>ways—define her one second longer.</ORIGINAL_TEXT>
        <TOKEN id="token-129-0" pos="word" morph="none" start_char="5658" end_char="5661">ways</TOKEN>
        <TOKEN id="token-129-1" pos="punct" morph="none" start_char="5662" end_char="5662">—</TOKEN>
        <TOKEN id="token-129-2" pos="word" morph="none" start_char="5663" end_char="5668">define</TOKEN>
        <TOKEN id="token-129-3" pos="word" morph="none" start_char="5670" end_char="5672">her</TOKEN>
        <TOKEN id="token-129-4" pos="word" morph="none" start_char="5674" end_char="5676">one</TOKEN>
        <TOKEN id="token-129-5" pos="word" morph="none" start_char="5678" end_char="5683">second</TOKEN>
        <TOKEN id="token-129-6" pos="word" morph="none" start_char="5685" end_char="5690">longer</TOKEN>
        <TOKEN id="token-129-7" pos="punct" morph="none" start_char="5691" end_char="5691">.</TOKEN>
      </SEG>
      <SEG id="segment-130" start_char="5693" end_char="5696">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-130-0" pos="unknown" morph="none" start_char="5693" end_char="5696">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-131" start_char="5698" end_char="5704">
        <ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-131-0" pos="unknown" morph="none" start_char="5698" end_char="5704">&lt;/TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-132" start_char="5706" end_char="5711">
        <ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-132-0" pos="unknown" morph="none" start_char="5706" end_char="5711">&lt;/DOC&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
