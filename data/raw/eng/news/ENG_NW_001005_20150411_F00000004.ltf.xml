<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="ENG_NW_001005_20150411_F00000004.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="5998" raw_text_md5="aaece0b52fef7f48d573ff2a1bc82f49">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001005_20150411_F00000004"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001005_20150411_F00000004"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="203">
        <ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.ap.org/Content/AP-In-The-News/2015/ap-sues-state-department-seeking-access-to-clinton-records&lt;/SOURCE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="203">&lt;SOURCE&gt;http://www.ap.org/Content/AP-In-The-News/2015/ap-sues-state-department-seeking-access-to-clinton-records&lt;/SOURCE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="205" end_char="246">
        <ORIGINAL_TEXT>&lt;DATE_TIME&gt;2015-04-11T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="unknown" morph="none" start_char="205" end_char="246">&lt;DATE_TIME&gt;2015-04-11T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="248" end_char="257">
        <ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="248" end_char="257">&lt;HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="259" end_char="317">
        <ORIGINAL_TEXT>AP sues State Department, seeking access to Clinton records</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="word" morph="none" start_char="259" end_char="260">AP</TOKEN>
        <TOKEN id="token-5-1" pos="word" morph="none" start_char="262" end_char="265">sues</TOKEN>
        <TOKEN id="token-5-2" pos="word" morph="none" start_char="267" end_char="271">State</TOKEN>
        <TOKEN id="token-5-3" pos="word" morph="none" start_char="273" end_char="282">Department</TOKEN>
        <TOKEN id="token-5-4" pos="punct" morph="none" start_char="283" end_char="283">,</TOKEN>
        <TOKEN id="token-5-5" pos="word" morph="none" start_char="285" end_char="291">seeking</TOKEN>
        <TOKEN id="token-5-6" pos="word" morph="none" start_char="293" end_char="298">access</TOKEN>
        <TOKEN id="token-5-7" pos="word" morph="none" start_char="300" end_char="301">to</TOKEN>
        <TOKEN id="token-5-8" pos="word" morph="none" start_char="303" end_char="309">Clinton</TOKEN>
        <TOKEN id="token-5-9" pos="word" morph="none" start_char="311" end_char="317">records</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="319" end_char="329">
        <ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="unknown" morph="none" start_char="319" end_char="329">&lt;/HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="331" end_char="336">
        <ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="331" end_char="336">&lt;TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="338" end_char="340">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="338" end_char="340">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="342" end_char="419">
        <ORIGINAL_TEXT>The Associated Press filed a lawsuit Wednesday against the State Department to</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="342" end_char="344">The</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="346" end_char="355">Associated</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="357" end_char="361">Press</TOKEN>
        <TOKEN id="token-9-3" pos="word" morph="none" start_char="363" end_char="367">filed</TOKEN>
        <TOKEN id="token-9-4" pos="word" morph="none" start_char="369" end_char="369">a</TOKEN>
        <TOKEN id="token-9-5" pos="word" morph="none" start_char="371" end_char="377">lawsuit</TOKEN>
        <TOKEN id="token-9-6" pos="word" morph="none" start_char="379" end_char="387">Wednesday</TOKEN>
        <TOKEN id="token-9-7" pos="word" morph="none" start_char="389" end_char="395">against</TOKEN>
        <TOKEN id="token-9-8" pos="word" morph="none" start_char="397" end_char="399">the</TOKEN>
        <TOKEN id="token-9-9" pos="word" morph="none" start_char="401" end_char="405">State</TOKEN>
        <TOKEN id="token-9-10" pos="word" morph="none" start_char="407" end_char="416">Department</TOKEN>
        <TOKEN id="token-9-11" pos="word" morph="none" start_char="418" end_char="419">to</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="421" end_char="491">
        <ORIGINAL_TEXT>force the release of email correspondence and government documents from</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="word" morph="none" start_char="421" end_char="425">force</TOKEN>
        <TOKEN id="token-10-1" pos="word" morph="none" start_char="427" end_char="429">the</TOKEN>
        <TOKEN id="token-10-2" pos="word" morph="none" start_char="431" end_char="437">release</TOKEN>
        <TOKEN id="token-10-3" pos="word" morph="none" start_char="439" end_char="440">of</TOKEN>
        <TOKEN id="token-10-4" pos="word" morph="none" start_char="442" end_char="446">email</TOKEN>
        <TOKEN id="token-10-5" pos="word" morph="none" start_char="448" end_char="461">correspondence</TOKEN>
        <TOKEN id="token-10-6" pos="word" morph="none" start_char="463" end_char="465">and</TOKEN>
        <TOKEN id="token-10-7" pos="word" morph="none" start_char="467" end_char="476">government</TOKEN>
        <TOKEN id="token-10-8" pos="word" morph="none" start_char="478" end_char="486">documents</TOKEN>
        <TOKEN id="token-10-9" pos="word" morph="none" start_char="488" end_char="491">from</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="493" end_char="546">
        <ORIGINAL_TEXT>Hillary Rodham Clinton's tenure as secretary of state.</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="word" morph="none" start_char="493" end_char="499">Hillary</TOKEN>
        <TOKEN id="token-11-1" pos="word" morph="none" start_char="501" end_char="506">Rodham</TOKEN>
        <TOKEN id="token-11-2" pos="word" morph="none" start_char="508" end_char="514">Clinton</TOKEN>
        <TOKEN id="token-11-3" pos="punct" morph="none" start_char="515" end_char="515">'</TOKEN>
        <TOKEN id="token-11-4" pos="word" morph="none" start_char="516" end_char="516">s</TOKEN>
        <TOKEN id="token-11-5" pos="word" morph="none" start_char="518" end_char="523">tenure</TOKEN>
        <TOKEN id="token-11-6" pos="word" morph="none" start_char="525" end_char="526">as</TOKEN>
        <TOKEN id="token-11-7" pos="word" morph="none" start_char="528" end_char="536">secretary</TOKEN>
        <TOKEN id="token-11-8" pos="word" morph="none" start_char="538" end_char="539">of</TOKEN>
        <TOKEN id="token-11-9" pos="word" morph="none" start_char="541" end_char="545">state</TOKEN>
        <TOKEN id="token-11-10" pos="punct" morph="none" start_char="546" end_char="546">.</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="548" end_char="551">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="unknown" morph="none" start_char="548" end_char="551">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="553" end_char="555">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="unknown" morph="none" start_char="553" end_char="555">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="557" end_char="634">
        <ORIGINAL_TEXT>The legal action comes after repeated requests filed under the U.S. Freedom of</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="word" morph="none" start_char="557" end_char="559">The</TOKEN>
        <TOKEN id="token-14-1" pos="word" morph="none" start_char="561" end_char="565">legal</TOKEN>
        <TOKEN id="token-14-2" pos="word" morph="none" start_char="567" end_char="572">action</TOKEN>
        <TOKEN id="token-14-3" pos="word" morph="none" start_char="574" end_char="578">comes</TOKEN>
        <TOKEN id="token-14-4" pos="word" morph="none" start_char="580" end_char="584">after</TOKEN>
        <TOKEN id="token-14-5" pos="word" morph="none" start_char="586" end_char="593">repeated</TOKEN>
        <TOKEN id="token-14-6" pos="word" morph="none" start_char="595" end_char="602">requests</TOKEN>
        <TOKEN id="token-14-7" pos="word" morph="none" start_char="604" end_char="608">filed</TOKEN>
        <TOKEN id="token-14-8" pos="word" morph="none" start_char="610" end_char="614">under</TOKEN>
        <TOKEN id="token-14-9" pos="word" morph="none" start_char="616" end_char="618">the</TOKEN>
        <TOKEN id="token-14-10" pos="word" morph="none" start_char="620" end_char="620">U</TOKEN>
        <TOKEN id="token-14-11" pos="punct" morph="none" start_char="621" end_char="621">.</TOKEN>
        <TOKEN id="token-14-12" pos="word" morph="none" start_char="622" end_char="622">S</TOKEN>
        <TOKEN id="token-14-13" pos="punct" morph="none" start_char="623" end_char="623">.</TOKEN>
        <TOKEN id="token-14-14" pos="word" morph="none" start_char="625" end_char="631">Freedom</TOKEN>
        <TOKEN id="token-14-15" pos="word" morph="none" start_char="633" end_char="634">of</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="636" end_char="711">
        <ORIGINAL_TEXT>Information Act have gone unfulfilled. They include one request AP made five</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="word" morph="none" start_char="636" end_char="646">Information</TOKEN>
        <TOKEN id="token-15-1" pos="word" morph="none" start_char="648" end_char="650">Act</TOKEN>
        <TOKEN id="token-15-2" pos="word" morph="none" start_char="652" end_char="655">have</TOKEN>
        <TOKEN id="token-15-3" pos="word" morph="none" start_char="657" end_char="660">gone</TOKEN>
        <TOKEN id="token-15-4" pos="word" morph="none" start_char="662" end_char="672">unfulfilled</TOKEN>
        <TOKEN id="token-15-5" pos="punct" morph="none" start_char="673" end_char="673">.</TOKEN>
        <TOKEN id="token-15-6" pos="word" morph="none" start_char="675" end_char="678">They</TOKEN>
        <TOKEN id="token-15-7" pos="word" morph="none" start_char="680" end_char="686">include</TOKEN>
        <TOKEN id="token-15-8" pos="word" morph="none" start_char="688" end_char="690">one</TOKEN>
        <TOKEN id="token-15-9" pos="word" morph="none" start_char="692" end_char="698">request</TOKEN>
        <TOKEN id="token-15-10" pos="word" morph="none" start_char="700" end_char="701">AP</TOKEN>
        <TOKEN id="token-15-11" pos="word" morph="none" start_char="703" end_char="706">made</TOKEN>
        <TOKEN id="token-15-12" pos="word" morph="none" start_char="708" end_char="711">five</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="713" end_char="766">
        <ORIGINAL_TEXT>years ago and others pending since the summer of 2013.</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="word" morph="none" start_char="713" end_char="717">years</TOKEN>
        <TOKEN id="token-16-1" pos="word" morph="none" start_char="719" end_char="721">ago</TOKEN>
        <TOKEN id="token-16-2" pos="word" morph="none" start_char="723" end_char="725">and</TOKEN>
        <TOKEN id="token-16-3" pos="word" morph="none" start_char="727" end_char="732">others</TOKEN>
        <TOKEN id="token-16-4" pos="word" morph="none" start_char="734" end_char="740">pending</TOKEN>
        <TOKEN id="token-16-5" pos="word" morph="none" start_char="742" end_char="746">since</TOKEN>
        <TOKEN id="token-16-6" pos="word" morph="none" start_char="748" end_char="750">the</TOKEN>
        <TOKEN id="token-16-7" pos="word" morph="none" start_char="752" end_char="757">summer</TOKEN>
        <TOKEN id="token-16-8" pos="word" morph="none" start_char="759" end_char="760">of</TOKEN>
        <TOKEN id="token-16-9" pos="word" morph="none" start_char="762" end_char="765">2013</TOKEN>
        <TOKEN id="token-16-10" pos="punct" morph="none" start_char="766" end_char="766">.</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="768" end_char="771">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="unknown" morph="none" start_char="768" end_char="771">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="773" end_char="775">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="unknown" morph="none" start_char="773" end_char="775">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-19" start_char="777" end_char="851">
        <ORIGINAL_TEXT>The lawsuit, filed in the U.S. District Court for the District of Columbia,</ORIGINAL_TEXT>
        <TOKEN id="token-19-0" pos="word" morph="none" start_char="777" end_char="779">The</TOKEN>
        <TOKEN id="token-19-1" pos="word" morph="none" start_char="781" end_char="787">lawsuit</TOKEN>
        <TOKEN id="token-19-2" pos="punct" morph="none" start_char="788" end_char="788">,</TOKEN>
        <TOKEN id="token-19-3" pos="word" morph="none" start_char="790" end_char="794">filed</TOKEN>
        <TOKEN id="token-19-4" pos="word" morph="none" start_char="796" end_char="797">in</TOKEN>
        <TOKEN id="token-19-5" pos="word" morph="none" start_char="799" end_char="801">the</TOKEN>
        <TOKEN id="token-19-6" pos="word" morph="none" start_char="803" end_char="803">U</TOKEN>
        <TOKEN id="token-19-7" pos="punct" morph="none" start_char="804" end_char="804">.</TOKEN>
        <TOKEN id="token-19-8" pos="word" morph="none" start_char="805" end_char="805">S</TOKEN>
        <TOKEN id="token-19-9" pos="punct" morph="none" start_char="806" end_char="806">.</TOKEN>
        <TOKEN id="token-19-10" pos="word" morph="none" start_char="808" end_char="815">District</TOKEN>
        <TOKEN id="token-19-11" pos="word" morph="none" start_char="817" end_char="821">Court</TOKEN>
        <TOKEN id="token-19-12" pos="word" morph="none" start_char="823" end_char="825">for</TOKEN>
        <TOKEN id="token-19-13" pos="word" morph="none" start_char="827" end_char="829">the</TOKEN>
        <TOKEN id="token-19-14" pos="word" morph="none" start_char="831" end_char="838">District</TOKEN>
        <TOKEN id="token-19-15" pos="word" morph="none" start_char="840" end_char="841">of</TOKEN>
        <TOKEN id="token-19-16" pos="word" morph="none" start_char="843" end_char="850">Columbia</TOKEN>
        <TOKEN id="token-19-17" pos="punct" morph="none" start_char="851" end_char="851">,</TOKEN>
      </SEG>
      <SEG id="segment-20" start_char="853" end_char="928">
        <ORIGINAL_TEXT>comes a day after Clinton broke her silence about her use of a private email</ORIGINAL_TEXT>
        <TOKEN id="token-20-0" pos="word" morph="none" start_char="853" end_char="857">comes</TOKEN>
        <TOKEN id="token-20-1" pos="word" morph="none" start_char="859" end_char="859">a</TOKEN>
        <TOKEN id="token-20-2" pos="word" morph="none" start_char="861" end_char="863">day</TOKEN>
        <TOKEN id="token-20-3" pos="word" morph="none" start_char="865" end_char="869">after</TOKEN>
        <TOKEN id="token-20-4" pos="word" morph="none" start_char="871" end_char="877">Clinton</TOKEN>
        <TOKEN id="token-20-5" pos="word" morph="none" start_char="879" end_char="883">broke</TOKEN>
        <TOKEN id="token-20-6" pos="word" morph="none" start_char="885" end_char="887">her</TOKEN>
        <TOKEN id="token-20-7" pos="word" morph="none" start_char="889" end_char="895">silence</TOKEN>
        <TOKEN id="token-20-8" pos="word" morph="none" start_char="897" end_char="901">about</TOKEN>
        <TOKEN id="token-20-9" pos="word" morph="none" start_char="903" end_char="905">her</TOKEN>
        <TOKEN id="token-20-10" pos="word" morph="none" start_char="907" end_char="909">use</TOKEN>
        <TOKEN id="token-20-11" pos="word" morph="none" start_char="911" end_char="912">of</TOKEN>
        <TOKEN id="token-20-12" pos="word" morph="none" start_char="914" end_char="914">a</TOKEN>
        <TOKEN id="token-20-13" pos="word" morph="none" start_char="916" end_char="922">private</TOKEN>
        <TOKEN id="token-20-14" pos="word" morph="none" start_char="924" end_char="928">email</TOKEN>
      </SEG>
      <SEG id="segment-21" start_char="930" end_char="1007">
        <ORIGINAL_TEXT>account while secretary of state. The FOIA requests and lawsuit seek materials</ORIGINAL_TEXT>
        <TOKEN id="token-21-0" pos="word" morph="none" start_char="930" end_char="936">account</TOKEN>
        <TOKEN id="token-21-1" pos="word" morph="none" start_char="938" end_char="942">while</TOKEN>
        <TOKEN id="token-21-2" pos="word" morph="none" start_char="944" end_char="952">secretary</TOKEN>
        <TOKEN id="token-21-3" pos="word" morph="none" start_char="954" end_char="955">of</TOKEN>
        <TOKEN id="token-21-4" pos="word" morph="none" start_char="957" end_char="961">state</TOKEN>
        <TOKEN id="token-21-5" pos="punct" morph="none" start_char="962" end_char="962">.</TOKEN>
        <TOKEN id="token-21-6" pos="word" morph="none" start_char="964" end_char="966">The</TOKEN>
        <TOKEN id="token-21-7" pos="word" morph="none" start_char="968" end_char="971">FOIA</TOKEN>
        <TOKEN id="token-21-8" pos="word" morph="none" start_char="973" end_char="980">requests</TOKEN>
        <TOKEN id="token-21-9" pos="word" morph="none" start_char="982" end_char="984">and</TOKEN>
        <TOKEN id="token-21-10" pos="word" morph="none" start_char="986" end_char="992">lawsuit</TOKEN>
        <TOKEN id="token-21-11" pos="word" morph="none" start_char="994" end_char="997">seek</TOKEN>
        <TOKEN id="token-21-12" pos="word" morph="none" start_char="999" end_char="1007">materials</TOKEN>
      </SEG>
      <SEG id="segment-22" start_char="1009" end_char="1086">
        <ORIGINAL_TEXT>related to her public and private calendars, correspondence involving longtime</ORIGINAL_TEXT>
        <TOKEN id="token-22-0" pos="word" morph="none" start_char="1009" end_char="1015">related</TOKEN>
        <TOKEN id="token-22-1" pos="word" morph="none" start_char="1017" end_char="1018">to</TOKEN>
        <TOKEN id="token-22-2" pos="word" morph="none" start_char="1020" end_char="1022">her</TOKEN>
        <TOKEN id="token-22-3" pos="word" morph="none" start_char="1024" end_char="1029">public</TOKEN>
        <TOKEN id="token-22-4" pos="word" morph="none" start_char="1031" end_char="1033">and</TOKEN>
        <TOKEN id="token-22-5" pos="word" morph="none" start_char="1035" end_char="1041">private</TOKEN>
        <TOKEN id="token-22-6" pos="word" morph="none" start_char="1043" end_char="1051">calendars</TOKEN>
        <TOKEN id="token-22-7" pos="punct" morph="none" start_char="1052" end_char="1052">,</TOKEN>
        <TOKEN id="token-22-8" pos="word" morph="none" start_char="1054" end_char="1067">correspondence</TOKEN>
        <TOKEN id="token-22-9" pos="word" morph="none" start_char="1069" end_char="1077">involving</TOKEN>
        <TOKEN id="token-22-10" pos="word" morph="none" start_char="1079" end_char="1086">longtime</TOKEN>
      </SEG>
      <SEG id="segment-23" start_char="1088" end_char="1161">
        <ORIGINAL_TEXT>aides likely to play key roles in her expected campaign for president, and</ORIGINAL_TEXT>
        <TOKEN id="token-23-0" pos="word" morph="none" start_char="1088" end_char="1092">aides</TOKEN>
        <TOKEN id="token-23-1" pos="word" morph="none" start_char="1094" end_char="1099">likely</TOKEN>
        <TOKEN id="token-23-2" pos="word" morph="none" start_char="1101" end_char="1102">to</TOKEN>
        <TOKEN id="token-23-3" pos="word" morph="none" start_char="1104" end_char="1107">play</TOKEN>
        <TOKEN id="token-23-4" pos="word" morph="none" start_char="1109" end_char="1111">key</TOKEN>
        <TOKEN id="token-23-5" pos="word" morph="none" start_char="1113" end_char="1117">roles</TOKEN>
        <TOKEN id="token-23-6" pos="word" morph="none" start_char="1119" end_char="1120">in</TOKEN>
        <TOKEN id="token-23-7" pos="word" morph="none" start_char="1122" end_char="1124">her</TOKEN>
        <TOKEN id="token-23-8" pos="word" morph="none" start_char="1126" end_char="1133">expected</TOKEN>
        <TOKEN id="token-23-9" pos="word" morph="none" start_char="1135" end_char="1142">campaign</TOKEN>
        <TOKEN id="token-23-10" pos="word" morph="none" start_char="1144" end_char="1146">for</TOKEN>
        <TOKEN id="token-23-11" pos="word" morph="none" start_char="1148" end_char="1156">president</TOKEN>
        <TOKEN id="token-23-12" pos="punct" morph="none" start_char="1157" end_char="1157">,</TOKEN>
        <TOKEN id="token-23-13" pos="word" morph="none" start_char="1159" end_char="1161">and</TOKEN>
      </SEG>
      <SEG id="segment-24" start_char="1163" end_char="1237">
        <ORIGINAL_TEXT>Clinton-related emails about the Osama bin Laden raid and National Security</ORIGINAL_TEXT>
        <TOKEN id="token-24-0" pos="word" morph="none" start_char="1163" end_char="1169">Clinton</TOKEN>
        <TOKEN id="token-24-1" pos="punct" morph="none" start_char="1170" end_char="1170">-</TOKEN>
        <TOKEN id="token-24-2" pos="word" morph="none" start_char="1171" end_char="1177">related</TOKEN>
        <TOKEN id="token-24-3" pos="word" morph="none" start_char="1179" end_char="1184">emails</TOKEN>
        <TOKEN id="token-24-4" pos="word" morph="none" start_char="1186" end_char="1190">about</TOKEN>
        <TOKEN id="token-24-5" pos="word" morph="none" start_char="1192" end_char="1194">the</TOKEN>
        <TOKEN id="token-24-6" pos="word" morph="none" start_char="1196" end_char="1200">Osama</TOKEN>
        <TOKEN id="token-24-7" pos="word" morph="none" start_char="1202" end_char="1204">bin</TOKEN>
        <TOKEN id="token-24-8" pos="word" morph="none" start_char="1206" end_char="1210">Laden</TOKEN>
        <TOKEN id="token-24-9" pos="word" morph="none" start_char="1212" end_char="1215">raid</TOKEN>
        <TOKEN id="token-24-10" pos="word" morph="none" start_char="1217" end_char="1219">and</TOKEN>
        <TOKEN id="token-24-11" pos="word" morph="none" start_char="1221" end_char="1228">National</TOKEN>
        <TOKEN id="token-24-12" pos="word" morph="none" start_char="1230" end_char="1237">Security</TOKEN>
      </SEG>
      <SEG id="segment-25" start_char="1239" end_char="1268">
        <ORIGINAL_TEXT>Agency surveillance practices.</ORIGINAL_TEXT>
        <TOKEN id="token-25-0" pos="word" morph="none" start_char="1239" end_char="1244">Agency</TOKEN>
        <TOKEN id="token-25-1" pos="word" morph="none" start_char="1246" end_char="1257">surveillance</TOKEN>
        <TOKEN id="token-25-2" pos="word" morph="none" start_char="1259" end_char="1267">practices</TOKEN>
        <TOKEN id="token-25-3" pos="punct" morph="none" start_char="1268" end_char="1268">.</TOKEN>
      </SEG>
      <SEG id="segment-26" start_char="1270" end_char="1273">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-26-0" pos="unknown" morph="none" start_char="1270" end_char="1273">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-27" start_char="1275" end_char="1277">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-27-0" pos="unknown" morph="none" start_char="1275" end_char="1277">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-28" start_char="1279" end_char="1354">
        <ORIGINAL_TEXT>"After careful deliberation and exhausting our other options, The Associated</ORIGINAL_TEXT>
        <TOKEN id="token-28-0" pos="punct" morph="none" start_char="1279" end_char="1279">"</TOKEN>
        <TOKEN id="token-28-1" pos="word" morph="none" start_char="1280" end_char="1284">After</TOKEN>
        <TOKEN id="token-28-2" pos="word" morph="none" start_char="1286" end_char="1292">careful</TOKEN>
        <TOKEN id="token-28-3" pos="word" morph="none" start_char="1294" end_char="1305">deliberation</TOKEN>
        <TOKEN id="token-28-4" pos="word" morph="none" start_char="1307" end_char="1309">and</TOKEN>
        <TOKEN id="token-28-5" pos="word" morph="none" start_char="1311" end_char="1320">exhausting</TOKEN>
        <TOKEN id="token-28-6" pos="word" morph="none" start_char="1322" end_char="1324">our</TOKEN>
        <TOKEN id="token-28-7" pos="word" morph="none" start_char="1326" end_char="1330">other</TOKEN>
        <TOKEN id="token-28-8" pos="word" morph="none" start_char="1332" end_char="1338">options</TOKEN>
        <TOKEN id="token-28-9" pos="punct" morph="none" start_char="1339" end_char="1339">,</TOKEN>
        <TOKEN id="token-28-10" pos="word" morph="none" start_char="1341" end_char="1343">The</TOKEN>
        <TOKEN id="token-28-11" pos="word" morph="none" start_char="1345" end_char="1354">Associated</TOKEN>
      </SEG>
      <SEG id="segment-29" start_char="1356" end_char="1430">
        <ORIGINAL_TEXT>Press is taking the necessary legal steps to gain access to these important</ORIGINAL_TEXT>
        <TOKEN id="token-29-0" pos="word" morph="none" start_char="1356" end_char="1360">Press</TOKEN>
        <TOKEN id="token-29-1" pos="word" morph="none" start_char="1362" end_char="1363">is</TOKEN>
        <TOKEN id="token-29-2" pos="word" morph="none" start_char="1365" end_char="1370">taking</TOKEN>
        <TOKEN id="token-29-3" pos="word" morph="none" start_char="1372" end_char="1374">the</TOKEN>
        <TOKEN id="token-29-4" pos="word" morph="none" start_char="1376" end_char="1384">necessary</TOKEN>
        <TOKEN id="token-29-5" pos="word" morph="none" start_char="1386" end_char="1390">legal</TOKEN>
        <TOKEN id="token-29-6" pos="word" morph="none" start_char="1392" end_char="1396">steps</TOKEN>
        <TOKEN id="token-29-7" pos="word" morph="none" start_char="1398" end_char="1399">to</TOKEN>
        <TOKEN id="token-29-8" pos="word" morph="none" start_char="1401" end_char="1404">gain</TOKEN>
        <TOKEN id="token-29-9" pos="word" morph="none" start_char="1406" end_char="1411">access</TOKEN>
        <TOKEN id="token-29-10" pos="word" morph="none" start_char="1413" end_char="1414">to</TOKEN>
        <TOKEN id="token-29-11" pos="word" morph="none" start_char="1416" end_char="1420">these</TOKEN>
        <TOKEN id="token-29-12" pos="word" morph="none" start_char="1422" end_char="1430">important</TOKEN>
      </SEG>
      <SEG id="segment-30" start_char="1432" end_char="1509">
        <ORIGINAL_TEXT>documents, which will shed light on actions by the State Department and former</ORIGINAL_TEXT>
        <TOKEN id="token-30-0" pos="word" morph="none" start_char="1432" end_char="1440">documents</TOKEN>
        <TOKEN id="token-30-1" pos="punct" morph="none" start_char="1441" end_char="1441">,</TOKEN>
        <TOKEN id="token-30-2" pos="word" morph="none" start_char="1443" end_char="1447">which</TOKEN>
        <TOKEN id="token-30-3" pos="word" morph="none" start_char="1449" end_char="1452">will</TOKEN>
        <TOKEN id="token-30-4" pos="word" morph="none" start_char="1454" end_char="1457">shed</TOKEN>
        <TOKEN id="token-30-5" pos="word" morph="none" start_char="1459" end_char="1463">light</TOKEN>
        <TOKEN id="token-30-6" pos="word" morph="none" start_char="1465" end_char="1466">on</TOKEN>
        <TOKEN id="token-30-7" pos="word" morph="none" start_char="1468" end_char="1474">actions</TOKEN>
        <TOKEN id="token-30-8" pos="word" morph="none" start_char="1476" end_char="1477">by</TOKEN>
        <TOKEN id="token-30-9" pos="word" morph="none" start_char="1479" end_char="1481">the</TOKEN>
        <TOKEN id="token-30-10" pos="word" morph="none" start_char="1483" end_char="1487">State</TOKEN>
        <TOKEN id="token-30-11" pos="word" morph="none" start_char="1489" end_char="1498">Department</TOKEN>
        <TOKEN id="token-30-12" pos="word" morph="none" start_char="1500" end_char="1502">and</TOKEN>
        <TOKEN id="token-30-13" pos="word" morph="none" start_char="1504" end_char="1509">former</TOKEN>
      </SEG>
      <SEG id="segment-31" start_char="1511" end_char="1586">
        <ORIGINAL_TEXT>Secretary Clinton, a presumptive 2016 presidential candidate, during some of</ORIGINAL_TEXT>
        <TOKEN id="token-31-0" pos="word" morph="none" start_char="1511" end_char="1519">Secretary</TOKEN>
        <TOKEN id="token-31-1" pos="word" morph="none" start_char="1521" end_char="1527">Clinton</TOKEN>
        <TOKEN id="token-31-2" pos="punct" morph="none" start_char="1528" end_char="1528">,</TOKEN>
        <TOKEN id="token-31-3" pos="word" morph="none" start_char="1530" end_char="1530">a</TOKEN>
        <TOKEN id="token-31-4" pos="word" morph="none" start_char="1532" end_char="1542">presumptive</TOKEN>
        <TOKEN id="token-31-5" pos="number" morph="none" start_char="1544" end_char="1547">2016</TOKEN>
        <TOKEN id="token-31-6" pos="word" morph="none" start_char="1549" end_char="1560">presidential</TOKEN>
        <TOKEN id="token-31-7" pos="word" morph="none" start_char="1562" end_char="1570">candidate</TOKEN>
        <TOKEN id="token-31-8" pos="punct" morph="none" start_char="1571" end_char="1571">,</TOKEN>
        <TOKEN id="token-31-9" pos="word" morph="none" start_char="1573" end_char="1578">during</TOKEN>
        <TOKEN id="token-31-10" pos="word" morph="none" start_char="1580" end_char="1583">some</TOKEN>
        <TOKEN id="token-31-11" pos="word" morph="none" start_char="1585" end_char="1586">of</TOKEN>
      </SEG>
      <SEG id="segment-32" start_char="1588" end_char="1660">
        <ORIGINAL_TEXT>the most significant issues of our time," said Karen Kaiser, AP's general</ORIGINAL_TEXT>
        <TOKEN id="token-32-0" pos="word" morph="none" start_char="1588" end_char="1590">the</TOKEN>
        <TOKEN id="token-32-1" pos="word" morph="none" start_char="1592" end_char="1595">most</TOKEN>
        <TOKEN id="token-32-2" pos="word" morph="none" start_char="1597" end_char="1607">significant</TOKEN>
        <TOKEN id="token-32-3" pos="word" morph="none" start_char="1609" end_char="1614">issues</TOKEN>
        <TOKEN id="token-32-4" pos="word" morph="none" start_char="1616" end_char="1617">of</TOKEN>
        <TOKEN id="token-32-5" pos="word" morph="none" start_char="1619" end_char="1621">our</TOKEN>
        <TOKEN id="token-32-6" pos="word" morph="none" start_char="1623" end_char="1626">time</TOKEN>
        <TOKEN id="token-32-7" pos="punct" morph="none" start_char="1627" end_char="1628">,"</TOKEN>
        <TOKEN id="token-32-8" pos="word" morph="none" start_char="1630" end_char="1633">said</TOKEN>
        <TOKEN id="token-32-9" pos="word" morph="none" start_char="1635" end_char="1639">Karen</TOKEN>
        <TOKEN id="token-32-10" pos="word" morph="none" start_char="1641" end_char="1646">Kaiser</TOKEN>
        <TOKEN id="token-32-11" pos="punct" morph="none" start_char="1647" end_char="1647">,</TOKEN>
        <TOKEN id="token-32-12" pos="word" morph="none" start_char="1649" end_char="1650">AP</TOKEN>
        <TOKEN id="token-32-13" pos="punct" morph="none" start_char="1651" end_char="1651">'</TOKEN>
        <TOKEN id="token-32-14" pos="word" morph="none" start_char="1652" end_char="1652">s</TOKEN>
        <TOKEN id="token-32-15" pos="word" morph="none" start_char="1654" end_char="1660">general</TOKEN>
      </SEG>
      <SEG id="segment-33" start_char="1662" end_char="1669">
        <ORIGINAL_TEXT>counsel.</ORIGINAL_TEXT>
        <TOKEN id="token-33-0" pos="word" morph="none" start_char="1662" end_char="1668">counsel</TOKEN>
        <TOKEN id="token-33-1" pos="punct" morph="none" start_char="1669" end_char="1669">.</TOKEN>
      </SEG>
      <SEG id="segment-34" start_char="1671" end_char="1674">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-34-0" pos="unknown" morph="none" start_char="1671" end_char="1674">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-35" start_char="1676" end_char="1678">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-35-0" pos="unknown" morph="none" start_char="1676" end_char="1678">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-36" start_char="1680" end_char="1753">
        <ORIGINAL_TEXT>Said AP Executive Editor Kathleen Carroll, "The Freedom of Information Act</ORIGINAL_TEXT>
        <TOKEN id="token-36-0" pos="word" morph="none" start_char="1680" end_char="1683">Said</TOKEN>
        <TOKEN id="token-36-1" pos="word" morph="none" start_char="1685" end_char="1686">AP</TOKEN>
        <TOKEN id="token-36-2" pos="word" morph="none" start_char="1688" end_char="1696">Executive</TOKEN>
        <TOKEN id="token-36-3" pos="word" morph="none" start_char="1698" end_char="1703">Editor</TOKEN>
        <TOKEN id="token-36-4" pos="word" morph="none" start_char="1705" end_char="1712">Kathleen</TOKEN>
        <TOKEN id="token-36-5" pos="word" morph="none" start_char="1714" end_char="1720">Carroll</TOKEN>
        <TOKEN id="token-36-6" pos="punct" morph="none" start_char="1721" end_char="1721">,</TOKEN>
        <TOKEN id="token-36-7" pos="punct" morph="none" start_char="1723" end_char="1723">"</TOKEN>
        <TOKEN id="token-36-8" pos="word" morph="none" start_char="1724" end_char="1726">The</TOKEN>
        <TOKEN id="token-36-9" pos="word" morph="none" start_char="1728" end_char="1734">Freedom</TOKEN>
        <TOKEN id="token-36-10" pos="word" morph="none" start_char="1736" end_char="1737">of</TOKEN>
        <TOKEN id="token-36-11" pos="word" morph="none" start_char="1739" end_char="1749">Information</TOKEN>
        <TOKEN id="token-36-12" pos="word" morph="none" start_char="1751" end_char="1753">Act</TOKEN>
      </SEG>
      <SEG id="segment-37" start_char="1755" end_char="1832">
        <ORIGINAL_TEXT>exists to give citizens a clear view of what government officials are doing on</ORIGINAL_TEXT>
        <TOKEN id="token-37-0" pos="word" morph="none" start_char="1755" end_char="1760">exists</TOKEN>
        <TOKEN id="token-37-1" pos="word" morph="none" start_char="1762" end_char="1763">to</TOKEN>
        <TOKEN id="token-37-2" pos="word" morph="none" start_char="1765" end_char="1768">give</TOKEN>
        <TOKEN id="token-37-3" pos="word" morph="none" start_char="1770" end_char="1777">citizens</TOKEN>
        <TOKEN id="token-37-4" pos="word" morph="none" start_char="1779" end_char="1779">a</TOKEN>
        <TOKEN id="token-37-5" pos="word" morph="none" start_char="1781" end_char="1785">clear</TOKEN>
        <TOKEN id="token-37-6" pos="word" morph="none" start_char="1787" end_char="1790">view</TOKEN>
        <TOKEN id="token-37-7" pos="word" morph="none" start_char="1792" end_char="1793">of</TOKEN>
        <TOKEN id="token-37-8" pos="word" morph="none" start_char="1795" end_char="1798">what</TOKEN>
        <TOKEN id="token-37-9" pos="word" morph="none" start_char="1800" end_char="1809">government</TOKEN>
        <TOKEN id="token-37-10" pos="word" morph="none" start_char="1811" end_char="1819">officials</TOKEN>
        <TOKEN id="token-37-11" pos="word" morph="none" start_char="1821" end_char="1823">are</TOKEN>
        <TOKEN id="token-37-12" pos="word" morph="none" start_char="1825" end_char="1829">doing</TOKEN>
        <TOKEN id="token-37-13" pos="word" morph="none" start_char="1831" end_char="1832">on</TOKEN>
      </SEG>
      <SEG id="segment-38" start_char="1834" end_char="1904">
        <ORIGINAL_TEXT>their behalf. When that view is denied, the next resort is the courts."</ORIGINAL_TEXT>
        <TOKEN id="token-38-0" pos="word" morph="none" start_char="1834" end_char="1838">their</TOKEN>
        <TOKEN id="token-38-1" pos="word" morph="none" start_char="1840" end_char="1845">behalf</TOKEN>
        <TOKEN id="token-38-2" pos="punct" morph="none" start_char="1846" end_char="1846">.</TOKEN>
        <TOKEN id="token-38-3" pos="word" morph="none" start_char="1848" end_char="1851">When</TOKEN>
        <TOKEN id="token-38-4" pos="word" morph="none" start_char="1853" end_char="1856">that</TOKEN>
        <TOKEN id="token-38-5" pos="word" morph="none" start_char="1858" end_char="1861">view</TOKEN>
        <TOKEN id="token-38-6" pos="word" morph="none" start_char="1863" end_char="1864">is</TOKEN>
        <TOKEN id="token-38-7" pos="word" morph="none" start_char="1866" end_char="1871">denied</TOKEN>
        <TOKEN id="token-38-8" pos="punct" morph="none" start_char="1872" end_char="1872">,</TOKEN>
        <TOKEN id="token-38-9" pos="word" morph="none" start_char="1874" end_char="1876">the</TOKEN>
        <TOKEN id="token-38-10" pos="word" morph="none" start_char="1878" end_char="1881">next</TOKEN>
        <TOKEN id="token-38-11" pos="word" morph="none" start_char="1883" end_char="1888">resort</TOKEN>
        <TOKEN id="token-38-12" pos="word" morph="none" start_char="1890" end_char="1891">is</TOKEN>
        <TOKEN id="token-38-13" pos="word" morph="none" start_char="1893" end_char="1895">the</TOKEN>
        <TOKEN id="token-38-14" pos="word" morph="none" start_char="1897" end_char="1902">courts</TOKEN>
        <TOKEN id="token-38-15" pos="punct" morph="none" start_char="1903" end_char="1904">."</TOKEN>
      </SEG>
      <SEG id="segment-39" start_char="1906" end_char="1909">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-39-0" pos="unknown" morph="none" start_char="1906" end_char="1909">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-40" start_char="1911" end_char="1913">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-40-0" pos="unknown" morph="none" start_char="1911" end_char="1913">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-41" start_char="1915" end_char="1992">
        <ORIGINAL_TEXT>State Department spokesman Alec Gerlach declined to comment. He had previously</ORIGINAL_TEXT>
        <TOKEN id="token-41-0" pos="word" morph="none" start_char="1915" end_char="1919">State</TOKEN>
        <TOKEN id="token-41-1" pos="word" morph="none" start_char="1921" end_char="1930">Department</TOKEN>
        <TOKEN id="token-41-2" pos="word" morph="none" start_char="1932" end_char="1940">spokesman</TOKEN>
        <TOKEN id="token-41-3" pos="word" morph="none" start_char="1942" end_char="1945">Alec</TOKEN>
        <TOKEN id="token-41-4" pos="word" morph="none" start_char="1947" end_char="1953">Gerlach</TOKEN>
        <TOKEN id="token-41-5" pos="word" morph="none" start_char="1955" end_char="1962">declined</TOKEN>
        <TOKEN id="token-41-6" pos="word" morph="none" start_char="1964" end_char="1965">to</TOKEN>
        <TOKEN id="token-41-7" pos="word" morph="none" start_char="1967" end_char="1973">comment</TOKEN>
        <TOKEN id="token-41-8" pos="punct" morph="none" start_char="1974" end_char="1974">.</TOKEN>
        <TOKEN id="token-41-9" pos="word" morph="none" start_char="1976" end_char="1977">He</TOKEN>
        <TOKEN id="token-41-10" pos="word" morph="none" start_char="1979" end_char="1981">had</TOKEN>
        <TOKEN id="token-41-11" pos="word" morph="none" start_char="1983" end_char="1992">previously</TOKEN>
      </SEG>
      <SEG id="segment-42" start_char="1994" end_char="2069">
        <ORIGINAL_TEXT>cited the department's heavy annual load of FOIA requests — 19,000 last year</ORIGINAL_TEXT>
        <TOKEN id="token-42-0" pos="word" morph="none" start_char="1994" end_char="1998">cited</TOKEN>
        <TOKEN id="token-42-1" pos="word" morph="none" start_char="2000" end_char="2002">the</TOKEN>
        <TOKEN id="token-42-2" pos="word" morph="none" start_char="2004" end_char="2013">department</TOKEN>
        <TOKEN id="token-42-3" pos="punct" morph="none" start_char="2014" end_char="2014">'</TOKEN>
        <TOKEN id="token-42-4" pos="word" morph="none" start_char="2015" end_char="2015">s</TOKEN>
        <TOKEN id="token-42-5" pos="word" morph="none" start_char="2017" end_char="2021">heavy</TOKEN>
        <TOKEN id="token-42-6" pos="word" morph="none" start_char="2023" end_char="2028">annual</TOKEN>
        <TOKEN id="token-42-7" pos="word" morph="none" start_char="2030" end_char="2033">load</TOKEN>
        <TOKEN id="token-42-8" pos="word" morph="none" start_char="2035" end_char="2036">of</TOKEN>
        <TOKEN id="token-42-9" pos="word" morph="none" start_char="2038" end_char="2041">FOIA</TOKEN>
        <TOKEN id="token-42-10" pos="word" morph="none" start_char="2043" end_char="2050">requests</TOKEN>
        <TOKEN id="token-42-11" pos="unknown" morph="none" start_char="2052" end_char="2052">—</TOKEN>
        <TOKEN id="token-42-12" pos="word" morph="none" start_char="2054" end_char="2055">19</TOKEN>
        <TOKEN id="token-42-13" pos="punct" morph="none" start_char="2056" end_char="2056">,</TOKEN>
        <TOKEN id="token-42-14" pos="word" morph="none" start_char="2057" end_char="2059">000</TOKEN>
        <TOKEN id="token-42-15" pos="word" morph="none" start_char="2061" end_char="2064">last</TOKEN>
        <TOKEN id="token-42-16" pos="word" morph="none" start_char="2066" end_char="2069">year</TOKEN>
      </SEG>
      <SEG id="segment-43" start_char="2071" end_char="2133">
        <ORIGINAL_TEXT>— in saying that the department "does its best to meet its FOIA</ORIGINAL_TEXT>
        <TOKEN id="token-43-0" pos="unknown" morph="none" start_char="2071" end_char="2071">—</TOKEN>
        <TOKEN id="token-43-1" pos="word" morph="none" start_char="2073" end_char="2074">in</TOKEN>
        <TOKEN id="token-43-2" pos="word" morph="none" start_char="2076" end_char="2081">saying</TOKEN>
        <TOKEN id="token-43-3" pos="word" morph="none" start_char="2083" end_char="2086">that</TOKEN>
        <TOKEN id="token-43-4" pos="word" morph="none" start_char="2088" end_char="2090">the</TOKEN>
        <TOKEN id="token-43-5" pos="word" morph="none" start_char="2092" end_char="2101">department</TOKEN>
        <TOKEN id="token-43-6" pos="punct" morph="none" start_char="2103" end_char="2103">"</TOKEN>
        <TOKEN id="token-43-7" pos="word" morph="none" start_char="2104" end_char="2107">does</TOKEN>
        <TOKEN id="token-43-8" pos="word" morph="none" start_char="2109" end_char="2111">its</TOKEN>
        <TOKEN id="token-43-9" pos="word" morph="none" start_char="2113" end_char="2116">best</TOKEN>
        <TOKEN id="token-43-10" pos="word" morph="none" start_char="2118" end_char="2119">to</TOKEN>
        <TOKEN id="token-43-11" pos="word" morph="none" start_char="2121" end_char="2124">meet</TOKEN>
        <TOKEN id="token-43-12" pos="word" morph="none" start_char="2126" end_char="2128">its</TOKEN>
        <TOKEN id="token-43-13" pos="word" morph="none" start_char="2130" end_char="2133">FOIA</TOKEN>
      </SEG>
      <SEG id="segment-44" start_char="2135" end_char="2207">
        <ORIGINAL_TEXT>responsibilities." He said the department takes requests "first in, first</ORIGINAL_TEXT>
        <TOKEN id="token-44-0" pos="word" morph="none" start_char="2135" end_char="2150">responsibilities</TOKEN>
        <TOKEN id="token-44-1" pos="punct" morph="none" start_char="2151" end_char="2152">."</TOKEN>
        <TOKEN id="token-44-2" pos="word" morph="none" start_char="2154" end_char="2155">He</TOKEN>
        <TOKEN id="token-44-3" pos="word" morph="none" start_char="2157" end_char="2160">said</TOKEN>
        <TOKEN id="token-44-4" pos="word" morph="none" start_char="2162" end_char="2164">the</TOKEN>
        <TOKEN id="token-44-5" pos="word" morph="none" start_char="2166" end_char="2175">department</TOKEN>
        <TOKEN id="token-44-6" pos="word" morph="none" start_char="2177" end_char="2181">takes</TOKEN>
        <TOKEN id="token-44-7" pos="word" morph="none" start_char="2183" end_char="2190">requests</TOKEN>
        <TOKEN id="token-44-8" pos="punct" morph="none" start_char="2192" end_char="2192">"</TOKEN>
        <TOKEN id="token-44-9" pos="word" morph="none" start_char="2193" end_char="2197">first</TOKEN>
        <TOKEN id="token-44-10" pos="word" morph="none" start_char="2199" end_char="2200">in</TOKEN>
        <TOKEN id="token-44-11" pos="punct" morph="none" start_char="2201" end_char="2201">,</TOKEN>
        <TOKEN id="token-44-12" pos="word" morph="none" start_char="2203" end_char="2207">first</TOKEN>
      </SEG>
      <SEG id="segment-45" start_char="2209" end_char="2279">
        <ORIGINAL_TEXT>out," but noted that timing depends on "the complexity of the request."</ORIGINAL_TEXT>
        <TOKEN id="token-45-0" pos="word" morph="none" start_char="2209" end_char="2211">out</TOKEN>
        <TOKEN id="token-45-1" pos="punct" morph="none" start_char="2212" end_char="2213">,"</TOKEN>
        <TOKEN id="token-45-2" pos="word" morph="none" start_char="2215" end_char="2217">but</TOKEN>
        <TOKEN id="token-45-3" pos="word" morph="none" start_char="2219" end_char="2223">noted</TOKEN>
        <TOKEN id="token-45-4" pos="word" morph="none" start_char="2225" end_char="2228">that</TOKEN>
        <TOKEN id="token-45-5" pos="word" morph="none" start_char="2230" end_char="2235">timing</TOKEN>
        <TOKEN id="token-45-6" pos="word" morph="none" start_char="2237" end_char="2243">depends</TOKEN>
        <TOKEN id="token-45-7" pos="word" morph="none" start_char="2245" end_char="2246">on</TOKEN>
        <TOKEN id="token-45-8" pos="punct" morph="none" start_char="2248" end_char="2248">"</TOKEN>
        <TOKEN id="token-45-9" pos="word" morph="none" start_char="2249" end_char="2251">the</TOKEN>
        <TOKEN id="token-45-10" pos="word" morph="none" start_char="2253" end_char="2262">complexity</TOKEN>
        <TOKEN id="token-45-11" pos="word" morph="none" start_char="2264" end_char="2265">of</TOKEN>
        <TOKEN id="token-45-12" pos="word" morph="none" start_char="2267" end_char="2269">the</TOKEN>
        <TOKEN id="token-45-13" pos="word" morph="none" start_char="2271" end_char="2277">request</TOKEN>
        <TOKEN id="token-45-14" pos="punct" morph="none" start_char="2278" end_char="2279">."</TOKEN>
      </SEG>
      <SEG id="segment-46" start_char="2281" end_char="2284">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-46-0" pos="unknown" morph="none" start_char="2281" end_char="2284">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-47" start_char="2286" end_char="2288">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-47-0" pos="unknown" morph="none" start_char="2286" end_char="2288">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-48" start_char="2290" end_char="2365">
        <ORIGINAL_TEXT>Carroll said the AP intends to file additional requests using FOIA and other</ORIGINAL_TEXT>
        <TOKEN id="token-48-0" pos="word" morph="none" start_char="2290" end_char="2296">Carroll</TOKEN>
        <TOKEN id="token-48-1" pos="word" morph="none" start_char="2298" end_char="2301">said</TOKEN>
        <TOKEN id="token-48-2" pos="word" morph="none" start_char="2303" end_char="2305">the</TOKEN>
        <TOKEN id="token-48-3" pos="word" morph="none" start_char="2307" end_char="2308">AP</TOKEN>
        <TOKEN id="token-48-4" pos="word" morph="none" start_char="2310" end_char="2316">intends</TOKEN>
        <TOKEN id="token-48-5" pos="word" morph="none" start_char="2318" end_char="2319">to</TOKEN>
        <TOKEN id="token-48-6" pos="word" morph="none" start_char="2321" end_char="2324">file</TOKEN>
        <TOKEN id="token-48-7" pos="word" morph="none" start_char="2326" end_char="2335">additional</TOKEN>
        <TOKEN id="token-48-8" pos="word" morph="none" start_char="2337" end_char="2344">requests</TOKEN>
        <TOKEN id="token-48-9" pos="word" morph="none" start_char="2346" end_char="2350">using</TOKEN>
        <TOKEN id="token-48-10" pos="word" morph="none" start_char="2352" end_char="2355">FOIA</TOKEN>
        <TOKEN id="token-48-11" pos="word" morph="none" start_char="2357" end_char="2359">and</TOKEN>
        <TOKEN id="token-48-12" pos="word" morph="none" start_char="2361" end_char="2365">other</TOKEN>
      </SEG>
      <SEG id="segment-49" start_char="2367" end_char="2440">
        <ORIGINAL_TEXT>tools following the disclosure last week that Clinton used a private email</ORIGINAL_TEXT>
        <TOKEN id="token-49-0" pos="word" morph="none" start_char="2367" end_char="2371">tools</TOKEN>
        <TOKEN id="token-49-1" pos="word" morph="none" start_char="2373" end_char="2381">following</TOKEN>
        <TOKEN id="token-49-2" pos="word" morph="none" start_char="2383" end_char="2385">the</TOKEN>
        <TOKEN id="token-49-3" pos="word" morph="none" start_char="2387" end_char="2396">disclosure</TOKEN>
        <TOKEN id="token-49-4" pos="word" morph="none" start_char="2398" end_char="2401">last</TOKEN>
        <TOKEN id="token-49-5" pos="word" morph="none" start_char="2403" end_char="2406">week</TOKEN>
        <TOKEN id="token-49-6" pos="word" morph="none" start_char="2408" end_char="2411">that</TOKEN>
        <TOKEN id="token-49-7" pos="word" morph="none" start_char="2413" end_char="2419">Clinton</TOKEN>
        <TOKEN id="token-49-8" pos="word" morph="none" start_char="2421" end_char="2424">used</TOKEN>
        <TOKEN id="token-49-9" pos="word" morph="none" start_char="2426" end_char="2426">a</TOKEN>
        <TOKEN id="token-49-10" pos="word" morph="none" start_char="2428" end_char="2434">private</TOKEN>
        <TOKEN id="token-49-11" pos="word" morph="none" start_char="2436" end_char="2440">email</TOKEN>
      </SEG>
      <SEG id="segment-50" start_char="2442" end_char="2518">
        <ORIGINAL_TEXT>account run on a server on her property outside New York while working at the</ORIGINAL_TEXT>
        <TOKEN id="token-50-0" pos="word" morph="none" start_char="2442" end_char="2448">account</TOKEN>
        <TOKEN id="token-50-1" pos="word" morph="none" start_char="2450" end_char="2452">run</TOKEN>
        <TOKEN id="token-50-2" pos="word" morph="none" start_char="2454" end_char="2455">on</TOKEN>
        <TOKEN id="token-50-3" pos="word" morph="none" start_char="2457" end_char="2457">a</TOKEN>
        <TOKEN id="token-50-4" pos="word" morph="none" start_char="2459" end_char="2464">server</TOKEN>
        <TOKEN id="token-50-5" pos="word" morph="none" start_char="2466" end_char="2467">on</TOKEN>
        <TOKEN id="token-50-6" pos="word" morph="none" start_char="2469" end_char="2471">her</TOKEN>
        <TOKEN id="token-50-7" pos="word" morph="none" start_char="2473" end_char="2480">property</TOKEN>
        <TOKEN id="token-50-8" pos="word" morph="none" start_char="2482" end_char="2488">outside</TOKEN>
        <TOKEN id="token-50-9" pos="word" morph="none" start_char="2490" end_char="2492">New</TOKEN>
        <TOKEN id="token-50-10" pos="word" morph="none" start_char="2494" end_char="2497">York</TOKEN>
        <TOKEN id="token-50-11" pos="word" morph="none" start_char="2499" end_char="2503">while</TOKEN>
        <TOKEN id="token-50-12" pos="word" morph="none" start_char="2505" end_char="2511">working</TOKEN>
        <TOKEN id="token-50-13" pos="word" morph="none" start_char="2513" end_char="2514">at</TOKEN>
        <TOKEN id="token-50-14" pos="word" morph="none" start_char="2516" end_char="2518">the</TOKEN>
      </SEG>
      <SEG id="segment-51" start_char="2520" end_char="2536">
        <ORIGINAL_TEXT>State Department.</ORIGINAL_TEXT>
        <TOKEN id="token-51-0" pos="word" morph="none" start_char="2520" end_char="2524">State</TOKEN>
        <TOKEN id="token-51-1" pos="word" morph="none" start_char="2526" end_char="2535">Department</TOKEN>
        <TOKEN id="token-51-2" pos="punct" morph="none" start_char="2536" end_char="2536">.</TOKEN>
      </SEG>
      <SEG id="segment-52" start_char="2538" end_char="2541">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-52-0" pos="unknown" morph="none" start_char="2538" end_char="2541">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-53" start_char="2543" end_char="2545">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-53-0" pos="unknown" morph="none" start_char="2543" end_char="2545">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-54" start_char="2547" end_char="2620">
        <ORIGINAL_TEXT>Clinton on Tuesday said she sent and received about 60,000 emails from her</ORIGINAL_TEXT>
        <TOKEN id="token-54-0" pos="word" morph="none" start_char="2547" end_char="2553">Clinton</TOKEN>
        <TOKEN id="token-54-1" pos="word" morph="none" start_char="2555" end_char="2556">on</TOKEN>
        <TOKEN id="token-54-2" pos="word" morph="none" start_char="2558" end_char="2564">Tuesday</TOKEN>
        <TOKEN id="token-54-3" pos="word" morph="none" start_char="2566" end_char="2569">said</TOKEN>
        <TOKEN id="token-54-4" pos="word" morph="none" start_char="2571" end_char="2573">she</TOKEN>
        <TOKEN id="token-54-5" pos="word" morph="none" start_char="2575" end_char="2578">sent</TOKEN>
        <TOKEN id="token-54-6" pos="word" morph="none" start_char="2580" end_char="2582">and</TOKEN>
        <TOKEN id="token-54-7" pos="word" morph="none" start_char="2584" end_char="2591">received</TOKEN>
        <TOKEN id="token-54-8" pos="word" morph="none" start_char="2593" end_char="2597">about</TOKEN>
        <TOKEN id="token-54-9" pos="word" morph="none" start_char="2599" end_char="2600">60</TOKEN>
        <TOKEN id="token-54-10" pos="punct" morph="none" start_char="2601" end_char="2601">,</TOKEN>
        <TOKEN id="token-54-11" pos="word" morph="none" start_char="2602" end_char="2604">000</TOKEN>
        <TOKEN id="token-54-12" pos="word" morph="none" start_char="2606" end_char="2611">emails</TOKEN>
        <TOKEN id="token-54-13" pos="word" morph="none" start_char="2613" end_char="2616">from</TOKEN>
        <TOKEN id="token-54-14" pos="word" morph="none" start_char="2618" end_char="2620">her</TOKEN>
      </SEG>
      <SEG id="segment-55" start_char="2622" end_char="2699">
        <ORIGINAL_TEXT>personal email address in her four years as President Barack Obama's secretary</ORIGINAL_TEXT>
        <TOKEN id="token-55-0" pos="word" morph="none" start_char="2622" end_char="2629">personal</TOKEN>
        <TOKEN id="token-55-1" pos="word" morph="none" start_char="2631" end_char="2635">email</TOKEN>
        <TOKEN id="token-55-2" pos="word" morph="none" start_char="2637" end_char="2643">address</TOKEN>
        <TOKEN id="token-55-3" pos="word" morph="none" start_char="2645" end_char="2646">in</TOKEN>
        <TOKEN id="token-55-4" pos="word" morph="none" start_char="2648" end_char="2650">her</TOKEN>
        <TOKEN id="token-55-5" pos="word" morph="none" start_char="2652" end_char="2655">four</TOKEN>
        <TOKEN id="token-55-6" pos="word" morph="none" start_char="2657" end_char="2661">years</TOKEN>
        <TOKEN id="token-55-7" pos="word" morph="none" start_char="2663" end_char="2664">as</TOKEN>
        <TOKEN id="token-55-8" pos="word" morph="none" start_char="2666" end_char="2674">President</TOKEN>
        <TOKEN id="token-55-9" pos="word" morph="none" start_char="2676" end_char="2681">Barack</TOKEN>
        <TOKEN id="token-55-10" pos="word" morph="none" start_char="2683" end_char="2687">Obama</TOKEN>
        <TOKEN id="token-55-11" pos="punct" morph="none" start_char="2688" end_char="2688">'</TOKEN>
        <TOKEN id="token-55-12" pos="word" morph="none" start_char="2689" end_char="2689">s</TOKEN>
        <TOKEN id="token-55-13" pos="word" morph="none" start_char="2691" end_char="2699">secretary</TOKEN>
      </SEG>
      <SEG id="segment-56" start_char="2701" end_char="2775">
        <ORIGINAL_TEXT>of state. She said roughly half were work-related, which she turned over to</ORIGINAL_TEXT>
        <TOKEN id="token-56-0" pos="word" morph="none" start_char="2701" end_char="2702">of</TOKEN>
        <TOKEN id="token-56-1" pos="word" morph="none" start_char="2704" end_char="2708">state</TOKEN>
        <TOKEN id="token-56-2" pos="punct" morph="none" start_char="2709" end_char="2709">.</TOKEN>
        <TOKEN id="token-56-3" pos="word" morph="none" start_char="2711" end_char="2713">She</TOKEN>
        <TOKEN id="token-56-4" pos="word" morph="none" start_char="2715" end_char="2718">said</TOKEN>
        <TOKEN id="token-56-5" pos="word" morph="none" start_char="2720" end_char="2726">roughly</TOKEN>
        <TOKEN id="token-56-6" pos="word" morph="none" start_char="2728" end_char="2731">half</TOKEN>
        <TOKEN id="token-56-7" pos="word" morph="none" start_char="2733" end_char="2736">were</TOKEN>
        <TOKEN id="token-56-8" pos="word" morph="none" start_char="2738" end_char="2741">work</TOKEN>
        <TOKEN id="token-56-9" pos="punct" morph="none" start_char="2742" end_char="2742">-</TOKEN>
        <TOKEN id="token-56-10" pos="word" morph="none" start_char="2743" end_char="2749">related</TOKEN>
        <TOKEN id="token-56-11" pos="punct" morph="none" start_char="2750" end_char="2750">,</TOKEN>
        <TOKEN id="token-56-12" pos="word" morph="none" start_char="2752" end_char="2756">which</TOKEN>
        <TOKEN id="token-56-13" pos="word" morph="none" start_char="2758" end_char="2760">she</TOKEN>
        <TOKEN id="token-56-14" pos="word" morph="none" start_char="2762" end_char="2767">turned</TOKEN>
        <TOKEN id="token-56-15" pos="word" morph="none" start_char="2769" end_char="2772">over</TOKEN>
        <TOKEN id="token-56-16" pos="word" morph="none" start_char="2774" end_char="2775">to</TOKEN>
      </SEG>
      <SEG id="segment-57" start_char="2777" end_char="2854">
        <ORIGINAL_TEXT>the State Department, while deleting tens of thousands more that were personal</ORIGINAL_TEXT>
        <TOKEN id="token-57-0" pos="word" morph="none" start_char="2777" end_char="2779">the</TOKEN>
        <TOKEN id="token-57-1" pos="word" morph="none" start_char="2781" end_char="2785">State</TOKEN>
        <TOKEN id="token-57-2" pos="word" morph="none" start_char="2787" end_char="2796">Department</TOKEN>
        <TOKEN id="token-57-3" pos="punct" morph="none" start_char="2797" end_char="2797">,</TOKEN>
        <TOKEN id="token-57-4" pos="word" morph="none" start_char="2799" end_char="2803">while</TOKEN>
        <TOKEN id="token-57-5" pos="word" morph="none" start_char="2805" end_char="2812">deleting</TOKEN>
        <TOKEN id="token-57-6" pos="word" morph="none" start_char="2814" end_char="2817">tens</TOKEN>
        <TOKEN id="token-57-7" pos="word" morph="none" start_char="2819" end_char="2820">of</TOKEN>
        <TOKEN id="token-57-8" pos="word" morph="none" start_char="2822" end_char="2830">thousands</TOKEN>
        <TOKEN id="token-57-9" pos="word" morph="none" start_char="2832" end_char="2835">more</TOKEN>
        <TOKEN id="token-57-10" pos="word" morph="none" start_char="2837" end_char="2840">that</TOKEN>
        <TOKEN id="token-57-11" pos="word" morph="none" start_char="2842" end_char="2845">were</TOKEN>
        <TOKEN id="token-57-12" pos="word" morph="none" start_char="2847" end_char="2854">personal</TOKEN>
      </SEG>
      <SEG id="segment-58" start_char="2856" end_char="2865">
        <ORIGINAL_TEXT>in nature.</ORIGINAL_TEXT>
        <TOKEN id="token-58-0" pos="word" morph="none" start_char="2856" end_char="2857">in</TOKEN>
        <TOKEN id="token-58-1" pos="word" morph="none" start_char="2859" end_char="2864">nature</TOKEN>
        <TOKEN id="token-58-2" pos="punct" morph="none" start_char="2865" end_char="2865">.</TOKEN>
      </SEG>
      <SEG id="segment-59" start_char="2867" end_char="2870">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-59-0" pos="unknown" morph="none" start_char="2867" end_char="2870">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-60" start_char="2872" end_char="2874">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-60-0" pos="unknown" morph="none" start_char="2872" end_char="2874">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-61" start_char="2876" end_char="2953">
        <ORIGINAL_TEXT>The department says it will take several months to review the material Clinton</ORIGINAL_TEXT>
        <TOKEN id="token-61-0" pos="word" morph="none" start_char="2876" end_char="2878">The</TOKEN>
        <TOKEN id="token-61-1" pos="word" morph="none" start_char="2880" end_char="2889">department</TOKEN>
        <TOKEN id="token-61-2" pos="word" morph="none" start_char="2891" end_char="2894">says</TOKEN>
        <TOKEN id="token-61-3" pos="word" morph="none" start_char="2896" end_char="2897">it</TOKEN>
        <TOKEN id="token-61-4" pos="word" morph="none" start_char="2899" end_char="2902">will</TOKEN>
        <TOKEN id="token-61-5" pos="word" morph="none" start_char="2904" end_char="2907">take</TOKEN>
        <TOKEN id="token-61-6" pos="word" morph="none" start_char="2909" end_char="2915">several</TOKEN>
        <TOKEN id="token-61-7" pos="word" morph="none" start_char="2917" end_char="2922">months</TOKEN>
        <TOKEN id="token-61-8" pos="word" morph="none" start_char="2924" end_char="2925">to</TOKEN>
        <TOKEN id="token-61-9" pos="word" morph="none" start_char="2927" end_char="2932">review</TOKEN>
        <TOKEN id="token-61-10" pos="word" morph="none" start_char="2934" end_char="2936">the</TOKEN>
        <TOKEN id="token-61-11" pos="word" morph="none" start_char="2938" end_char="2945">material</TOKEN>
        <TOKEN id="token-61-12" pos="word" morph="none" start_char="2947" end_char="2953">Clinton</TOKEN>
      </SEG>
      <SEG id="segment-62" start_char="2955" end_char="3030">
        <ORIGINAL_TEXT>turned over last year. Once the review is complete, the department said, the</ORIGINAL_TEXT>
        <TOKEN id="token-62-0" pos="word" morph="none" start_char="2955" end_char="2960">turned</TOKEN>
        <TOKEN id="token-62-1" pos="word" morph="none" start_char="2962" end_char="2965">over</TOKEN>
        <TOKEN id="token-62-2" pos="word" morph="none" start_char="2967" end_char="2970">last</TOKEN>
        <TOKEN id="token-62-3" pos="word" morph="none" start_char="2972" end_char="2975">year</TOKEN>
        <TOKEN id="token-62-4" pos="punct" morph="none" start_char="2976" end_char="2976">.</TOKEN>
        <TOKEN id="token-62-5" pos="word" morph="none" start_char="2978" end_char="2981">Once</TOKEN>
        <TOKEN id="token-62-6" pos="word" morph="none" start_char="2983" end_char="2985">the</TOKEN>
        <TOKEN id="token-62-7" pos="word" morph="none" start_char="2987" end_char="2992">review</TOKEN>
        <TOKEN id="token-62-8" pos="word" morph="none" start_char="2994" end_char="2995">is</TOKEN>
        <TOKEN id="token-62-9" pos="word" morph="none" start_char="2997" end_char="3004">complete</TOKEN>
        <TOKEN id="token-62-10" pos="punct" morph="none" start_char="3005" end_char="3005">,</TOKEN>
        <TOKEN id="token-62-11" pos="word" morph="none" start_char="3007" end_char="3009">the</TOKEN>
        <TOKEN id="token-62-12" pos="word" morph="none" start_char="3011" end_char="3020">department</TOKEN>
        <TOKEN id="token-62-13" pos="word" morph="none" start_char="3022" end_char="3025">said</TOKEN>
        <TOKEN id="token-62-14" pos="punct" morph="none" start_char="3026" end_char="3026">,</TOKEN>
        <TOKEN id="token-62-15" pos="word" morph="none" start_char="3028" end_char="3030">the</TOKEN>
      </SEG>
      <SEG id="segment-63" start_char="3032" end_char="3060">
        <ORIGINAL_TEXT>emails will be posted online.</ORIGINAL_TEXT>
        <TOKEN id="token-63-0" pos="word" morph="none" start_char="3032" end_char="3037">emails</TOKEN>
        <TOKEN id="token-63-1" pos="word" morph="none" start_char="3039" end_char="3042">will</TOKEN>
        <TOKEN id="token-63-2" pos="word" morph="none" start_char="3044" end_char="3045">be</TOKEN>
        <TOKEN id="token-63-3" pos="word" morph="none" start_char="3047" end_char="3052">posted</TOKEN>
        <TOKEN id="token-63-4" pos="word" morph="none" start_char="3054" end_char="3059">online</TOKEN>
        <TOKEN id="token-63-5" pos="punct" morph="none" start_char="3060" end_char="3060">.</TOKEN>
      </SEG>
      <SEG id="segment-64" start_char="3062" end_char="3065">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-64-0" pos="unknown" morph="none" start_char="3062" end_char="3065">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-65" start_char="3067" end_char="3069">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-65-0" pos="unknown" morph="none" start_char="3067" end_char="3069">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-66" start_char="3071" end_char="3147">
        <ORIGINAL_TEXT>The AP had sought Clinton-related correspondence before her use of a personal</ORIGINAL_TEXT>
        <TOKEN id="token-66-0" pos="word" morph="none" start_char="3071" end_char="3073">The</TOKEN>
        <TOKEN id="token-66-1" pos="word" morph="none" start_char="3075" end_char="3076">AP</TOKEN>
        <TOKEN id="token-66-2" pos="word" morph="none" start_char="3078" end_char="3080">had</TOKEN>
        <TOKEN id="token-66-3" pos="word" morph="none" start_char="3082" end_char="3087">sought</TOKEN>
        <TOKEN id="token-66-4" pos="word" morph="none" start_char="3089" end_char="3095">Clinton</TOKEN>
        <TOKEN id="token-66-5" pos="punct" morph="none" start_char="3096" end_char="3096">-</TOKEN>
        <TOKEN id="token-66-6" pos="word" morph="none" start_char="3097" end_char="3103">related</TOKEN>
        <TOKEN id="token-66-7" pos="word" morph="none" start_char="3105" end_char="3118">correspondence</TOKEN>
        <TOKEN id="token-66-8" pos="word" morph="none" start_char="3120" end_char="3125">before</TOKEN>
        <TOKEN id="token-66-9" pos="word" morph="none" start_char="3127" end_char="3129">her</TOKEN>
        <TOKEN id="token-66-10" pos="word" morph="none" start_char="3131" end_char="3133">use</TOKEN>
        <TOKEN id="token-66-11" pos="word" morph="none" start_char="3135" end_char="3136">of</TOKEN>
        <TOKEN id="token-66-12" pos="word" morph="none" start_char="3138" end_char="3138">a</TOKEN>
        <TOKEN id="token-66-13" pos="word" morph="none" start_char="3140" end_char="3147">personal</TOKEN>
      </SEG>
      <SEG id="segment-67" start_char="3149" end_char="3223">
        <ORIGINAL_TEXT>email account was publicly known, although Wednesday's court filing alleges</ORIGINAL_TEXT>
        <TOKEN id="token-67-0" pos="word" morph="none" start_char="3149" end_char="3153">email</TOKEN>
        <TOKEN id="token-67-1" pos="word" morph="none" start_char="3155" end_char="3161">account</TOKEN>
        <TOKEN id="token-67-2" pos="word" morph="none" start_char="3163" end_char="3165">was</TOKEN>
        <TOKEN id="token-67-3" pos="word" morph="none" start_char="3167" end_char="3174">publicly</TOKEN>
        <TOKEN id="token-67-4" pos="word" morph="none" start_char="3176" end_char="3180">known</TOKEN>
        <TOKEN id="token-67-5" pos="punct" morph="none" start_char="3181" end_char="3181">,</TOKEN>
        <TOKEN id="token-67-6" pos="word" morph="none" start_char="3183" end_char="3190">although</TOKEN>
        <TOKEN id="token-67-7" pos="word" morph="none" start_char="3192" end_char="3200">Wednesday</TOKEN>
        <TOKEN id="token-67-8" pos="punct" morph="none" start_char="3201" end_char="3201">'</TOKEN>
        <TOKEN id="token-67-9" pos="word" morph="none" start_char="3202" end_char="3202">s</TOKEN>
        <TOKEN id="token-67-10" pos="word" morph="none" start_char="3204" end_char="3208">court</TOKEN>
        <TOKEN id="token-67-11" pos="word" morph="none" start_char="3210" end_char="3215">filing</TOKEN>
        <TOKEN id="token-67-12" pos="word" morph="none" start_char="3217" end_char="3223">alleges</TOKEN>
      </SEG>
      <SEG id="segment-68" start_char="3225" end_char="3295">
        <ORIGINAL_TEXT>that the State Department is responsible for including emails from that</ORIGINAL_TEXT>
        <TOKEN id="token-68-0" pos="word" morph="none" start_char="3225" end_char="3228">that</TOKEN>
        <TOKEN id="token-68-1" pos="word" morph="none" start_char="3230" end_char="3232">the</TOKEN>
        <TOKEN id="token-68-2" pos="word" morph="none" start_char="3234" end_char="3238">State</TOKEN>
        <TOKEN id="token-68-3" pos="word" morph="none" start_char="3240" end_char="3249">Department</TOKEN>
        <TOKEN id="token-68-4" pos="word" morph="none" start_char="3251" end_char="3252">is</TOKEN>
        <TOKEN id="token-68-5" pos="word" morph="none" start_char="3254" end_char="3264">responsible</TOKEN>
        <TOKEN id="token-68-6" pos="word" morph="none" start_char="3266" end_char="3268">for</TOKEN>
        <TOKEN id="token-68-7" pos="word" morph="none" start_char="3270" end_char="3278">including</TOKEN>
        <TOKEN id="token-68-8" pos="word" morph="none" start_char="3280" end_char="3285">emails</TOKEN>
        <TOKEN id="token-68-9" pos="word" morph="none" start_char="3287" end_char="3290">from</TOKEN>
        <TOKEN id="token-68-10" pos="word" morph="none" start_char="3292" end_char="3295">that</TOKEN>
      </SEG>
      <SEG id="segment-69" start_char="3297" end_char="3334">
        <ORIGINAL_TEXT>account in any public records request.</ORIGINAL_TEXT>
        <TOKEN id="token-69-0" pos="word" morph="none" start_char="3297" end_char="3303">account</TOKEN>
        <TOKEN id="token-69-1" pos="word" morph="none" start_char="3305" end_char="3306">in</TOKEN>
        <TOKEN id="token-69-2" pos="word" morph="none" start_char="3308" end_char="3310">any</TOKEN>
        <TOKEN id="token-69-3" pos="word" morph="none" start_char="3312" end_char="3317">public</TOKEN>
        <TOKEN id="token-69-4" pos="word" morph="none" start_char="3319" end_char="3325">records</TOKEN>
        <TOKEN id="token-69-5" pos="word" morph="none" start_char="3327" end_char="3333">request</TOKEN>
        <TOKEN id="token-69-6" pos="punct" morph="none" start_char="3334" end_char="3334">.</TOKEN>
      </SEG>
      <SEG id="segment-70" start_char="3336" end_char="3339">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-70-0" pos="unknown" morph="none" start_char="3336" end_char="3339">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-71" start_char="3341" end_char="3343">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-71-0" pos="unknown" morph="none" start_char="3341" end_char="3343">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-72" start_char="3345" end_char="3420">
        <ORIGINAL_TEXT>"State's failure to ensure that Secretary Clinton's governmental emails were</ORIGINAL_TEXT>
        <TOKEN id="token-72-0" pos="punct" morph="none" start_char="3345" end_char="3345">"</TOKEN>
        <TOKEN id="token-72-1" pos="word" morph="none" start_char="3346" end_char="3350">State</TOKEN>
        <TOKEN id="token-72-2" pos="punct" morph="none" start_char="3351" end_char="3351">'</TOKEN>
        <TOKEN id="token-72-3" pos="word" morph="none" start_char="3352" end_char="3352">s</TOKEN>
        <TOKEN id="token-72-4" pos="word" morph="none" start_char="3354" end_char="3360">failure</TOKEN>
        <TOKEN id="token-72-5" pos="word" morph="none" start_char="3362" end_char="3363">to</TOKEN>
        <TOKEN id="token-72-6" pos="word" morph="none" start_char="3365" end_char="3370">ensure</TOKEN>
        <TOKEN id="token-72-7" pos="word" morph="none" start_char="3372" end_char="3375">that</TOKEN>
        <TOKEN id="token-72-8" pos="word" morph="none" start_char="3377" end_char="3385">Secretary</TOKEN>
        <TOKEN id="token-72-9" pos="word" morph="none" start_char="3387" end_char="3393">Clinton</TOKEN>
        <TOKEN id="token-72-10" pos="punct" morph="none" start_char="3394" end_char="3394">'</TOKEN>
        <TOKEN id="token-72-11" pos="word" morph="none" start_char="3395" end_char="3395">s</TOKEN>
        <TOKEN id="token-72-12" pos="word" morph="none" start_char="3397" end_char="3408">governmental</TOKEN>
        <TOKEN id="token-72-13" pos="word" morph="none" start_char="3410" end_char="3415">emails</TOKEN>
        <TOKEN id="token-72-14" pos="word" morph="none" start_char="3417" end_char="3420">were</TOKEN>
      </SEG>
      <SEG id="segment-73" start_char="3422" end_char="3497">
        <ORIGINAL_TEXT>retained and preserved by the agency, and its failure timely to seek out and</ORIGINAL_TEXT>
        <TOKEN id="token-73-0" pos="word" morph="none" start_char="3422" end_char="3429">retained</TOKEN>
        <TOKEN id="token-73-1" pos="word" morph="none" start_char="3431" end_char="3433">and</TOKEN>
        <TOKEN id="token-73-2" pos="word" morph="none" start_char="3435" end_char="3443">preserved</TOKEN>
        <TOKEN id="token-73-3" pos="word" morph="none" start_char="3445" end_char="3446">by</TOKEN>
        <TOKEN id="token-73-4" pos="word" morph="none" start_char="3448" end_char="3450">the</TOKEN>
        <TOKEN id="token-73-5" pos="word" morph="none" start_char="3452" end_char="3457">agency</TOKEN>
        <TOKEN id="token-73-6" pos="punct" morph="none" start_char="3458" end_char="3458">,</TOKEN>
        <TOKEN id="token-73-7" pos="word" morph="none" start_char="3460" end_char="3462">and</TOKEN>
        <TOKEN id="token-73-8" pos="word" morph="none" start_char="3464" end_char="3466">its</TOKEN>
        <TOKEN id="token-73-9" pos="word" morph="none" start_char="3468" end_char="3474">failure</TOKEN>
        <TOKEN id="token-73-10" pos="word" morph="none" start_char="3476" end_char="3481">timely</TOKEN>
        <TOKEN id="token-73-11" pos="word" morph="none" start_char="3483" end_char="3484">to</TOKEN>
        <TOKEN id="token-73-12" pos="word" morph="none" start_char="3486" end_char="3489">seek</TOKEN>
        <TOKEN id="token-73-13" pos="word" morph="none" start_char="3491" end_char="3493">out</TOKEN>
        <TOKEN id="token-73-14" pos="word" morph="none" start_char="3495" end_char="3497">and</TOKEN>
      </SEG>
      <SEG id="segment-74" start_char="3499" end_char="3574">
        <ORIGINAL_TEXT>search those emails in response to AP's requests, indicate at the very least</ORIGINAL_TEXT>
        <TOKEN id="token-74-0" pos="word" morph="none" start_char="3499" end_char="3504">search</TOKEN>
        <TOKEN id="token-74-1" pos="word" morph="none" start_char="3506" end_char="3510">those</TOKEN>
        <TOKEN id="token-74-2" pos="word" morph="none" start_char="3512" end_char="3517">emails</TOKEN>
        <TOKEN id="token-74-3" pos="word" morph="none" start_char="3519" end_char="3520">in</TOKEN>
        <TOKEN id="token-74-4" pos="word" morph="none" start_char="3522" end_char="3529">response</TOKEN>
        <TOKEN id="token-74-5" pos="word" morph="none" start_char="3531" end_char="3532">to</TOKEN>
        <TOKEN id="token-74-6" pos="word" morph="none" start_char="3534" end_char="3535">AP</TOKEN>
        <TOKEN id="token-74-7" pos="punct" morph="none" start_char="3536" end_char="3536">'</TOKEN>
        <TOKEN id="token-74-8" pos="word" morph="none" start_char="3537" end_char="3537">s</TOKEN>
        <TOKEN id="token-74-9" pos="word" morph="none" start_char="3539" end_char="3546">requests</TOKEN>
        <TOKEN id="token-74-10" pos="punct" morph="none" start_char="3547" end_char="3547">,</TOKEN>
        <TOKEN id="token-74-11" pos="word" morph="none" start_char="3549" end_char="3556">indicate</TOKEN>
        <TOKEN id="token-74-12" pos="word" morph="none" start_char="3558" end_char="3559">at</TOKEN>
        <TOKEN id="token-74-13" pos="word" morph="none" start_char="3561" end_char="3563">the</TOKEN>
        <TOKEN id="token-74-14" pos="word" morph="none" start_char="3565" end_char="3568">very</TOKEN>
        <TOKEN id="token-74-15" pos="word" morph="none" start_char="3570" end_char="3574">least</TOKEN>
      </SEG>
      <SEG id="segment-75" start_char="3576" end_char="3646">
        <ORIGINAL_TEXT>that State has not engaged in the diligent, good-faith search that FOIA</ORIGINAL_TEXT>
        <TOKEN id="token-75-0" pos="word" morph="none" start_char="3576" end_char="3579">that</TOKEN>
        <TOKEN id="token-75-1" pos="word" morph="none" start_char="3581" end_char="3585">State</TOKEN>
        <TOKEN id="token-75-2" pos="word" morph="none" start_char="3587" end_char="3589">has</TOKEN>
        <TOKEN id="token-75-3" pos="word" morph="none" start_char="3591" end_char="3593">not</TOKEN>
        <TOKEN id="token-75-4" pos="word" morph="none" start_char="3595" end_char="3601">engaged</TOKEN>
        <TOKEN id="token-75-5" pos="word" morph="none" start_char="3603" end_char="3604">in</TOKEN>
        <TOKEN id="token-75-6" pos="word" morph="none" start_char="3606" end_char="3608">the</TOKEN>
        <TOKEN id="token-75-7" pos="word" morph="none" start_char="3610" end_char="3617">diligent</TOKEN>
        <TOKEN id="token-75-8" pos="punct" morph="none" start_char="3618" end_char="3618">,</TOKEN>
        <TOKEN id="token-75-9" pos="word" morph="none" start_char="3620" end_char="3623">good</TOKEN>
        <TOKEN id="token-75-10" pos="punct" morph="none" start_char="3624" end_char="3624">-</TOKEN>
        <TOKEN id="token-75-11" pos="word" morph="none" start_char="3625" end_char="3629">faith</TOKEN>
        <TOKEN id="token-75-12" pos="word" morph="none" start_char="3631" end_char="3636">search</TOKEN>
        <TOKEN id="token-75-13" pos="word" morph="none" start_char="3638" end_char="3641">that</TOKEN>
        <TOKEN id="token-75-14" pos="word" morph="none" start_char="3643" end_char="3646">FOIA</TOKEN>
      </SEG>
      <SEG id="segment-76" start_char="3648" end_char="3681">
        <ORIGINAL_TEXT>requires," says AP's legal filing.</ORIGINAL_TEXT>
        <TOKEN id="token-76-0" pos="word" morph="none" start_char="3648" end_char="3655">requires</TOKEN>
        <TOKEN id="token-76-1" pos="punct" morph="none" start_char="3656" end_char="3657">,"</TOKEN>
        <TOKEN id="token-76-2" pos="word" morph="none" start_char="3659" end_char="3662">says</TOKEN>
        <TOKEN id="token-76-3" pos="word" morph="none" start_char="3664" end_char="3665">AP</TOKEN>
        <TOKEN id="token-76-4" pos="punct" morph="none" start_char="3666" end_char="3666">'</TOKEN>
        <TOKEN id="token-76-5" pos="word" morph="none" start_char="3667" end_char="3667">s</TOKEN>
        <TOKEN id="token-76-6" pos="word" morph="none" start_char="3669" end_char="3673">legal</TOKEN>
        <TOKEN id="token-76-7" pos="word" morph="none" start_char="3675" end_char="3680">filing</TOKEN>
        <TOKEN id="token-76-8" pos="punct" morph="none" start_char="3681" end_char="3681">.</TOKEN>
      </SEG>
      <SEG id="segment-77" start_char="3683" end_char="3686">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-77-0" pos="unknown" morph="none" start_char="3683" end_char="3686">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-78" start_char="3688" end_char="3690">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-78-0" pos="unknown" morph="none" start_char="3688" end_char="3690">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-79" start_char="3692" end_char="3767">
        <ORIGINAL_TEXT>Specifically, AP is seeking copies of Clinton's full schedules and calendars</ORIGINAL_TEXT>
        <TOKEN id="token-79-0" pos="word" morph="none" start_char="3692" end_char="3703">Specifically</TOKEN>
        <TOKEN id="token-79-1" pos="punct" morph="none" start_char="3704" end_char="3704">,</TOKEN>
        <TOKEN id="token-79-2" pos="word" morph="none" start_char="3706" end_char="3707">AP</TOKEN>
        <TOKEN id="token-79-3" pos="word" morph="none" start_char="3709" end_char="3710">is</TOKEN>
        <TOKEN id="token-79-4" pos="word" morph="none" start_char="3712" end_char="3718">seeking</TOKEN>
        <TOKEN id="token-79-5" pos="word" morph="none" start_char="3720" end_char="3725">copies</TOKEN>
        <TOKEN id="token-79-6" pos="word" morph="none" start_char="3727" end_char="3728">of</TOKEN>
        <TOKEN id="token-79-7" pos="word" morph="none" start_char="3730" end_char="3736">Clinton</TOKEN>
        <TOKEN id="token-79-8" pos="punct" morph="none" start_char="3737" end_char="3737">'</TOKEN>
        <TOKEN id="token-79-9" pos="word" morph="none" start_char="3738" end_char="3738">s</TOKEN>
        <TOKEN id="token-79-10" pos="word" morph="none" start_char="3740" end_char="3743">full</TOKEN>
        <TOKEN id="token-79-11" pos="word" morph="none" start_char="3745" end_char="3753">schedules</TOKEN>
        <TOKEN id="token-79-12" pos="word" morph="none" start_char="3755" end_char="3757">and</TOKEN>
        <TOKEN id="token-79-13" pos="word" morph="none" start_char="3759" end_char="3767">calendars</TOKEN>
      </SEG>
      <SEG id="segment-80" start_char="3769" end_char="3835">
        <ORIGINAL_TEXT>from her four years as secretary of state; documents related to her</ORIGINAL_TEXT>
        <TOKEN id="token-80-0" pos="word" morph="none" start_char="3769" end_char="3772">from</TOKEN>
        <TOKEN id="token-80-1" pos="word" morph="none" start_char="3774" end_char="3776">her</TOKEN>
        <TOKEN id="token-80-2" pos="word" morph="none" start_char="3778" end_char="3781">four</TOKEN>
        <TOKEN id="token-80-3" pos="word" morph="none" start_char="3783" end_char="3787">years</TOKEN>
        <TOKEN id="token-80-4" pos="word" morph="none" start_char="3789" end_char="3790">as</TOKEN>
        <TOKEN id="token-80-5" pos="word" morph="none" start_char="3792" end_char="3800">secretary</TOKEN>
        <TOKEN id="token-80-6" pos="word" morph="none" start_char="3802" end_char="3803">of</TOKEN>
        <TOKEN id="token-80-7" pos="word" morph="none" start_char="3805" end_char="3809">state</TOKEN>
        <TOKEN id="token-80-8" pos="punct" morph="none" start_char="3810" end_char="3810">;</TOKEN>
        <TOKEN id="token-80-9" pos="word" morph="none" start_char="3812" end_char="3820">documents</TOKEN>
        <TOKEN id="token-80-10" pos="word" morph="none" start_char="3822" end_char="3828">related</TOKEN>
        <TOKEN id="token-80-11" pos="word" morph="none" start_char="3830" end_char="3831">to</TOKEN>
        <TOKEN id="token-80-12" pos="word" morph="none" start_char="3833" end_char="3835">her</TOKEN>
      </SEG>
      <SEG id="segment-81" start_char="3837" end_char="3907">
        <ORIGINAL_TEXT>department's decision to grant a special position to longtime aide Huma</ORIGINAL_TEXT>
        <TOKEN id="token-81-0" pos="word" morph="none" start_char="3837" end_char="3846">department</TOKEN>
        <TOKEN id="token-81-1" pos="punct" morph="none" start_char="3847" end_char="3847">'</TOKEN>
        <TOKEN id="token-81-2" pos="word" morph="none" start_char="3848" end_char="3848">s</TOKEN>
        <TOKEN id="token-81-3" pos="word" morph="none" start_char="3850" end_char="3857">decision</TOKEN>
        <TOKEN id="token-81-4" pos="word" morph="none" start_char="3859" end_char="3860">to</TOKEN>
        <TOKEN id="token-81-5" pos="word" morph="none" start_char="3862" end_char="3866">grant</TOKEN>
        <TOKEN id="token-81-6" pos="word" morph="none" start_char="3868" end_char="3868">a</TOKEN>
        <TOKEN id="token-81-7" pos="word" morph="none" start_char="3870" end_char="3876">special</TOKEN>
        <TOKEN id="token-81-8" pos="word" morph="none" start_char="3878" end_char="3885">position</TOKEN>
        <TOKEN id="token-81-9" pos="word" morph="none" start_char="3887" end_char="3888">to</TOKEN>
        <TOKEN id="token-81-10" pos="word" morph="none" start_char="3890" end_char="3897">longtime</TOKEN>
        <TOKEN id="token-81-11" pos="word" morph="none" start_char="3899" end_char="3902">aide</TOKEN>
        <TOKEN id="token-81-12" pos="word" morph="none" start_char="3904" end_char="3907">Huma</TOKEN>
      </SEG>
      <SEG id="segment-82" start_char="3909" end_char="3981">
        <ORIGINAL_TEXT>Abedin; related correspondence from longtime advisers Philippe Reines and</ORIGINAL_TEXT>
        <TOKEN id="token-82-0" pos="word" morph="none" start_char="3909" end_char="3914">Abedin</TOKEN>
        <TOKEN id="token-82-1" pos="punct" morph="none" start_char="3915" end_char="3915">;</TOKEN>
        <TOKEN id="token-82-2" pos="word" morph="none" start_char="3917" end_char="3923">related</TOKEN>
        <TOKEN id="token-82-3" pos="word" morph="none" start_char="3925" end_char="3938">correspondence</TOKEN>
        <TOKEN id="token-82-4" pos="word" morph="none" start_char="3940" end_char="3943">from</TOKEN>
        <TOKEN id="token-82-5" pos="word" morph="none" start_char="3945" end_char="3952">longtime</TOKEN>
        <TOKEN id="token-82-6" pos="word" morph="none" start_char="3954" end_char="3961">advisers</TOKEN>
        <TOKEN id="token-82-7" pos="word" morph="none" start_char="3963" end_char="3970">Philippe</TOKEN>
        <TOKEN id="token-82-8" pos="word" morph="none" start_char="3972" end_char="3977">Reines</TOKEN>
        <TOKEN id="token-82-9" pos="word" morph="none" start_char="3979" end_char="3981">and</TOKEN>
      </SEG>
      <SEG id="segment-83" start_char="3983" end_char="4059">
        <ORIGINAL_TEXT>Cheryl Mills, who, like Abedin, are likely to play central roles in a Clinton</ORIGINAL_TEXT>
        <TOKEN id="token-83-0" pos="word" morph="none" start_char="3983" end_char="3988">Cheryl</TOKEN>
        <TOKEN id="token-83-1" pos="word" morph="none" start_char="3990" end_char="3994">Mills</TOKEN>
        <TOKEN id="token-83-2" pos="punct" morph="none" start_char="3995" end_char="3995">,</TOKEN>
        <TOKEN id="token-83-3" pos="word" morph="none" start_char="3997" end_char="3999">who</TOKEN>
        <TOKEN id="token-83-4" pos="punct" morph="none" start_char="4000" end_char="4000">,</TOKEN>
        <TOKEN id="token-83-5" pos="word" morph="none" start_char="4002" end_char="4005">like</TOKEN>
        <TOKEN id="token-83-6" pos="word" morph="none" start_char="4007" end_char="4012">Abedin</TOKEN>
        <TOKEN id="token-83-7" pos="punct" morph="none" start_char="4013" end_char="4013">,</TOKEN>
        <TOKEN id="token-83-8" pos="word" morph="none" start_char="4015" end_char="4017">are</TOKEN>
        <TOKEN id="token-83-9" pos="word" morph="none" start_char="4019" end_char="4024">likely</TOKEN>
        <TOKEN id="token-83-10" pos="word" morph="none" start_char="4026" end_char="4027">to</TOKEN>
        <TOKEN id="token-83-11" pos="word" morph="none" start_char="4029" end_char="4032">play</TOKEN>
        <TOKEN id="token-83-12" pos="word" morph="none" start_char="4034" end_char="4040">central</TOKEN>
        <TOKEN id="token-83-13" pos="word" morph="none" start_char="4042" end_char="4046">roles</TOKEN>
        <TOKEN id="token-83-14" pos="word" morph="none" start_char="4048" end_char="4049">in</TOKEN>
        <TOKEN id="token-83-15" pos="word" morph="none" start_char="4051" end_char="4051">a</TOKEN>
        <TOKEN id="token-83-16" pos="word" morph="none" start_char="4053" end_char="4059">Clinton</TOKEN>
      </SEG>
      <SEG id="segment-84" start_char="4061" end_char="4136">
        <ORIGINAL_TEXT>presidential campaign; documents related to Clinton's and the agency's roles</ORIGINAL_TEXT>
        <TOKEN id="token-84-0" pos="word" morph="none" start_char="4061" end_char="4072">presidential</TOKEN>
        <TOKEN id="token-84-1" pos="word" morph="none" start_char="4074" end_char="4081">campaign</TOKEN>
        <TOKEN id="token-84-2" pos="punct" morph="none" start_char="4082" end_char="4082">;</TOKEN>
        <TOKEN id="token-84-3" pos="word" morph="none" start_char="4084" end_char="4092">documents</TOKEN>
        <TOKEN id="token-84-4" pos="word" morph="none" start_char="4094" end_char="4100">related</TOKEN>
        <TOKEN id="token-84-5" pos="word" morph="none" start_char="4102" end_char="4103">to</TOKEN>
        <TOKEN id="token-84-6" pos="word" morph="none" start_char="4105" end_char="4111">Clinton</TOKEN>
        <TOKEN id="token-84-7" pos="punct" morph="none" start_char="4112" end_char="4112">'</TOKEN>
        <TOKEN id="token-84-8" pos="word" morph="none" start_char="4113" end_char="4113">s</TOKEN>
        <TOKEN id="token-84-9" pos="word" morph="none" start_char="4115" end_char="4117">and</TOKEN>
        <TOKEN id="token-84-10" pos="word" morph="none" start_char="4119" end_char="4121">the</TOKEN>
        <TOKEN id="token-84-11" pos="word" morph="none" start_char="4123" end_char="4128">agency</TOKEN>
        <TOKEN id="token-84-12" pos="punct" morph="none" start_char="4129" end_char="4129">'</TOKEN>
        <TOKEN id="token-84-13" pos="word" morph="none" start_char="4130" end_char="4130">s</TOKEN>
        <TOKEN id="token-84-14" pos="word" morph="none" start_char="4132" end_char="4136">roles</TOKEN>
      </SEG>
      <SEG id="segment-85" start_char="4138" end_char="4206">
        <ORIGINAL_TEXT>in the Osama bin Laden raid and National Security Agency surveillance</ORIGINAL_TEXT>
        <TOKEN id="token-85-0" pos="word" morph="none" start_char="4138" end_char="4139">in</TOKEN>
        <TOKEN id="token-85-1" pos="word" morph="none" start_char="4141" end_char="4143">the</TOKEN>
        <TOKEN id="token-85-2" pos="word" morph="none" start_char="4145" end_char="4149">Osama</TOKEN>
        <TOKEN id="token-85-3" pos="word" morph="none" start_char="4151" end_char="4153">bin</TOKEN>
        <TOKEN id="token-85-4" pos="word" morph="none" start_char="4155" end_char="4159">Laden</TOKEN>
        <TOKEN id="token-85-5" pos="word" morph="none" start_char="4161" end_char="4164">raid</TOKEN>
        <TOKEN id="token-85-6" pos="word" morph="none" start_char="4166" end_char="4168">and</TOKEN>
        <TOKEN id="token-85-7" pos="word" morph="none" start_char="4170" end_char="4177">National</TOKEN>
        <TOKEN id="token-85-8" pos="word" morph="none" start_char="4179" end_char="4186">Security</TOKEN>
        <TOKEN id="token-85-9" pos="word" morph="none" start_char="4188" end_char="4193">Agency</TOKEN>
        <TOKEN id="token-85-10" pos="word" morph="none" start_char="4195" end_char="4206">surveillance</TOKEN>
      </SEG>
      <SEG id="segment-86" start_char="4208" end_char="4278">
        <ORIGINAL_TEXT>practices; and documents related to her role overseeing a major Defense</ORIGINAL_TEXT>
        <TOKEN id="token-86-0" pos="word" morph="none" start_char="4208" end_char="4216">practices</TOKEN>
        <TOKEN id="token-86-1" pos="punct" morph="none" start_char="4217" end_char="4217">;</TOKEN>
        <TOKEN id="token-86-2" pos="word" morph="none" start_char="4219" end_char="4221">and</TOKEN>
        <TOKEN id="token-86-3" pos="word" morph="none" start_char="4223" end_char="4231">documents</TOKEN>
        <TOKEN id="token-86-4" pos="word" morph="none" start_char="4233" end_char="4239">related</TOKEN>
        <TOKEN id="token-86-5" pos="word" morph="none" start_char="4241" end_char="4242">to</TOKEN>
        <TOKEN id="token-86-6" pos="word" morph="none" start_char="4244" end_char="4246">her</TOKEN>
        <TOKEN id="token-86-7" pos="word" morph="none" start_char="4248" end_char="4251">role</TOKEN>
        <TOKEN id="token-86-8" pos="word" morph="none" start_char="4253" end_char="4262">overseeing</TOKEN>
        <TOKEN id="token-86-9" pos="word" morph="none" start_char="4264" end_char="4264">a</TOKEN>
        <TOKEN id="token-86-10" pos="word" morph="none" start_char="4266" end_char="4270">major</TOKEN>
        <TOKEN id="token-86-11" pos="word" morph="none" start_char="4272" end_char="4278">Defense</TOKEN>
      </SEG>
      <SEG id="segment-87" start_char="4280" end_char="4301">
        <ORIGINAL_TEXT>Department contractor.</ORIGINAL_TEXT>
        <TOKEN id="token-87-0" pos="word" morph="none" start_char="4280" end_char="4289">Department</TOKEN>
        <TOKEN id="token-87-1" pos="word" morph="none" start_char="4291" end_char="4300">contractor</TOKEN>
        <TOKEN id="token-87-2" pos="punct" morph="none" start_char="4301" end_char="4301">.</TOKEN>
      </SEG>
      <SEG id="segment-88" start_char="4303" end_char="4306">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-88-0" pos="unknown" morph="none" start_char="4303" end_char="4306">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-89" start_char="4308" end_char="4310">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-89-0" pos="unknown" morph="none" start_char="4308" end_char="4310">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-90" start_char="4312" end_char="4389">
        <ORIGINAL_TEXT>The AP made most of its requests in the summer of 2013, although one was filed</ORIGINAL_TEXT>
        <TOKEN id="token-90-0" pos="word" morph="none" start_char="4312" end_char="4314">The</TOKEN>
        <TOKEN id="token-90-1" pos="word" morph="none" start_char="4316" end_char="4317">AP</TOKEN>
        <TOKEN id="token-90-2" pos="word" morph="none" start_char="4319" end_char="4322">made</TOKEN>
        <TOKEN id="token-90-3" pos="word" morph="none" start_char="4324" end_char="4327">most</TOKEN>
        <TOKEN id="token-90-4" pos="word" morph="none" start_char="4329" end_char="4330">of</TOKEN>
        <TOKEN id="token-90-5" pos="word" morph="none" start_char="4332" end_char="4334">its</TOKEN>
        <TOKEN id="token-90-6" pos="word" morph="none" start_char="4336" end_char="4343">requests</TOKEN>
        <TOKEN id="token-90-7" pos="word" morph="none" start_char="4345" end_char="4346">in</TOKEN>
        <TOKEN id="token-90-8" pos="word" morph="none" start_char="4348" end_char="4350">the</TOKEN>
        <TOKEN id="token-90-9" pos="word" morph="none" start_char="4352" end_char="4357">summer</TOKEN>
        <TOKEN id="token-90-10" pos="word" morph="none" start_char="4359" end_char="4360">of</TOKEN>
        <TOKEN id="token-90-11" pos="word" morph="none" start_char="4362" end_char="4365">2013</TOKEN>
        <TOKEN id="token-90-12" pos="punct" morph="none" start_char="4366" end_char="4366">,</TOKEN>
        <TOKEN id="token-90-13" pos="word" morph="none" start_char="4368" end_char="4375">although</TOKEN>
        <TOKEN id="token-90-14" pos="word" morph="none" start_char="4377" end_char="4379">one</TOKEN>
        <TOKEN id="token-90-15" pos="word" morph="none" start_char="4381" end_char="4383">was</TOKEN>
        <TOKEN id="token-90-16" pos="word" morph="none" start_char="4385" end_char="4389">filed</TOKEN>
      </SEG>
      <SEG id="segment-91" start_char="4391" end_char="4463">
        <ORIGINAL_TEXT>in March 2010. AP is also seeking attorney's fees related to the lawsuit.</ORIGINAL_TEXT>
        <TOKEN id="token-91-0" pos="word" morph="none" start_char="4391" end_char="4392">in</TOKEN>
        <TOKEN id="token-91-1" pos="word" morph="none" start_char="4394" end_char="4398">March</TOKEN>
        <TOKEN id="token-91-2" pos="word" morph="none" start_char="4400" end_char="4403">2010</TOKEN>
        <TOKEN id="token-91-3" pos="punct" morph="none" start_char="4404" end_char="4404">.</TOKEN>
        <TOKEN id="token-91-4" pos="word" morph="none" start_char="4406" end_char="4407">AP</TOKEN>
        <TOKEN id="token-91-5" pos="word" morph="none" start_char="4409" end_char="4410">is</TOKEN>
        <TOKEN id="token-91-6" pos="word" morph="none" start_char="4412" end_char="4415">also</TOKEN>
        <TOKEN id="token-91-7" pos="word" morph="none" start_char="4417" end_char="4423">seeking</TOKEN>
        <TOKEN id="token-91-8" pos="word" morph="none" start_char="4425" end_char="4432">attorney</TOKEN>
        <TOKEN id="token-91-9" pos="punct" morph="none" start_char="4433" end_char="4433">'</TOKEN>
        <TOKEN id="token-91-10" pos="word" morph="none" start_char="4434" end_char="4434">s</TOKEN>
        <TOKEN id="token-91-11" pos="word" morph="none" start_char="4436" end_char="4439">fees</TOKEN>
        <TOKEN id="token-91-12" pos="word" morph="none" start_char="4441" end_char="4447">related</TOKEN>
        <TOKEN id="token-91-13" pos="word" morph="none" start_char="4449" end_char="4450">to</TOKEN>
        <TOKEN id="token-91-14" pos="word" morph="none" start_char="4452" end_char="4454">the</TOKEN>
        <TOKEN id="token-91-15" pos="word" morph="none" start_char="4456" end_char="4462">lawsuit</TOKEN>
        <TOKEN id="token-91-16" pos="punct" morph="none" start_char="4463" end_char="4463">.</TOKEN>
      </SEG>
      <SEG id="segment-92" start_char="4465" end_char="4468">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-92-0" pos="unknown" morph="none" start_char="4465" end_char="4468">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-93" start_char="4470" end_char="4472">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-93-0" pos="unknown" morph="none" start_char="4470" end_char="4472">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-94" start_char="4474" end_char="4551">
        <ORIGINAL_TEXT>Other organizations have also sued the State Department recently after lengthy</ORIGINAL_TEXT>
        <TOKEN id="token-94-0" pos="word" morph="none" start_char="4474" end_char="4478">Other</TOKEN>
        <TOKEN id="token-94-1" pos="word" morph="none" start_char="4480" end_char="4492">organizations</TOKEN>
        <TOKEN id="token-94-2" pos="word" morph="none" start_char="4494" end_char="4497">have</TOKEN>
        <TOKEN id="token-94-3" pos="word" morph="none" start_char="4499" end_char="4502">also</TOKEN>
        <TOKEN id="token-94-4" pos="word" morph="none" start_char="4504" end_char="4507">sued</TOKEN>
        <TOKEN id="token-94-5" pos="word" morph="none" start_char="4509" end_char="4511">the</TOKEN>
        <TOKEN id="token-94-6" pos="word" morph="none" start_char="4513" end_char="4517">State</TOKEN>
        <TOKEN id="token-94-7" pos="word" morph="none" start_char="4519" end_char="4528">Department</TOKEN>
        <TOKEN id="token-94-8" pos="word" morph="none" start_char="4530" end_char="4537">recently</TOKEN>
        <TOKEN id="token-94-9" pos="word" morph="none" start_char="4539" end_char="4543">after</TOKEN>
        <TOKEN id="token-94-10" pos="word" morph="none" start_char="4545" end_char="4551">lengthy</TOKEN>
      </SEG>
      <SEG id="segment-95" start_char="4553" end_char="4596">
        <ORIGINAL_TEXT>delays responding to public record requests.</ORIGINAL_TEXT>
        <TOKEN id="token-95-0" pos="word" morph="none" start_char="4553" end_char="4558">delays</TOKEN>
        <TOKEN id="token-95-1" pos="word" morph="none" start_char="4560" end_char="4569">responding</TOKEN>
        <TOKEN id="token-95-2" pos="word" morph="none" start_char="4571" end_char="4572">to</TOKEN>
        <TOKEN id="token-95-3" pos="word" morph="none" start_char="4574" end_char="4579">public</TOKEN>
        <TOKEN id="token-95-4" pos="word" morph="none" start_char="4581" end_char="4586">record</TOKEN>
        <TOKEN id="token-95-5" pos="word" morph="none" start_char="4588" end_char="4595">requests</TOKEN>
        <TOKEN id="token-95-6" pos="punct" morph="none" start_char="4596" end_char="4596">.</TOKEN>
      </SEG>
      <SEG id="segment-96" start_char="4598" end_char="4601">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-96-0" pos="unknown" morph="none" start_char="4598" end_char="4601">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-97" start_char="4603" end_char="4605">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-97-0" pos="unknown" morph="none" start_char="4603" end_char="4605">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-98" start_char="4607" end_char="4681">
        <ORIGINAL_TEXT>In December, the conservative political advocacy group Citizens United sued</ORIGINAL_TEXT>
        <TOKEN id="token-98-0" pos="word" morph="none" start_char="4607" end_char="4608">In</TOKEN>
        <TOKEN id="token-98-1" pos="word" morph="none" start_char="4610" end_char="4617">December</TOKEN>
        <TOKEN id="token-98-2" pos="punct" morph="none" start_char="4618" end_char="4618">,</TOKEN>
        <TOKEN id="token-98-3" pos="word" morph="none" start_char="4620" end_char="4622">the</TOKEN>
        <TOKEN id="token-98-4" pos="word" morph="none" start_char="4624" end_char="4635">conservative</TOKEN>
        <TOKEN id="token-98-5" pos="word" morph="none" start_char="4637" end_char="4645">political</TOKEN>
        <TOKEN id="token-98-6" pos="word" morph="none" start_char="4647" end_char="4654">advocacy</TOKEN>
        <TOKEN id="token-98-7" pos="word" morph="none" start_char="4656" end_char="4660">group</TOKEN>
        <TOKEN id="token-98-8" pos="word" morph="none" start_char="4662" end_char="4669">Citizens</TOKEN>
        <TOKEN id="token-98-9" pos="word" morph="none" start_char="4671" end_char="4676">United</TOKEN>
        <TOKEN id="token-98-10" pos="word" morph="none" start_char="4678" end_char="4681">sued</TOKEN>
      </SEG>
      <SEG id="segment-99" start_char="4683" end_char="4753">
        <ORIGINAL_TEXT>the State Department for failing to disclose flight records showing who</ORIGINAL_TEXT>
        <TOKEN id="token-99-0" pos="word" morph="none" start_char="4683" end_char="4685">the</TOKEN>
        <TOKEN id="token-99-1" pos="word" morph="none" start_char="4687" end_char="4691">State</TOKEN>
        <TOKEN id="token-99-2" pos="word" morph="none" start_char="4693" end_char="4702">Department</TOKEN>
        <TOKEN id="token-99-3" pos="word" morph="none" start_char="4704" end_char="4706">for</TOKEN>
        <TOKEN id="token-99-4" pos="word" morph="none" start_char="4708" end_char="4714">failing</TOKEN>
        <TOKEN id="token-99-5" pos="word" morph="none" start_char="4716" end_char="4717">to</TOKEN>
        <TOKEN id="token-99-6" pos="word" morph="none" start_char="4719" end_char="4726">disclose</TOKEN>
        <TOKEN id="token-99-7" pos="word" morph="none" start_char="4728" end_char="4733">flight</TOKEN>
        <TOKEN id="token-99-8" pos="word" morph="none" start_char="4735" end_char="4741">records</TOKEN>
        <TOKEN id="token-99-9" pos="word" morph="none" start_char="4743" end_char="4749">showing</TOKEN>
        <TOKEN id="token-99-10" pos="word" morph="none" start_char="4751" end_char="4753">who</TOKEN>
      </SEG>
      <SEG id="segment-100" start_char="4755" end_char="4825">
        <ORIGINAL_TEXT>accompanied Clinton on overseas trips. Last week, the National Security</ORIGINAL_TEXT>
        <TOKEN id="token-100-0" pos="word" morph="none" start_char="4755" end_char="4765">accompanied</TOKEN>
        <TOKEN id="token-100-1" pos="word" morph="none" start_char="4767" end_char="4773">Clinton</TOKEN>
        <TOKEN id="token-100-2" pos="word" morph="none" start_char="4775" end_char="4776">on</TOKEN>
        <TOKEN id="token-100-3" pos="word" morph="none" start_char="4778" end_char="4785">overseas</TOKEN>
        <TOKEN id="token-100-4" pos="word" morph="none" start_char="4787" end_char="4791">trips</TOKEN>
        <TOKEN id="token-100-5" pos="punct" morph="none" start_char="4792" end_char="4792">.</TOKEN>
        <TOKEN id="token-100-6" pos="word" morph="none" start_char="4794" end_char="4797">Last</TOKEN>
        <TOKEN id="token-100-7" pos="word" morph="none" start_char="4799" end_char="4802">week</TOKEN>
        <TOKEN id="token-100-8" pos="punct" morph="none" start_char="4803" end_char="4803">,</TOKEN>
        <TOKEN id="token-100-9" pos="word" morph="none" start_char="4805" end_char="4807">the</TOKEN>
        <TOKEN id="token-100-10" pos="word" morph="none" start_char="4809" end_char="4816">National</TOKEN>
        <TOKEN id="token-100-11" pos="word" morph="none" start_char="4818" end_char="4825">Security</TOKEN>
      </SEG>
      <SEG id="segment-101" start_char="4827" end_char="4904">
        <ORIGINAL_TEXT>Archive, an organization that gathers declassified government records, filed a</ORIGINAL_TEXT>
        <TOKEN id="token-101-0" pos="word" morph="none" start_char="4827" end_char="4833">Archive</TOKEN>
        <TOKEN id="token-101-1" pos="punct" morph="none" start_char="4834" end_char="4834">,</TOKEN>
        <TOKEN id="token-101-2" pos="word" morph="none" start_char="4836" end_char="4837">an</TOKEN>
        <TOKEN id="token-101-3" pos="word" morph="none" start_char="4839" end_char="4850">organization</TOKEN>
        <TOKEN id="token-101-4" pos="word" morph="none" start_char="4852" end_char="4855">that</TOKEN>
        <TOKEN id="token-101-5" pos="word" morph="none" start_char="4857" end_char="4863">gathers</TOKEN>
        <TOKEN id="token-101-6" pos="word" morph="none" start_char="4865" end_char="4876">declassified</TOKEN>
        <TOKEN id="token-101-7" pos="word" morph="none" start_char="4878" end_char="4887">government</TOKEN>
        <TOKEN id="token-101-8" pos="word" morph="none" start_char="4889" end_char="4895">records</TOKEN>
        <TOKEN id="token-101-9" pos="punct" morph="none" start_char="4896" end_char="4896">,</TOKEN>
        <TOKEN id="token-101-10" pos="word" morph="none" start_char="4898" end_char="4902">filed</TOKEN>
        <TOKEN id="token-101-11" pos="word" morph="none" start_char="4904" end_char="4904">a</TOKEN>
      </SEG>
      <SEG id="segment-102" start_char="4906" end_char="4976">
        <ORIGINAL_TEXT>lawsuit after waiting more than seven years for the State Department to</ORIGINAL_TEXT>
        <TOKEN id="token-102-0" pos="word" morph="none" start_char="4906" end_char="4912">lawsuit</TOKEN>
        <TOKEN id="token-102-1" pos="word" morph="none" start_char="4914" end_char="4918">after</TOKEN>
        <TOKEN id="token-102-2" pos="word" morph="none" start_char="4920" end_char="4926">waiting</TOKEN>
        <TOKEN id="token-102-3" pos="word" morph="none" start_char="4928" end_char="4931">more</TOKEN>
        <TOKEN id="token-102-4" pos="word" morph="none" start_char="4933" end_char="4936">than</TOKEN>
        <TOKEN id="token-102-5" pos="word" morph="none" start_char="4938" end_char="4942">seven</TOKEN>
        <TOKEN id="token-102-6" pos="word" morph="none" start_char="4944" end_char="4948">years</TOKEN>
        <TOKEN id="token-102-7" pos="word" morph="none" start_char="4950" end_char="4952">for</TOKEN>
        <TOKEN id="token-102-8" pos="word" morph="none" start_char="4954" end_char="4956">the</TOKEN>
        <TOKEN id="token-102-9" pos="word" morph="none" start_char="4958" end_char="4962">State</TOKEN>
        <TOKEN id="token-102-10" pos="word" morph="none" start_char="4964" end_char="4973">Department</TOKEN>
        <TOKEN id="token-102-11" pos="word" morph="none" start_char="4975" end_char="4976">to</TOKEN>
      </SEG>
      <SEG id="segment-103" start_char="4978" end_char="5052">
        <ORIGINAL_TEXT>release of details of former secretary of state Henry Kissinger's telephone</ORIGINAL_TEXT>
        <TOKEN id="token-103-0" pos="word" morph="none" start_char="4978" end_char="4984">release</TOKEN>
        <TOKEN id="token-103-1" pos="word" morph="none" start_char="4986" end_char="4987">of</TOKEN>
        <TOKEN id="token-103-2" pos="word" morph="none" start_char="4989" end_char="4995">details</TOKEN>
        <TOKEN id="token-103-3" pos="word" morph="none" start_char="4997" end_char="4998">of</TOKEN>
        <TOKEN id="token-103-4" pos="word" morph="none" start_char="5000" end_char="5005">former</TOKEN>
        <TOKEN id="token-103-5" pos="word" morph="none" start_char="5007" end_char="5015">secretary</TOKEN>
        <TOKEN id="token-103-6" pos="word" morph="none" start_char="5017" end_char="5018">of</TOKEN>
        <TOKEN id="token-103-7" pos="word" morph="none" start_char="5020" end_char="5024">state</TOKEN>
        <TOKEN id="token-103-8" pos="word" morph="none" start_char="5026" end_char="5030">Henry</TOKEN>
        <TOKEN id="token-103-9" pos="word" morph="none" start_char="5032" end_char="5040">Kissinger</TOKEN>
        <TOKEN id="token-103-10" pos="punct" morph="none" start_char="5041" end_char="5041">'</TOKEN>
        <TOKEN id="token-103-11" pos="word" morph="none" start_char="5042" end_char="5042">s</TOKEN>
        <TOKEN id="token-103-12" pos="word" morph="none" start_char="5044" end_char="5052">telephone</TOKEN>
      </SEG>
      <SEG id="segment-104" start_char="5054" end_char="5067">
        <ORIGINAL_TEXT>conversations.</ORIGINAL_TEXT>
        <TOKEN id="token-104-0" pos="word" morph="none" start_char="5054" end_char="5066">conversations</TOKEN>
        <TOKEN id="token-104-1" pos="punct" morph="none" start_char="5067" end_char="5067">.</TOKEN>
      </SEG>
      <SEG id="segment-105" start_char="5069" end_char="5072">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-105-0" pos="unknown" morph="none" start_char="5069" end_char="5072">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-106" start_char="5074" end_char="5076">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-106-0" pos="unknown" morph="none" start_char="5074" end_char="5076">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-107" start_char="5078" end_char="5155">
        <ORIGINAL_TEXT>Thomas Blanton, director of the National Security Archive, predicted the State</ORIGINAL_TEXT>
        <TOKEN id="token-107-0" pos="word" morph="none" start_char="5078" end_char="5083">Thomas</TOKEN>
        <TOKEN id="token-107-1" pos="word" morph="none" start_char="5085" end_char="5091">Blanton</TOKEN>
        <TOKEN id="token-107-2" pos="punct" morph="none" start_char="5092" end_char="5092">,</TOKEN>
        <TOKEN id="token-107-3" pos="word" morph="none" start_char="5094" end_char="5101">director</TOKEN>
        <TOKEN id="token-107-4" pos="word" morph="none" start_char="5103" end_char="5104">of</TOKEN>
        <TOKEN id="token-107-5" pos="word" morph="none" start_char="5106" end_char="5108">the</TOKEN>
        <TOKEN id="token-107-6" pos="word" morph="none" start_char="5110" end_char="5117">National</TOKEN>
        <TOKEN id="token-107-7" pos="word" morph="none" start_char="5119" end_char="5126">Security</TOKEN>
        <TOKEN id="token-107-8" pos="word" morph="none" start_char="5128" end_char="5134">Archive</TOKEN>
        <TOKEN id="token-107-9" pos="punct" morph="none" start_char="5135" end_char="5135">,</TOKEN>
        <TOKEN id="token-107-10" pos="word" morph="none" start_char="5137" end_char="5145">predicted</TOKEN>
        <TOKEN id="token-107-11" pos="word" morph="none" start_char="5147" end_char="5149">the</TOKEN>
        <TOKEN id="token-107-12" pos="word" morph="none" start_char="5151" end_char="5155">State</TOKEN>
      </SEG>
      <SEG id="segment-108" start_char="5157" end_char="5232">
        <ORIGINAL_TEXT>Department would speed up its review facing legal action, particularly given</ORIGINAL_TEXT>
        <TOKEN id="token-108-0" pos="word" morph="none" start_char="5157" end_char="5166">Department</TOKEN>
        <TOKEN id="token-108-1" pos="word" morph="none" start_char="5168" end_char="5172">would</TOKEN>
        <TOKEN id="token-108-2" pos="word" morph="none" start_char="5174" end_char="5178">speed</TOKEN>
        <TOKEN id="token-108-3" pos="word" morph="none" start_char="5180" end_char="5181">up</TOKEN>
        <TOKEN id="token-108-4" pos="word" morph="none" start_char="5183" end_char="5185">its</TOKEN>
        <TOKEN id="token-108-5" pos="word" morph="none" start_char="5187" end_char="5192">review</TOKEN>
        <TOKEN id="token-108-6" pos="word" morph="none" start_char="5194" end_char="5199">facing</TOKEN>
        <TOKEN id="token-108-7" pos="word" morph="none" start_char="5201" end_char="5205">legal</TOKEN>
        <TOKEN id="token-108-8" pos="word" morph="none" start_char="5207" end_char="5212">action</TOKEN>
        <TOKEN id="token-108-9" pos="punct" morph="none" start_char="5213" end_char="5213">,</TOKEN>
        <TOKEN id="token-108-10" pos="word" morph="none" start_char="5215" end_char="5226">particularly</TOKEN>
        <TOKEN id="token-108-11" pos="word" morph="none" start_char="5228" end_char="5232">given</TOKEN>
      </SEG>
      <SEG id="segment-109" start_char="5234" end_char="5311">
        <ORIGINAL_TEXT>that Clinton has said that her email correspondence doesn't include classified</ORIGINAL_TEXT>
        <TOKEN id="token-109-0" pos="word" morph="none" start_char="5234" end_char="5237">that</TOKEN>
        <TOKEN id="token-109-1" pos="word" morph="none" start_char="5239" end_char="5245">Clinton</TOKEN>
        <TOKEN id="token-109-2" pos="word" morph="none" start_char="5247" end_char="5249">has</TOKEN>
        <TOKEN id="token-109-3" pos="word" morph="none" start_char="5251" end_char="5254">said</TOKEN>
        <TOKEN id="token-109-4" pos="word" morph="none" start_char="5256" end_char="5259">that</TOKEN>
        <TOKEN id="token-109-5" pos="word" morph="none" start_char="5261" end_char="5263">her</TOKEN>
        <TOKEN id="token-109-6" pos="word" morph="none" start_char="5265" end_char="5269">email</TOKEN>
        <TOKEN id="token-109-7" pos="word" morph="none" start_char="5271" end_char="5284">correspondence</TOKEN>
        <TOKEN id="token-109-8" pos="word" morph="none" start_char="5286" end_char="5290">doesn</TOKEN>
        <TOKEN id="token-109-9" pos="punct" morph="none" start_char="5291" end_char="5291">'</TOKEN>
        <TOKEN id="token-109-10" pos="word" morph="none" start_char="5292" end_char="5292">t</TOKEN>
        <TOKEN id="token-109-11" pos="word" morph="none" start_char="5294" end_char="5300">include</TOKEN>
        <TOKEN id="token-109-12" pos="word" morph="none" start_char="5302" end_char="5311">classified</TOKEN>
      </SEG>
      <SEG id="segment-110" start_char="5313" end_char="5321">
        <ORIGINAL_TEXT>material.</ORIGINAL_TEXT>
        <TOKEN id="token-110-0" pos="word" morph="none" start_char="5313" end_char="5320">material</TOKEN>
        <TOKEN id="token-110-1" pos="punct" morph="none" start_char="5321" end_char="5321">.</TOKEN>
      </SEG>
      <SEG id="segment-111" start_char="5323" end_char="5326">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-111-0" pos="unknown" morph="none" start_char="5323" end_char="5326">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-112" start_char="5328" end_char="5330">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-112-0" pos="unknown" morph="none" start_char="5328" end_char="5330">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-113" start_char="5332" end_char="5405">
        <ORIGINAL_TEXT>"When the government is under a court deadline, or really wants to review,</ORIGINAL_TEXT>
        <TOKEN id="token-113-0" pos="punct" morph="none" start_char="5332" end_char="5332">"</TOKEN>
        <TOKEN id="token-113-1" pos="word" morph="none" start_char="5333" end_char="5336">When</TOKEN>
        <TOKEN id="token-113-2" pos="word" morph="none" start_char="5338" end_char="5340">the</TOKEN>
        <TOKEN id="token-113-3" pos="word" morph="none" start_char="5342" end_char="5351">government</TOKEN>
        <TOKEN id="token-113-4" pos="word" morph="none" start_char="5353" end_char="5354">is</TOKEN>
        <TOKEN id="token-113-5" pos="word" morph="none" start_char="5356" end_char="5360">under</TOKEN>
        <TOKEN id="token-113-6" pos="word" morph="none" start_char="5362" end_char="5362">a</TOKEN>
        <TOKEN id="token-113-7" pos="word" morph="none" start_char="5364" end_char="5368">court</TOKEN>
        <TOKEN id="token-113-8" pos="word" morph="none" start_char="5370" end_char="5377">deadline</TOKEN>
        <TOKEN id="token-113-9" pos="punct" morph="none" start_char="5378" end_char="5378">,</TOKEN>
        <TOKEN id="token-113-10" pos="word" morph="none" start_char="5380" end_char="5381">or</TOKEN>
        <TOKEN id="token-113-11" pos="word" morph="none" start_char="5383" end_char="5388">really</TOKEN>
        <TOKEN id="token-113-12" pos="word" morph="none" start_char="5390" end_char="5394">wants</TOKEN>
        <TOKEN id="token-113-13" pos="word" morph="none" start_char="5396" end_char="5397">to</TOKEN>
        <TOKEN id="token-113-14" pos="word" morph="none" start_char="5399" end_char="5404">review</TOKEN>
        <TOKEN id="token-113-15" pos="punct" morph="none" start_char="5405" end_char="5405">,</TOKEN>
      </SEG>
      <SEG id="segment-114" start_char="5407" end_char="5479">
        <ORIGINAL_TEXT>they can whip through thousands of pages in a matter of weeks, which they</ORIGINAL_TEXT>
        <TOKEN id="token-114-0" pos="word" morph="none" start_char="5407" end_char="5410">they</TOKEN>
        <TOKEN id="token-114-1" pos="word" morph="none" start_char="5412" end_char="5414">can</TOKEN>
        <TOKEN id="token-114-2" pos="word" morph="none" start_char="5416" end_char="5419">whip</TOKEN>
        <TOKEN id="token-114-3" pos="word" morph="none" start_char="5421" end_char="5427">through</TOKEN>
        <TOKEN id="token-114-4" pos="word" morph="none" start_char="5429" end_char="5437">thousands</TOKEN>
        <TOKEN id="token-114-5" pos="word" morph="none" start_char="5439" end_char="5440">of</TOKEN>
        <TOKEN id="token-114-6" pos="word" morph="none" start_char="5442" end_char="5446">pages</TOKEN>
        <TOKEN id="token-114-7" pos="word" morph="none" start_char="5448" end_char="5449">in</TOKEN>
        <TOKEN id="token-114-8" pos="word" morph="none" start_char="5451" end_char="5451">a</TOKEN>
        <TOKEN id="token-114-9" pos="word" morph="none" start_char="5453" end_char="5458">matter</TOKEN>
        <TOKEN id="token-114-10" pos="word" morph="none" start_char="5460" end_char="5461">of</TOKEN>
        <TOKEN id="token-114-11" pos="word" morph="none" start_char="5463" end_char="5467">weeks</TOKEN>
        <TOKEN id="token-114-12" pos="punct" morph="none" start_char="5468" end_char="5468">,</TOKEN>
        <TOKEN id="token-114-13" pos="word" morph="none" start_char="5470" end_char="5474">which</TOKEN>
        <TOKEN id="token-114-14" pos="word" morph="none" start_char="5476" end_char="5479">they</TOKEN>
      </SEG>
      <SEG id="segment-115" start_char="5481" end_char="5510">
        <ORIGINAL_TEXT>should do here," Blanton said.</ORIGINAL_TEXT>
        <TOKEN id="token-115-0" pos="word" morph="none" start_char="5481" end_char="5486">should</TOKEN>
        <TOKEN id="token-115-1" pos="word" morph="none" start_char="5488" end_char="5489">do</TOKEN>
        <TOKEN id="token-115-2" pos="word" morph="none" start_char="5491" end_char="5494">here</TOKEN>
        <TOKEN id="token-115-3" pos="punct" morph="none" start_char="5495" end_char="5496">,"</TOKEN>
        <TOKEN id="token-115-4" pos="word" morph="none" start_char="5498" end_char="5504">Blanton</TOKEN>
        <TOKEN id="token-115-5" pos="word" morph="none" start_char="5506" end_char="5509">said</TOKEN>
        <TOKEN id="token-115-6" pos="punct" morph="none" start_char="5510" end_char="5510">.</TOKEN>
      </SEG>
      <SEG id="segment-116" start_char="5512" end_char="5515">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-116-0" pos="unknown" morph="none" start_char="5512" end_char="5515">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-117" start_char="5517" end_char="5519">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-117-0" pos="unknown" morph="none" start_char="5517" end_char="5519">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-118" start_char="5521" end_char="5595">
        <ORIGINAL_TEXT>The State Department generally takes about 450 days to turn over records it</ORIGINAL_TEXT>
        <TOKEN id="token-118-0" pos="word" morph="none" start_char="5521" end_char="5523">The</TOKEN>
        <TOKEN id="token-118-1" pos="word" morph="none" start_char="5525" end_char="5529">State</TOKEN>
        <TOKEN id="token-118-2" pos="word" morph="none" start_char="5531" end_char="5540">Department</TOKEN>
        <TOKEN id="token-118-3" pos="word" morph="none" start_char="5542" end_char="5550">generally</TOKEN>
        <TOKEN id="token-118-4" pos="word" morph="none" start_char="5552" end_char="5556">takes</TOKEN>
        <TOKEN id="token-118-5" pos="word" morph="none" start_char="5558" end_char="5562">about</TOKEN>
        <TOKEN id="token-118-6" pos="number" morph="none" start_char="5564" end_char="5566">450</TOKEN>
        <TOKEN id="token-118-7" pos="word" morph="none" start_char="5568" end_char="5571">days</TOKEN>
        <TOKEN id="token-118-8" pos="word" morph="none" start_char="5573" end_char="5574">to</TOKEN>
        <TOKEN id="token-118-9" pos="word" morph="none" start_char="5576" end_char="5579">turn</TOKEN>
        <TOKEN id="token-118-10" pos="word" morph="none" start_char="5581" end_char="5584">over</TOKEN>
        <TOKEN id="token-118-11" pos="word" morph="none" start_char="5586" end_char="5592">records</TOKEN>
        <TOKEN id="token-118-12" pos="word" morph="none" start_char="5594" end_char="5595">it</TOKEN>
      </SEG>
      <SEG id="segment-119" start_char="5597" end_char="5674">
        <ORIGINAL_TEXT>considers to be part of complex requests under the Freedom of Information Act.</ORIGINAL_TEXT>
        <TOKEN id="token-119-0" pos="word" morph="none" start_char="5597" end_char="5605">considers</TOKEN>
        <TOKEN id="token-119-1" pos="word" morph="none" start_char="5607" end_char="5608">to</TOKEN>
        <TOKEN id="token-119-2" pos="word" morph="none" start_char="5610" end_char="5611">be</TOKEN>
        <TOKEN id="token-119-3" pos="word" morph="none" start_char="5613" end_char="5616">part</TOKEN>
        <TOKEN id="token-119-4" pos="word" morph="none" start_char="5618" end_char="5619">of</TOKEN>
        <TOKEN id="token-119-5" pos="word" morph="none" start_char="5621" end_char="5627">complex</TOKEN>
        <TOKEN id="token-119-6" pos="word" morph="none" start_char="5629" end_char="5636">requests</TOKEN>
        <TOKEN id="token-119-7" pos="word" morph="none" start_char="5638" end_char="5642">under</TOKEN>
        <TOKEN id="token-119-8" pos="word" morph="none" start_char="5644" end_char="5646">the</TOKEN>
        <TOKEN id="token-119-9" pos="word" morph="none" start_char="5648" end_char="5654">Freedom</TOKEN>
        <TOKEN id="token-119-10" pos="word" morph="none" start_char="5656" end_char="5657">of</TOKEN>
        <TOKEN id="token-119-11" pos="word" morph="none" start_char="5659" end_char="5669">Information</TOKEN>
        <TOKEN id="token-119-12" pos="word" morph="none" start_char="5671" end_char="5673">Act</TOKEN>
        <TOKEN id="token-119-13" pos="punct" morph="none" start_char="5674" end_char="5674">.</TOKEN>
      </SEG>
      <SEG id="segment-120" start_char="5676" end_char="5751">
        <ORIGINAL_TEXT>That is seven times longer than the Justice Department and CIA, and 30 times</ORIGINAL_TEXT>
        <TOKEN id="token-120-0" pos="word" morph="none" start_char="5676" end_char="5679">That</TOKEN>
        <TOKEN id="token-120-1" pos="word" morph="none" start_char="5681" end_char="5682">is</TOKEN>
        <TOKEN id="token-120-2" pos="word" morph="none" start_char="5684" end_char="5688">seven</TOKEN>
        <TOKEN id="token-120-3" pos="word" morph="none" start_char="5690" end_char="5694">times</TOKEN>
        <TOKEN id="token-120-4" pos="word" morph="none" start_char="5696" end_char="5701">longer</TOKEN>
        <TOKEN id="token-120-5" pos="word" morph="none" start_char="5703" end_char="5706">than</TOKEN>
        <TOKEN id="token-120-6" pos="word" morph="none" start_char="5708" end_char="5710">the</TOKEN>
        <TOKEN id="token-120-7" pos="word" morph="none" start_char="5712" end_char="5718">Justice</TOKEN>
        <TOKEN id="token-120-8" pos="word" morph="none" start_char="5720" end_char="5729">Department</TOKEN>
        <TOKEN id="token-120-9" pos="word" morph="none" start_char="5731" end_char="5733">and</TOKEN>
        <TOKEN id="token-120-10" pos="word" morph="none" start_char="5735" end_char="5737">CIA</TOKEN>
        <TOKEN id="token-120-11" pos="punct" morph="none" start_char="5738" end_char="5738">,</TOKEN>
        <TOKEN id="token-120-12" pos="word" morph="none" start_char="5740" end_char="5742">and</TOKEN>
        <TOKEN id="token-120-13" pos="number" morph="none" start_char="5744" end_char="5745">30</TOKEN>
        <TOKEN id="token-120-14" pos="word" morph="none" start_char="5747" end_char="5751">times</TOKEN>
      </SEG>
      <SEG id="segment-121" start_char="5753" end_char="5788">
        <ORIGINAL_TEXT>longer than the Treasury Department.</ORIGINAL_TEXT>
        <TOKEN id="token-121-0" pos="word" morph="none" start_char="5753" end_char="5758">longer</TOKEN>
        <TOKEN id="token-121-1" pos="word" morph="none" start_char="5760" end_char="5763">than</TOKEN>
        <TOKEN id="token-121-2" pos="word" morph="none" start_char="5765" end_char="5767">the</TOKEN>
        <TOKEN id="token-121-3" pos="word" morph="none" start_char="5769" end_char="5776">Treasury</TOKEN>
        <TOKEN id="token-121-4" pos="word" morph="none" start_char="5778" end_char="5787">Department</TOKEN>
        <TOKEN id="token-121-5" pos="punct" morph="none" start_char="5788" end_char="5788">.</TOKEN>
      </SEG>
      <SEG id="segment-122" start_char="5790" end_char="5793">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-122-0" pos="unknown" morph="none" start_char="5790" end_char="5793">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-123" start_char="5795" end_char="5797">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-123-0" pos="unknown" morph="none" start_char="5795" end_char="5797">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-124" start_char="5799" end_char="5869">
        <ORIGINAL_TEXT>An inspector general's report in 2012 criticized the State Department's</ORIGINAL_TEXT>
        <TOKEN id="token-124-0" pos="word" morph="none" start_char="5799" end_char="5800">An</TOKEN>
        <TOKEN id="token-124-1" pos="word" morph="none" start_char="5802" end_char="5810">inspector</TOKEN>
        <TOKEN id="token-124-2" pos="word" morph="none" start_char="5812" end_char="5818">general</TOKEN>
        <TOKEN id="token-124-3" pos="punct" morph="none" start_char="5819" end_char="5819">'</TOKEN>
        <TOKEN id="token-124-4" pos="word" morph="none" start_char="5820" end_char="5820">s</TOKEN>
        <TOKEN id="token-124-5" pos="word" morph="none" start_char="5822" end_char="5827">report</TOKEN>
        <TOKEN id="token-124-6" pos="word" morph="none" start_char="5829" end_char="5830">in</TOKEN>
        <TOKEN id="token-124-7" pos="number" morph="none" start_char="5832" end_char="5835">2012</TOKEN>
        <TOKEN id="token-124-8" pos="word" morph="none" start_char="5837" end_char="5846">criticized</TOKEN>
        <TOKEN id="token-124-9" pos="word" morph="none" start_char="5848" end_char="5850">the</TOKEN>
        <TOKEN id="token-124-10" pos="word" morph="none" start_char="5852" end_char="5856">State</TOKEN>
        <TOKEN id="token-124-11" pos="word" morph="none" start_char="5858" end_char="5867">Department</TOKEN>
        <TOKEN id="token-124-12" pos="punct" morph="none" start_char="5868" end_char="5868">'</TOKEN>
        <TOKEN id="token-124-13" pos="word" morph="none" start_char="5869" end_char="5869">s</TOKEN>
      </SEG>
      <SEG id="segment-125" start_char="5871" end_char="5944">
        <ORIGINAL_TEXT>practices as "inefficient and ineffective," citing a heavy workload, small</ORIGINAL_TEXT>
        <TOKEN id="token-125-0" pos="word" morph="none" start_char="5871" end_char="5879">practices</TOKEN>
        <TOKEN id="token-125-1" pos="word" morph="none" start_char="5881" end_char="5882">as</TOKEN>
        <TOKEN id="token-125-2" pos="punct" morph="none" start_char="5884" end_char="5884">"</TOKEN>
        <TOKEN id="token-125-3" pos="word" morph="none" start_char="5885" end_char="5895">inefficient</TOKEN>
        <TOKEN id="token-125-4" pos="word" morph="none" start_char="5897" end_char="5899">and</TOKEN>
        <TOKEN id="token-125-5" pos="word" morph="none" start_char="5901" end_char="5911">ineffective</TOKEN>
        <TOKEN id="token-125-6" pos="punct" morph="none" start_char="5912" end_char="5913">,"</TOKEN>
        <TOKEN id="token-125-7" pos="word" morph="none" start_char="5915" end_char="5920">citing</TOKEN>
        <TOKEN id="token-125-8" pos="word" morph="none" start_char="5922" end_char="5922">a</TOKEN>
        <TOKEN id="token-125-9" pos="word" morph="none" start_char="5924" end_char="5928">heavy</TOKEN>
        <TOKEN id="token-125-10" pos="word" morph="none" start_char="5930" end_char="5937">workload</TOKEN>
        <TOKEN id="token-125-11" pos="punct" morph="none" start_char="5938" end_char="5938">,</TOKEN>
        <TOKEN id="token-125-12" pos="word" morph="none" start_char="5940" end_char="5944">small</TOKEN>
      </SEG>
      <SEG id="segment-126" start_char="5946" end_char="5976">
        <ORIGINAL_TEXT>staff and interagency problems.</ORIGINAL_TEXT>
        <TOKEN id="token-126-0" pos="word" morph="none" start_char="5946" end_char="5950">staff</TOKEN>
        <TOKEN id="token-126-1" pos="word" morph="none" start_char="5952" end_char="5954">and</TOKEN>
        <TOKEN id="token-126-2" pos="word" morph="none" start_char="5956" end_char="5966">interagency</TOKEN>
        <TOKEN id="token-126-3" pos="word" morph="none" start_char="5968" end_char="5975">problems</TOKEN>
        <TOKEN id="token-126-4" pos="punct" morph="none" start_char="5976" end_char="5976">.</TOKEN>
      </SEG>
      <SEG id="segment-127" start_char="5978" end_char="5981">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-127-0" pos="unknown" morph="none" start_char="5978" end_char="5981">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-128" start_char="5983" end_char="5989">
        <ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-128-0" pos="unknown" morph="none" start_char="5983" end_char="5989">&lt;/TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-129" start_char="5991" end_char="5996">
        <ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-129-0" pos="unknown" morph="none" start_char="5991" end_char="5996">&lt;/DOC&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
