<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="ENG_NW_001051_20150329_F0000001Y.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="2262" raw_text_md5="8ebe6bd2e724371b118132136e5a304b">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001051_20150329_F0000001Y"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001051_20150329_F0000001Y"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="183">
        <ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.thelocal.ch/20150329/iran-journalist-covering-lausanne-talks-seeks-asylum&lt;/SOURCE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="183">&lt;SOURCE&gt;http://www.thelocal.ch/20150329/iran-journalist-covering-lausanne-talks-seeks-asylum&lt;/SOURCE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="185" end_char="226">
        <ORIGINAL_TEXT>&lt;DATE_TIME&gt;2015-03-29T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="unknown" morph="none" start_char="185" end_char="226">&lt;DATE_TIME&gt;2015-03-29T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="228" end_char="237">
        <ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="228" end_char="237">&lt;HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="239" end_char="286">
        <ORIGINAL_TEXT>Iran journo at Lausanne talks seeks Swiss asylum</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="word" morph="none" start_char="239" end_char="242">Iran</TOKEN>
        <TOKEN id="token-5-1" pos="word" morph="none" start_char="244" end_char="249">journo</TOKEN>
        <TOKEN id="token-5-2" pos="word" morph="none" start_char="251" end_char="252">at</TOKEN>
        <TOKEN id="token-5-3" pos="word" morph="none" start_char="254" end_char="261">Lausanne</TOKEN>
        <TOKEN id="token-5-4" pos="word" morph="none" start_char="263" end_char="267">talks</TOKEN>
        <TOKEN id="token-5-5" pos="word" morph="none" start_char="269" end_char="273">seeks</TOKEN>
        <TOKEN id="token-5-6" pos="word" morph="none" start_char="275" end_char="279">Swiss</TOKEN>
        <TOKEN id="token-5-7" pos="word" morph="none" start_char="281" end_char="286">asylum</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="288" end_char="298">
        <ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="unknown" morph="none" start_char="288" end_char="298">&lt;/HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="300" end_char="305">
        <ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="300" end_char="305">&lt;TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="307" end_char="309">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="307" end_char="309">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="311" end_char="381">
        <ORIGINAL_TEXT>In the margins of intense talks in Lausanne to reach a deal over Iran’s</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="311" end_char="312">In</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="314" end_char="316">the</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="318" end_char="324">margins</TOKEN>
        <TOKEN id="token-9-3" pos="word" morph="none" start_char="326" end_char="327">of</TOKEN>
        <TOKEN id="token-9-4" pos="word" morph="none" start_char="329" end_char="335">intense</TOKEN>
        <TOKEN id="token-9-5" pos="word" morph="none" start_char="337" end_char="341">talks</TOKEN>
        <TOKEN id="token-9-6" pos="word" morph="none" start_char="343" end_char="344">in</TOKEN>
        <TOKEN id="token-9-7" pos="word" morph="none" start_char="346" end_char="353">Lausanne</TOKEN>
        <TOKEN id="token-9-8" pos="word" morph="none" start_char="355" end_char="356">to</TOKEN>
        <TOKEN id="token-9-9" pos="word" morph="none" start_char="358" end_char="362">reach</TOKEN>
        <TOKEN id="token-9-10" pos="word" morph="none" start_char="364" end_char="364">a</TOKEN>
        <TOKEN id="token-9-11" pos="word" morph="none" start_char="366" end_char="369">deal</TOKEN>
        <TOKEN id="token-9-12" pos="word" morph="none" start_char="371" end_char="374">over</TOKEN>
        <TOKEN id="token-9-13" pos="word" morph="none" start_char="376" end_char="379">Iran</TOKEN>
        <TOKEN id="token-9-14" pos="punct" morph="none" start_char="380" end_char="380">’</TOKEN>
        <TOKEN id="token-9-15" pos="word" morph="none" start_char="381" end_char="381">s</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="383" end_char="457">
        <ORIGINAL_TEXT>nuclear future over the weekend an Iranian journalist took advantage of the</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="word" morph="none" start_char="383" end_char="389">nuclear</TOKEN>
        <TOKEN id="token-10-1" pos="word" morph="none" start_char="391" end_char="396">future</TOKEN>
        <TOKEN id="token-10-2" pos="word" morph="none" start_char="398" end_char="401">over</TOKEN>
        <TOKEN id="token-10-3" pos="word" morph="none" start_char="403" end_char="405">the</TOKEN>
        <TOKEN id="token-10-4" pos="word" morph="none" start_char="407" end_char="413">weekend</TOKEN>
        <TOKEN id="token-10-5" pos="word" morph="none" start_char="415" end_char="416">an</TOKEN>
        <TOKEN id="token-10-6" pos="word" morph="none" start_char="418" end_char="424">Iranian</TOKEN>
        <TOKEN id="token-10-7" pos="word" morph="none" start_char="426" end_char="435">journalist</TOKEN>
        <TOKEN id="token-10-8" pos="word" morph="none" start_char="437" end_char="440">took</TOKEN>
        <TOKEN id="token-10-9" pos="word" morph="none" start_char="442" end_char="450">advantage</TOKEN>
        <TOKEN id="token-10-10" pos="word" morph="none" start_char="452" end_char="453">of</TOKEN>
        <TOKEN id="token-10-11" pos="word" morph="none" start_char="455" end_char="457">the</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="459" end_char="532">
        <ORIGINAL_TEXT>situation to file a request for asylum in Switzerland, media reports said.</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="word" morph="none" start_char="459" end_char="467">situation</TOKEN>
        <TOKEN id="token-11-1" pos="word" morph="none" start_char="469" end_char="470">to</TOKEN>
        <TOKEN id="token-11-2" pos="word" morph="none" start_char="472" end_char="475">file</TOKEN>
        <TOKEN id="token-11-3" pos="word" morph="none" start_char="477" end_char="477">a</TOKEN>
        <TOKEN id="token-11-4" pos="word" morph="none" start_char="479" end_char="485">request</TOKEN>
        <TOKEN id="token-11-5" pos="word" morph="none" start_char="487" end_char="489">for</TOKEN>
        <TOKEN id="token-11-6" pos="word" morph="none" start_char="491" end_char="496">asylum</TOKEN>
        <TOKEN id="token-11-7" pos="word" morph="none" start_char="498" end_char="499">in</TOKEN>
        <TOKEN id="token-11-8" pos="word" morph="none" start_char="501" end_char="511">Switzerland</TOKEN>
        <TOKEN id="token-11-9" pos="punct" morph="none" start_char="512" end_char="512">,</TOKEN>
        <TOKEN id="token-11-10" pos="word" morph="none" start_char="514" end_char="518">media</TOKEN>
        <TOKEN id="token-11-11" pos="word" morph="none" start_char="520" end_char="526">reports</TOKEN>
        <TOKEN id="token-11-12" pos="word" morph="none" start_char="528" end_char="531">said</TOKEN>
        <TOKEN id="token-11-13" pos="punct" morph="none" start_char="532" end_char="532">.</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="534" end_char="537">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="unknown" morph="none" start_char="534" end_char="537">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="539" end_char="541">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="unknown" morph="none" start_char="539" end_char="541">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="543" end_char="610">
        <ORIGINAL_TEXT>The journalist was working for Iscanews, a news site managed by Azad</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="word" morph="none" start_char="543" end_char="545">The</TOKEN>
        <TOKEN id="token-14-1" pos="word" morph="none" start_char="547" end_char="556">journalist</TOKEN>
        <TOKEN id="token-14-2" pos="word" morph="none" start_char="558" end_char="560">was</TOKEN>
        <TOKEN id="token-14-3" pos="word" morph="none" start_char="562" end_char="568">working</TOKEN>
        <TOKEN id="token-14-4" pos="word" morph="none" start_char="570" end_char="572">for</TOKEN>
        <TOKEN id="token-14-5" pos="word" morph="none" start_char="574" end_char="581">Iscanews</TOKEN>
        <TOKEN id="token-14-6" pos="punct" morph="none" start_char="582" end_char="582">,</TOKEN>
        <TOKEN id="token-14-7" pos="word" morph="none" start_char="584" end_char="584">a</TOKEN>
        <TOKEN id="token-14-8" pos="word" morph="none" start_char="586" end_char="589">news</TOKEN>
        <TOKEN id="token-14-9" pos="word" morph="none" start_char="591" end_char="594">site</TOKEN>
        <TOKEN id="token-14-10" pos="word" morph="none" start_char="596" end_char="602">managed</TOKEN>
        <TOKEN id="token-14-11" pos="word" morph="none" start_char="604" end_char="605">by</TOKEN>
        <TOKEN id="token-14-12" pos="word" morph="none" start_char="607" end_char="610">Azad</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="612" end_char="672">
        <ORIGINAL_TEXT>University in Tehran, which also has other sites across Iran.</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="word" morph="none" start_char="612" end_char="621">University</TOKEN>
        <TOKEN id="token-15-1" pos="word" morph="none" start_char="623" end_char="624">in</TOKEN>
        <TOKEN id="token-15-2" pos="word" morph="none" start_char="626" end_char="631">Tehran</TOKEN>
        <TOKEN id="token-15-3" pos="punct" morph="none" start_char="632" end_char="632">,</TOKEN>
        <TOKEN id="token-15-4" pos="word" morph="none" start_char="634" end_char="638">which</TOKEN>
        <TOKEN id="token-15-5" pos="word" morph="none" start_char="640" end_char="643">also</TOKEN>
        <TOKEN id="token-15-6" pos="word" morph="none" start_char="645" end_char="647">has</TOKEN>
        <TOKEN id="token-15-7" pos="word" morph="none" start_char="649" end_char="653">other</TOKEN>
        <TOKEN id="token-15-8" pos="word" morph="none" start_char="655" end_char="659">sites</TOKEN>
        <TOKEN id="token-15-9" pos="word" morph="none" start_char="661" end_char="666">across</TOKEN>
        <TOKEN id="token-15-10" pos="word" morph="none" start_char="668" end_char="671">Iran</TOKEN>
        <TOKEN id="token-15-11" pos="punct" morph="none" start_char="672" end_char="672">.</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="674" end_char="677">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="unknown" morph="none" start_char="674" end_char="677">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="679" end_char="681">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="unknown" morph="none" start_char="679" end_char="681">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="683" end_char="753">
        <ORIGINAL_TEXT>Iscanews confirmed the development, the Swiss ATS news agency reported.</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="word" morph="none" start_char="683" end_char="690">Iscanews</TOKEN>
        <TOKEN id="token-18-1" pos="word" morph="none" start_char="692" end_char="700">confirmed</TOKEN>
        <TOKEN id="token-18-2" pos="word" morph="none" start_char="702" end_char="704">the</TOKEN>
        <TOKEN id="token-18-3" pos="word" morph="none" start_char="706" end_char="716">development</TOKEN>
        <TOKEN id="token-18-4" pos="punct" morph="none" start_char="717" end_char="717">,</TOKEN>
        <TOKEN id="token-18-5" pos="word" morph="none" start_char="719" end_char="721">the</TOKEN>
        <TOKEN id="token-18-6" pos="word" morph="none" start_char="723" end_char="727">Swiss</TOKEN>
        <TOKEN id="token-18-7" pos="word" morph="none" start_char="729" end_char="731">ATS</TOKEN>
        <TOKEN id="token-18-8" pos="word" morph="none" start_char="733" end_char="736">news</TOKEN>
        <TOKEN id="token-18-9" pos="word" morph="none" start_char="738" end_char="743">agency</TOKEN>
        <TOKEN id="token-18-10" pos="word" morph="none" start_char="745" end_char="752">reported</TOKEN>
        <TOKEN id="token-18-11" pos="punct" morph="none" start_char="753" end_char="753">.</TOKEN>
      </SEG>
      <SEG id="segment-19" start_char="755" end_char="758">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-19-0" pos="unknown" morph="none" start_char="755" end_char="758">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-20" start_char="760" end_char="762">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-20-0" pos="unknown" morph="none" start_char="760" end_char="762">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-21" start_char="764" end_char="836">
        <ORIGINAL_TEXT>The journalist had been sent to Lausanne to cover the negotiations with a</ORIGINAL_TEXT>
        <TOKEN id="token-21-0" pos="word" morph="none" start_char="764" end_char="766">The</TOKEN>
        <TOKEN id="token-21-1" pos="word" morph="none" start_char="768" end_char="777">journalist</TOKEN>
        <TOKEN id="token-21-2" pos="word" morph="none" start_char="779" end_char="781">had</TOKEN>
        <TOKEN id="token-21-3" pos="word" morph="none" start_char="783" end_char="786">been</TOKEN>
        <TOKEN id="token-21-4" pos="word" morph="none" start_char="788" end_char="791">sent</TOKEN>
        <TOKEN id="token-21-5" pos="word" morph="none" start_char="793" end_char="794">to</TOKEN>
        <TOKEN id="token-21-6" pos="word" morph="none" start_char="796" end_char="803">Lausanne</TOKEN>
        <TOKEN id="token-21-7" pos="word" morph="none" start_char="805" end_char="806">to</TOKEN>
        <TOKEN id="token-21-8" pos="word" morph="none" start_char="808" end_char="812">cover</TOKEN>
        <TOKEN id="token-21-9" pos="word" morph="none" start_char="814" end_char="816">the</TOKEN>
        <TOKEN id="token-21-10" pos="word" morph="none" start_char="818" end_char="829">negotiations</TOKEN>
        <TOKEN id="token-21-11" pos="word" morph="none" start_char="831" end_char="834">with</TOKEN>
        <TOKEN id="token-21-12" pos="word" morph="none" start_char="836" end_char="836">a</TOKEN>
      </SEG>
      <SEG id="segment-22" start_char="838" end_char="879">
        <ORIGINAL_TEXT>photographer, German news agency DPA said.</ORIGINAL_TEXT>
        <TOKEN id="token-22-0" pos="word" morph="none" start_char="838" end_char="849">photographer</TOKEN>
        <TOKEN id="token-22-1" pos="punct" morph="none" start_char="850" end_char="850">,</TOKEN>
        <TOKEN id="token-22-2" pos="word" morph="none" start_char="852" end_char="857">German</TOKEN>
        <TOKEN id="token-22-3" pos="word" morph="none" start_char="859" end_char="862">news</TOKEN>
        <TOKEN id="token-22-4" pos="word" morph="none" start_char="864" end_char="869">agency</TOKEN>
        <TOKEN id="token-22-5" pos="word" morph="none" start_char="871" end_char="873">DPA</TOKEN>
        <TOKEN id="token-22-6" pos="word" morph="none" start_char="875" end_char="878">said</TOKEN>
        <TOKEN id="token-22-7" pos="punct" morph="none" start_char="879" end_char="879">.</TOKEN>
      </SEG>
      <SEG id="segment-23" start_char="881" end_char="884">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-23-0" pos="unknown" morph="none" start_char="881" end_char="884">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-24" start_char="886" end_char="888">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-24-0" pos="unknown" morph="none" start_char="886" end_char="888">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-25" start_char="890" end_char="959">
        <ORIGINAL_TEXT>The state secretariat for migration in Bern declined to comment on the</ORIGINAL_TEXT>
        <TOKEN id="token-25-0" pos="word" morph="none" start_char="890" end_char="892">The</TOKEN>
        <TOKEN id="token-25-1" pos="word" morph="none" start_char="894" end_char="898">state</TOKEN>
        <TOKEN id="token-25-2" pos="word" morph="none" start_char="900" end_char="910">secretariat</TOKEN>
        <TOKEN id="token-25-3" pos="word" morph="none" start_char="912" end_char="914">for</TOKEN>
        <TOKEN id="token-25-4" pos="word" morph="none" start_char="916" end_char="924">migration</TOKEN>
        <TOKEN id="token-25-5" pos="word" morph="none" start_char="926" end_char="927">in</TOKEN>
        <TOKEN id="token-25-6" pos="word" morph="none" start_char="929" end_char="932">Bern</TOKEN>
        <TOKEN id="token-25-7" pos="word" morph="none" start_char="934" end_char="941">declined</TOKEN>
        <TOKEN id="token-25-8" pos="word" morph="none" start_char="943" end_char="944">to</TOKEN>
        <TOKEN id="token-25-9" pos="word" morph="none" start_char="946" end_char="952">comment</TOKEN>
        <TOKEN id="token-25-10" pos="word" morph="none" start_char="954" end_char="955">on</TOKEN>
        <TOKEN id="token-25-11" pos="word" morph="none" start_char="957" end_char="959">the</TOKEN>
      </SEG>
      <SEG id="segment-26" start_char="961" end_char="970">
        <ORIGINAL_TEXT>situation.</ORIGINAL_TEXT>
        <TOKEN id="token-26-0" pos="word" morph="none" start_char="961" end_char="969">situation</TOKEN>
        <TOKEN id="token-26-1" pos="punct" morph="none" start_char="970" end_char="970">.</TOKEN>
      </SEG>
      <SEG id="segment-27" start_char="972" end_char="975">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-27-0" pos="unknown" morph="none" start_char="972" end_char="975">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-28" start_char="977" end_char="979">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-28-0" pos="unknown" morph="none" start_char="977" end_char="979">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-29" start_char="981" end_char="1047">
        <ORIGINAL_TEXT>It does not give information on particular cases because of privacy</ORIGINAL_TEXT>
        <TOKEN id="token-29-0" pos="word" morph="none" start_char="981" end_char="982">It</TOKEN>
        <TOKEN id="token-29-1" pos="word" morph="none" start_char="984" end_char="987">does</TOKEN>
        <TOKEN id="token-29-2" pos="word" morph="none" start_char="989" end_char="991">not</TOKEN>
        <TOKEN id="token-29-3" pos="word" morph="none" start_char="993" end_char="996">give</TOKEN>
        <TOKEN id="token-29-4" pos="word" morph="none" start_char="998" end_char="1008">information</TOKEN>
        <TOKEN id="token-29-5" pos="word" morph="none" start_char="1010" end_char="1011">on</TOKEN>
        <TOKEN id="token-29-6" pos="word" morph="none" start_char="1013" end_char="1022">particular</TOKEN>
        <TOKEN id="token-29-7" pos="word" morph="none" start_char="1024" end_char="1028">cases</TOKEN>
        <TOKEN id="token-29-8" pos="word" morph="none" start_char="1030" end_char="1036">because</TOKEN>
        <TOKEN id="token-29-9" pos="word" morph="none" start_char="1038" end_char="1039">of</TOKEN>
        <TOKEN id="token-29-10" pos="word" morph="none" start_char="1041" end_char="1047">privacy</TOKEN>
      </SEG>
      <SEG id="segment-30" start_char="1049" end_char="1104">
        <ORIGINAL_TEXT>legislation, a spokeswoman for the secretariat told ATS.</ORIGINAL_TEXT>
        <TOKEN id="token-30-0" pos="word" morph="none" start_char="1049" end_char="1059">legislation</TOKEN>
        <TOKEN id="token-30-1" pos="punct" morph="none" start_char="1060" end_char="1060">,</TOKEN>
        <TOKEN id="token-30-2" pos="word" morph="none" start_char="1062" end_char="1062">a</TOKEN>
        <TOKEN id="token-30-3" pos="word" morph="none" start_char="1064" end_char="1074">spokeswoman</TOKEN>
        <TOKEN id="token-30-4" pos="word" morph="none" start_char="1076" end_char="1078">for</TOKEN>
        <TOKEN id="token-30-5" pos="word" morph="none" start_char="1080" end_char="1082">the</TOKEN>
        <TOKEN id="token-30-6" pos="word" morph="none" start_char="1084" end_char="1094">secretariat</TOKEN>
        <TOKEN id="token-30-7" pos="word" morph="none" start_char="1096" end_char="1099">told</TOKEN>
        <TOKEN id="token-30-8" pos="word" morph="none" start_char="1101" end_char="1103">ATS</TOKEN>
        <TOKEN id="token-30-9" pos="punct" morph="none" start_char="1104" end_char="1104">.</TOKEN>
      </SEG>
      <SEG id="segment-31" start_char="1106" end_char="1109">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-31-0" pos="unknown" morph="none" start_char="1106" end_char="1109">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-32" start_char="1111" end_char="1113">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-32-0" pos="unknown" morph="none" start_char="1111" end_char="1113">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-33" start_char="1115" end_char="1191">
        <ORIGINAL_TEXT>The development occurred on the sidelines of negotiations that aimed to reach</ORIGINAL_TEXT>
        <TOKEN id="token-33-0" pos="word" morph="none" start_char="1115" end_char="1117">The</TOKEN>
        <TOKEN id="token-33-1" pos="word" morph="none" start_char="1119" end_char="1129">development</TOKEN>
        <TOKEN id="token-33-2" pos="word" morph="none" start_char="1131" end_char="1138">occurred</TOKEN>
        <TOKEN id="token-33-3" pos="word" morph="none" start_char="1140" end_char="1141">on</TOKEN>
        <TOKEN id="token-33-4" pos="word" morph="none" start_char="1143" end_char="1145">the</TOKEN>
        <TOKEN id="token-33-5" pos="word" morph="none" start_char="1147" end_char="1155">sidelines</TOKEN>
        <TOKEN id="token-33-6" pos="word" morph="none" start_char="1157" end_char="1158">of</TOKEN>
        <TOKEN id="token-33-7" pos="word" morph="none" start_char="1160" end_char="1171">negotiations</TOKEN>
        <TOKEN id="token-33-8" pos="word" morph="none" start_char="1173" end_char="1176">that</TOKEN>
        <TOKEN id="token-33-9" pos="word" morph="none" start_char="1178" end_char="1182">aimed</TOKEN>
        <TOKEN id="token-33-10" pos="word" morph="none" start_char="1184" end_char="1185">to</TOKEN>
        <TOKEN id="token-33-11" pos="word" morph="none" start_char="1187" end_char="1191">reach</TOKEN>
      </SEG>
      <SEG id="segment-34" start_char="1193" end_char="1246">
        <ORIGINAL_TEXT>a deal on Iran's nuclear future by a Tuesday deadline.</ORIGINAL_TEXT>
        <TOKEN id="token-34-0" pos="word" morph="none" start_char="1193" end_char="1193">a</TOKEN>
        <TOKEN id="token-34-1" pos="word" morph="none" start_char="1195" end_char="1198">deal</TOKEN>
        <TOKEN id="token-34-2" pos="word" morph="none" start_char="1200" end_char="1201">on</TOKEN>
        <TOKEN id="token-34-3" pos="word" morph="none" start_char="1203" end_char="1206">Iran</TOKEN>
        <TOKEN id="token-34-4" pos="punct" morph="none" start_char="1207" end_char="1207">'</TOKEN>
        <TOKEN id="token-34-5" pos="word" morph="none" start_char="1208" end_char="1208">s</TOKEN>
        <TOKEN id="token-34-6" pos="word" morph="none" start_char="1210" end_char="1216">nuclear</TOKEN>
        <TOKEN id="token-34-7" pos="word" morph="none" start_char="1218" end_char="1223">future</TOKEN>
        <TOKEN id="token-34-8" pos="word" morph="none" start_char="1225" end_char="1226">by</TOKEN>
        <TOKEN id="token-34-9" pos="word" morph="none" start_char="1228" end_char="1228">a</TOKEN>
        <TOKEN id="token-34-10" pos="word" morph="none" start_char="1230" end_char="1236">Tuesday</TOKEN>
        <TOKEN id="token-34-11" pos="word" morph="none" start_char="1238" end_char="1245">deadline</TOKEN>
        <TOKEN id="token-34-12" pos="punct" morph="none" start_char="1246" end_char="1246">.</TOKEN>
      </SEG>
      <SEG id="segment-35" start_char="1248" end_char="1251">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-35-0" pos="unknown" morph="none" start_char="1248" end_char="1251">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-36" start_char="1253" end_char="1255">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-36-0" pos="unknown" morph="none" start_char="1253" end_char="1255">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-37" start_char="1257" end_char="1330">
        <ORIGINAL_TEXT>An agreement between Iran and world powers is "doable" with "two or three"</ORIGINAL_TEXT>
        <TOKEN id="token-37-0" pos="word" morph="none" start_char="1257" end_char="1258">An</TOKEN>
        <TOKEN id="token-37-1" pos="word" morph="none" start_char="1260" end_char="1268">agreement</TOKEN>
        <TOKEN id="token-37-2" pos="word" morph="none" start_char="1270" end_char="1276">between</TOKEN>
        <TOKEN id="token-37-3" pos="word" morph="none" start_char="1278" end_char="1281">Iran</TOKEN>
        <TOKEN id="token-37-4" pos="word" morph="none" start_char="1283" end_char="1285">and</TOKEN>
        <TOKEN id="token-37-5" pos="word" morph="none" start_char="1287" end_char="1291">world</TOKEN>
        <TOKEN id="token-37-6" pos="word" morph="none" start_char="1293" end_char="1298">powers</TOKEN>
        <TOKEN id="token-37-7" pos="word" morph="none" start_char="1300" end_char="1301">is</TOKEN>
        <TOKEN id="token-37-8" pos="punct" morph="none" start_char="1303" end_char="1303">"</TOKEN>
        <TOKEN id="token-37-9" pos="word" morph="none" start_char="1304" end_char="1309">doable</TOKEN>
        <TOKEN id="token-37-10" pos="punct" morph="none" start_char="1310" end_char="1310">"</TOKEN>
        <TOKEN id="token-37-11" pos="word" morph="none" start_char="1312" end_char="1315">with</TOKEN>
        <TOKEN id="token-37-12" pos="punct" morph="none" start_char="1317" end_char="1317">"</TOKEN>
        <TOKEN id="token-37-13" pos="word" morph="none" start_char="1318" end_char="1320">two</TOKEN>
        <TOKEN id="token-37-14" pos="word" morph="none" start_char="1322" end_char="1323">or</TOKEN>
        <TOKEN id="token-37-15" pos="word" morph="none" start_char="1325" end_char="1329">three</TOKEN>
        <TOKEN id="token-37-16" pos="punct" morph="none" start_char="1330" end_char="1330">"</TOKEN>
      </SEG>
      <SEG id="segment-38" start_char="1332" end_char="1409">
        <ORIGINAL_TEXT>issues left to resolve, Tehran's lead negotiator said on Sunday, AFP reported.</ORIGINAL_TEXT>
        <TOKEN id="token-38-0" pos="word" morph="none" start_char="1332" end_char="1337">issues</TOKEN>
        <TOKEN id="token-38-1" pos="word" morph="none" start_char="1339" end_char="1342">left</TOKEN>
        <TOKEN id="token-38-2" pos="word" morph="none" start_char="1344" end_char="1345">to</TOKEN>
        <TOKEN id="token-38-3" pos="word" morph="none" start_char="1347" end_char="1353">resolve</TOKEN>
        <TOKEN id="token-38-4" pos="punct" morph="none" start_char="1354" end_char="1354">,</TOKEN>
        <TOKEN id="token-38-5" pos="word" morph="none" start_char="1356" end_char="1361">Tehran</TOKEN>
        <TOKEN id="token-38-6" pos="punct" morph="none" start_char="1362" end_char="1362">'</TOKEN>
        <TOKEN id="token-38-7" pos="word" morph="none" start_char="1363" end_char="1363">s</TOKEN>
        <TOKEN id="token-38-8" pos="word" morph="none" start_char="1365" end_char="1368">lead</TOKEN>
        <TOKEN id="token-38-9" pos="word" morph="none" start_char="1370" end_char="1379">negotiator</TOKEN>
        <TOKEN id="token-38-10" pos="word" morph="none" start_char="1381" end_char="1384">said</TOKEN>
        <TOKEN id="token-38-11" pos="word" morph="none" start_char="1386" end_char="1387">on</TOKEN>
        <TOKEN id="token-38-12" pos="word" morph="none" start_char="1389" end_char="1394">Sunday</TOKEN>
        <TOKEN id="token-38-13" pos="punct" morph="none" start_char="1395" end_char="1395">,</TOKEN>
        <TOKEN id="token-38-14" pos="word" morph="none" start_char="1397" end_char="1399">AFP</TOKEN>
        <TOKEN id="token-38-15" pos="word" morph="none" start_char="1401" end_char="1408">reported</TOKEN>
        <TOKEN id="token-38-16" pos="punct" morph="none" start_char="1409" end_char="1409">.</TOKEN>
      </SEG>
      <SEG id="segment-39" start_char="1411" end_char="1414">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-39-0" pos="unknown" morph="none" start_char="1411" end_char="1414">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-40" start_char="1416" end_char="1418">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-40-0" pos="unknown" morph="none" start_char="1416" end_char="1418">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-41" start_char="1420" end_char="1495">
        <ORIGINAL_TEXT> "Getting to an accord is doable," Abbas Araqchi told reporters in Lausanne.</ORIGINAL_TEXT>
        <TOKEN id="token-41-0" pos="punct" morph="none" start_char="1421" end_char="1421">"</TOKEN>
        <TOKEN id="token-41-1" pos="word" morph="none" start_char="1422" end_char="1428">Getting</TOKEN>
        <TOKEN id="token-41-2" pos="word" morph="none" start_char="1430" end_char="1431">to</TOKEN>
        <TOKEN id="token-41-3" pos="word" morph="none" start_char="1433" end_char="1434">an</TOKEN>
        <TOKEN id="token-41-4" pos="word" morph="none" start_char="1436" end_char="1441">accord</TOKEN>
        <TOKEN id="token-41-5" pos="word" morph="none" start_char="1443" end_char="1444">is</TOKEN>
        <TOKEN id="token-41-6" pos="word" morph="none" start_char="1446" end_char="1451">doable</TOKEN>
        <TOKEN id="token-41-7" pos="punct" morph="none" start_char="1452" end_char="1453">,"</TOKEN>
        <TOKEN id="token-41-8" pos="word" morph="none" start_char="1455" end_char="1459">Abbas</TOKEN>
        <TOKEN id="token-41-9" pos="word" morph="none" start_char="1461" end_char="1467">Araqchi</TOKEN>
        <TOKEN id="token-41-10" pos="word" morph="none" start_char="1469" end_char="1472">told</TOKEN>
        <TOKEN id="token-41-11" pos="word" morph="none" start_char="1474" end_char="1482">reporters</TOKEN>
        <TOKEN id="token-41-12" pos="word" morph="none" start_char="1484" end_char="1485">in</TOKEN>
        <TOKEN id="token-41-13" pos="word" morph="none" start_char="1487" end_char="1494">Lausanne</TOKEN>
        <TOKEN id="token-41-14" pos="punct" morph="none" start_char="1495" end_char="1495">.</TOKEN>
      </SEG>
      <SEG id="segment-42" start_char="1497" end_char="1500">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-42-0" pos="unknown" morph="none" start_char="1497" end_char="1500">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-43" start_char="1502" end_char="1504">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-43-0" pos="unknown" morph="none" start_char="1502" end_char="1504">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-44" start_char="1506" end_char="1565">
        <ORIGINAL_TEXT>"Solutions have been found for numerous questions," he said.</ORIGINAL_TEXT>
        <TOKEN id="token-44-0" pos="punct" morph="none" start_char="1506" end_char="1506">"</TOKEN>
        <TOKEN id="token-44-1" pos="word" morph="none" start_char="1507" end_char="1515">Solutions</TOKEN>
        <TOKEN id="token-44-2" pos="word" morph="none" start_char="1517" end_char="1520">have</TOKEN>
        <TOKEN id="token-44-3" pos="word" morph="none" start_char="1522" end_char="1525">been</TOKEN>
        <TOKEN id="token-44-4" pos="word" morph="none" start_char="1527" end_char="1531">found</TOKEN>
        <TOKEN id="token-44-5" pos="word" morph="none" start_char="1533" end_char="1535">for</TOKEN>
        <TOKEN id="token-44-6" pos="word" morph="none" start_char="1537" end_char="1544">numerous</TOKEN>
        <TOKEN id="token-44-7" pos="word" morph="none" start_char="1546" end_char="1554">questions</TOKEN>
        <TOKEN id="token-44-8" pos="punct" morph="none" start_char="1555" end_char="1556">,"</TOKEN>
        <TOKEN id="token-44-9" pos="word" morph="none" start_char="1558" end_char="1559">he</TOKEN>
        <TOKEN id="token-44-10" pos="word" morph="none" start_char="1561" end_char="1564">said</TOKEN>
        <TOKEN id="token-44-11" pos="punct" morph="none" start_char="1565" end_char="1565">.</TOKEN>
      </SEG>
      <SEG id="segment-45" start_char="1567" end_char="1570">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-45-0" pos="unknown" morph="none" start_char="1567" end_char="1570">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-46" start_char="1572" end_char="1574">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-46-0" pos="unknown" morph="none" start_char="1572" end_char="1574">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-47" start_char="1576" end_char="1648">
        <ORIGINAL_TEXT>"We are still working on two or three issues . . . the talks are in their</ORIGINAL_TEXT>
        <TOKEN id="token-47-0" pos="punct" morph="none" start_char="1576" end_char="1576">"</TOKEN>
        <TOKEN id="token-47-1" pos="word" morph="none" start_char="1577" end_char="1578">We</TOKEN>
        <TOKEN id="token-47-2" pos="word" morph="none" start_char="1580" end_char="1582">are</TOKEN>
        <TOKEN id="token-47-3" pos="word" morph="none" start_char="1584" end_char="1588">still</TOKEN>
        <TOKEN id="token-47-4" pos="word" morph="none" start_char="1590" end_char="1596">working</TOKEN>
        <TOKEN id="token-47-5" pos="word" morph="none" start_char="1598" end_char="1599">on</TOKEN>
        <TOKEN id="token-47-6" pos="word" morph="none" start_char="1601" end_char="1603">two</TOKEN>
        <TOKEN id="token-47-7" pos="word" morph="none" start_char="1605" end_char="1606">or</TOKEN>
        <TOKEN id="token-47-8" pos="word" morph="none" start_char="1608" end_char="1612">three</TOKEN>
        <TOKEN id="token-47-9" pos="word" morph="none" start_char="1614" end_char="1619">issues</TOKEN>
        <TOKEN id="token-47-10" pos="unknown" morph="none" start_char="1621" end_char="1621">.</TOKEN>
        <TOKEN id="token-47-11" pos="unknown" morph="none" start_char="1623" end_char="1623">.</TOKEN>
        <TOKEN id="token-47-12" pos="unknown" morph="none" start_char="1625" end_char="1625">.</TOKEN>
        <TOKEN id="token-47-13" pos="word" morph="none" start_char="1627" end_char="1629">the</TOKEN>
        <TOKEN id="token-47-14" pos="word" morph="none" start_char="1631" end_char="1635">talks</TOKEN>
        <TOKEN id="token-47-15" pos="word" morph="none" start_char="1637" end_char="1639">are</TOKEN>
        <TOKEN id="token-47-16" pos="word" morph="none" start_char="1641" end_char="1642">in</TOKEN>
        <TOKEN id="token-47-17" pos="word" morph="none" start_char="1644" end_char="1648">their</TOKEN>
      </SEG>
      <SEG id="segment-48" start_char="1650" end_char="1685">
        <ORIGINAL_TEXT>final phase and are very difficult."</ORIGINAL_TEXT>
        <TOKEN id="token-48-0" pos="word" morph="none" start_char="1650" end_char="1654">final</TOKEN>
        <TOKEN id="token-48-1" pos="word" morph="none" start_char="1656" end_char="1660">phase</TOKEN>
        <TOKEN id="token-48-2" pos="word" morph="none" start_char="1662" end_char="1664">and</TOKEN>
        <TOKEN id="token-48-3" pos="word" morph="none" start_char="1666" end_char="1668">are</TOKEN>
        <TOKEN id="token-48-4" pos="word" morph="none" start_char="1670" end_char="1673">very</TOKEN>
        <TOKEN id="token-48-5" pos="word" morph="none" start_char="1675" end_char="1683">difficult</TOKEN>
        <TOKEN id="token-48-6" pos="punct" morph="none" start_char="1684" end_char="1685">."</TOKEN>
      </SEG>
      <SEG id="segment-49" start_char="1687" end_char="1690">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-49-0" pos="unknown" morph="none" start_char="1687" end_char="1690">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-50" start_char="1692" end_char="1694">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-50-0" pos="unknown" morph="none" start_char="1692" end_char="1694">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-51" start_char="1696" end_char="1764">
        <ORIGINAL_TEXT>Araqchi said world powers would meet on Monday to discuss the issues.</ORIGINAL_TEXT>
        <TOKEN id="token-51-0" pos="word" morph="none" start_char="1696" end_char="1702">Araqchi</TOKEN>
        <TOKEN id="token-51-1" pos="word" morph="none" start_char="1704" end_char="1707">said</TOKEN>
        <TOKEN id="token-51-2" pos="word" morph="none" start_char="1709" end_char="1713">world</TOKEN>
        <TOKEN id="token-51-3" pos="word" morph="none" start_char="1715" end_char="1720">powers</TOKEN>
        <TOKEN id="token-51-4" pos="word" morph="none" start_char="1722" end_char="1726">would</TOKEN>
        <TOKEN id="token-51-5" pos="word" morph="none" start_char="1728" end_char="1731">meet</TOKEN>
        <TOKEN id="token-51-6" pos="word" morph="none" start_char="1733" end_char="1734">on</TOKEN>
        <TOKEN id="token-51-7" pos="word" morph="none" start_char="1736" end_char="1741">Monday</TOKEN>
        <TOKEN id="token-51-8" pos="word" morph="none" start_char="1743" end_char="1744">to</TOKEN>
        <TOKEN id="token-51-9" pos="word" morph="none" start_char="1746" end_char="1752">discuss</TOKEN>
        <TOKEN id="token-51-10" pos="word" morph="none" start_char="1754" end_char="1756">the</TOKEN>
        <TOKEN id="token-51-11" pos="word" morph="none" start_char="1758" end_char="1763">issues</TOKEN>
        <TOKEN id="token-51-12" pos="punct" morph="none" start_char="1764" end_char="1764">.</TOKEN>
      </SEG>
      <SEG id="segment-52" start_char="1766" end_char="1769">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-52-0" pos="unknown" morph="none" start_char="1766" end_char="1769">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-53" start_char="1771" end_char="1773">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-53-0" pos="unknown" morph="none" start_char="1771" end_char="1773">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-54" start_char="1775" end_char="1850">
        <ORIGINAL_TEXT>US Secretary of State John Kerry and the German and French foreign ministers</ORIGINAL_TEXT>
        <TOKEN id="token-54-0" pos="word" morph="none" start_char="1775" end_char="1776">US</TOKEN>
        <TOKEN id="token-54-1" pos="word" morph="none" start_char="1778" end_char="1786">Secretary</TOKEN>
        <TOKEN id="token-54-2" pos="word" morph="none" start_char="1788" end_char="1789">of</TOKEN>
        <TOKEN id="token-54-3" pos="word" morph="none" start_char="1791" end_char="1795">State</TOKEN>
        <TOKEN id="token-54-4" pos="word" morph="none" start_char="1797" end_char="1800">John</TOKEN>
        <TOKEN id="token-54-5" pos="word" morph="none" start_char="1802" end_char="1806">Kerry</TOKEN>
        <TOKEN id="token-54-6" pos="word" morph="none" start_char="1808" end_char="1810">and</TOKEN>
        <TOKEN id="token-54-7" pos="word" morph="none" start_char="1812" end_char="1814">the</TOKEN>
        <TOKEN id="token-54-8" pos="word" morph="none" start_char="1816" end_char="1821">German</TOKEN>
        <TOKEN id="token-54-9" pos="word" morph="none" start_char="1823" end_char="1825">and</TOKEN>
        <TOKEN id="token-54-10" pos="word" morph="none" start_char="1827" end_char="1832">French</TOKEN>
        <TOKEN id="token-54-11" pos="word" morph="none" start_char="1834" end_char="1840">foreign</TOKEN>
        <TOKEN id="token-54-12" pos="word" morph="none" start_char="1842" end_char="1850">ministers</TOKEN>
      </SEG>
      <SEG id="segment-55" start_char="1852" end_char="1927">
        <ORIGINAL_TEXT>Frank-Walter Steinmeier and Laurent Fabius were due to sit down with Chinese</ORIGINAL_TEXT>
        <TOKEN id="token-55-0" pos="word" morph="none" start_char="1852" end_char="1856">Frank</TOKEN>
        <TOKEN id="token-55-1" pos="punct" morph="none" start_char="1857" end_char="1857">-</TOKEN>
        <TOKEN id="token-55-2" pos="word" morph="none" start_char="1858" end_char="1863">Walter</TOKEN>
        <TOKEN id="token-55-3" pos="word" morph="none" start_char="1865" end_char="1874">Steinmeier</TOKEN>
        <TOKEN id="token-55-4" pos="word" morph="none" start_char="1876" end_char="1878">and</TOKEN>
        <TOKEN id="token-55-5" pos="word" morph="none" start_char="1880" end_char="1886">Laurent</TOKEN>
        <TOKEN id="token-55-6" pos="word" morph="none" start_char="1888" end_char="1893">Fabius</TOKEN>
        <TOKEN id="token-55-7" pos="word" morph="none" start_char="1895" end_char="1898">were</TOKEN>
        <TOKEN id="token-55-8" pos="word" morph="none" start_char="1900" end_char="1902">due</TOKEN>
        <TOKEN id="token-55-9" pos="word" morph="none" start_char="1904" end_char="1905">to</TOKEN>
        <TOKEN id="token-55-10" pos="word" morph="none" start_char="1907" end_char="1909">sit</TOKEN>
        <TOKEN id="token-55-11" pos="word" morph="none" start_char="1911" end_char="1914">down</TOKEN>
        <TOKEN id="token-55-12" pos="word" morph="none" start_char="1916" end_char="1919">with</TOKEN>
        <TOKEN id="token-55-13" pos="word" morph="none" start_char="1921" end_char="1927">Chinese</TOKEN>
      </SEG>
      <SEG id="segment-56" start_char="1929" end_char="2003">
        <ORIGINAL_TEXT>foreign minister Wang Yi and EU foreign policy chief Federica Mogherini, as</ORIGINAL_TEXT>
        <TOKEN id="token-56-0" pos="word" morph="none" start_char="1929" end_char="1935">foreign</TOKEN>
        <TOKEN id="token-56-1" pos="word" morph="none" start_char="1937" end_char="1944">minister</TOKEN>
        <TOKEN id="token-56-2" pos="word" morph="none" start_char="1946" end_char="1949">Wang</TOKEN>
        <TOKEN id="token-56-3" pos="word" morph="none" start_char="1951" end_char="1952">Yi</TOKEN>
        <TOKEN id="token-56-4" pos="word" morph="none" start_char="1954" end_char="1956">and</TOKEN>
        <TOKEN id="token-56-5" pos="word" morph="none" start_char="1958" end_char="1959">EU</TOKEN>
        <TOKEN id="token-56-6" pos="word" morph="none" start_char="1961" end_char="1967">foreign</TOKEN>
        <TOKEN id="token-56-7" pos="word" morph="none" start_char="1969" end_char="1974">policy</TOKEN>
        <TOKEN id="token-56-8" pos="word" morph="none" start_char="1976" end_char="1980">chief</TOKEN>
        <TOKEN id="token-56-9" pos="word" morph="none" start_char="1982" end_char="1989">Federica</TOKEN>
        <TOKEN id="token-56-10" pos="word" morph="none" start_char="1991" end_char="1999">Mogherini</TOKEN>
        <TOKEN id="token-56-11" pos="punct" morph="none" start_char="2000" end_char="2000">,</TOKEN>
        <TOKEN id="token-56-12" pos="word" morph="none" start_char="2002" end_char="2003">as</TOKEN>
      </SEG>
      <SEG id="segment-57" start_char="2005" end_char="2059">
        <ORIGINAL_TEXT>well as their Iranian counterpart Mohammad Javad Zarif.</ORIGINAL_TEXT>
        <TOKEN id="token-57-0" pos="word" morph="none" start_char="2005" end_char="2008">well</TOKEN>
        <TOKEN id="token-57-1" pos="word" morph="none" start_char="2010" end_char="2011">as</TOKEN>
        <TOKEN id="token-57-2" pos="word" morph="none" start_char="2013" end_char="2017">their</TOKEN>
        <TOKEN id="token-57-3" pos="word" morph="none" start_char="2019" end_char="2025">Iranian</TOKEN>
        <TOKEN id="token-57-4" pos="word" morph="none" start_char="2027" end_char="2037">counterpart</TOKEN>
        <TOKEN id="token-57-5" pos="word" morph="none" start_char="2039" end_char="2046">Mohammad</TOKEN>
        <TOKEN id="token-57-6" pos="word" morph="none" start_char="2048" end_char="2052">Javad</TOKEN>
        <TOKEN id="token-57-7" pos="word" morph="none" start_char="2054" end_char="2058">Zarif</TOKEN>
        <TOKEN id="token-57-8" pos="punct" morph="none" start_char="2059" end_char="2059">.</TOKEN>
      </SEG>
      <SEG id="segment-58" start_char="2061" end_char="2064">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-58-0" pos="unknown" morph="none" start_char="2061" end_char="2064">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-59" start_char="2066" end_char="2068">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-59-0" pos="unknown" morph="none" start_char="2066" end_char="2068">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-60" start_char="2071" end_char="2074">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-60-0" pos="unknown" morph="none" start_char="2071" end_char="2074">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-61" start_char="2076" end_char="2078">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-61-0" pos="unknown" morph="none" start_char="2076" end_char="2078">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-62" start_char="2080" end_char="2156">
        <ORIGINAL_TEXT>They will be joined by Russian foreign minister Sergei Lavrov and his British</ORIGINAL_TEXT>
        <TOKEN id="token-62-0" pos="word" morph="none" start_char="2080" end_char="2083">They</TOKEN>
        <TOKEN id="token-62-1" pos="word" morph="none" start_char="2085" end_char="2088">will</TOKEN>
        <TOKEN id="token-62-2" pos="word" morph="none" start_char="2090" end_char="2091">be</TOKEN>
        <TOKEN id="token-62-3" pos="word" morph="none" start_char="2093" end_char="2098">joined</TOKEN>
        <TOKEN id="token-62-4" pos="word" morph="none" start_char="2100" end_char="2101">by</TOKEN>
        <TOKEN id="token-62-5" pos="word" morph="none" start_char="2103" end_char="2109">Russian</TOKEN>
        <TOKEN id="token-62-6" pos="word" morph="none" start_char="2111" end_char="2117">foreign</TOKEN>
        <TOKEN id="token-62-7" pos="word" morph="none" start_char="2119" end_char="2126">minister</TOKEN>
        <TOKEN id="token-62-8" pos="word" morph="none" start_char="2128" end_char="2133">Sergei</TOKEN>
        <TOKEN id="token-62-9" pos="word" morph="none" start_char="2135" end_char="2140">Lavrov</TOKEN>
        <TOKEN id="token-62-10" pos="word" morph="none" start_char="2142" end_char="2144">and</TOKEN>
        <TOKEN id="token-62-11" pos="word" morph="none" start_char="2146" end_char="2148">his</TOKEN>
        <TOKEN id="token-62-12" pos="word" morph="none" start_char="2150" end_char="2156">British</TOKEN>
      </SEG>
      <SEG id="segment-63" start_char="2158" end_char="2232">
        <ORIGINAL_TEXT>counterpart Philip Hammond, who was the last to arrive in Lausanne, late on</ORIGINAL_TEXT>
        <TOKEN id="token-63-0" pos="word" morph="none" start_char="2158" end_char="2168">counterpart</TOKEN>
        <TOKEN id="token-63-1" pos="word" morph="none" start_char="2170" end_char="2175">Philip</TOKEN>
        <TOKEN id="token-63-2" pos="word" morph="none" start_char="2177" end_char="2183">Hammond</TOKEN>
        <TOKEN id="token-63-3" pos="punct" morph="none" start_char="2184" end_char="2184">,</TOKEN>
        <TOKEN id="token-63-4" pos="word" morph="none" start_char="2186" end_char="2188">who</TOKEN>
        <TOKEN id="token-63-5" pos="word" morph="none" start_char="2190" end_char="2192">was</TOKEN>
        <TOKEN id="token-63-6" pos="word" morph="none" start_char="2194" end_char="2196">the</TOKEN>
        <TOKEN id="token-63-7" pos="word" morph="none" start_char="2198" end_char="2201">last</TOKEN>
        <TOKEN id="token-63-8" pos="word" morph="none" start_char="2203" end_char="2204">to</TOKEN>
        <TOKEN id="token-63-9" pos="word" morph="none" start_char="2206" end_char="2211">arrive</TOKEN>
        <TOKEN id="token-63-10" pos="word" morph="none" start_char="2213" end_char="2214">in</TOKEN>
        <TOKEN id="token-63-11" pos="word" morph="none" start_char="2216" end_char="2223">Lausanne</TOKEN>
        <TOKEN id="token-63-12" pos="punct" morph="none" start_char="2224" end_char="2224">,</TOKEN>
        <TOKEN id="token-63-13" pos="word" morph="none" start_char="2226" end_char="2229">late</TOKEN>
        <TOKEN id="token-63-14" pos="word" morph="none" start_char="2231" end_char="2232">on</TOKEN>
      </SEG>
      <SEG id="segment-64" start_char="2234" end_char="2240">
        <ORIGINAL_TEXT>Sunday.</ORIGINAL_TEXT>
        <TOKEN id="token-64-0" pos="word" morph="none" start_char="2234" end_char="2239">Sunday</TOKEN>
        <TOKEN id="token-64-1" pos="punct" morph="none" start_char="2240" end_char="2240">.</TOKEN>
      </SEG>
      <SEG id="segment-65" start_char="2242" end_char="2245">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-65-0" pos="unknown" morph="none" start_char="2242" end_char="2245">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-66" start_char="2247" end_char="2253">
        <ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-66-0" pos="unknown" morph="none" start_char="2247" end_char="2253">&lt;/TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-67" start_char="2255" end_char="2260">
        <ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-67-0" pos="unknown" morph="none" start_char="2255" end_char="2260">&lt;/DOC&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
