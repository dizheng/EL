<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="ENG_NW_001034_20140803_F00000016.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="21401" raw_text_md5="282defa741d7b7114704c916771414b3">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001034_20140803_F00000016"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001034_20140803_F00000016"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="201">
        <ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.newrepublic.com/article/118705/hillary-rodham-clintons-hard-choices-reviewed-anne-applebaum&lt;/SOURCE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="201">&lt;SOURCE&gt;http://www.newrepublic.com/article/118705/hillary-rodham-clintons-hard-choices-reviewed-anne-applebaum&lt;/SOURCE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="203" end_char="244">
        <ORIGINAL_TEXT>&lt;DATE_TIME&gt;2014-08-03T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="unknown" morph="none" start_char="203" end_char="244">&lt;DATE_TIME&gt;2014-08-03T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="246" end_char="255">
        <ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="246" end_char="255">&lt;HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="257" end_char="286">
        <ORIGINAL_TEXT>Hillary Clinton's Crystal Ball</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="word" morph="none" start_char="257" end_char="263">Hillary</TOKEN>
        <TOKEN id="token-5-1" pos="word" morph="none" start_char="265" end_char="271">Clinton</TOKEN>
        <TOKEN id="token-5-2" pos="punct" morph="none" start_char="272" end_char="272">'</TOKEN>
        <TOKEN id="token-5-3" pos="word" morph="none" start_char="273" end_char="273">s</TOKEN>
        <TOKEN id="token-5-4" pos="word" morph="none" start_char="275" end_char="281">Crystal</TOKEN>
        <TOKEN id="token-5-5" pos="word" morph="none" start_char="283" end_char="286">Ball</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="288" end_char="298">
        <ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="unknown" morph="none" start_char="288" end_char="298">&lt;/HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="300" end_char="305">
        <ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="300" end_char="305">&lt;TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="307" end_char="309">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="307" end_char="309">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="311" end_char="386">
        <ORIGINAL_TEXT>Even while Hard Choices was still wafting its way across the Atlantic Ocean—</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="311" end_char="314">Even</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="316" end_char="320">while</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="322" end_char="325">Hard</TOKEN>
        <TOKEN id="token-9-3" pos="word" morph="none" start_char="327" end_char="333">Choices</TOKEN>
        <TOKEN id="token-9-4" pos="word" morph="none" start_char="335" end_char="337">was</TOKEN>
        <TOKEN id="token-9-5" pos="word" morph="none" start_char="339" end_char="343">still</TOKEN>
        <TOKEN id="token-9-6" pos="word" morph="none" start_char="345" end_char="351">wafting</TOKEN>
        <TOKEN id="token-9-7" pos="word" morph="none" start_char="353" end_char="355">its</TOKEN>
        <TOKEN id="token-9-8" pos="word" morph="none" start_char="357" end_char="359">way</TOKEN>
        <TOKEN id="token-9-9" pos="word" morph="none" start_char="361" end_char="366">across</TOKEN>
        <TOKEN id="token-9-10" pos="word" morph="none" start_char="368" end_char="370">the</TOKEN>
        <TOKEN id="token-9-11" pos="word" morph="none" start_char="372" end_char="379">Atlantic</TOKEN>
        <TOKEN id="token-9-12" pos="word" morph="none" start_char="381" end_char="385">Ocean</TOKEN>
        <TOKEN id="token-9-13" pos="punct" morph="none" start_char="386" end_char="386">—</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="388" end_char="464">
        <ORIGINAL_TEXT>and long before it landed on my desk in central Europe, an entire twenty-four</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="word" morph="none" start_char="388" end_char="390">and</TOKEN>
        <TOKEN id="token-10-1" pos="word" morph="none" start_char="392" end_char="395">long</TOKEN>
        <TOKEN id="token-10-2" pos="word" morph="none" start_char="397" end_char="402">before</TOKEN>
        <TOKEN id="token-10-3" pos="word" morph="none" start_char="404" end_char="405">it</TOKEN>
        <TOKEN id="token-10-4" pos="word" morph="none" start_char="407" end_char="412">landed</TOKEN>
        <TOKEN id="token-10-5" pos="word" morph="none" start_char="414" end_char="415">on</TOKEN>
        <TOKEN id="token-10-6" pos="word" morph="none" start_char="417" end_char="418">my</TOKEN>
        <TOKEN id="token-10-7" pos="word" morph="none" start_char="420" end_char="423">desk</TOKEN>
        <TOKEN id="token-10-8" pos="word" morph="none" start_char="425" end_char="426">in</TOKEN>
        <TOKEN id="token-10-9" pos="word" morph="none" start_char="428" end_char="434">central</TOKEN>
        <TOKEN id="token-10-10" pos="word" morph="none" start_char="436" end_char="441">Europe</TOKEN>
        <TOKEN id="token-10-11" pos="punct" morph="none" start_char="442" end_char="442">,</TOKEN>
        <TOKEN id="token-10-12" pos="word" morph="none" start_char="444" end_char="445">an</TOKEN>
        <TOKEN id="token-10-13" pos="word" morph="none" start_char="447" end_char="452">entire</TOKEN>
        <TOKEN id="token-10-14" pos="word" morph="none" start_char="454" end_char="459">twenty</TOKEN>
        <TOKEN id="token-10-15" pos="punct" morph="none" start_char="460" end_char="460">-</TOKEN>
        <TOKEN id="token-10-16" pos="word" morph="none" start_char="461" end_char="464">four</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="466" end_char="539">
        <ORIGINAL_TEXT>hours after the official publication date—Hillary Clinton’s account of her</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="word" morph="none" start_char="466" end_char="470">hours</TOKEN>
        <TOKEN id="token-11-1" pos="word" morph="none" start_char="472" end_char="476">after</TOKEN>
        <TOKEN id="token-11-2" pos="word" morph="none" start_char="478" end_char="480">the</TOKEN>
        <TOKEN id="token-11-3" pos="word" morph="none" start_char="482" end_char="489">official</TOKEN>
        <TOKEN id="token-11-4" pos="word" morph="none" start_char="491" end_char="501">publication</TOKEN>
        <TOKEN id="token-11-5" pos="word" morph="none" start_char="503" end_char="506">date</TOKEN>
        <TOKEN id="token-11-6" pos="punct" morph="none" start_char="507" end_char="507">—</TOKEN>
        <TOKEN id="token-11-7" pos="word" morph="none" start_char="508" end_char="514">Hillary</TOKEN>
        <TOKEN id="token-11-8" pos="word" morph="none" start_char="516" end_char="522">Clinton</TOKEN>
        <TOKEN id="token-11-9" pos="punct" morph="none" start_char="523" end_char="523">’</TOKEN>
        <TOKEN id="token-11-10" pos="word" morph="none" start_char="524" end_char="524">s</TOKEN>
        <TOKEN id="token-11-11" pos="word" morph="none" start_char="526" end_char="532">account</TOKEN>
        <TOKEN id="token-11-12" pos="word" morph="none" start_char="534" end_char="535">of</TOKEN>
        <TOKEN id="token-11-13" pos="word" morph="none" start_char="537" end_char="539">her</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="541" end_char="618">
        <ORIGINAL_TEXT>State Department years had already led several news cycles, inspired thousands</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="word" morph="none" start_char="541" end_char="545">State</TOKEN>
        <TOKEN id="token-12-1" pos="word" morph="none" start_char="547" end_char="556">Department</TOKEN>
        <TOKEN id="token-12-2" pos="word" morph="none" start_char="558" end_char="562">years</TOKEN>
        <TOKEN id="token-12-3" pos="word" morph="none" start_char="564" end_char="566">had</TOKEN>
        <TOKEN id="token-12-4" pos="word" morph="none" start_char="568" end_char="574">already</TOKEN>
        <TOKEN id="token-12-5" pos="word" morph="none" start_char="576" end_char="578">led</TOKEN>
        <TOKEN id="token-12-6" pos="word" morph="none" start_char="580" end_char="586">several</TOKEN>
        <TOKEN id="token-12-7" pos="word" morph="none" start_char="588" end_char="591">news</TOKEN>
        <TOKEN id="token-12-8" pos="word" morph="none" start_char="593" end_char="598">cycles</TOKEN>
        <TOKEN id="token-12-9" pos="punct" morph="none" start_char="599" end_char="599">,</TOKEN>
        <TOKEN id="token-12-10" pos="word" morph="none" start_char="601" end_char="608">inspired</TOKEN>
        <TOKEN id="token-12-11" pos="word" morph="none" start_char="610" end_char="618">thousands</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="620" end_char="693">
        <ORIGINAL_TEXT>of megabytes of commentary, and left its subsequent reviewers with serious</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="word" morph="none" start_char="620" end_char="621">of</TOKEN>
        <TOKEN id="token-13-1" pos="word" morph="none" start_char="623" end_char="631">megabytes</TOKEN>
        <TOKEN id="token-13-2" pos="word" morph="none" start_char="633" end_char="634">of</TOKEN>
        <TOKEN id="token-13-3" pos="word" morph="none" start_char="636" end_char="645">commentary</TOKEN>
        <TOKEN id="token-13-4" pos="punct" morph="none" start_char="646" end_char="646">,</TOKEN>
        <TOKEN id="token-13-5" pos="word" morph="none" start_char="648" end_char="650">and</TOKEN>
        <TOKEN id="token-13-6" pos="word" morph="none" start_char="652" end_char="655">left</TOKEN>
        <TOKEN id="token-13-7" pos="word" morph="none" start_char="657" end_char="659">its</TOKEN>
        <TOKEN id="token-13-8" pos="word" morph="none" start_char="661" end_char="670">subsequent</TOKEN>
        <TOKEN id="token-13-9" pos="word" morph="none" start_char="672" end_char="680">reviewers</TOKEN>
        <TOKEN id="token-13-10" pos="word" morph="none" start_char="682" end_char="685">with</TOKEN>
        <TOKEN id="token-13-11" pos="word" morph="none" start_char="687" end_char="693">serious</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="695" end_char="730">
        <ORIGINAL_TEXT>literary and philosophical dilemmas.</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="word" morph="none" start_char="695" end_char="702">literary</TOKEN>
        <TOKEN id="token-14-1" pos="word" morph="none" start_char="704" end_char="706">and</TOKEN>
        <TOKEN id="token-14-2" pos="word" morph="none" start_char="708" end_char="720">philosophical</TOKEN>
        <TOKEN id="token-14-3" pos="word" morph="none" start_char="722" end_char="729">dilemmas</TOKEN>
        <TOKEN id="token-14-4" pos="punct" morph="none" start_char="730" end_char="730">.</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="732" end_char="735">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="unknown" morph="none" start_char="732" end_char="735">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="737" end_char="739">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="unknown" morph="none" start_char="737" end_char="739">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="741" end_char="816">
        <ORIGINAL_TEXT>Normally, the process of writing a book review begins after the reviewer has</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="word" morph="none" start_char="741" end_char="748">Normally</TOKEN>
        <TOKEN id="token-17-1" pos="punct" morph="none" start_char="749" end_char="749">,</TOKEN>
        <TOKEN id="token-17-2" pos="word" morph="none" start_char="751" end_char="753">the</TOKEN>
        <TOKEN id="token-17-3" pos="word" morph="none" start_char="755" end_char="761">process</TOKEN>
        <TOKEN id="token-17-4" pos="word" morph="none" start_char="763" end_char="764">of</TOKEN>
        <TOKEN id="token-17-5" pos="word" morph="none" start_char="766" end_char="772">writing</TOKEN>
        <TOKEN id="token-17-6" pos="word" morph="none" start_char="774" end_char="774">a</TOKEN>
        <TOKEN id="token-17-7" pos="word" morph="none" start_char="776" end_char="779">book</TOKEN>
        <TOKEN id="token-17-8" pos="word" morph="none" start_char="781" end_char="786">review</TOKEN>
        <TOKEN id="token-17-9" pos="word" morph="none" start_char="788" end_char="793">begins</TOKEN>
        <TOKEN id="token-17-10" pos="word" morph="none" start_char="795" end_char="799">after</TOKEN>
        <TOKEN id="token-17-11" pos="word" morph="none" start_char="801" end_char="803">the</TOKEN>
        <TOKEN id="token-17-12" pos="word" morph="none" start_char="805" end_char="812">reviewer</TOKEN>
        <TOKEN id="token-17-13" pos="word" morph="none" start_char="814" end_char="816">has</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="818" end_char="885">
        <ORIGINAL_TEXT>read the book in question. The process of “reading” Hard Choices, by</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="word" morph="none" start_char="818" end_char="821">read</TOKEN>
        <TOKEN id="token-18-1" pos="word" morph="none" start_char="823" end_char="825">the</TOKEN>
        <TOKEN id="token-18-2" pos="word" morph="none" start_char="827" end_char="830">book</TOKEN>
        <TOKEN id="token-18-3" pos="word" morph="none" start_char="832" end_char="833">in</TOKEN>
        <TOKEN id="token-18-4" pos="word" morph="none" start_char="835" end_char="842">question</TOKEN>
        <TOKEN id="token-18-5" pos="punct" morph="none" start_char="843" end_char="843">.</TOKEN>
        <TOKEN id="token-18-6" pos="word" morph="none" start_char="845" end_char="847">The</TOKEN>
        <TOKEN id="token-18-7" pos="word" morph="none" start_char="849" end_char="855">process</TOKEN>
        <TOKEN id="token-18-8" pos="word" morph="none" start_char="857" end_char="858">of</TOKEN>
        <TOKEN id="token-18-9" pos="punct" morph="none" start_char="860" end_char="860">“</TOKEN>
        <TOKEN id="token-18-10" pos="word" morph="none" start_char="861" end_char="867">reading</TOKEN>
        <TOKEN id="token-18-11" pos="punct" morph="none" start_char="868" end_char="868">”</TOKEN>
        <TOKEN id="token-18-12" pos="word" morph="none" start_char="870" end_char="873">Hard</TOKEN>
        <TOKEN id="token-18-13" pos="word" morph="none" start_char="875" end_char="881">Choices</TOKEN>
        <TOKEN id="token-18-14" pos="punct" morph="none" start_char="882" end_char="882">,</TOKEN>
        <TOKEN id="token-18-15" pos="word" morph="none" start_char="884" end_char="885">by</TOKEN>
      </SEG>
      <SEG id="segment-19" start_char="887" end_char="964">
        <ORIGINAL_TEXT>contrast, begins not with the physical or even the electronic book, but rather</ORIGINAL_TEXT>
        <TOKEN id="token-19-0" pos="word" morph="none" start_char="887" end_char="894">contrast</TOKEN>
        <TOKEN id="token-19-1" pos="punct" morph="none" start_char="895" end_char="895">,</TOKEN>
        <TOKEN id="token-19-2" pos="word" morph="none" start_char="897" end_char="902">begins</TOKEN>
        <TOKEN id="token-19-3" pos="word" morph="none" start_char="904" end_char="906">not</TOKEN>
        <TOKEN id="token-19-4" pos="word" morph="none" start_char="908" end_char="911">with</TOKEN>
        <TOKEN id="token-19-5" pos="word" morph="none" start_char="913" end_char="915">the</TOKEN>
        <TOKEN id="token-19-6" pos="word" morph="none" start_char="917" end_char="924">physical</TOKEN>
        <TOKEN id="token-19-7" pos="word" morph="none" start_char="926" end_char="927">or</TOKEN>
        <TOKEN id="token-19-8" pos="word" morph="none" start_char="929" end_char="932">even</TOKEN>
        <TOKEN id="token-19-9" pos="word" morph="none" start_char="934" end_char="936">the</TOKEN>
        <TOKEN id="token-19-10" pos="word" morph="none" start_char="938" end_char="947">electronic</TOKEN>
        <TOKEN id="token-19-11" pos="word" morph="none" start_char="949" end_char="952">book</TOKEN>
        <TOKEN id="token-19-12" pos="punct" morph="none" start_char="953" end_char="953">,</TOKEN>
        <TOKEN id="token-19-13" pos="word" morph="none" start_char="955" end_char="957">but</TOKEN>
        <TOKEN id="token-19-14" pos="word" morph="none" start_char="959" end_char="964">rather</TOKEN>
      </SEG>
      <SEG id="segment-20" start_char="966" end_char="1037">
        <ORIGINAL_TEXT>with the advance “leaks” in Politico, and the Fox News reports about the</ORIGINAL_TEXT>
        <TOKEN id="token-20-0" pos="word" morph="none" start_char="966" end_char="969">with</TOKEN>
        <TOKEN id="token-20-1" pos="word" morph="none" start_char="971" end_char="973">the</TOKEN>
        <TOKEN id="token-20-2" pos="word" morph="none" start_char="975" end_char="981">advance</TOKEN>
        <TOKEN id="token-20-3" pos="punct" morph="none" start_char="983" end_char="983">“</TOKEN>
        <TOKEN id="token-20-4" pos="word" morph="none" start_char="984" end_char="988">leaks</TOKEN>
        <TOKEN id="token-20-5" pos="punct" morph="none" start_char="989" end_char="989">”</TOKEN>
        <TOKEN id="token-20-6" pos="word" morph="none" start_char="991" end_char="992">in</TOKEN>
        <TOKEN id="token-20-7" pos="word" morph="none" start_char="994" end_char="1001">Politico</TOKEN>
        <TOKEN id="token-20-8" pos="punct" morph="none" start_char="1002" end_char="1002">,</TOKEN>
        <TOKEN id="token-20-9" pos="word" morph="none" start_char="1004" end_char="1006">and</TOKEN>
        <TOKEN id="token-20-10" pos="word" morph="none" start_char="1008" end_char="1010">the</TOKEN>
        <TOKEN id="token-20-11" pos="word" morph="none" start_char="1012" end_char="1014">Fox</TOKEN>
        <TOKEN id="token-20-12" pos="word" morph="none" start_char="1016" end_char="1019">News</TOKEN>
        <TOKEN id="token-20-13" pos="word" morph="none" start_char="1021" end_char="1027">reports</TOKEN>
        <TOKEN id="token-20-14" pos="word" morph="none" start_char="1029" end_char="1033">about</TOKEN>
        <TOKEN id="token-20-15" pos="word" morph="none" start_char="1035" end_char="1037">the</TOKEN>
      </SEG>
      <SEG id="segment-21" start_char="1039" end_char="1104">
        <ORIGINAL_TEXT>advance “leaks” in Politico, and The Wire’s report on the Fox News</ORIGINAL_TEXT>
        <TOKEN id="token-21-0" pos="word" morph="none" start_char="1039" end_char="1045">advance</TOKEN>
        <TOKEN id="token-21-1" pos="punct" morph="none" start_char="1047" end_char="1047">“</TOKEN>
        <TOKEN id="token-21-2" pos="word" morph="none" start_char="1048" end_char="1052">leaks</TOKEN>
        <TOKEN id="token-21-3" pos="punct" morph="none" start_char="1053" end_char="1053">”</TOKEN>
        <TOKEN id="token-21-4" pos="word" morph="none" start_char="1055" end_char="1056">in</TOKEN>
        <TOKEN id="token-21-5" pos="word" morph="none" start_char="1058" end_char="1065">Politico</TOKEN>
        <TOKEN id="token-21-6" pos="punct" morph="none" start_char="1066" end_char="1066">,</TOKEN>
        <TOKEN id="token-21-7" pos="word" morph="none" start_char="1068" end_char="1070">and</TOKEN>
        <TOKEN id="token-21-8" pos="word" morph="none" start_char="1072" end_char="1074">The</TOKEN>
        <TOKEN id="token-21-9" pos="word" morph="none" start_char="1076" end_char="1079">Wire</TOKEN>
        <TOKEN id="token-21-10" pos="punct" morph="none" start_char="1080" end_char="1080">’</TOKEN>
        <TOKEN id="token-21-11" pos="word" morph="none" start_char="1081" end_char="1081">s</TOKEN>
        <TOKEN id="token-21-12" pos="word" morph="none" start_char="1083" end_char="1088">report</TOKEN>
        <TOKEN id="token-21-13" pos="word" morph="none" start_char="1090" end_char="1091">on</TOKEN>
        <TOKEN id="token-21-14" pos="word" morph="none" start_char="1093" end_char="1095">the</TOKEN>
        <TOKEN id="token-21-15" pos="word" morph="none" start_char="1097" end_char="1099">Fox</TOKEN>
        <TOKEN id="token-21-16" pos="word" morph="none" start_char="1101" end_char="1104">News</TOKEN>
      </SEG>
      <SEG id="segment-22" start_char="1106" end_char="1179">
        <ORIGINAL_TEXT>reporting on the advance “leaks” in Politico. To understand this book, one</ORIGINAL_TEXT>
        <TOKEN id="token-22-0" pos="word" morph="none" start_char="1106" end_char="1114">reporting</TOKEN>
        <TOKEN id="token-22-1" pos="word" morph="none" start_char="1116" end_char="1117">on</TOKEN>
        <TOKEN id="token-22-2" pos="word" morph="none" start_char="1119" end_char="1121">the</TOKEN>
        <TOKEN id="token-22-3" pos="word" morph="none" start_char="1123" end_char="1129">advance</TOKEN>
        <TOKEN id="token-22-4" pos="punct" morph="none" start_char="1131" end_char="1131">“</TOKEN>
        <TOKEN id="token-22-5" pos="word" morph="none" start_char="1132" end_char="1136">leaks</TOKEN>
        <TOKEN id="token-22-6" pos="punct" morph="none" start_char="1137" end_char="1137">”</TOKEN>
        <TOKEN id="token-22-7" pos="word" morph="none" start_char="1139" end_char="1140">in</TOKEN>
        <TOKEN id="token-22-8" pos="word" morph="none" start_char="1142" end_char="1149">Politico</TOKEN>
        <TOKEN id="token-22-9" pos="punct" morph="none" start_char="1150" end_char="1150">.</TOKEN>
        <TOKEN id="token-22-10" pos="word" morph="none" start_char="1152" end_char="1153">To</TOKEN>
        <TOKEN id="token-22-11" pos="word" morph="none" start_char="1155" end_char="1164">understand</TOKEN>
        <TOKEN id="token-22-12" pos="word" morph="none" start_char="1166" end_char="1169">this</TOKEN>
        <TOKEN id="token-22-13" pos="word" morph="none" start_char="1171" end_char="1174">book</TOKEN>
        <TOKEN id="token-22-14" pos="punct" morph="none" start_char="1175" end_char="1175">,</TOKEN>
        <TOKEN id="token-22-15" pos="word" morph="none" start_char="1177" end_char="1179">one</TOKEN>
      </SEG>
      <SEG id="segment-23" start_char="1181" end_char="1258">
        <ORIGINAL_TEXT>must be aware also of the Diane Sawyer interview with Hillary Clinton, and the</ORIGINAL_TEXT>
        <TOKEN id="token-23-0" pos="word" morph="none" start_char="1181" end_char="1184">must</TOKEN>
        <TOKEN id="token-23-1" pos="word" morph="none" start_char="1186" end_char="1187">be</TOKEN>
        <TOKEN id="token-23-2" pos="word" morph="none" start_char="1189" end_char="1193">aware</TOKEN>
        <TOKEN id="token-23-3" pos="word" morph="none" start_char="1195" end_char="1198">also</TOKEN>
        <TOKEN id="token-23-4" pos="word" morph="none" start_char="1200" end_char="1201">of</TOKEN>
        <TOKEN id="token-23-5" pos="word" morph="none" start_char="1203" end_char="1205">the</TOKEN>
        <TOKEN id="token-23-6" pos="word" morph="none" start_char="1207" end_char="1211">Diane</TOKEN>
        <TOKEN id="token-23-7" pos="word" morph="none" start_char="1213" end_char="1218">Sawyer</TOKEN>
        <TOKEN id="token-23-8" pos="word" morph="none" start_char="1220" end_char="1228">interview</TOKEN>
        <TOKEN id="token-23-9" pos="word" morph="none" start_char="1230" end_char="1233">with</TOKEN>
        <TOKEN id="token-23-10" pos="word" morph="none" start_char="1235" end_char="1241">Hillary</TOKEN>
        <TOKEN id="token-23-11" pos="word" morph="none" start_char="1243" end_char="1249">Clinton</TOKEN>
        <TOKEN id="token-23-12" pos="punct" morph="none" start_char="1250" end_char="1250">,</TOKEN>
        <TOKEN id="token-23-13" pos="word" morph="none" start_char="1252" end_char="1254">and</TOKEN>
        <TOKEN id="token-23-14" pos="word" morph="none" start_char="1256" end_char="1258">the</TOKEN>
      </SEG>
      <SEG id="segment-24" start_char="1260" end_char="1334">
        <ORIGINAL_TEXT>Twitter rage about the Diane Sawyer interview with Hillary Clinton, and the</ORIGINAL_TEXT>
        <TOKEN id="token-24-0" pos="word" morph="none" start_char="1260" end_char="1266">Twitter</TOKEN>
        <TOKEN id="token-24-1" pos="word" morph="none" start_char="1268" end_char="1271">rage</TOKEN>
        <TOKEN id="token-24-2" pos="word" morph="none" start_char="1273" end_char="1277">about</TOKEN>
        <TOKEN id="token-24-3" pos="word" morph="none" start_char="1279" end_char="1281">the</TOKEN>
        <TOKEN id="token-24-4" pos="word" morph="none" start_char="1283" end_char="1287">Diane</TOKEN>
        <TOKEN id="token-24-5" pos="word" morph="none" start_char="1289" end_char="1294">Sawyer</TOKEN>
        <TOKEN id="token-24-6" pos="word" morph="none" start_char="1296" end_char="1304">interview</TOKEN>
        <TOKEN id="token-24-7" pos="word" morph="none" start_char="1306" end_char="1309">with</TOKEN>
        <TOKEN id="token-24-8" pos="word" morph="none" start_char="1311" end_char="1317">Hillary</TOKEN>
        <TOKEN id="token-24-9" pos="word" morph="none" start_char="1319" end_char="1325">Clinton</TOKEN>
        <TOKEN id="token-24-10" pos="punct" morph="none" start_char="1326" end_char="1326">,</TOKEN>
        <TOKEN id="token-24-11" pos="word" morph="none" start_char="1328" end_char="1330">and</TOKEN>
        <TOKEN id="token-24-12" pos="word" morph="none" start_char="1332" end_char="1334">the</TOKEN>
      </SEG>
      <SEG id="segment-25" start_char="1336" end_char="1407">
        <ORIGINAL_TEXT>Slate analysis of the Twitter rage about the Diane Sawyer interview with</ORIGINAL_TEXT>
        <TOKEN id="token-25-0" pos="word" morph="none" start_char="1336" end_char="1340">Slate</TOKEN>
        <TOKEN id="token-25-1" pos="word" morph="none" start_char="1342" end_char="1349">analysis</TOKEN>
        <TOKEN id="token-25-2" pos="word" morph="none" start_char="1351" end_char="1352">of</TOKEN>
        <TOKEN id="token-25-3" pos="word" morph="none" start_char="1354" end_char="1356">the</TOKEN>
        <TOKEN id="token-25-4" pos="word" morph="none" start_char="1358" end_char="1364">Twitter</TOKEN>
        <TOKEN id="token-25-5" pos="word" morph="none" start_char="1366" end_char="1369">rage</TOKEN>
        <TOKEN id="token-25-6" pos="word" morph="none" start_char="1371" end_char="1375">about</TOKEN>
        <TOKEN id="token-25-7" pos="word" morph="none" start_char="1377" end_char="1379">the</TOKEN>
        <TOKEN id="token-25-8" pos="word" morph="none" start_char="1381" end_char="1385">Diane</TOKEN>
        <TOKEN id="token-25-9" pos="word" morph="none" start_char="1387" end_char="1392">Sawyer</TOKEN>
        <TOKEN id="token-25-10" pos="word" morph="none" start_char="1394" end_char="1402">interview</TOKEN>
        <TOKEN id="token-25-11" pos="word" morph="none" start_char="1404" end_char="1407">with</TOKEN>
      </SEG>
      <SEG id="segment-26" start_char="1409" end_char="1472">
        <ORIGINAL_TEXT>Hillary Clinton. And then there is the NPR interview, and so on.</ORIGINAL_TEXT>
        <TOKEN id="token-26-0" pos="word" morph="none" start_char="1409" end_char="1415">Hillary</TOKEN>
        <TOKEN id="token-26-1" pos="word" morph="none" start_char="1417" end_char="1423">Clinton</TOKEN>
        <TOKEN id="token-26-2" pos="punct" morph="none" start_char="1424" end_char="1424">.</TOKEN>
        <TOKEN id="token-26-3" pos="word" morph="none" start_char="1426" end_char="1428">And</TOKEN>
        <TOKEN id="token-26-4" pos="word" morph="none" start_char="1430" end_char="1433">then</TOKEN>
        <TOKEN id="token-26-5" pos="word" morph="none" start_char="1435" end_char="1439">there</TOKEN>
        <TOKEN id="token-26-6" pos="word" morph="none" start_char="1441" end_char="1442">is</TOKEN>
        <TOKEN id="token-26-7" pos="word" morph="none" start_char="1444" end_char="1446">the</TOKEN>
        <TOKEN id="token-26-8" pos="word" morph="none" start_char="1448" end_char="1450">NPR</TOKEN>
        <TOKEN id="token-26-9" pos="word" morph="none" start_char="1452" end_char="1460">interview</TOKEN>
        <TOKEN id="token-26-10" pos="punct" morph="none" start_char="1461" end_char="1461">,</TOKEN>
        <TOKEN id="token-26-11" pos="word" morph="none" start_char="1463" end_char="1465">and</TOKEN>
        <TOKEN id="token-26-12" pos="word" morph="none" start_char="1467" end_char="1468">so</TOKEN>
        <TOKEN id="token-26-13" pos="word" morph="none" start_char="1470" end_char="1471">on</TOKEN>
        <TOKEN id="token-26-14" pos="punct" morph="none" start_char="1472" end_char="1472">.</TOKEN>
      </SEG>
      <SEG id="segment-27" start_char="1474" end_char="1477">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-27-0" pos="unknown" morph="none" start_char="1474" end_char="1477">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-28" start_char="1479" end_char="1481">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-28-0" pos="unknown" morph="none" start_char="1479" end_char="1481">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-29" start_char="1483" end_char="1553">
        <ORIGINAL_TEXT>For this reason, Hard Choices presents the reviewer with an existential</ORIGINAL_TEXT>
        <TOKEN id="token-29-0" pos="word" morph="none" start_char="1483" end_char="1485">For</TOKEN>
        <TOKEN id="token-29-1" pos="word" morph="none" start_char="1487" end_char="1490">this</TOKEN>
        <TOKEN id="token-29-2" pos="word" morph="none" start_char="1492" end_char="1497">reason</TOKEN>
        <TOKEN id="token-29-3" pos="punct" morph="none" start_char="1498" end_char="1498">,</TOKEN>
        <TOKEN id="token-29-4" pos="word" morph="none" start_char="1500" end_char="1503">Hard</TOKEN>
        <TOKEN id="token-29-5" pos="word" morph="none" start_char="1505" end_char="1511">Choices</TOKEN>
        <TOKEN id="token-29-6" pos="word" morph="none" start_char="1513" end_char="1520">presents</TOKEN>
        <TOKEN id="token-29-7" pos="word" morph="none" start_char="1522" end_char="1524">the</TOKEN>
        <TOKEN id="token-29-8" pos="word" morph="none" start_char="1526" end_char="1533">reviewer</TOKEN>
        <TOKEN id="token-29-9" pos="word" morph="none" start_char="1535" end_char="1538">with</TOKEN>
        <TOKEN id="token-29-10" pos="word" morph="none" start_char="1540" end_char="1541">an</TOKEN>
        <TOKEN id="token-29-11" pos="word" morph="none" start_char="1543" end_char="1553">existential</TOKEN>
      </SEG>
      <SEG id="segment-30" start_char="1555" end_char="1631">
        <ORIGINAL_TEXT>problem: is it actually a book? Is it even intended to be a thing that people</ORIGINAL_TEXT>
        <TOKEN id="token-30-0" pos="word" morph="none" start_char="1555" end_char="1561">problem</TOKEN>
        <TOKEN id="token-30-1" pos="punct" morph="none" start_char="1562" end_char="1562">:</TOKEN>
        <TOKEN id="token-30-2" pos="word" morph="none" start_char="1564" end_char="1565">is</TOKEN>
        <TOKEN id="token-30-3" pos="word" morph="none" start_char="1567" end_char="1568">it</TOKEN>
        <TOKEN id="token-30-4" pos="word" morph="none" start_char="1570" end_char="1577">actually</TOKEN>
        <TOKEN id="token-30-5" pos="word" morph="none" start_char="1579" end_char="1579">a</TOKEN>
        <TOKEN id="token-30-6" pos="word" morph="none" start_char="1581" end_char="1584">book</TOKEN>
        <TOKEN id="token-30-7" pos="punct" morph="none" start_char="1585" end_char="1585">?</TOKEN>
        <TOKEN id="token-30-8" pos="word" morph="none" start_char="1587" end_char="1588">Is</TOKEN>
        <TOKEN id="token-30-9" pos="word" morph="none" start_char="1590" end_char="1591">it</TOKEN>
        <TOKEN id="token-30-10" pos="word" morph="none" start_char="1593" end_char="1596">even</TOKEN>
        <TOKEN id="token-30-11" pos="word" morph="none" start_char="1598" end_char="1605">intended</TOKEN>
        <TOKEN id="token-30-12" pos="word" morph="none" start_char="1607" end_char="1608">to</TOKEN>
        <TOKEN id="token-30-13" pos="word" morph="none" start_char="1610" end_char="1611">be</TOKEN>
        <TOKEN id="token-30-14" pos="word" morph="none" start_char="1613" end_char="1613">a</TOKEN>
        <TOKEN id="token-30-15" pos="word" morph="none" start_char="1615" end_char="1619">thing</TOKEN>
        <TOKEN id="token-30-16" pos="word" morph="none" start_char="1621" end_char="1624">that</TOKEN>
        <TOKEN id="token-30-17" pos="word" morph="none" start_char="1626" end_char="1631">people</TOKEN>
      </SEG>
      <SEG id="segment-31" start_char="1633" end_char="1708">
        <ORIGINAL_TEXT>sit down and read, cover to cover? Or is it rather a collection of carefully</ORIGINAL_TEXT>
        <TOKEN id="token-31-0" pos="word" morph="none" start_char="1633" end_char="1635">sit</TOKEN>
        <TOKEN id="token-31-1" pos="word" morph="none" start_char="1637" end_char="1640">down</TOKEN>
        <TOKEN id="token-31-2" pos="word" morph="none" start_char="1642" end_char="1644">and</TOKEN>
        <TOKEN id="token-31-3" pos="word" morph="none" start_char="1646" end_char="1649">read</TOKEN>
        <TOKEN id="token-31-4" pos="punct" morph="none" start_char="1650" end_char="1650">,</TOKEN>
        <TOKEN id="token-31-5" pos="word" morph="none" start_char="1652" end_char="1656">cover</TOKEN>
        <TOKEN id="token-31-6" pos="word" morph="none" start_char="1658" end_char="1659">to</TOKEN>
        <TOKEN id="token-31-7" pos="word" morph="none" start_char="1661" end_char="1665">cover</TOKEN>
        <TOKEN id="token-31-8" pos="punct" morph="none" start_char="1666" end_char="1666">?</TOKEN>
        <TOKEN id="token-31-9" pos="word" morph="none" start_char="1668" end_char="1669">Or</TOKEN>
        <TOKEN id="token-31-10" pos="word" morph="none" start_char="1671" end_char="1672">is</TOKEN>
        <TOKEN id="token-31-11" pos="word" morph="none" start_char="1674" end_char="1675">it</TOKEN>
        <TOKEN id="token-31-12" pos="word" morph="none" start_char="1677" end_char="1682">rather</TOKEN>
        <TOKEN id="token-31-13" pos="word" morph="none" start_char="1684" end_char="1684">a</TOKEN>
        <TOKEN id="token-31-14" pos="word" morph="none" start_char="1686" end_char="1695">collection</TOKEN>
        <TOKEN id="token-31-15" pos="word" morph="none" start_char="1697" end_char="1698">of</TOKEN>
        <TOKEN id="token-31-16" pos="word" morph="none" start_char="1700" end_char="1708">carefully</TOKEN>
      </SEG>
      <SEG id="segment-32" start_char="1710" end_char="1786">
        <ORIGINAL_TEXT>crafted messages, each designed to reach a particular person, or to deflect a</ORIGINAL_TEXT>
        <TOKEN id="token-32-0" pos="word" morph="none" start_char="1710" end_char="1716">crafted</TOKEN>
        <TOKEN id="token-32-1" pos="word" morph="none" start_char="1718" end_char="1725">messages</TOKEN>
        <TOKEN id="token-32-2" pos="punct" morph="none" start_char="1726" end_char="1726">,</TOKEN>
        <TOKEN id="token-32-3" pos="word" morph="none" start_char="1728" end_char="1731">each</TOKEN>
        <TOKEN id="token-32-4" pos="word" morph="none" start_char="1733" end_char="1740">designed</TOKEN>
        <TOKEN id="token-32-5" pos="word" morph="none" start_char="1742" end_char="1743">to</TOKEN>
        <TOKEN id="token-32-6" pos="word" morph="none" start_char="1745" end_char="1749">reach</TOKEN>
        <TOKEN id="token-32-7" pos="word" morph="none" start_char="1751" end_char="1751">a</TOKEN>
        <TOKEN id="token-32-8" pos="word" morph="none" start_char="1753" end_char="1762">particular</TOKEN>
        <TOKEN id="token-32-9" pos="word" morph="none" start_char="1764" end_char="1769">person</TOKEN>
        <TOKEN id="token-32-10" pos="punct" morph="none" start_char="1770" end_char="1770">,</TOKEN>
        <TOKEN id="token-32-11" pos="word" morph="none" start_char="1772" end_char="1773">or</TOKEN>
        <TOKEN id="token-32-12" pos="word" morph="none" start_char="1775" end_char="1776">to</TOKEN>
        <TOKEN id="token-32-13" pos="word" morph="none" start_char="1778" end_char="1784">deflect</TOKEN>
        <TOKEN id="token-32-14" pos="word" morph="none" start_char="1786" end_char="1786">a</TOKEN>
      </SEG>
      <SEG id="segment-33" start_char="1788" end_char="1865">
        <ORIGINAL_TEXT>particular criticism, or to inspire a certain kind of remark? When my husband,</ORIGINAL_TEXT>
        <TOKEN id="token-33-0" pos="word" morph="none" start_char="1788" end_char="1797">particular</TOKEN>
        <TOKEN id="token-33-1" pos="word" morph="none" start_char="1799" end_char="1807">criticism</TOKEN>
        <TOKEN id="token-33-2" pos="punct" morph="none" start_char="1808" end_char="1808">,</TOKEN>
        <TOKEN id="token-33-3" pos="word" morph="none" start_char="1810" end_char="1811">or</TOKEN>
        <TOKEN id="token-33-4" pos="word" morph="none" start_char="1813" end_char="1814">to</TOKEN>
        <TOKEN id="token-33-5" pos="word" morph="none" start_char="1816" end_char="1822">inspire</TOKEN>
        <TOKEN id="token-33-6" pos="word" morph="none" start_char="1824" end_char="1824">a</TOKEN>
        <TOKEN id="token-33-7" pos="word" morph="none" start_char="1826" end_char="1832">certain</TOKEN>
        <TOKEN id="token-33-8" pos="word" morph="none" start_char="1834" end_char="1837">kind</TOKEN>
        <TOKEN id="token-33-9" pos="word" morph="none" start_char="1839" end_char="1840">of</TOKEN>
        <TOKEN id="token-33-10" pos="word" morph="none" start_char="1842" end_char="1847">remark</TOKEN>
        <TOKEN id="token-33-11" pos="punct" morph="none" start_char="1848" end_char="1848">?</TOKEN>
        <TOKEN id="token-33-12" pos="word" morph="none" start_char="1850" end_char="1853">When</TOKEN>
        <TOKEN id="token-33-13" pos="word" morph="none" start_char="1855" end_char="1856">my</TOKEN>
        <TOKEN id="token-33-14" pos="word" morph="none" start_char="1858" end_char="1864">husband</TOKEN>
        <TOKEN id="token-33-15" pos="punct" morph="none" start_char="1865" end_char="1865">,</TOKEN>
      </SEG>
      <SEG id="segment-34" start_char="1867" end_char="1943">
        <ORIGINAL_TEXT>who happens to be the foreign minister of Poland, saw the book on my desk, he</ORIGINAL_TEXT>
        <TOKEN id="token-34-0" pos="word" morph="none" start_char="1867" end_char="1869">who</TOKEN>
        <TOKEN id="token-34-1" pos="word" morph="none" start_char="1871" end_char="1877">happens</TOKEN>
        <TOKEN id="token-34-2" pos="word" morph="none" start_char="1879" end_char="1880">to</TOKEN>
        <TOKEN id="token-34-3" pos="word" morph="none" start_char="1882" end_char="1883">be</TOKEN>
        <TOKEN id="token-34-4" pos="word" morph="none" start_char="1885" end_char="1887">the</TOKEN>
        <TOKEN id="token-34-5" pos="word" morph="none" start_char="1889" end_char="1895">foreign</TOKEN>
        <TOKEN id="token-34-6" pos="word" morph="none" start_char="1897" end_char="1904">minister</TOKEN>
        <TOKEN id="token-34-7" pos="word" morph="none" start_char="1906" end_char="1907">of</TOKEN>
        <TOKEN id="token-34-8" pos="word" morph="none" start_char="1909" end_char="1914">Poland</TOKEN>
        <TOKEN id="token-34-9" pos="punct" morph="none" start_char="1915" end_char="1915">,</TOKEN>
        <TOKEN id="token-34-10" pos="word" morph="none" start_char="1917" end_char="1919">saw</TOKEN>
        <TOKEN id="token-34-11" pos="word" morph="none" start_char="1921" end_char="1923">the</TOKEN>
        <TOKEN id="token-34-12" pos="word" morph="none" start_char="1925" end_char="1928">book</TOKEN>
        <TOKEN id="token-34-13" pos="word" morph="none" start_char="1930" end_char="1931">on</TOKEN>
        <TOKEN id="token-34-14" pos="word" morph="none" start_char="1933" end_char="1934">my</TOKEN>
        <TOKEN id="token-34-15" pos="word" morph="none" start_char="1936" end_char="1939">desk</TOKEN>
        <TOKEN id="token-34-16" pos="punct" morph="none" start_char="1940" end_char="1940">,</TOKEN>
        <TOKEN id="token-34-17" pos="word" morph="none" start_char="1942" end_char="1943">he</TOKEN>
      </SEG>
      <SEG id="segment-35" start_char="1945" end_char="2022">
        <ORIGINAL_TEXT>picked it up, flipped to the index, and checked to see if he is mentioned. (He</ORIGINAL_TEXT>
        <TOKEN id="token-35-0" pos="word" morph="none" start_char="1945" end_char="1950">picked</TOKEN>
        <TOKEN id="token-35-1" pos="word" morph="none" start_char="1952" end_char="1953">it</TOKEN>
        <TOKEN id="token-35-2" pos="word" morph="none" start_char="1955" end_char="1956">up</TOKEN>
        <TOKEN id="token-35-3" pos="punct" morph="none" start_char="1957" end_char="1957">,</TOKEN>
        <TOKEN id="token-35-4" pos="word" morph="none" start_char="1959" end_char="1965">flipped</TOKEN>
        <TOKEN id="token-35-5" pos="word" morph="none" start_char="1967" end_char="1968">to</TOKEN>
        <TOKEN id="token-35-6" pos="word" morph="none" start_char="1970" end_char="1972">the</TOKEN>
        <TOKEN id="token-35-7" pos="word" morph="none" start_char="1974" end_char="1978">index</TOKEN>
        <TOKEN id="token-35-8" pos="punct" morph="none" start_char="1979" end_char="1979">,</TOKEN>
        <TOKEN id="token-35-9" pos="word" morph="none" start_char="1981" end_char="1983">and</TOKEN>
        <TOKEN id="token-35-10" pos="word" morph="none" start_char="1985" end_char="1991">checked</TOKEN>
        <TOKEN id="token-35-11" pos="word" morph="none" start_char="1993" end_char="1994">to</TOKEN>
        <TOKEN id="token-35-12" pos="word" morph="none" start_char="1996" end_char="1998">see</TOKEN>
        <TOKEN id="token-35-13" pos="word" morph="none" start_char="2000" end_char="2001">if</TOKEN>
        <TOKEN id="token-35-14" pos="word" morph="none" start_char="2003" end_char="2004">he</TOKEN>
        <TOKEN id="token-35-15" pos="word" morph="none" start_char="2006" end_char="2007">is</TOKEN>
        <TOKEN id="token-35-16" pos="word" morph="none" start_char="2009" end_char="2017">mentioned</TOKEN>
        <TOKEN id="token-35-17" pos="punct" morph="none" start_char="2018" end_char="2018">.</TOKEN>
        <TOKEN id="token-35-18" pos="punct" morph="none" start_char="2020" end_char="2020">(</TOKEN>
        <TOKEN id="token-35-19" pos="word" morph="none" start_char="2021" end_char="2022">He</TOKEN>
      </SEG>
      <SEG id="segment-36" start_char="2024" end_char="2097">
        <ORIGINAL_TEXT>is.) I have absolutely no doubt that over the past several weeks that same</ORIGINAL_TEXT>
        <TOKEN id="token-36-0" pos="word" morph="none" start_char="2024" end_char="2025">is</TOKEN>
        <TOKEN id="token-36-1" pos="punct" morph="none" start_char="2026" end_char="2027">.)</TOKEN>
        <TOKEN id="token-36-2" pos="word" morph="none" start_char="2029" end_char="2029">I</TOKEN>
        <TOKEN id="token-36-3" pos="word" morph="none" start_char="2031" end_char="2034">have</TOKEN>
        <TOKEN id="token-36-4" pos="word" morph="none" start_char="2036" end_char="2045">absolutely</TOKEN>
        <TOKEN id="token-36-5" pos="word" morph="none" start_char="2047" end_char="2048">no</TOKEN>
        <TOKEN id="token-36-6" pos="word" morph="none" start_char="2050" end_char="2054">doubt</TOKEN>
        <TOKEN id="token-36-7" pos="word" morph="none" start_char="2056" end_char="2059">that</TOKEN>
        <TOKEN id="token-36-8" pos="word" morph="none" start_char="2061" end_char="2064">over</TOKEN>
        <TOKEN id="token-36-9" pos="word" morph="none" start_char="2066" end_char="2068">the</TOKEN>
        <TOKEN id="token-36-10" pos="word" morph="none" start_char="2070" end_char="2073">past</TOKEN>
        <TOKEN id="token-36-11" pos="word" morph="none" start_char="2075" end_char="2081">several</TOKEN>
        <TOKEN id="token-36-12" pos="word" morph="none" start_char="2083" end_char="2087">weeks</TOKEN>
        <TOKEN id="token-36-13" pos="word" morph="none" start_char="2089" end_char="2092">that</TOKEN>
        <TOKEN id="token-36-14" pos="word" morph="none" start_char="2094" end_char="2097">same</TOKEN>
      </SEG>
      <SEG id="segment-37" start_char="2099" end_char="2171">
        <ORIGINAL_TEXT>action was performed by dozens of people in dozens of capitals around the</ORIGINAL_TEXT>
        <TOKEN id="token-37-0" pos="word" morph="none" start_char="2099" end_char="2104">action</TOKEN>
        <TOKEN id="token-37-1" pos="word" morph="none" start_char="2106" end_char="2108">was</TOKEN>
        <TOKEN id="token-37-2" pos="word" morph="none" start_char="2110" end_char="2118">performed</TOKEN>
        <TOKEN id="token-37-3" pos="word" morph="none" start_char="2120" end_char="2121">by</TOKEN>
        <TOKEN id="token-37-4" pos="word" morph="none" start_char="2123" end_char="2128">dozens</TOKEN>
        <TOKEN id="token-37-5" pos="word" morph="none" start_char="2130" end_char="2131">of</TOKEN>
        <TOKEN id="token-37-6" pos="word" morph="none" start_char="2133" end_char="2138">people</TOKEN>
        <TOKEN id="token-37-7" pos="word" morph="none" start_char="2140" end_char="2141">in</TOKEN>
        <TOKEN id="token-37-8" pos="word" morph="none" start_char="2143" end_char="2148">dozens</TOKEN>
        <TOKEN id="token-37-9" pos="word" morph="none" start_char="2150" end_char="2151">of</TOKEN>
        <TOKEN id="token-37-10" pos="word" morph="none" start_char="2153" end_char="2160">capitals</TOKEN>
        <TOKEN id="token-37-11" pos="word" morph="none" start_char="2162" end_char="2167">around</TOKEN>
        <TOKEN id="token-37-12" pos="word" morph="none" start_char="2169" end_char="2171">the</TOKEN>
      </SEG>
      <SEG id="segment-38" start_char="2173" end_char="2178">
        <ORIGINAL_TEXT>world.</ORIGINAL_TEXT>
        <TOKEN id="token-38-0" pos="word" morph="none" start_char="2173" end_char="2177">world</TOKEN>
        <TOKEN id="token-38-1" pos="punct" morph="none" start_char="2178" end_char="2178">.</TOKEN>
      </SEG>
      <SEG id="segment-39" start_char="2180" end_char="2183">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-39-0" pos="unknown" morph="none" start_char="2180" end_char="2183">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-40" start_char="2185" end_char="2187">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-40-0" pos="unknown" morph="none" start_char="2185" end_char="2187">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-41" start_char="2189" end_char="2264">
        <ORIGINAL_TEXT>Of course Clinton and her team anticipated, and helped to arrange, the media</ORIGINAL_TEXT>
        <TOKEN id="token-41-0" pos="word" morph="none" start_char="2189" end_char="2190">Of</TOKEN>
        <TOKEN id="token-41-1" pos="word" morph="none" start_char="2192" end_char="2197">course</TOKEN>
        <TOKEN id="token-41-2" pos="word" morph="none" start_char="2199" end_char="2205">Clinton</TOKEN>
        <TOKEN id="token-41-3" pos="word" morph="none" start_char="2207" end_char="2209">and</TOKEN>
        <TOKEN id="token-41-4" pos="word" morph="none" start_char="2211" end_char="2213">her</TOKEN>
        <TOKEN id="token-41-5" pos="word" morph="none" start_char="2215" end_char="2218">team</TOKEN>
        <TOKEN id="token-41-6" pos="word" morph="none" start_char="2220" end_char="2230">anticipated</TOKEN>
        <TOKEN id="token-41-7" pos="punct" morph="none" start_char="2231" end_char="2231">,</TOKEN>
        <TOKEN id="token-41-8" pos="word" morph="none" start_char="2233" end_char="2235">and</TOKEN>
        <TOKEN id="token-41-9" pos="word" morph="none" start_char="2237" end_char="2242">helped</TOKEN>
        <TOKEN id="token-41-10" pos="word" morph="none" start_char="2244" end_char="2245">to</TOKEN>
        <TOKEN id="token-41-11" pos="word" morph="none" start_char="2247" end_char="2253">arrange</TOKEN>
        <TOKEN id="token-41-12" pos="punct" morph="none" start_char="2254" end_char="2254">,</TOKEN>
        <TOKEN id="token-41-13" pos="word" morph="none" start_char="2256" end_char="2258">the</TOKEN>
        <TOKEN id="token-41-14" pos="word" morph="none" start_char="2260" end_char="2264">media</TOKEN>
      </SEG>
      <SEG id="segment-42" start_char="2266" end_char="2339">
        <ORIGINAL_TEXT>frenzy, and they knew that many would read the index before the book. Each</ORIGINAL_TEXT>
        <TOKEN id="token-42-0" pos="word" morph="none" start_char="2266" end_char="2271">frenzy</TOKEN>
        <TOKEN id="token-42-1" pos="punct" morph="none" start_char="2272" end_char="2272">,</TOKEN>
        <TOKEN id="token-42-2" pos="word" morph="none" start_char="2274" end_char="2276">and</TOKEN>
        <TOKEN id="token-42-3" pos="word" morph="none" start_char="2278" end_char="2281">they</TOKEN>
        <TOKEN id="token-42-4" pos="word" morph="none" start_char="2283" end_char="2286">knew</TOKEN>
        <TOKEN id="token-42-5" pos="word" morph="none" start_char="2288" end_char="2291">that</TOKEN>
        <TOKEN id="token-42-6" pos="word" morph="none" start_char="2293" end_char="2296">many</TOKEN>
        <TOKEN id="token-42-7" pos="word" morph="none" start_char="2298" end_char="2302">would</TOKEN>
        <TOKEN id="token-42-8" pos="word" morph="none" start_char="2304" end_char="2307">read</TOKEN>
        <TOKEN id="token-42-9" pos="word" morph="none" start_char="2309" end_char="2311">the</TOKEN>
        <TOKEN id="token-42-10" pos="word" morph="none" start_char="2313" end_char="2317">index</TOKEN>
        <TOKEN id="token-42-11" pos="word" morph="none" start_char="2319" end_char="2324">before</TOKEN>
        <TOKEN id="token-42-12" pos="word" morph="none" start_char="2326" end_char="2328">the</TOKEN>
        <TOKEN id="token-42-13" pos="word" morph="none" start_char="2330" end_char="2333">book</TOKEN>
        <TOKEN id="token-42-14" pos="punct" morph="none" start_char="2334" end_char="2334">.</TOKEN>
        <TOKEN id="token-42-15" pos="word" morph="none" start_char="2336" end_char="2339">Each</TOKEN>
      </SEG>
      <SEG id="segment-43" start_char="2341" end_char="2418">
        <ORIGINAL_TEXT>description therefore reads as if it had been vetted for that purpose. In Hard</ORIGINAL_TEXT>
        <TOKEN id="token-43-0" pos="word" morph="none" start_char="2341" end_char="2351">description</TOKEN>
        <TOKEN id="token-43-1" pos="word" morph="none" start_char="2353" end_char="2361">therefore</TOKEN>
        <TOKEN id="token-43-2" pos="word" morph="none" start_char="2363" end_char="2367">reads</TOKEN>
        <TOKEN id="token-43-3" pos="word" morph="none" start_char="2369" end_char="2370">as</TOKEN>
        <TOKEN id="token-43-4" pos="word" morph="none" start_char="2372" end_char="2373">if</TOKEN>
        <TOKEN id="token-43-5" pos="word" morph="none" start_char="2375" end_char="2376">it</TOKEN>
        <TOKEN id="token-43-6" pos="word" morph="none" start_char="2378" end_char="2380">had</TOKEN>
        <TOKEN id="token-43-7" pos="word" morph="none" start_char="2382" end_char="2385">been</TOKEN>
        <TOKEN id="token-43-8" pos="word" morph="none" start_char="2387" end_char="2392">vetted</TOKEN>
        <TOKEN id="token-43-9" pos="word" morph="none" start_char="2394" end_char="2396">for</TOKEN>
        <TOKEN id="token-43-10" pos="word" morph="none" start_char="2398" end_char="2401">that</TOKEN>
        <TOKEN id="token-43-11" pos="word" morph="none" start_char="2403" end_char="2409">purpose</TOKEN>
        <TOKEN id="token-43-12" pos="punct" morph="none" start_char="2410" end_char="2410">.</TOKEN>
        <TOKEN id="token-43-13" pos="word" morph="none" start_char="2412" end_char="2413">In</TOKEN>
        <TOKEN id="token-43-14" pos="word" morph="none" start_char="2415" end_char="2418">Hard</TOKEN>
      </SEG>
      <SEG id="segment-44" start_char="2420" end_char="2493">
        <ORIGINAL_TEXT>Choices, almost all of Clinton’s colleagues are admirable people who are a</ORIGINAL_TEXT>
        <TOKEN id="token-44-0" pos="word" morph="none" start_char="2420" end_char="2426">Choices</TOKEN>
        <TOKEN id="token-44-1" pos="punct" morph="none" start_char="2427" end_char="2427">,</TOKEN>
        <TOKEN id="token-44-2" pos="word" morph="none" start_char="2429" end_char="2434">almost</TOKEN>
        <TOKEN id="token-44-3" pos="word" morph="none" start_char="2436" end_char="2438">all</TOKEN>
        <TOKEN id="token-44-4" pos="word" morph="none" start_char="2440" end_char="2441">of</TOKEN>
        <TOKEN id="token-44-5" pos="word" morph="none" start_char="2443" end_char="2449">Clinton</TOKEN>
        <TOKEN id="token-44-6" pos="punct" morph="none" start_char="2450" end_char="2450">’</TOKEN>
        <TOKEN id="token-44-7" pos="word" morph="none" start_char="2451" end_char="2451">s</TOKEN>
        <TOKEN id="token-44-8" pos="word" morph="none" start_char="2453" end_char="2462">colleagues</TOKEN>
        <TOKEN id="token-44-9" pos="word" morph="none" start_char="2464" end_char="2466">are</TOKEN>
        <TOKEN id="token-44-10" pos="word" morph="none" start_char="2468" end_char="2476">admirable</TOKEN>
        <TOKEN id="token-44-11" pos="word" morph="none" start_char="2478" end_char="2483">people</TOKEN>
        <TOKEN id="token-44-12" pos="word" morph="none" start_char="2485" end_char="2487">who</TOKEN>
        <TOKEN id="token-44-13" pos="word" morph="none" start_char="2489" end_char="2491">are</TOKEN>
        <TOKEN id="token-44-14" pos="word" morph="none" start_char="2493" end_char="2493">a</TOKEN>
      </SEG>
      <SEG id="segment-45" start_char="2495" end_char="2551">
        <ORIGINAL_TEXT>“living embodiment of the American Dream,” or a “terrific</ORIGINAL_TEXT>
        <TOKEN id="token-45-0" pos="punct" morph="none" start_char="2495" end_char="2495">“</TOKEN>
        <TOKEN id="token-45-1" pos="word" morph="none" start_char="2496" end_char="2501">living</TOKEN>
        <TOKEN id="token-45-2" pos="word" morph="none" start_char="2503" end_char="2512">embodiment</TOKEN>
        <TOKEN id="token-45-3" pos="word" morph="none" start_char="2514" end_char="2515">of</TOKEN>
        <TOKEN id="token-45-4" pos="word" morph="none" start_char="2517" end_char="2519">the</TOKEN>
        <TOKEN id="token-45-5" pos="word" morph="none" start_char="2521" end_char="2528">American</TOKEN>
        <TOKEN id="token-45-6" pos="word" morph="none" start_char="2530" end_char="2534">Dream</TOKEN>
        <TOKEN id="token-45-7" pos="punct" morph="none" start_char="2535" end_char="2536">,”</TOKEN>
        <TOKEN id="token-45-8" pos="word" morph="none" start_char="2538" end_char="2539">or</TOKEN>
        <TOKEN id="token-45-9" pos="word" morph="none" start_char="2541" end_char="2541">a</TOKEN>
        <TOKEN id="token-45-10" pos="punct" morph="none" start_char="2543" end_char="2543">“</TOKEN>
        <TOKEN id="token-45-11" pos="word" morph="none" start_char="2544" end_char="2551">terrific</TOKEN>
      </SEG>
      <SEG id="segment-46" start_char="2553" end_char="2627">
        <ORIGINAL_TEXT>communicator” who works hard while always remaining decent, passionate, and</ORIGINAL_TEXT>
        <TOKEN id="token-46-0" pos="word" morph="none" start_char="2553" end_char="2564">communicator</TOKEN>
        <TOKEN id="token-46-1" pos="punct" morph="none" start_char="2565" end_char="2565">”</TOKEN>
        <TOKEN id="token-46-2" pos="word" morph="none" start_char="2567" end_char="2569">who</TOKEN>
        <TOKEN id="token-46-3" pos="word" morph="none" start_char="2571" end_char="2575">works</TOKEN>
        <TOKEN id="token-46-4" pos="word" morph="none" start_char="2577" end_char="2580">hard</TOKEN>
        <TOKEN id="token-46-5" pos="word" morph="none" start_char="2582" end_char="2586">while</TOKEN>
        <TOKEN id="token-46-6" pos="word" morph="none" start_char="2588" end_char="2593">always</TOKEN>
        <TOKEN id="token-46-7" pos="word" morph="none" start_char="2595" end_char="2603">remaining</TOKEN>
        <TOKEN id="token-46-8" pos="word" morph="none" start_char="2605" end_char="2610">decent</TOKEN>
        <TOKEN id="token-46-9" pos="punct" morph="none" start_char="2611" end_char="2611">,</TOKEN>
        <TOKEN id="token-46-10" pos="word" morph="none" start_char="2613" end_char="2622">passionate</TOKEN>
        <TOKEN id="token-46-11" pos="punct" morph="none" start_char="2623" end_char="2623">,</TOKEN>
        <TOKEN id="token-46-12" pos="word" morph="none" start_char="2625" end_char="2627">and</TOKEN>
      </SEG>
      <SEG id="segment-47" start_char="2629" end_char="2699">
        <ORIGINAL_TEXT>unstoppable. If they are slightly difficult colleagues, they might be a</ORIGINAL_TEXT>
        <TOKEN id="token-47-0" pos="word" morph="none" start_char="2629" end_char="2639">unstoppable</TOKEN>
        <TOKEN id="token-47-1" pos="punct" morph="none" start_char="2640" end_char="2640">.</TOKEN>
        <TOKEN id="token-47-2" pos="word" morph="none" start_char="2642" end_char="2643">If</TOKEN>
        <TOKEN id="token-47-3" pos="word" morph="none" start_char="2645" end_char="2648">they</TOKEN>
        <TOKEN id="token-47-4" pos="word" morph="none" start_char="2650" end_char="2652">are</TOKEN>
        <TOKEN id="token-47-5" pos="word" morph="none" start_char="2654" end_char="2661">slightly</TOKEN>
        <TOKEN id="token-47-6" pos="word" morph="none" start_char="2663" end_char="2671">difficult</TOKEN>
        <TOKEN id="token-47-7" pos="word" morph="none" start_char="2673" end_char="2682">colleagues</TOKEN>
        <TOKEN id="token-47-8" pos="punct" morph="none" start_char="2683" end_char="2683">,</TOKEN>
        <TOKEN id="token-47-9" pos="word" morph="none" start_char="2685" end_char="2688">they</TOKEN>
        <TOKEN id="token-47-10" pos="word" morph="none" start_char="2690" end_char="2694">might</TOKEN>
        <TOKEN id="token-47-11" pos="word" morph="none" start_char="2696" end_char="2697">be</TOKEN>
        <TOKEN id="token-47-12" pos="word" morph="none" start_char="2699" end_char="2699">a</TOKEN>
      </SEG>
      <SEG id="segment-48" start_char="2701" end_char="2770">
        <ORIGINAL_TEXT>“creative thinker” (Rahm Emanuel) or have a “bulldozer style” (Richard</ORIGINAL_TEXT>
        <TOKEN id="token-48-0" pos="punct" morph="none" start_char="2701" end_char="2701">“</TOKEN>
        <TOKEN id="token-48-1" pos="word" morph="none" start_char="2702" end_char="2709">creative</TOKEN>
        <TOKEN id="token-48-2" pos="word" morph="none" start_char="2711" end_char="2717">thinker</TOKEN>
        <TOKEN id="token-48-3" pos="punct" morph="none" start_char="2718" end_char="2718">”</TOKEN>
        <TOKEN id="token-48-4" pos="punct" morph="none" start_char="2720" end_char="2720">(</TOKEN>
        <TOKEN id="token-48-5" pos="word" morph="none" start_char="2721" end_char="2724">Rahm</TOKEN>
        <TOKEN id="token-48-6" pos="word" morph="none" start_char="2726" end_char="2732">Emanuel</TOKEN>
        <TOKEN id="token-48-7" pos="punct" morph="none" start_char="2733" end_char="2733">)</TOKEN>
        <TOKEN id="token-48-8" pos="word" morph="none" start_char="2735" end_char="2736">or</TOKEN>
        <TOKEN id="token-48-9" pos="word" morph="none" start_char="2738" end_char="2741">have</TOKEN>
        <TOKEN id="token-48-10" pos="word" morph="none" start_char="2743" end_char="2743">a</TOKEN>
        <TOKEN id="token-48-11" pos="punct" morph="none" start_char="2745" end_char="2745">“</TOKEN>
        <TOKEN id="token-48-12" pos="word" morph="none" start_char="2746" end_char="2754">bulldozer</TOKEN>
        <TOKEN id="token-48-13" pos="word" morph="none" start_char="2756" end_char="2760">style</TOKEN>
        <TOKEN id="token-48-14" pos="punct" morph="none" start_char="2761" end_char="2761">”</TOKEN>
        <TOKEN id="token-48-15" pos="punct" morph="none" start_char="2763" end_char="2763">(</TOKEN>
        <TOKEN id="token-48-16" pos="word" morph="none" start_char="2764" end_char="2770">Richard</TOKEN>
      </SEG>
      <SEG id="segment-49" start_char="2772" end_char="2847">
        <ORIGINAL_TEXT>Holbrooke) with which the secretary nevertheless learned cheerfully to live.</ORIGINAL_TEXT>
        <TOKEN id="token-49-0" pos="word" morph="none" start_char="2772" end_char="2780">Holbrooke</TOKEN>
        <TOKEN id="token-49-1" pos="punct" morph="none" start_char="2781" end_char="2781">)</TOKEN>
        <TOKEN id="token-49-2" pos="word" morph="none" start_char="2783" end_char="2786">with</TOKEN>
        <TOKEN id="token-49-3" pos="word" morph="none" start_char="2788" end_char="2792">which</TOKEN>
        <TOKEN id="token-49-4" pos="word" morph="none" start_char="2794" end_char="2796">the</TOKEN>
        <TOKEN id="token-49-5" pos="word" morph="none" start_char="2798" end_char="2806">secretary</TOKEN>
        <TOKEN id="token-49-6" pos="word" morph="none" start_char="2808" end_char="2819">nevertheless</TOKEN>
        <TOKEN id="token-49-7" pos="word" morph="none" start_char="2821" end_char="2827">learned</TOKEN>
        <TOKEN id="token-49-8" pos="word" morph="none" start_char="2829" end_char="2838">cheerfully</TOKEN>
        <TOKEN id="token-49-9" pos="word" morph="none" start_char="2840" end_char="2841">to</TOKEN>
        <TOKEN id="token-49-10" pos="word" morph="none" start_char="2843" end_char="2846">live</TOKEN>
        <TOKEN id="token-49-11" pos="punct" morph="none" start_char="2847" end_char="2847">.</TOKEN>
      </SEG>
      <SEG id="segment-50" start_char="2849" end_char="2852">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-50-0" pos="unknown" morph="none" start_char="2849" end_char="2852">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-51" start_char="2854" end_char="2856">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-51-0" pos="unknown" morph="none" start_char="2854" end_char="2856">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-52" start_char="2858" end_char="2928">
        <ORIGINAL_TEXT>Her foreign partners are much the same. In general they are “consummate</ORIGINAL_TEXT>
        <TOKEN id="token-52-0" pos="word" morph="none" start_char="2858" end_char="2860">Her</TOKEN>
        <TOKEN id="token-52-1" pos="word" morph="none" start_char="2862" end_char="2868">foreign</TOKEN>
        <TOKEN id="token-52-2" pos="word" morph="none" start_char="2870" end_char="2877">partners</TOKEN>
        <TOKEN id="token-52-3" pos="word" morph="none" start_char="2879" end_char="2881">are</TOKEN>
        <TOKEN id="token-52-4" pos="word" morph="none" start_char="2883" end_char="2886">much</TOKEN>
        <TOKEN id="token-52-5" pos="word" morph="none" start_char="2888" end_char="2890">the</TOKEN>
        <TOKEN id="token-52-6" pos="word" morph="none" start_char="2892" end_char="2895">same</TOKEN>
        <TOKEN id="token-52-7" pos="punct" morph="none" start_char="2896" end_char="2896">.</TOKEN>
        <TOKEN id="token-52-8" pos="word" morph="none" start_char="2898" end_char="2899">In</TOKEN>
        <TOKEN id="token-52-9" pos="word" morph="none" start_char="2901" end_char="2907">general</TOKEN>
        <TOKEN id="token-52-10" pos="word" morph="none" start_char="2909" end_char="2912">they</TOKEN>
        <TOKEN id="token-52-11" pos="word" morph="none" start_char="2914" end_char="2916">are</TOKEN>
        <TOKEN id="token-52-12" pos="punct" morph="none" start_char="2918" end_char="2918">“</TOKEN>
        <TOKEN id="token-52-13" pos="word" morph="none" start_char="2919" end_char="2928">consummate</TOKEN>
      </SEG>
      <SEG id="segment-53" start_char="2930" end_char="2993">
        <ORIGINAL_TEXT>professionals” and “enjoyable company.” A few, such as ex–French</ORIGINAL_TEXT>
        <TOKEN id="token-53-0" pos="word" morph="none" start_char="2930" end_char="2942">professionals</TOKEN>
        <TOKEN id="token-53-1" pos="punct" morph="none" start_char="2943" end_char="2943">”</TOKEN>
        <TOKEN id="token-53-2" pos="word" morph="none" start_char="2945" end_char="2947">and</TOKEN>
        <TOKEN id="token-53-3" pos="punct" morph="none" start_char="2949" end_char="2949">“</TOKEN>
        <TOKEN id="token-53-4" pos="word" morph="none" start_char="2950" end_char="2958">enjoyable</TOKEN>
        <TOKEN id="token-53-5" pos="word" morph="none" start_char="2960" end_char="2966">company</TOKEN>
        <TOKEN id="token-53-6" pos="punct" morph="none" start_char="2967" end_char="2968">.”</TOKEN>
        <TOKEN id="token-53-7" pos="word" morph="none" start_char="2970" end_char="2970">A</TOKEN>
        <TOKEN id="token-53-8" pos="word" morph="none" start_char="2972" end_char="2974">few</TOKEN>
        <TOKEN id="token-53-9" pos="punct" morph="none" start_char="2975" end_char="2975">,</TOKEN>
        <TOKEN id="token-53-10" pos="word" morph="none" start_char="2977" end_char="2980">such</TOKEN>
        <TOKEN id="token-53-11" pos="word" morph="none" start_char="2982" end_char="2983">as</TOKEN>
        <TOKEN id="token-53-12" pos="word" morph="none" start_char="2985" end_char="2986">ex</TOKEN>
        <TOKEN id="token-53-13" pos="punct" morph="none" start_char="2987" end_char="2987">–</TOKEN>
        <TOKEN id="token-53-14" pos="word" morph="none" start_char="2988" end_char="2993">French</TOKEN>
      </SEG>
      <SEG id="segment-54" start_char="2995" end_char="3062">
        <ORIGINAL_TEXT>President Sarkozy, can even be “fun.” And even with more challenging</ORIGINAL_TEXT>
        <TOKEN id="token-54-0" pos="word" morph="none" start_char="2995" end_char="3003">President</TOKEN>
        <TOKEN id="token-54-1" pos="word" morph="none" start_char="3005" end_char="3011">Sarkozy</TOKEN>
        <TOKEN id="token-54-2" pos="punct" morph="none" start_char="3012" end_char="3012">,</TOKEN>
        <TOKEN id="token-54-3" pos="word" morph="none" start_char="3014" end_char="3016">can</TOKEN>
        <TOKEN id="token-54-4" pos="word" morph="none" start_char="3018" end_char="3021">even</TOKEN>
        <TOKEN id="token-54-5" pos="word" morph="none" start_char="3023" end_char="3024">be</TOKEN>
        <TOKEN id="token-54-6" pos="punct" morph="none" start_char="3026" end_char="3026">“</TOKEN>
        <TOKEN id="token-54-7" pos="word" morph="none" start_char="3027" end_char="3029">fun</TOKEN>
        <TOKEN id="token-54-8" pos="punct" morph="none" start_char="3030" end_char="3031">.”</TOKEN>
        <TOKEN id="token-54-9" pos="word" morph="none" start_char="3033" end_char="3035">And</TOKEN>
        <TOKEN id="token-54-10" pos="word" morph="none" start_char="3037" end_char="3040">even</TOKEN>
        <TOKEN id="token-54-11" pos="word" morph="none" start_char="3042" end_char="3045">with</TOKEN>
        <TOKEN id="token-54-12" pos="word" morph="none" start_char="3047" end_char="3050">more</TOKEN>
        <TOKEN id="token-54-13" pos="word" morph="none" start_char="3052" end_char="3062">challenging</TOKEN>
      </SEG>
      <SEG id="segment-55" start_char="3064" end_char="3135">
        <ORIGINAL_TEXT>interlocutors, such as the Chinese official Dai Bingguo, Clinton usually</ORIGINAL_TEXT>
        <TOKEN id="token-55-0" pos="word" morph="none" start_char="3064" end_char="3076">interlocutors</TOKEN>
        <TOKEN id="token-55-1" pos="punct" morph="none" start_char="3077" end_char="3077">,</TOKEN>
        <TOKEN id="token-55-2" pos="word" morph="none" start_char="3079" end_char="3082">such</TOKEN>
        <TOKEN id="token-55-3" pos="word" morph="none" start_char="3084" end_char="3085">as</TOKEN>
        <TOKEN id="token-55-4" pos="word" morph="none" start_char="3087" end_char="3089">the</TOKEN>
        <TOKEN id="token-55-5" pos="word" morph="none" start_char="3091" end_char="3097">Chinese</TOKEN>
        <TOKEN id="token-55-6" pos="word" morph="none" start_char="3099" end_char="3106">official</TOKEN>
        <TOKEN id="token-55-7" pos="word" morph="none" start_char="3108" end_char="3110">Dai</TOKEN>
        <TOKEN id="token-55-8" pos="word" morph="none" start_char="3112" end_char="3118">Bingguo</TOKEN>
        <TOKEN id="token-55-9" pos="punct" morph="none" start_char="3119" end_char="3119">,</TOKEN>
        <TOKEN id="token-55-10" pos="word" morph="none" start_char="3121" end_char="3127">Clinton</TOKEN>
        <TOKEN id="token-55-11" pos="word" morph="none" start_char="3129" end_char="3135">usually</TOKEN>
      </SEG>
      <SEG id="segment-56" start_char="3137" end_char="3204">
        <ORIGINAL_TEXT>manages to speak “deeply and personally about the need to put the U.</ORIGINAL_TEXT>
        <TOKEN id="token-56-0" pos="word" morph="none" start_char="3137" end_char="3143">manages</TOKEN>
        <TOKEN id="token-56-1" pos="word" morph="none" start_char="3145" end_char="3146">to</TOKEN>
        <TOKEN id="token-56-2" pos="word" morph="none" start_char="3148" end_char="3152">speak</TOKEN>
        <TOKEN id="token-56-3" pos="punct" morph="none" start_char="3154" end_char="3154">“</TOKEN>
        <TOKEN id="token-56-4" pos="word" morph="none" start_char="3155" end_char="3160">deeply</TOKEN>
        <TOKEN id="token-56-5" pos="word" morph="none" start_char="3162" end_char="3164">and</TOKEN>
        <TOKEN id="token-56-6" pos="word" morph="none" start_char="3166" end_char="3175">personally</TOKEN>
        <TOKEN id="token-56-7" pos="word" morph="none" start_char="3177" end_char="3181">about</TOKEN>
        <TOKEN id="token-56-8" pos="word" morph="none" start_char="3183" end_char="3185">the</TOKEN>
        <TOKEN id="token-56-9" pos="word" morph="none" start_char="3187" end_char="3190">need</TOKEN>
        <TOKEN id="token-56-10" pos="word" morph="none" start_char="3192" end_char="3193">to</TOKEN>
        <TOKEN id="token-56-11" pos="word" morph="none" start_char="3195" end_char="3197">put</TOKEN>
        <TOKEN id="token-56-12" pos="word" morph="none" start_char="3199" end_char="3201">the</TOKEN>
        <TOKEN id="token-56-13" pos="word" morph="none" start_char="3203" end_char="3203">U</TOKEN>
        <TOKEN id="token-56-14" pos="punct" morph="none" start_char="3204" end_char="3204">.</TOKEN>
      </SEG>
      <SEG id="segment-57" start_char="3206" end_char="3268">
        <ORIGINAL_TEXT>S.-China relationship on a sound footing for the sake of future</ORIGINAL_TEXT>
        <TOKEN id="token-57-0" pos="word" morph="none" start_char="3206" end_char="3206">S</TOKEN>
        <TOKEN id="token-57-1" pos="punct" morph="none" start_char="3207" end_char="3208">.-</TOKEN>
        <TOKEN id="token-57-2" pos="word" morph="none" start_char="3209" end_char="3213">China</TOKEN>
        <TOKEN id="token-57-3" pos="word" morph="none" start_char="3215" end_char="3226">relationship</TOKEN>
        <TOKEN id="token-57-4" pos="word" morph="none" start_char="3228" end_char="3229">on</TOKEN>
        <TOKEN id="token-57-5" pos="word" morph="none" start_char="3231" end_char="3231">a</TOKEN>
        <TOKEN id="token-57-6" pos="word" morph="none" start_char="3233" end_char="3237">sound</TOKEN>
        <TOKEN id="token-57-7" pos="word" morph="none" start_char="3239" end_char="3245">footing</TOKEN>
        <TOKEN id="token-57-8" pos="word" morph="none" start_char="3247" end_char="3249">for</TOKEN>
        <TOKEN id="token-57-9" pos="word" morph="none" start_char="3251" end_char="3253">the</TOKEN>
        <TOKEN id="token-57-10" pos="word" morph="none" start_char="3255" end_char="3258">sake</TOKEN>
        <TOKEN id="token-57-11" pos="word" morph="none" start_char="3260" end_char="3261">of</TOKEN>
        <TOKEN id="token-57-12" pos="word" morph="none" start_char="3263" end_char="3268">future</TOKEN>
      </SEG>
      <SEG id="segment-58" start_char="3270" end_char="3345">
        <ORIGINAL_TEXT>generations.” Do not read Hard Choices if you seek a nuanced analysis of the</ORIGINAL_TEXT>
        <TOKEN id="token-58-0" pos="word" morph="none" start_char="3270" end_char="3280">generations</TOKEN>
        <TOKEN id="token-58-1" pos="punct" morph="none" start_char="3281" end_char="3282">.”</TOKEN>
        <TOKEN id="token-58-2" pos="word" morph="none" start_char="3284" end_char="3285">Do</TOKEN>
        <TOKEN id="token-58-3" pos="word" morph="none" start_char="3287" end_char="3289">not</TOKEN>
        <TOKEN id="token-58-4" pos="word" morph="none" start_char="3291" end_char="3294">read</TOKEN>
        <TOKEN id="token-58-5" pos="word" morph="none" start_char="3296" end_char="3299">Hard</TOKEN>
        <TOKEN id="token-58-6" pos="word" morph="none" start_char="3301" end_char="3307">Choices</TOKEN>
        <TOKEN id="token-58-7" pos="word" morph="none" start_char="3309" end_char="3310">if</TOKEN>
        <TOKEN id="token-58-8" pos="word" morph="none" start_char="3312" end_char="3314">you</TOKEN>
        <TOKEN id="token-58-9" pos="word" morph="none" start_char="3316" end_char="3319">seek</TOKEN>
        <TOKEN id="token-58-10" pos="word" morph="none" start_char="3321" end_char="3321">a</TOKEN>
        <TOKEN id="token-58-11" pos="word" morph="none" start_char="3323" end_char="3329">nuanced</TOKEN>
        <TOKEN id="token-58-12" pos="word" morph="none" start_char="3331" end_char="3338">analysis</TOKEN>
        <TOKEN id="token-58-13" pos="word" morph="none" start_char="3340" end_char="3341">of</TOKEN>
        <TOKEN id="token-58-14" pos="word" morph="none" start_char="3343" end_char="3345">the</TOKEN>
      </SEG>
      <SEG id="segment-59" start_char="3347" end_char="3421">
        <ORIGINAL_TEXT>people who run the world’s foreign policy, let alone any juicy gossip. Even</ORIGINAL_TEXT>
        <TOKEN id="token-59-0" pos="word" morph="none" start_char="3347" end_char="3352">people</TOKEN>
        <TOKEN id="token-59-1" pos="word" morph="none" start_char="3354" end_char="3356">who</TOKEN>
        <TOKEN id="token-59-2" pos="word" morph="none" start_char="3358" end_char="3360">run</TOKEN>
        <TOKEN id="token-59-3" pos="word" morph="none" start_char="3362" end_char="3364">the</TOKEN>
        <TOKEN id="token-59-4" pos="word" morph="none" start_char="3366" end_char="3370">world</TOKEN>
        <TOKEN id="token-59-5" pos="punct" morph="none" start_char="3371" end_char="3371">’</TOKEN>
        <TOKEN id="token-59-6" pos="word" morph="none" start_char="3372" end_char="3372">s</TOKEN>
        <TOKEN id="token-59-7" pos="word" morph="none" start_char="3374" end_char="3380">foreign</TOKEN>
        <TOKEN id="token-59-8" pos="word" morph="none" start_char="3382" end_char="3387">policy</TOKEN>
        <TOKEN id="token-59-9" pos="punct" morph="none" start_char="3388" end_char="3388">,</TOKEN>
        <TOKEN id="token-59-10" pos="word" morph="none" start_char="3390" end_char="3392">let</TOKEN>
        <TOKEN id="token-59-11" pos="word" morph="none" start_char="3394" end_char="3398">alone</TOKEN>
        <TOKEN id="token-59-12" pos="word" morph="none" start_char="3400" end_char="3402">any</TOKEN>
        <TOKEN id="token-59-13" pos="word" morph="none" start_char="3404" end_char="3408">juicy</TOKEN>
        <TOKEN id="token-59-14" pos="word" morph="none" start_char="3410" end_char="3415">gossip</TOKEN>
        <TOKEN id="token-59-15" pos="punct" morph="none" start_char="3416" end_char="3416">.</TOKEN>
        <TOKEN id="token-59-16" pos="word" morph="none" start_char="3418" end_char="3421">Even</TOKEN>
      </SEG>
      <SEG id="segment-60" start_char="3423" end_char="3491">
        <ORIGINAL_TEXT>the “candid” photos look staged: Hillary, Bill, and Bono sitting at a</ORIGINAL_TEXT>
        <TOKEN id="token-60-0" pos="word" morph="none" start_char="3423" end_char="3425">the</TOKEN>
        <TOKEN id="token-60-1" pos="punct" morph="none" start_char="3427" end_char="3427">“</TOKEN>
        <TOKEN id="token-60-2" pos="word" morph="none" start_char="3428" end_char="3433">candid</TOKEN>
        <TOKEN id="token-60-3" pos="punct" morph="none" start_char="3434" end_char="3434">”</TOKEN>
        <TOKEN id="token-60-4" pos="word" morph="none" start_char="3436" end_char="3441">photos</TOKEN>
        <TOKEN id="token-60-5" pos="word" morph="none" start_char="3443" end_char="3446">look</TOKEN>
        <TOKEN id="token-60-6" pos="word" morph="none" start_char="3448" end_char="3453">staged</TOKEN>
        <TOKEN id="token-60-7" pos="punct" morph="none" start_char="3454" end_char="3454">:</TOKEN>
        <TOKEN id="token-60-8" pos="word" morph="none" start_char="3456" end_char="3462">Hillary</TOKEN>
        <TOKEN id="token-60-9" pos="punct" morph="none" start_char="3463" end_char="3463">,</TOKEN>
        <TOKEN id="token-60-10" pos="word" morph="none" start_char="3465" end_char="3468">Bill</TOKEN>
        <TOKEN id="token-60-11" pos="punct" morph="none" start_char="3469" end_char="3469">,</TOKEN>
        <TOKEN id="token-60-12" pos="word" morph="none" start_char="3471" end_char="3473">and</TOKEN>
        <TOKEN id="token-60-13" pos="word" morph="none" start_char="3475" end_char="3478">Bono</TOKEN>
        <TOKEN id="token-60-14" pos="word" morph="none" start_char="3480" end_char="3486">sitting</TOKEN>
        <TOKEN id="token-60-15" pos="word" morph="none" start_char="3488" end_char="3489">at</TOKEN>
        <TOKEN id="token-60-16" pos="word" morph="none" start_char="3491" end_char="3491">a</TOKEN>
      </SEG>
      <SEG id="segment-61" start_char="3493" end_char="3511">
        <ORIGINAL_TEXT>piano, for example.</ORIGINAL_TEXT>
        <TOKEN id="token-61-0" pos="word" morph="none" start_char="3493" end_char="3497">piano</TOKEN>
        <TOKEN id="token-61-1" pos="punct" morph="none" start_char="3498" end_char="3498">,</TOKEN>
        <TOKEN id="token-61-2" pos="word" morph="none" start_char="3500" end_char="3502">for</TOKEN>
        <TOKEN id="token-61-3" pos="word" morph="none" start_char="3504" end_char="3510">example</TOKEN>
        <TOKEN id="token-61-4" pos="punct" morph="none" start_char="3511" end_char="3511">.</TOKEN>
      </SEG>
      <SEG id="segment-62" start_char="3513" end_char="3516">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-62-0" pos="unknown" morph="none" start_char="3513" end_char="3516">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-63" start_char="3518" end_char="3520">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-63-0" pos="unknown" morph="none" start_char="3518" end_char="3520">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-64" start_char="3522" end_char="3595">
        <ORIGINAL_TEXT>Yet even if we accept that Hard Choices really is a book—it has a binding,</ORIGINAL_TEXT>
        <TOKEN id="token-64-0" pos="word" morph="none" start_char="3522" end_char="3524">Yet</TOKEN>
        <TOKEN id="token-64-1" pos="word" morph="none" start_char="3526" end_char="3529">even</TOKEN>
        <TOKEN id="token-64-2" pos="word" morph="none" start_char="3531" end_char="3532">if</TOKEN>
        <TOKEN id="token-64-3" pos="word" morph="none" start_char="3534" end_char="3535">we</TOKEN>
        <TOKEN id="token-64-4" pos="word" morph="none" start_char="3537" end_char="3542">accept</TOKEN>
        <TOKEN id="token-64-5" pos="word" morph="none" start_char="3544" end_char="3547">that</TOKEN>
        <TOKEN id="token-64-6" pos="word" morph="none" start_char="3549" end_char="3552">Hard</TOKEN>
        <TOKEN id="token-64-7" pos="word" morph="none" start_char="3554" end_char="3560">Choices</TOKEN>
        <TOKEN id="token-64-8" pos="word" morph="none" start_char="3562" end_char="3567">really</TOKEN>
        <TOKEN id="token-64-9" pos="word" morph="none" start_char="3569" end_char="3570">is</TOKEN>
        <TOKEN id="token-64-10" pos="word" morph="none" start_char="3572" end_char="3572">a</TOKEN>
        <TOKEN id="token-64-11" pos="word" morph="none" start_char="3574" end_char="3577">book</TOKEN>
        <TOKEN id="token-64-12" pos="punct" morph="none" start_char="3578" end_char="3578">—</TOKEN>
        <TOKEN id="token-64-13" pos="word" morph="none" start_char="3579" end_char="3580">it</TOKEN>
        <TOKEN id="token-64-14" pos="word" morph="none" start_char="3582" end_char="3584">has</TOKEN>
        <TOKEN id="token-64-15" pos="word" morph="none" start_char="3586" end_char="3586">a</TOKEN>
        <TOKEN id="token-64-16" pos="word" morph="none" start_char="3588" end_char="3594">binding</TOKEN>
        <TOKEN id="token-64-17" pos="punct" morph="none" start_char="3595" end_char="3595">,</TOKEN>
      </SEG>
      <SEG id="segment-65" start_char="3597" end_char="3672">
        <ORIGINAL_TEXT>after all, and has been produced by a printing press under the auspices of a</ORIGINAL_TEXT>
        <TOKEN id="token-65-0" pos="word" morph="none" start_char="3597" end_char="3601">after</TOKEN>
        <TOKEN id="token-65-1" pos="word" morph="none" start_char="3603" end_char="3605">all</TOKEN>
        <TOKEN id="token-65-2" pos="punct" morph="none" start_char="3606" end_char="3606">,</TOKEN>
        <TOKEN id="token-65-3" pos="word" morph="none" start_char="3608" end_char="3610">and</TOKEN>
        <TOKEN id="token-65-4" pos="word" morph="none" start_char="3612" end_char="3614">has</TOKEN>
        <TOKEN id="token-65-5" pos="word" morph="none" start_char="3616" end_char="3619">been</TOKEN>
        <TOKEN id="token-65-6" pos="word" morph="none" start_char="3621" end_char="3628">produced</TOKEN>
        <TOKEN id="token-65-7" pos="word" morph="none" start_char="3630" end_char="3631">by</TOKEN>
        <TOKEN id="token-65-8" pos="word" morph="none" start_char="3633" end_char="3633">a</TOKEN>
        <TOKEN id="token-65-9" pos="word" morph="none" start_char="3635" end_char="3642">printing</TOKEN>
        <TOKEN id="token-65-10" pos="word" morph="none" start_char="3644" end_char="3648">press</TOKEN>
        <TOKEN id="token-65-11" pos="word" morph="none" start_char="3650" end_char="3654">under</TOKEN>
        <TOKEN id="token-65-12" pos="word" morph="none" start_char="3656" end_char="3658">the</TOKEN>
        <TOKEN id="token-65-13" pos="word" morph="none" start_char="3660" end_char="3667">auspices</TOKEN>
        <TOKEN id="token-65-14" pos="word" morph="none" start_char="3669" end_char="3670">of</TOKEN>
        <TOKEN id="token-65-15" pos="word" morph="none" start_char="3672" end_char="3672">a</TOKEN>
      </SEG>
      <SEG id="segment-66" start_char="3674" end_char="3745">
        <ORIGINAL_TEXT>publishing house—it isn’t that easy to say to which genre it belongs. It</ORIGINAL_TEXT>
        <TOKEN id="token-66-0" pos="word" morph="none" start_char="3674" end_char="3683">publishing</TOKEN>
        <TOKEN id="token-66-1" pos="word" morph="none" start_char="3685" end_char="3689">house</TOKEN>
        <TOKEN id="token-66-2" pos="punct" morph="none" start_char="3690" end_char="3690">—</TOKEN>
        <TOKEN id="token-66-3" pos="word" morph="none" start_char="3691" end_char="3692">it</TOKEN>
        <TOKEN id="token-66-4" pos="word" morph="none" start_char="3694" end_char="3696">isn</TOKEN>
        <TOKEN id="token-66-5" pos="punct" morph="none" start_char="3697" end_char="3697">’</TOKEN>
        <TOKEN id="token-66-6" pos="word" morph="none" start_char="3698" end_char="3698">t</TOKEN>
        <TOKEN id="token-66-7" pos="word" morph="none" start_char="3700" end_char="3703">that</TOKEN>
        <TOKEN id="token-66-8" pos="word" morph="none" start_char="3705" end_char="3708">easy</TOKEN>
        <TOKEN id="token-66-9" pos="word" morph="none" start_char="3710" end_char="3711">to</TOKEN>
        <TOKEN id="token-66-10" pos="word" morph="none" start_char="3713" end_char="3715">say</TOKEN>
        <TOKEN id="token-66-11" pos="word" morph="none" start_char="3717" end_char="3718">to</TOKEN>
        <TOKEN id="token-66-12" pos="word" morph="none" start_char="3720" end_char="3724">which</TOKEN>
        <TOKEN id="token-66-13" pos="word" morph="none" start_char="3726" end_char="3730">genre</TOKEN>
        <TOKEN id="token-66-14" pos="word" morph="none" start_char="3732" end_char="3733">it</TOKEN>
        <TOKEN id="token-66-15" pos="word" morph="none" start_char="3735" end_char="3741">belongs</TOKEN>
        <TOKEN id="token-66-16" pos="punct" morph="none" start_char="3742" end_char="3742">.</TOKEN>
        <TOKEN id="token-66-17" pos="word" morph="none" start_char="3744" end_char="3745">It</TOKEN>
      </SEG>
      <SEG id="segment-67" start_char="3747" end_char="3816">
        <ORIGINAL_TEXT>clearly is not a work of history: the book is constructed according to</ORIGINAL_TEXT>
        <TOKEN id="token-67-0" pos="word" morph="none" start_char="3747" end_char="3753">clearly</TOKEN>
        <TOKEN id="token-67-1" pos="word" morph="none" start_char="3755" end_char="3756">is</TOKEN>
        <TOKEN id="token-67-2" pos="word" morph="none" start_char="3758" end_char="3760">not</TOKEN>
        <TOKEN id="token-67-3" pos="word" morph="none" start_char="3762" end_char="3762">a</TOKEN>
        <TOKEN id="token-67-4" pos="word" morph="none" start_char="3764" end_char="3767">work</TOKEN>
        <TOKEN id="token-67-5" pos="word" morph="none" start_char="3769" end_char="3770">of</TOKEN>
        <TOKEN id="token-67-6" pos="word" morph="none" start_char="3772" end_char="3778">history</TOKEN>
        <TOKEN id="token-67-7" pos="punct" morph="none" start_char="3779" end_char="3779">:</TOKEN>
        <TOKEN id="token-67-8" pos="word" morph="none" start_char="3781" end_char="3783">the</TOKEN>
        <TOKEN id="token-67-9" pos="word" morph="none" start_char="3785" end_char="3788">book</TOKEN>
        <TOKEN id="token-67-10" pos="word" morph="none" start_char="3790" end_char="3791">is</TOKEN>
        <TOKEN id="token-67-11" pos="word" morph="none" start_char="3793" end_char="3803">constructed</TOKEN>
        <TOKEN id="token-67-12" pos="word" morph="none" start_char="3805" end_char="3813">according</TOKEN>
        <TOKEN id="token-67-13" pos="word" morph="none" start_char="3815" end_char="3816">to</TOKEN>
      </SEG>
      <SEG id="segment-68" start_char="3818" end_char="3893">
        <ORIGINAL_TEXT>geography rather than chronology, and although Clinton does give accounts of</ORIGINAL_TEXT>
        <TOKEN id="token-68-0" pos="word" morph="none" start_char="3818" end_char="3826">geography</TOKEN>
        <TOKEN id="token-68-1" pos="word" morph="none" start_char="3828" end_char="3833">rather</TOKEN>
        <TOKEN id="token-68-2" pos="word" morph="none" start_char="3835" end_char="3838">than</TOKEN>
        <TOKEN id="token-68-3" pos="word" morph="none" start_char="3840" end_char="3849">chronology</TOKEN>
        <TOKEN id="token-68-4" pos="punct" morph="none" start_char="3850" end_char="3850">,</TOKEN>
        <TOKEN id="token-68-5" pos="word" morph="none" start_char="3852" end_char="3854">and</TOKEN>
        <TOKEN id="token-68-6" pos="word" morph="none" start_char="3856" end_char="3863">although</TOKEN>
        <TOKEN id="token-68-7" pos="word" morph="none" start_char="3865" end_char="3871">Clinton</TOKEN>
        <TOKEN id="token-68-8" pos="word" morph="none" start_char="3873" end_char="3876">does</TOKEN>
        <TOKEN id="token-68-9" pos="word" morph="none" start_char="3878" end_char="3881">give</TOKEN>
        <TOKEN id="token-68-10" pos="word" morph="none" start_char="3883" end_char="3890">accounts</TOKEN>
        <TOKEN id="token-68-11" pos="word" morph="none" start_char="3892" end_char="3893">of</TOKEN>
      </SEG>
      <SEG id="segment-69" start_char="3895" end_char="3968">
        <ORIGINAL_TEXT>her more important policy decisions, she refrains from setting them in any</ORIGINAL_TEXT>
        <TOKEN id="token-69-0" pos="word" morph="none" start_char="3895" end_char="3897">her</TOKEN>
        <TOKEN id="token-69-1" pos="word" morph="none" start_char="3899" end_char="3902">more</TOKEN>
        <TOKEN id="token-69-2" pos="word" morph="none" start_char="3904" end_char="3912">important</TOKEN>
        <TOKEN id="token-69-3" pos="word" morph="none" start_char="3914" end_char="3919">policy</TOKEN>
        <TOKEN id="token-69-4" pos="word" morph="none" start_char="3921" end_char="3929">decisions</TOKEN>
        <TOKEN id="token-69-5" pos="punct" morph="none" start_char="3930" end_char="3930">,</TOKEN>
        <TOKEN id="token-69-6" pos="word" morph="none" start_char="3932" end_char="3934">she</TOKEN>
        <TOKEN id="token-69-7" pos="word" morph="none" start_char="3936" end_char="3943">refrains</TOKEN>
        <TOKEN id="token-69-8" pos="word" morph="none" start_char="3945" end_char="3948">from</TOKEN>
        <TOKEN id="token-69-9" pos="word" morph="none" start_char="3950" end_char="3956">setting</TOKEN>
        <TOKEN id="token-69-10" pos="word" morph="none" start_char="3958" end_char="3961">them</TOKEN>
        <TOKEN id="token-69-11" pos="word" morph="none" start_char="3963" end_char="3964">in</TOKEN>
        <TOKEN id="token-69-12" pos="word" morph="none" start_char="3966" end_char="3968">any</TOKEN>
      </SEG>
      <SEG id="segment-70" start_char="3970" end_char="4045">
        <ORIGINAL_TEXT>particular domestic or global context. Each one is told as a separate story,</ORIGINAL_TEXT>
        <TOKEN id="token-70-0" pos="word" morph="none" start_char="3970" end_char="3979">particular</TOKEN>
        <TOKEN id="token-70-1" pos="word" morph="none" start_char="3981" end_char="3988">domestic</TOKEN>
        <TOKEN id="token-70-2" pos="word" morph="none" start_char="3990" end_char="3991">or</TOKEN>
        <TOKEN id="token-70-3" pos="word" morph="none" start_char="3993" end_char="3998">global</TOKEN>
        <TOKEN id="token-70-4" pos="word" morph="none" start_char="4000" end_char="4006">context</TOKEN>
        <TOKEN id="token-70-5" pos="punct" morph="none" start_char="4007" end_char="4007">.</TOKEN>
        <TOKEN id="token-70-6" pos="word" morph="none" start_char="4009" end_char="4012">Each</TOKEN>
        <TOKEN id="token-70-7" pos="word" morph="none" start_char="4014" end_char="4016">one</TOKEN>
        <TOKEN id="token-70-8" pos="word" morph="none" start_char="4018" end_char="4019">is</TOKEN>
        <TOKEN id="token-70-9" pos="word" morph="none" start_char="4021" end_char="4024">told</TOKEN>
        <TOKEN id="token-70-10" pos="word" morph="none" start_char="4026" end_char="4027">as</TOKEN>
        <TOKEN id="token-70-11" pos="word" morph="none" start_char="4029" end_char="4029">a</TOKEN>
        <TOKEN id="token-70-12" pos="word" morph="none" start_char="4031" end_char="4038">separate</TOKEN>
        <TOKEN id="token-70-13" pos="word" morph="none" start_char="4040" end_char="4044">story</TOKEN>
        <TOKEN id="token-70-14" pos="punct" morph="none" start_char="4045" end_char="4045">,</TOKEN>
      </SEG>
      <SEG id="segment-71" start_char="4047" end_char="4115">
        <ORIGINAL_TEXT>and most of the stories have happy endings, even if in real life they</ORIGINAL_TEXT>
        <TOKEN id="token-71-0" pos="word" morph="none" start_char="4047" end_char="4049">and</TOKEN>
        <TOKEN id="token-71-1" pos="word" morph="none" start_char="4051" end_char="4054">most</TOKEN>
        <TOKEN id="token-71-2" pos="word" morph="none" start_char="4056" end_char="4057">of</TOKEN>
        <TOKEN id="token-71-3" pos="word" morph="none" start_char="4059" end_char="4061">the</TOKEN>
        <TOKEN id="token-71-4" pos="word" morph="none" start_char="4063" end_char="4069">stories</TOKEN>
        <TOKEN id="token-71-5" pos="word" morph="none" start_char="4071" end_char="4074">have</TOKEN>
        <TOKEN id="token-71-6" pos="word" morph="none" start_char="4076" end_char="4080">happy</TOKEN>
        <TOKEN id="token-71-7" pos="word" morph="none" start_char="4082" end_char="4088">endings</TOKEN>
        <TOKEN id="token-71-8" pos="punct" morph="none" start_char="4089" end_char="4089">,</TOKEN>
        <TOKEN id="token-71-9" pos="word" morph="none" start_char="4091" end_char="4094">even</TOKEN>
        <TOKEN id="token-71-10" pos="word" morph="none" start_char="4096" end_char="4097">if</TOKEN>
        <TOKEN id="token-71-11" pos="word" morph="none" start_char="4099" end_char="4100">in</TOKEN>
        <TOKEN id="token-71-12" pos="word" morph="none" start_char="4102" end_char="4105">real</TOKEN>
        <TOKEN id="token-71-13" pos="word" morph="none" start_char="4107" end_char="4110">life</TOKEN>
        <TOKEN id="token-71-14" pos="word" morph="none" start_char="4112" end_char="4115">they</TOKEN>
      </SEG>
      <SEG id="segment-72" start_char="4117" end_char="4123">
        <ORIGINAL_TEXT>didn’t.</ORIGINAL_TEXT>
        <TOKEN id="token-72-0" pos="word" morph="none" start_char="4117" end_char="4120">didn</TOKEN>
        <TOKEN id="token-72-1" pos="punct" morph="none" start_char="4121" end_char="4121">’</TOKEN>
        <TOKEN id="token-72-2" pos="word" morph="none" start_char="4122" end_char="4122">t</TOKEN>
        <TOKEN id="token-72-3" pos="punct" morph="none" start_char="4123" end_char="4123">.</TOKEN>
      </SEG>
      <SEG id="segment-73" start_char="4125" end_char="4128">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-73-0" pos="unknown" morph="none" start_char="4125" end_char="4128">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-74" start_char="4130" end_char="4132">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-74-0" pos="unknown" morph="none" start_char="4130" end_char="4132">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-75" start_char="4134" end_char="4207">
        <ORIGINAL_TEXT>Clinton’s chapter on Europe, for example, begins with the deterioration of</ORIGINAL_TEXT>
        <TOKEN id="token-75-0" pos="word" morph="none" start_char="4134" end_char="4140">Clinton</TOKEN>
        <TOKEN id="token-75-1" pos="punct" morph="none" start_char="4141" end_char="4141">’</TOKEN>
        <TOKEN id="token-75-2" pos="word" morph="none" start_char="4142" end_char="4142">s</TOKEN>
        <TOKEN id="token-75-3" pos="word" morph="none" start_char="4144" end_char="4150">chapter</TOKEN>
        <TOKEN id="token-75-4" pos="word" morph="none" start_char="4152" end_char="4153">on</TOKEN>
        <TOKEN id="token-75-5" pos="word" morph="none" start_char="4155" end_char="4160">Europe</TOKEN>
        <TOKEN id="token-75-6" pos="punct" morph="none" start_char="4161" end_char="4161">,</TOKEN>
        <TOKEN id="token-75-7" pos="word" morph="none" start_char="4163" end_char="4165">for</TOKEN>
        <TOKEN id="token-75-8" pos="word" morph="none" start_char="4167" end_char="4173">example</TOKEN>
        <TOKEN id="token-75-9" pos="punct" morph="none" start_char="4174" end_char="4174">,</TOKEN>
        <TOKEN id="token-75-10" pos="word" morph="none" start_char="4176" end_char="4181">begins</TOKEN>
        <TOKEN id="token-75-11" pos="word" morph="none" start_char="4183" end_char="4186">with</TOKEN>
        <TOKEN id="token-75-12" pos="word" morph="none" start_char="4188" end_char="4190">the</TOKEN>
        <TOKEN id="token-75-13" pos="word" morph="none" start_char="4192" end_char="4204">deterioration</TOKEN>
        <TOKEN id="token-75-14" pos="word" morph="none" start_char="4206" end_char="4207">of</TOKEN>
      </SEG>
      <SEG id="segment-76" start_char="4209" end_char="4283">
        <ORIGINAL_TEXT>the transatlantic alliance under George W. Bush, explains how she fixed the</ORIGINAL_TEXT>
        <TOKEN id="token-76-0" pos="word" morph="none" start_char="4209" end_char="4211">the</TOKEN>
        <TOKEN id="token-76-1" pos="word" morph="none" start_char="4213" end_char="4225">transatlantic</TOKEN>
        <TOKEN id="token-76-2" pos="word" morph="none" start_char="4227" end_char="4234">alliance</TOKEN>
        <TOKEN id="token-76-3" pos="word" morph="none" start_char="4236" end_char="4240">under</TOKEN>
        <TOKEN id="token-76-4" pos="word" morph="none" start_char="4242" end_char="4247">George</TOKEN>
        <TOKEN id="token-76-5" pos="word" morph="none" start_char="4249" end_char="4249">W</TOKEN>
        <TOKEN id="token-76-6" pos="punct" morph="none" start_char="4250" end_char="4250">.</TOKEN>
        <TOKEN id="token-76-7" pos="word" morph="none" start_char="4252" end_char="4255">Bush</TOKEN>
        <TOKEN id="token-76-8" pos="punct" morph="none" start_char="4256" end_char="4256">,</TOKEN>
        <TOKEN id="token-76-9" pos="word" morph="none" start_char="4258" end_char="4265">explains</TOKEN>
        <TOKEN id="token-76-10" pos="word" morph="none" start_char="4267" end_char="4269">how</TOKEN>
        <TOKEN id="token-76-11" pos="word" morph="none" start_char="4271" end_char="4273">she</TOKEN>
        <TOKEN id="token-76-12" pos="word" morph="none" start_char="4275" end_char="4279">fixed</TOKEN>
        <TOKEN id="token-76-13" pos="word" morph="none" start_char="4281" end_char="4283">the</TOKEN>
      </SEG>
      <SEG id="segment-77" start_char="4285" end_char="4354">
        <ORIGINAL_TEXT>problem by renewing relationships with “invaluable” partners, and ends</ORIGINAL_TEXT>
        <TOKEN id="token-77-0" pos="word" morph="none" start_char="4285" end_char="4291">problem</TOKEN>
        <TOKEN id="token-77-1" pos="word" morph="none" start_char="4293" end_char="4294">by</TOKEN>
        <TOKEN id="token-77-2" pos="word" morph="none" start_char="4296" end_char="4303">renewing</TOKEN>
        <TOKEN id="token-77-3" pos="word" morph="none" start_char="4305" end_char="4317">relationships</TOKEN>
        <TOKEN id="token-77-4" pos="word" morph="none" start_char="4319" end_char="4322">with</TOKEN>
        <TOKEN id="token-77-5" pos="punct" morph="none" start_char="4324" end_char="4324">“</TOKEN>
        <TOKEN id="token-77-6" pos="word" morph="none" start_char="4325" end_char="4334">invaluable</TOKEN>
        <TOKEN id="token-77-7" pos="punct" morph="none" start_char="4335" end_char="4335">”</TOKEN>
        <TOKEN id="token-77-8" pos="word" morph="none" start_char="4337" end_char="4344">partners</TOKEN>
        <TOKEN id="token-77-9" pos="punct" morph="none" start_char="4345" end_char="4345">,</TOKEN>
        <TOKEN id="token-77-10" pos="word" morph="none" start_char="4347" end_char="4349">and</TOKEN>
        <TOKEN id="token-77-11" pos="word" morph="none" start_char="4351" end_char="4354">ends</TOKEN>
      </SEG>
      <SEG id="segment-78" start_char="4356" end_char="4425">
        <ORIGINAL_TEXT>with a visit to Belfast where an “old friend” is now the lord mayor of</ORIGINAL_TEXT>
        <TOKEN id="token-78-0" pos="word" morph="none" start_char="4356" end_char="4359">with</TOKEN>
        <TOKEN id="token-78-1" pos="word" morph="none" start_char="4361" end_char="4361">a</TOKEN>
        <TOKEN id="token-78-2" pos="word" morph="none" start_char="4363" end_char="4367">visit</TOKEN>
        <TOKEN id="token-78-3" pos="word" morph="none" start_char="4369" end_char="4370">to</TOKEN>
        <TOKEN id="token-78-4" pos="word" morph="none" start_char="4372" end_char="4378">Belfast</TOKEN>
        <TOKEN id="token-78-5" pos="word" morph="none" start_char="4380" end_char="4384">where</TOKEN>
        <TOKEN id="token-78-6" pos="word" morph="none" start_char="4386" end_char="4387">an</TOKEN>
        <TOKEN id="token-78-7" pos="punct" morph="none" start_char="4389" end_char="4389">“</TOKEN>
        <TOKEN id="token-78-8" pos="word" morph="none" start_char="4390" end_char="4392">old</TOKEN>
        <TOKEN id="token-78-9" pos="word" morph="none" start_char="4394" end_char="4399">friend</TOKEN>
        <TOKEN id="token-78-10" pos="punct" morph="none" start_char="4400" end_char="4400">”</TOKEN>
        <TOKEN id="token-78-11" pos="word" morph="none" start_char="4402" end_char="4403">is</TOKEN>
        <TOKEN id="token-78-12" pos="word" morph="none" start_char="4405" end_char="4407">now</TOKEN>
        <TOKEN id="token-78-13" pos="word" morph="none" start_char="4409" end_char="4411">the</TOKEN>
        <TOKEN id="token-78-14" pos="word" morph="none" start_char="4413" end_char="4416">lord</TOKEN>
        <TOKEN id="token-78-15" pos="word" morph="none" start_char="4418" end_char="4422">mayor</TOKEN>
        <TOKEN id="token-78-16" pos="word" morph="none" start_char="4424" end_char="4425">of</TOKEN>
      </SEG>
      <SEG id="segment-79" start_char="4427" end_char="4499">
        <ORIGINAL_TEXT>Armagh. This latter event gives Clinton a moral for her Europe story: she</ORIGINAL_TEXT>
        <TOKEN id="token-79-0" pos="word" morph="none" start_char="4427" end_char="4432">Armagh</TOKEN>
        <TOKEN id="token-79-1" pos="punct" morph="none" start_char="4433" end_char="4433">.</TOKEN>
        <TOKEN id="token-79-2" pos="word" morph="none" start_char="4435" end_char="4438">This</TOKEN>
        <TOKEN id="token-79-3" pos="word" morph="none" start_char="4440" end_char="4445">latter</TOKEN>
        <TOKEN id="token-79-4" pos="word" morph="none" start_char="4447" end_char="4451">event</TOKEN>
        <TOKEN id="token-79-5" pos="word" morph="none" start_char="4453" end_char="4457">gives</TOKEN>
        <TOKEN id="token-79-6" pos="word" morph="none" start_char="4459" end_char="4465">Clinton</TOKEN>
        <TOKEN id="token-79-7" pos="word" morph="none" start_char="4467" end_char="4467">a</TOKEN>
        <TOKEN id="token-79-8" pos="word" morph="none" start_char="4469" end_char="4473">moral</TOKEN>
        <TOKEN id="token-79-9" pos="word" morph="none" start_char="4475" end_char="4477">for</TOKEN>
        <TOKEN id="token-79-10" pos="word" morph="none" start_char="4479" end_char="4481">her</TOKEN>
        <TOKEN id="token-79-11" pos="word" morph="none" start_char="4483" end_char="4488">Europe</TOKEN>
        <TOKEN id="token-79-12" pos="word" morph="none" start_char="4490" end_char="4494">story</TOKEN>
        <TOKEN id="token-79-13" pos="punct" morph="none" start_char="4495" end_char="4495">:</TOKEN>
        <TOKEN id="token-79-14" pos="word" morph="none" start_char="4497" end_char="4499">she</TOKEN>
      </SEG>
      <SEG id="segment-80" start_char="4501" end_char="4576">
        <ORIGINAL_TEXT>hopes that children growing up now in Northern Ireland will “never turn back</ORIGINAL_TEXT>
        <TOKEN id="token-80-0" pos="word" morph="none" start_char="4501" end_char="4505">hopes</TOKEN>
        <TOKEN id="token-80-1" pos="word" morph="none" start_char="4507" end_char="4510">that</TOKEN>
        <TOKEN id="token-80-2" pos="word" morph="none" start_char="4512" end_char="4519">children</TOKEN>
        <TOKEN id="token-80-3" pos="word" morph="none" start_char="4521" end_char="4527">growing</TOKEN>
        <TOKEN id="token-80-4" pos="word" morph="none" start_char="4529" end_char="4530">up</TOKEN>
        <TOKEN id="token-80-5" pos="word" morph="none" start_char="4532" end_char="4534">now</TOKEN>
        <TOKEN id="token-80-6" pos="word" morph="none" start_char="4536" end_char="4537">in</TOKEN>
        <TOKEN id="token-80-7" pos="word" morph="none" start_char="4539" end_char="4546">Northern</TOKEN>
        <TOKEN id="token-80-8" pos="word" morph="none" start_char="4548" end_char="4554">Ireland</TOKEN>
        <TOKEN id="token-80-9" pos="word" morph="none" start_char="4556" end_char="4559">will</TOKEN>
        <TOKEN id="token-80-10" pos="punct" morph="none" start_char="4561" end_char="4561">“</TOKEN>
        <TOKEN id="token-80-11" pos="word" morph="none" start_char="4562" end_char="4566">never</TOKEN>
        <TOKEN id="token-80-12" pos="word" morph="none" start_char="4568" end_char="4571">turn</TOKEN>
        <TOKEN id="token-80-13" pos="word" morph="none" start_char="4573" end_char="4576">back</TOKEN>
      </SEG>
      <SEG id="segment-81" start_char="4578" end_char="4650">
        <ORIGINAL_TEXT>and that their peace and progress would be an inspiration for the rest of</ORIGINAL_TEXT>
        <TOKEN id="token-81-0" pos="word" morph="none" start_char="4578" end_char="4580">and</TOKEN>
        <TOKEN id="token-81-1" pos="word" morph="none" start_char="4582" end_char="4585">that</TOKEN>
        <TOKEN id="token-81-2" pos="word" morph="none" start_char="4587" end_char="4591">their</TOKEN>
        <TOKEN id="token-81-3" pos="word" morph="none" start_char="4593" end_char="4597">peace</TOKEN>
        <TOKEN id="token-81-4" pos="word" morph="none" start_char="4599" end_char="4601">and</TOKEN>
        <TOKEN id="token-81-5" pos="word" morph="none" start_char="4603" end_char="4610">progress</TOKEN>
        <TOKEN id="token-81-6" pos="word" morph="none" start_char="4612" end_char="4616">would</TOKEN>
        <TOKEN id="token-81-7" pos="word" morph="none" start_char="4618" end_char="4619">be</TOKEN>
        <TOKEN id="token-81-8" pos="word" morph="none" start_char="4621" end_char="4622">an</TOKEN>
        <TOKEN id="token-81-9" pos="word" morph="none" start_char="4624" end_char="4634">inspiration</TOKEN>
        <TOKEN id="token-81-10" pos="word" morph="none" start_char="4636" end_char="4638">for</TOKEN>
        <TOKEN id="token-81-11" pos="word" morph="none" start_char="4640" end_char="4642">the</TOKEN>
        <TOKEN id="token-81-12" pos="word" morph="none" start_char="4644" end_char="4647">rest</TOKEN>
        <TOKEN id="token-81-13" pos="word" morph="none" start_char="4649" end_char="4650">of</TOKEN>
      </SEG>
      <SEG id="segment-82" start_char="4652" end_char="4724">
        <ORIGINAL_TEXT>Europe and the world.” A scant, bland paragraph or two are devoted to the</ORIGINAL_TEXT>
        <TOKEN id="token-82-0" pos="word" morph="none" start_char="4652" end_char="4657">Europe</TOKEN>
        <TOKEN id="token-82-1" pos="word" morph="none" start_char="4659" end_char="4661">and</TOKEN>
        <TOKEN id="token-82-2" pos="word" morph="none" start_char="4663" end_char="4665">the</TOKEN>
        <TOKEN id="token-82-3" pos="word" morph="none" start_char="4667" end_char="4671">world</TOKEN>
        <TOKEN id="token-82-4" pos="punct" morph="none" start_char="4672" end_char="4673">.”</TOKEN>
        <TOKEN id="token-82-5" pos="word" morph="none" start_char="4675" end_char="4675">A</TOKEN>
        <TOKEN id="token-82-6" pos="word" morph="none" start_char="4677" end_char="4681">scant</TOKEN>
        <TOKEN id="token-82-7" pos="punct" morph="none" start_char="4682" end_char="4682">,</TOKEN>
        <TOKEN id="token-82-8" pos="word" morph="none" start_char="4684" end_char="4688">bland</TOKEN>
        <TOKEN id="token-82-9" pos="word" morph="none" start_char="4690" end_char="4698">paragraph</TOKEN>
        <TOKEN id="token-82-10" pos="word" morph="none" start_char="4700" end_char="4701">or</TOKEN>
        <TOKEN id="token-82-11" pos="word" morph="none" start_char="4703" end_char="4705">two</TOKEN>
        <TOKEN id="token-82-12" pos="word" morph="none" start_char="4707" end_char="4709">are</TOKEN>
        <TOKEN id="token-82-13" pos="word" morph="none" start_char="4711" end_char="4717">devoted</TOKEN>
        <TOKEN id="token-82-14" pos="word" morph="none" start_char="4719" end_char="4720">to</TOKEN>
        <TOKEN id="token-82-15" pos="word" morph="none" start_char="4722" end_char="4724">the</TOKEN>
      </SEG>
      <SEG id="segment-83" start_char="4726" end_char="4799">
        <ORIGINAL_TEXT>European economic crisis, which was by far the most important issue at the</ORIGINAL_TEXT>
        <TOKEN id="token-83-0" pos="word" morph="none" start_char="4726" end_char="4733">European</TOKEN>
        <TOKEN id="token-83-1" pos="word" morph="none" start_char="4735" end_char="4742">economic</TOKEN>
        <TOKEN id="token-83-2" pos="word" morph="none" start_char="4744" end_char="4749">crisis</TOKEN>
        <TOKEN id="token-83-3" pos="punct" morph="none" start_char="4750" end_char="4750">,</TOKEN>
        <TOKEN id="token-83-4" pos="word" morph="none" start_char="4752" end_char="4756">which</TOKEN>
        <TOKEN id="token-83-5" pos="word" morph="none" start_char="4758" end_char="4760">was</TOKEN>
        <TOKEN id="token-83-6" pos="word" morph="none" start_char="4762" end_char="4763">by</TOKEN>
        <TOKEN id="token-83-7" pos="word" morph="none" start_char="4765" end_char="4767">far</TOKEN>
        <TOKEN id="token-83-8" pos="word" morph="none" start_char="4769" end_char="4771">the</TOKEN>
        <TOKEN id="token-83-9" pos="word" morph="none" start_char="4773" end_char="4776">most</TOKEN>
        <TOKEN id="token-83-10" pos="word" morph="none" start_char="4778" end_char="4786">important</TOKEN>
        <TOKEN id="token-83-11" pos="word" morph="none" start_char="4788" end_char="4792">issue</TOKEN>
        <TOKEN id="token-83-12" pos="word" morph="none" start_char="4794" end_char="4795">at</TOKEN>
        <TOKEN id="token-83-13" pos="word" morph="none" start_char="4797" end_char="4799">the</TOKEN>
      </SEG>
      <SEG id="segment-84" start_char="4801" end_char="4873">
        <ORIGINAL_TEXT>time. There is no mention of the European Union’s longstanding failure to</ORIGINAL_TEXT>
        <TOKEN id="token-84-0" pos="word" morph="none" start_char="4801" end_char="4804">time</TOKEN>
        <TOKEN id="token-84-1" pos="punct" morph="none" start_char="4805" end_char="4805">.</TOKEN>
        <TOKEN id="token-84-2" pos="word" morph="none" start_char="4807" end_char="4811">There</TOKEN>
        <TOKEN id="token-84-3" pos="word" morph="none" start_char="4813" end_char="4814">is</TOKEN>
        <TOKEN id="token-84-4" pos="word" morph="none" start_char="4816" end_char="4817">no</TOKEN>
        <TOKEN id="token-84-5" pos="word" morph="none" start_char="4819" end_char="4825">mention</TOKEN>
        <TOKEN id="token-84-6" pos="word" morph="none" start_char="4827" end_char="4828">of</TOKEN>
        <TOKEN id="token-84-7" pos="word" morph="none" start_char="4830" end_char="4832">the</TOKEN>
        <TOKEN id="token-84-8" pos="word" morph="none" start_char="4834" end_char="4841">European</TOKEN>
        <TOKEN id="token-84-9" pos="word" morph="none" start_char="4843" end_char="4847">Union</TOKEN>
        <TOKEN id="token-84-10" pos="punct" morph="none" start_char="4848" end_char="4848">’</TOKEN>
        <TOKEN id="token-84-11" pos="word" morph="none" start_char="4849" end_char="4849">s</TOKEN>
        <TOKEN id="token-84-12" pos="word" morph="none" start_char="4851" end_char="4862">longstanding</TOKEN>
        <TOKEN id="token-84-13" pos="word" morph="none" start_char="4864" end_char="4870">failure</TOKEN>
        <TOKEN id="token-84-14" pos="word" morph="none" start_char="4872" end_char="4873">to</TOKEN>
      </SEG>
      <SEG id="segment-85" start_char="4875" end_char="4952">
        <ORIGINAL_TEXT>come up with a coherent foreign policy, no sense that anything at all is wrong</ORIGINAL_TEXT>
        <TOKEN id="token-85-0" pos="word" morph="none" start_char="4875" end_char="4878">come</TOKEN>
        <TOKEN id="token-85-1" pos="word" morph="none" start_char="4880" end_char="4881">up</TOKEN>
        <TOKEN id="token-85-2" pos="word" morph="none" start_char="4883" end_char="4886">with</TOKEN>
        <TOKEN id="token-85-3" pos="word" morph="none" start_char="4888" end_char="4888">a</TOKEN>
        <TOKEN id="token-85-4" pos="word" morph="none" start_char="4890" end_char="4897">coherent</TOKEN>
        <TOKEN id="token-85-5" pos="word" morph="none" start_char="4899" end_char="4905">foreign</TOKEN>
        <TOKEN id="token-85-6" pos="word" morph="none" start_char="4907" end_char="4912">policy</TOKEN>
        <TOKEN id="token-85-7" pos="punct" morph="none" start_char="4913" end_char="4913">,</TOKEN>
        <TOKEN id="token-85-8" pos="word" morph="none" start_char="4915" end_char="4916">no</TOKEN>
        <TOKEN id="token-85-9" pos="word" morph="none" start_char="4918" end_char="4922">sense</TOKEN>
        <TOKEN id="token-85-10" pos="word" morph="none" start_char="4924" end_char="4927">that</TOKEN>
        <TOKEN id="token-85-11" pos="word" morph="none" start_char="4929" end_char="4936">anything</TOKEN>
        <TOKEN id="token-85-12" pos="word" morph="none" start_char="4938" end_char="4939">at</TOKEN>
        <TOKEN id="token-85-13" pos="word" morph="none" start_char="4941" end_char="4943">all</TOKEN>
        <TOKEN id="token-85-14" pos="word" morph="none" start_char="4945" end_char="4946">is</TOKEN>
        <TOKEN id="token-85-15" pos="word" morph="none" start_char="4948" end_char="4952">wrong</TOKEN>
      </SEG>
      <SEG id="segment-86" start_char="4954" end_char="5020">
        <ORIGINAL_TEXT>with an institution which has made “many contributions to peace and</ORIGINAL_TEXT>
        <TOKEN id="token-86-0" pos="word" morph="none" start_char="4954" end_char="4957">with</TOKEN>
        <TOKEN id="token-86-1" pos="word" morph="none" start_char="4959" end_char="4960">an</TOKEN>
        <TOKEN id="token-86-2" pos="word" morph="none" start_char="4962" end_char="4972">institution</TOKEN>
        <TOKEN id="token-86-3" pos="word" morph="none" start_char="4974" end_char="4978">which</TOKEN>
        <TOKEN id="token-86-4" pos="word" morph="none" start_char="4980" end_char="4982">has</TOKEN>
        <TOKEN id="token-86-5" pos="word" morph="none" start_char="4984" end_char="4987">made</TOKEN>
        <TOKEN id="token-86-6" pos="punct" morph="none" start_char="4989" end_char="4989">“</TOKEN>
        <TOKEN id="token-86-7" pos="word" morph="none" start_char="4990" end_char="4993">many</TOKEN>
        <TOKEN id="token-86-8" pos="word" morph="none" start_char="4995" end_char="5007">contributions</TOKEN>
        <TOKEN id="token-86-9" pos="word" morph="none" start_char="5009" end_char="5010">to</TOKEN>
        <TOKEN id="token-86-10" pos="word" morph="none" start_char="5012" end_char="5016">peace</TOKEN>
        <TOKEN id="token-86-11" pos="word" morph="none" start_char="5018" end_char="5020">and</TOKEN>
      </SEG>
      <SEG id="segment-87" start_char="5022" end_char="5063">
        <ORIGINAL_TEXT>prosperity within and beyond its borders.”</ORIGINAL_TEXT>
        <TOKEN id="token-87-0" pos="word" morph="none" start_char="5022" end_char="5031">prosperity</TOKEN>
        <TOKEN id="token-87-1" pos="word" morph="none" start_char="5033" end_char="5038">within</TOKEN>
        <TOKEN id="token-87-2" pos="word" morph="none" start_char="5040" end_char="5042">and</TOKEN>
        <TOKEN id="token-87-3" pos="word" morph="none" start_char="5044" end_char="5049">beyond</TOKEN>
        <TOKEN id="token-87-4" pos="word" morph="none" start_char="5051" end_char="5053">its</TOKEN>
        <TOKEN id="token-87-5" pos="word" morph="none" start_char="5055" end_char="5061">borders</TOKEN>
        <TOKEN id="token-87-6" pos="punct" morph="none" start_char="5062" end_char="5063">.”</TOKEN>
      </SEG>
      <SEG id="segment-88" start_char="5065" end_char="5068">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-88-0" pos="unknown" morph="none" start_char="5065" end_char="5068">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-89" start_char="5070" end_char="5072">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-89-0" pos="unknown" morph="none" start_char="5070" end_char="5072">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-90" start_char="5074" end_char="5149">
        <ORIGINAL_TEXT>Clinton’s chapter on Burma is similarly glossy. It begins with a description</ORIGINAL_TEXT>
        <TOKEN id="token-90-0" pos="word" morph="none" start_char="5074" end_char="5080">Clinton</TOKEN>
        <TOKEN id="token-90-1" pos="punct" morph="none" start_char="5081" end_char="5081">’</TOKEN>
        <TOKEN id="token-90-2" pos="word" morph="none" start_char="5082" end_char="5082">s</TOKEN>
        <TOKEN id="token-90-3" pos="word" morph="none" start_char="5084" end_char="5090">chapter</TOKEN>
        <TOKEN id="token-90-4" pos="word" morph="none" start_char="5092" end_char="5093">on</TOKEN>
        <TOKEN id="token-90-5" pos="word" morph="none" start_char="5095" end_char="5099">Burma</TOKEN>
        <TOKEN id="token-90-6" pos="word" morph="none" start_char="5101" end_char="5102">is</TOKEN>
        <TOKEN id="token-90-7" pos="word" morph="none" start_char="5104" end_char="5112">similarly</TOKEN>
        <TOKEN id="token-90-8" pos="word" morph="none" start_char="5114" end_char="5119">glossy</TOKEN>
        <TOKEN id="token-90-9" pos="punct" morph="none" start_char="5120" end_char="5120">.</TOKEN>
        <TOKEN id="token-90-10" pos="word" morph="none" start_char="5122" end_char="5123">It</TOKEN>
        <TOKEN id="token-90-11" pos="word" morph="none" start_char="5125" end_char="5130">begins</TOKEN>
        <TOKEN id="token-90-12" pos="word" morph="none" start_char="5132" end_char="5135">with</TOKEN>
        <TOKEN id="token-90-13" pos="word" morph="none" start_char="5137" end_char="5137">a</TOKEN>
        <TOKEN id="token-90-14" pos="word" morph="none" start_char="5139" end_char="5149">description</TOKEN>
      </SEG>
      <SEG id="segment-91" start_char="5151" end_char="5219">
        <ORIGINAL_TEXT>of Aung San Suu Kyi—“frail, but with unmistakable inner strength”—and</ORIGINAL_TEXT>
        <TOKEN id="token-91-0" pos="word" morph="none" start_char="5151" end_char="5152">of</TOKEN>
        <TOKEN id="token-91-1" pos="word" morph="none" start_char="5154" end_char="5157">Aung</TOKEN>
        <TOKEN id="token-91-2" pos="word" morph="none" start_char="5159" end_char="5161">San</TOKEN>
        <TOKEN id="token-91-3" pos="word" morph="none" start_char="5163" end_char="5165">Suu</TOKEN>
        <TOKEN id="token-91-4" pos="word" morph="none" start_char="5167" end_char="5169">Kyi</TOKEN>
        <TOKEN id="token-91-5" pos="punct" morph="none" start_char="5170" end_char="5171">—“</TOKEN>
        <TOKEN id="token-91-6" pos="word" morph="none" start_char="5172" end_char="5176">frail</TOKEN>
        <TOKEN id="token-91-7" pos="punct" morph="none" start_char="5177" end_char="5177">,</TOKEN>
        <TOKEN id="token-91-8" pos="word" morph="none" start_char="5179" end_char="5181">but</TOKEN>
        <TOKEN id="token-91-9" pos="word" morph="none" start_char="5183" end_char="5186">with</TOKEN>
        <TOKEN id="token-91-10" pos="word" morph="none" start_char="5188" end_char="5199">unmistakable</TOKEN>
        <TOKEN id="token-91-11" pos="word" morph="none" start_char="5201" end_char="5205">inner</TOKEN>
        <TOKEN id="token-91-12" pos="word" morph="none" start_char="5207" end_char="5214">strength</TOKEN>
        <TOKEN id="token-91-13" pos="punct" morph="none" start_char="5215" end_char="5216">”—</TOKEN>
        <TOKEN id="token-91-14" pos="word" morph="none" start_char="5217" end_char="5219">and</TOKEN>
      </SEG>
      <SEG id="segment-92" start_char="5221" end_char="5292">
        <ORIGINAL_TEXT>ends with Burma on the road to democracy, a story that she calls a “high</ORIGINAL_TEXT>
        <TOKEN id="token-92-0" pos="word" morph="none" start_char="5221" end_char="5224">ends</TOKEN>
        <TOKEN id="token-92-1" pos="word" morph="none" start_char="5226" end_char="5229">with</TOKEN>
        <TOKEN id="token-92-2" pos="word" morph="none" start_char="5231" end_char="5235">Burma</TOKEN>
        <TOKEN id="token-92-3" pos="word" morph="none" start_char="5237" end_char="5238">on</TOKEN>
        <TOKEN id="token-92-4" pos="word" morph="none" start_char="5240" end_char="5242">the</TOKEN>
        <TOKEN id="token-92-5" pos="word" morph="none" start_char="5244" end_char="5247">road</TOKEN>
        <TOKEN id="token-92-6" pos="word" morph="none" start_char="5249" end_char="5250">to</TOKEN>
        <TOKEN id="token-92-7" pos="word" morph="none" start_char="5252" end_char="5260">democracy</TOKEN>
        <TOKEN id="token-92-8" pos="punct" morph="none" start_char="5261" end_char="5261">,</TOKEN>
        <TOKEN id="token-92-9" pos="word" morph="none" start_char="5263" end_char="5263">a</TOKEN>
        <TOKEN id="token-92-10" pos="word" morph="none" start_char="5265" end_char="5269">story</TOKEN>
        <TOKEN id="token-92-11" pos="word" morph="none" start_char="5271" end_char="5274">that</TOKEN>
        <TOKEN id="token-92-12" pos="word" morph="none" start_char="5276" end_char="5278">she</TOKEN>
        <TOKEN id="token-92-13" pos="word" morph="none" start_char="5280" end_char="5284">calls</TOKEN>
        <TOKEN id="token-92-14" pos="word" morph="none" start_char="5286" end_char="5286">a</TOKEN>
        <TOKEN id="token-92-15" pos="punct" morph="none" start_char="5288" end_char="5288">“</TOKEN>
        <TOKEN id="token-92-16" pos="word" morph="none" start_char="5289" end_char="5292">high</TOKEN>
      </SEG>
      <SEG id="segment-93" start_char="5294" end_char="5364">
        <ORIGINAL_TEXT>point” of her term in office and “an affirmation of the unique role the</ORIGINAL_TEXT>
        <TOKEN id="token-93-0" pos="word" morph="none" start_char="5294" end_char="5298">point</TOKEN>
        <TOKEN id="token-93-1" pos="punct" morph="none" start_char="5299" end_char="5299">”</TOKEN>
        <TOKEN id="token-93-2" pos="word" morph="none" start_char="5301" end_char="5302">of</TOKEN>
        <TOKEN id="token-93-3" pos="word" morph="none" start_char="5304" end_char="5306">her</TOKEN>
        <TOKEN id="token-93-4" pos="word" morph="none" start_char="5308" end_char="5311">term</TOKEN>
        <TOKEN id="token-93-5" pos="word" morph="none" start_char="5313" end_char="5314">in</TOKEN>
        <TOKEN id="token-93-6" pos="word" morph="none" start_char="5316" end_char="5321">office</TOKEN>
        <TOKEN id="token-93-7" pos="word" morph="none" start_char="5323" end_char="5325">and</TOKEN>
        <TOKEN id="token-93-8" pos="punct" morph="none" start_char="5327" end_char="5327">“</TOKEN>
        <TOKEN id="token-93-9" pos="word" morph="none" start_char="5328" end_char="5329">an</TOKEN>
        <TOKEN id="token-93-10" pos="word" morph="none" start_char="5331" end_char="5341">affirmation</TOKEN>
        <TOKEN id="token-93-11" pos="word" morph="none" start_char="5343" end_char="5344">of</TOKEN>
        <TOKEN id="token-93-12" pos="word" morph="none" start_char="5346" end_char="5348">the</TOKEN>
        <TOKEN id="token-93-13" pos="word" morph="none" start_char="5350" end_char="5355">unique</TOKEN>
        <TOKEN id="token-93-14" pos="word" morph="none" start_char="5357" end_char="5360">role</TOKEN>
        <TOKEN id="token-93-15" pos="word" morph="none" start_char="5362" end_char="5364">the</TOKEN>
      </SEG>
      <SEG id="segment-94" start_char="5366" end_char="5440">
        <ORIGINAL_TEXT>United States can and should play in the world as a champion of dignity and</ORIGINAL_TEXT>
        <TOKEN id="token-94-0" pos="word" morph="none" start_char="5366" end_char="5371">United</TOKEN>
        <TOKEN id="token-94-1" pos="word" morph="none" start_char="5373" end_char="5378">States</TOKEN>
        <TOKEN id="token-94-2" pos="word" morph="none" start_char="5380" end_char="5382">can</TOKEN>
        <TOKEN id="token-94-3" pos="word" morph="none" start_char="5384" end_char="5386">and</TOKEN>
        <TOKEN id="token-94-4" pos="word" morph="none" start_char="5388" end_char="5393">should</TOKEN>
        <TOKEN id="token-94-5" pos="word" morph="none" start_char="5395" end_char="5398">play</TOKEN>
        <TOKEN id="token-94-6" pos="word" morph="none" start_char="5400" end_char="5401">in</TOKEN>
        <TOKEN id="token-94-7" pos="word" morph="none" start_char="5403" end_char="5405">the</TOKEN>
        <TOKEN id="token-94-8" pos="word" morph="none" start_char="5407" end_char="5411">world</TOKEN>
        <TOKEN id="token-94-9" pos="word" morph="none" start_char="5413" end_char="5414">as</TOKEN>
        <TOKEN id="token-94-10" pos="word" morph="none" start_char="5416" end_char="5416">a</TOKEN>
        <TOKEN id="token-94-11" pos="word" morph="none" start_char="5418" end_char="5425">champion</TOKEN>
        <TOKEN id="token-94-12" pos="word" morph="none" start_char="5427" end_char="5428">of</TOKEN>
        <TOKEN id="token-94-13" pos="word" morph="none" start_char="5430" end_char="5436">dignity</TOKEN>
        <TOKEN id="token-94-14" pos="word" morph="none" start_char="5438" end_char="5440">and</TOKEN>
      </SEG>
      <SEG id="segment-95" start_char="5442" end_char="5515">
        <ORIGINAL_TEXT>democracy.” There is no hint that the Burmese army was just then beginning</ORIGINAL_TEXT>
        <TOKEN id="token-95-0" pos="word" morph="none" start_char="5442" end_char="5450">democracy</TOKEN>
        <TOKEN id="token-95-1" pos="punct" morph="none" start_char="5451" end_char="5452">.”</TOKEN>
        <TOKEN id="token-95-2" pos="word" morph="none" start_char="5454" end_char="5458">There</TOKEN>
        <TOKEN id="token-95-3" pos="word" morph="none" start_char="5460" end_char="5461">is</TOKEN>
        <TOKEN id="token-95-4" pos="word" morph="none" start_char="5463" end_char="5464">no</TOKEN>
        <TOKEN id="token-95-5" pos="word" morph="none" start_char="5466" end_char="5469">hint</TOKEN>
        <TOKEN id="token-95-6" pos="word" morph="none" start_char="5471" end_char="5474">that</TOKEN>
        <TOKEN id="token-95-7" pos="word" morph="none" start_char="5476" end_char="5478">the</TOKEN>
        <TOKEN id="token-95-8" pos="word" morph="none" start_char="5480" end_char="5486">Burmese</TOKEN>
        <TOKEN id="token-95-9" pos="word" morph="none" start_char="5488" end_char="5491">army</TOKEN>
        <TOKEN id="token-95-10" pos="word" morph="none" start_char="5493" end_char="5495">was</TOKEN>
        <TOKEN id="token-95-11" pos="word" morph="none" start_char="5497" end_char="5500">just</TOKEN>
        <TOKEN id="token-95-12" pos="word" morph="none" start_char="5502" end_char="5505">then</TOKEN>
        <TOKEN id="token-95-13" pos="word" morph="none" start_char="5507" end_char="5515">beginning</TOKEN>
      </SEG>
      <SEG id="segment-96" start_char="5517" end_char="5592">
        <ORIGINAL_TEXT>its vicious war against the Karen insurgency, that a brutal conflict between</ORIGINAL_TEXT>
        <TOKEN id="token-96-0" pos="word" morph="none" start_char="5517" end_char="5519">its</TOKEN>
        <TOKEN id="token-96-1" pos="word" morph="none" start_char="5521" end_char="5527">vicious</TOKEN>
        <TOKEN id="token-96-2" pos="word" morph="none" start_char="5529" end_char="5531">war</TOKEN>
        <TOKEN id="token-96-3" pos="word" morph="none" start_char="5533" end_char="5539">against</TOKEN>
        <TOKEN id="token-96-4" pos="word" morph="none" start_char="5541" end_char="5543">the</TOKEN>
        <TOKEN id="token-96-5" pos="word" morph="none" start_char="5545" end_char="5549">Karen</TOKEN>
        <TOKEN id="token-96-6" pos="word" morph="none" start_char="5551" end_char="5560">insurgency</TOKEN>
        <TOKEN id="token-96-7" pos="punct" morph="none" start_char="5561" end_char="5561">,</TOKEN>
        <TOKEN id="token-96-8" pos="word" morph="none" start_char="5563" end_char="5566">that</TOKEN>
        <TOKEN id="token-96-9" pos="word" morph="none" start_char="5568" end_char="5568">a</TOKEN>
        <TOKEN id="token-96-10" pos="word" morph="none" start_char="5570" end_char="5575">brutal</TOKEN>
        <TOKEN id="token-96-11" pos="word" morph="none" start_char="5577" end_char="5584">conflict</TOKEN>
        <TOKEN id="token-96-12" pos="word" morph="none" start_char="5586" end_char="5592">between</TOKEN>
      </SEG>
      <SEG id="segment-97" start_char="5594" end_char="5668">
        <ORIGINAL_TEXT>Buddhists and Muslims was already growing worse, or that Suu Kyi’s prestige</ORIGINAL_TEXT>
        <TOKEN id="token-97-0" pos="word" morph="none" start_char="5594" end_char="5602">Buddhists</TOKEN>
        <TOKEN id="token-97-1" pos="word" morph="none" start_char="5604" end_char="5606">and</TOKEN>
        <TOKEN id="token-97-2" pos="word" morph="none" start_char="5608" end_char="5614">Muslims</TOKEN>
        <TOKEN id="token-97-3" pos="word" morph="none" start_char="5616" end_char="5618">was</TOKEN>
        <TOKEN id="token-97-4" pos="word" morph="none" start_char="5620" end_char="5626">already</TOKEN>
        <TOKEN id="token-97-5" pos="word" morph="none" start_char="5628" end_char="5634">growing</TOKEN>
        <TOKEN id="token-97-6" pos="word" morph="none" start_char="5636" end_char="5640">worse</TOKEN>
        <TOKEN id="token-97-7" pos="punct" morph="none" start_char="5641" end_char="5641">,</TOKEN>
        <TOKEN id="token-97-8" pos="word" morph="none" start_char="5643" end_char="5644">or</TOKEN>
        <TOKEN id="token-97-9" pos="word" morph="none" start_char="5646" end_char="5649">that</TOKEN>
        <TOKEN id="token-97-10" pos="word" morph="none" start_char="5651" end_char="5653">Suu</TOKEN>
        <TOKEN id="token-97-11" pos="word" morph="none" start_char="5655" end_char="5657">Kyi</TOKEN>
        <TOKEN id="token-97-12" pos="punct" morph="none" start_char="5658" end_char="5658">’</TOKEN>
        <TOKEN id="token-97-13" pos="word" morph="none" start_char="5659" end_char="5659">s</TOKEN>
        <TOKEN id="token-97-14" pos="word" morph="none" start_char="5661" end_char="5668">prestige</TOKEN>
      </SEG>
      <SEG id="segment-98" start_char="5670" end_char="5744">
        <ORIGINAL_TEXT>was starting to plummet as she failed to exert any influence to stop either</ORIGINAL_TEXT>
        <TOKEN id="token-98-0" pos="word" morph="none" start_char="5670" end_char="5672">was</TOKEN>
        <TOKEN id="token-98-1" pos="word" morph="none" start_char="5674" end_char="5681">starting</TOKEN>
        <TOKEN id="token-98-2" pos="word" morph="none" start_char="5683" end_char="5684">to</TOKEN>
        <TOKEN id="token-98-3" pos="word" morph="none" start_char="5686" end_char="5692">plummet</TOKEN>
        <TOKEN id="token-98-4" pos="word" morph="none" start_char="5694" end_char="5695">as</TOKEN>
        <TOKEN id="token-98-5" pos="word" morph="none" start_char="5697" end_char="5699">she</TOKEN>
        <TOKEN id="token-98-6" pos="word" morph="none" start_char="5701" end_char="5706">failed</TOKEN>
        <TOKEN id="token-98-7" pos="word" morph="none" start_char="5708" end_char="5709">to</TOKEN>
        <TOKEN id="token-98-8" pos="word" morph="none" start_char="5711" end_char="5715">exert</TOKEN>
        <TOKEN id="token-98-9" pos="word" morph="none" start_char="5717" end_char="5719">any</TOKEN>
        <TOKEN id="token-98-10" pos="word" morph="none" start_char="5721" end_char="5729">influence</TOKEN>
        <TOKEN id="token-98-11" pos="word" morph="none" start_char="5731" end_char="5732">to</TOKEN>
        <TOKEN id="token-98-12" pos="word" morph="none" start_char="5734" end_char="5737">stop</TOKEN>
        <TOKEN id="token-98-13" pos="word" morph="none" start_char="5739" end_char="5744">either</TOKEN>
      </SEG>
      <SEG id="segment-99" start_char="5746" end_char="5820">
        <ORIGINAL_TEXT>one of those outrages. Even Clinton’s portrayal of Haiti, where she and her</ORIGINAL_TEXT>
        <TOKEN id="token-99-0" pos="word" morph="none" start_char="5746" end_char="5748">one</TOKEN>
        <TOKEN id="token-99-1" pos="word" morph="none" start_char="5750" end_char="5751">of</TOKEN>
        <TOKEN id="token-99-2" pos="word" morph="none" start_char="5753" end_char="5757">those</TOKEN>
        <TOKEN id="token-99-3" pos="word" morph="none" start_char="5759" end_char="5766">outrages</TOKEN>
        <TOKEN id="token-99-4" pos="punct" morph="none" start_char="5767" end_char="5767">.</TOKEN>
        <TOKEN id="token-99-5" pos="word" morph="none" start_char="5769" end_char="5772">Even</TOKEN>
        <TOKEN id="token-99-6" pos="word" morph="none" start_char="5774" end_char="5780">Clinton</TOKEN>
        <TOKEN id="token-99-7" pos="punct" morph="none" start_char="5781" end_char="5781">’</TOKEN>
        <TOKEN id="token-99-8" pos="word" morph="none" start_char="5782" end_char="5782">s</TOKEN>
        <TOKEN id="token-99-9" pos="word" morph="none" start_char="5784" end_char="5792">portrayal</TOKEN>
        <TOKEN id="token-99-10" pos="word" morph="none" start_char="5794" end_char="5795">of</TOKEN>
        <TOKEN id="token-99-11" pos="word" morph="none" start_char="5797" end_char="5801">Haiti</TOKEN>
        <TOKEN id="token-99-12" pos="punct" morph="none" start_char="5802" end_char="5802">,</TOKEN>
        <TOKEN id="token-99-13" pos="word" morph="none" start_char="5804" end_char="5808">where</TOKEN>
        <TOKEN id="token-99-14" pos="word" morph="none" start_char="5810" end_char="5812">she</TOKEN>
        <TOKEN id="token-99-15" pos="word" morph="none" start_char="5814" end_char="5816">and</TOKEN>
        <TOKEN id="token-99-16" pos="word" morph="none" start_char="5818" end_char="5820">her</TOKEN>
      </SEG>
      <SEG id="segment-100" start_char="5822" end_char="5893">
        <ORIGINAL_TEXT>husband have a long involvement, fails to note that their plan to “Build</ORIGINAL_TEXT>
        <TOKEN id="token-100-0" pos="word" morph="none" start_char="5822" end_char="5828">husband</TOKEN>
        <TOKEN id="token-100-1" pos="word" morph="none" start_char="5830" end_char="5833">have</TOKEN>
        <TOKEN id="token-100-2" pos="word" morph="none" start_char="5835" end_char="5835">a</TOKEN>
        <TOKEN id="token-100-3" pos="word" morph="none" start_char="5837" end_char="5840">long</TOKEN>
        <TOKEN id="token-100-4" pos="word" morph="none" start_char="5842" end_char="5852">involvement</TOKEN>
        <TOKEN id="token-100-5" pos="punct" morph="none" start_char="5853" end_char="5853">,</TOKEN>
        <TOKEN id="token-100-6" pos="word" morph="none" start_char="5855" end_char="5859">fails</TOKEN>
        <TOKEN id="token-100-7" pos="word" morph="none" start_char="5861" end_char="5862">to</TOKEN>
        <TOKEN id="token-100-8" pos="word" morph="none" start_char="5864" end_char="5867">note</TOKEN>
        <TOKEN id="token-100-9" pos="word" morph="none" start_char="5869" end_char="5872">that</TOKEN>
        <TOKEN id="token-100-10" pos="word" morph="none" start_char="5874" end_char="5878">their</TOKEN>
        <TOKEN id="token-100-11" pos="word" morph="none" start_char="5880" end_char="5883">plan</TOKEN>
        <TOKEN id="token-100-12" pos="word" morph="none" start_char="5885" end_char="5886">to</TOKEN>
        <TOKEN id="token-100-13" pos="punct" morph="none" start_char="5888" end_char="5888">“</TOKEN>
        <TOKEN id="token-100-14" pos="word" morph="none" start_char="5889" end_char="5893">Build</TOKEN>
      </SEG>
      <SEG id="segment-101" start_char="5895" end_char="5966">
        <ORIGINAL_TEXT>Back Better” after Haiti’s earthquake in 2010 is now widely perceived to</ORIGINAL_TEXT>
        <TOKEN id="token-101-0" pos="word" morph="none" start_char="5895" end_char="5898">Back</TOKEN>
        <TOKEN id="token-101-1" pos="word" morph="none" start_char="5900" end_char="5905">Better</TOKEN>
        <TOKEN id="token-101-2" pos="punct" morph="none" start_char="5906" end_char="5906">”</TOKEN>
        <TOKEN id="token-101-3" pos="word" morph="none" start_char="5908" end_char="5912">after</TOKEN>
        <TOKEN id="token-101-4" pos="word" morph="none" start_char="5914" end_char="5918">Haiti</TOKEN>
        <TOKEN id="token-101-5" pos="punct" morph="none" start_char="5919" end_char="5919">’</TOKEN>
        <TOKEN id="token-101-6" pos="word" morph="none" start_char="5920" end_char="5920">s</TOKEN>
        <TOKEN id="token-101-7" pos="word" morph="none" start_char="5922" end_char="5931">earthquake</TOKEN>
        <TOKEN id="token-101-8" pos="word" morph="none" start_char="5933" end_char="5934">in</TOKEN>
        <TOKEN id="token-101-9" pos="number" morph="none" start_char="5936" end_char="5939">2010</TOKEN>
        <TOKEN id="token-101-10" pos="word" morph="none" start_char="5941" end_char="5942">is</TOKEN>
        <TOKEN id="token-101-11" pos="word" morph="none" start_char="5944" end_char="5946">now</TOKEN>
        <TOKEN id="token-101-12" pos="word" morph="none" start_char="5948" end_char="5953">widely</TOKEN>
        <TOKEN id="token-101-13" pos="word" morph="none" start_char="5955" end_char="5963">perceived</TOKEN>
        <TOKEN id="token-101-14" pos="word" morph="none" start_char="5965" end_char="5966">to</TOKEN>
      </SEG>
      <SEG id="segment-102" start_char="5968" end_char="5979">
        <ORIGINAL_TEXT>have failed.</ORIGINAL_TEXT>
        <TOKEN id="token-102-0" pos="word" morph="none" start_char="5968" end_char="5971">have</TOKEN>
        <TOKEN id="token-102-1" pos="word" morph="none" start_char="5973" end_char="5978">failed</TOKEN>
        <TOKEN id="token-102-2" pos="punct" morph="none" start_char="5979" end_char="5979">.</TOKEN>
      </SEG>
      <SEG id="segment-103" start_char="5981" end_char="5984">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-103-0" pos="unknown" morph="none" start_char="5981" end_char="5984">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-104" start_char="5986" end_char="5988">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-104-0" pos="unknown" morph="none" start_char="5986" end_char="5988">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-105" start_char="5990" end_char="6065">
        <ORIGINAL_TEXT>On topics that she knew would be examined more exhaustively, Clinton is more</ORIGINAL_TEXT>
        <TOKEN id="token-105-0" pos="word" morph="none" start_char="5990" end_char="5991">On</TOKEN>
        <TOKEN id="token-105-1" pos="word" morph="none" start_char="5993" end_char="5998">topics</TOKEN>
        <TOKEN id="token-105-2" pos="word" morph="none" start_char="6000" end_char="6003">that</TOKEN>
        <TOKEN id="token-105-3" pos="word" morph="none" start_char="6005" end_char="6007">she</TOKEN>
        <TOKEN id="token-105-4" pos="word" morph="none" start_char="6009" end_char="6012">knew</TOKEN>
        <TOKEN id="token-105-5" pos="word" morph="none" start_char="6014" end_char="6018">would</TOKEN>
        <TOKEN id="token-105-6" pos="word" morph="none" start_char="6020" end_char="6021">be</TOKEN>
        <TOKEN id="token-105-7" pos="word" morph="none" start_char="6023" end_char="6030">examined</TOKEN>
        <TOKEN id="token-105-8" pos="word" morph="none" start_char="6032" end_char="6035">more</TOKEN>
        <TOKEN id="token-105-9" pos="word" morph="none" start_char="6037" end_char="6048">exhaustively</TOKEN>
        <TOKEN id="token-105-10" pos="punct" morph="none" start_char="6049" end_char="6049">,</TOKEN>
        <TOKEN id="token-105-11" pos="word" morph="none" start_char="6051" end_char="6057">Clinton</TOKEN>
        <TOKEN id="token-105-12" pos="word" morph="none" start_char="6059" end_char="6060">is</TOKEN>
        <TOKEN id="token-105-13" pos="word" morph="none" start_char="6062" end_char="6065">more</TOKEN>
      </SEG>
      <SEG id="segment-106" start_char="6067" end_char="6138">
        <ORIGINAL_TEXT>careful to avoid overly sunny conclusions. Her account of her attempt to</ORIGINAL_TEXT>
        <TOKEN id="token-106-0" pos="word" morph="none" start_char="6067" end_char="6073">careful</TOKEN>
        <TOKEN id="token-106-1" pos="word" morph="none" start_char="6075" end_char="6076">to</TOKEN>
        <TOKEN id="token-106-2" pos="word" morph="none" start_char="6078" end_char="6082">avoid</TOKEN>
        <TOKEN id="token-106-3" pos="word" morph="none" start_char="6084" end_char="6089">overly</TOKEN>
        <TOKEN id="token-106-4" pos="word" morph="none" start_char="6091" end_char="6095">sunny</TOKEN>
        <TOKEN id="token-106-5" pos="word" morph="none" start_char="6097" end_char="6107">conclusions</TOKEN>
        <TOKEN id="token-106-6" pos="punct" morph="none" start_char="6108" end_char="6108">.</TOKEN>
        <TOKEN id="token-106-7" pos="word" morph="none" start_char="6110" end_char="6112">Her</TOKEN>
        <TOKEN id="token-106-8" pos="word" morph="none" start_char="6114" end_char="6120">account</TOKEN>
        <TOKEN id="token-106-9" pos="word" morph="none" start_char="6122" end_char="6123">of</TOKEN>
        <TOKEN id="token-106-10" pos="word" morph="none" start_char="6125" end_char="6127">her</TOKEN>
        <TOKEN id="token-106-11" pos="word" morph="none" start_char="6129" end_char="6135">attempt</TOKEN>
        <TOKEN id="token-106-12" pos="word" morph="none" start_char="6137" end_char="6138">to</TOKEN>
      </SEG>
      <SEG id="segment-107" start_char="6140" end_char="6202">
        <ORIGINAL_TEXT>“reset” relations with Russia was clearly rewritten just before</ORIGINAL_TEXT>
        <TOKEN id="token-107-0" pos="punct" morph="none" start_char="6140" end_char="6140">“</TOKEN>
        <TOKEN id="token-107-1" pos="word" morph="none" start_char="6141" end_char="6145">reset</TOKEN>
        <TOKEN id="token-107-2" pos="punct" morph="none" start_char="6146" end_char="6146">”</TOKEN>
        <TOKEN id="token-107-3" pos="word" morph="none" start_char="6148" end_char="6156">relations</TOKEN>
        <TOKEN id="token-107-4" pos="word" morph="none" start_char="6158" end_char="6161">with</TOKEN>
        <TOKEN id="token-107-5" pos="word" morph="none" start_char="6163" end_char="6168">Russia</TOKEN>
        <TOKEN id="token-107-6" pos="word" morph="none" start_char="6170" end_char="6172">was</TOKEN>
        <TOKEN id="token-107-7" pos="word" morph="none" start_char="6174" end_char="6180">clearly</TOKEN>
        <TOKEN id="token-107-8" pos="word" morph="none" start_char="6182" end_char="6190">rewritten</TOKEN>
        <TOKEN id="token-107-9" pos="word" morph="none" start_char="6192" end_char="6195">just</TOKEN>
        <TOKEN id="token-107-10" pos="word" morph="none" start_char="6197" end_char="6202">before</TOKEN>
      </SEG>
      <SEG id="segment-108" start_char="6204" end_char="6280">
        <ORIGINAL_TEXT>publication in order to include recent events in Ukraine. Here she draws what</ORIGINAL_TEXT>
        <TOKEN id="token-108-0" pos="word" morph="none" start_char="6204" end_char="6214">publication</TOKEN>
        <TOKEN id="token-108-1" pos="word" morph="none" start_char="6216" end_char="6217">in</TOKEN>
        <TOKEN id="token-108-2" pos="word" morph="none" start_char="6219" end_char="6223">order</TOKEN>
        <TOKEN id="token-108-3" pos="word" morph="none" start_char="6225" end_char="6226">to</TOKEN>
        <TOKEN id="token-108-4" pos="word" morph="none" start_char="6228" end_char="6234">include</TOKEN>
        <TOKEN id="token-108-5" pos="word" morph="none" start_char="6236" end_char="6241">recent</TOKEN>
        <TOKEN id="token-108-6" pos="word" morph="none" start_char="6243" end_char="6248">events</TOKEN>
        <TOKEN id="token-108-7" pos="word" morph="none" start_char="6250" end_char="6251">in</TOKEN>
        <TOKEN id="token-108-8" pos="word" morph="none" start_char="6253" end_char="6259">Ukraine</TOKEN>
        <TOKEN id="token-108-9" pos="punct" morph="none" start_char="6260" end_char="6260">.</TOKEN>
        <TOKEN id="token-108-10" pos="word" morph="none" start_char="6262" end_char="6265">Here</TOKEN>
        <TOKEN id="token-108-11" pos="word" morph="none" start_char="6267" end_char="6269">she</TOKEN>
        <TOKEN id="token-108-12" pos="word" morph="none" start_char="6271" end_char="6275">draws</TOKEN>
        <TOKEN id="token-108-13" pos="word" morph="none" start_char="6277" end_char="6280">what</TOKEN>
      </SEG>
      <SEG id="segment-109" start_char="6282" end_char="6355">
        <ORIGINAL_TEXT>positive stories she can—there was some cooperation with Russia in central</ORIGINAL_TEXT>
        <TOKEN id="token-109-0" pos="word" morph="none" start_char="6282" end_char="6289">positive</TOKEN>
        <TOKEN id="token-109-1" pos="word" morph="none" start_char="6291" end_char="6297">stories</TOKEN>
        <TOKEN id="token-109-2" pos="word" morph="none" start_char="6299" end_char="6301">she</TOKEN>
        <TOKEN id="token-109-3" pos="word" morph="none" start_char="6303" end_char="6305">can</TOKEN>
        <TOKEN id="token-109-4" pos="punct" morph="none" start_char="6306" end_char="6306">—</TOKEN>
        <TOKEN id="token-109-5" pos="word" morph="none" start_char="6307" end_char="6311">there</TOKEN>
        <TOKEN id="token-109-6" pos="word" morph="none" start_char="6313" end_char="6315">was</TOKEN>
        <TOKEN id="token-109-7" pos="word" morph="none" start_char="6317" end_char="6320">some</TOKEN>
        <TOKEN id="token-109-8" pos="word" morph="none" start_char="6322" end_char="6332">cooperation</TOKEN>
        <TOKEN id="token-109-9" pos="word" morph="none" start_char="6334" end_char="6337">with</TOKEN>
        <TOKEN id="token-109-10" pos="word" morph="none" start_char="6339" end_char="6344">Russia</TOKEN>
        <TOKEN id="token-109-11" pos="word" morph="none" start_char="6346" end_char="6347">in</TOKEN>
        <TOKEN id="token-109-12" pos="word" morph="none" start_char="6349" end_char="6355">central</TOKEN>
      </SEG>
      <SEG id="segment-110" start_char="6357" end_char="6427">
        <ORIGINAL_TEXT>Asia, for example—but makes clear that she had low expectations for the</ORIGINAL_TEXT>
        <TOKEN id="token-110-0" pos="word" morph="none" start_char="6357" end_char="6360">Asia</TOKEN>
        <TOKEN id="token-110-1" pos="punct" morph="none" start_char="6361" end_char="6361">,</TOKEN>
        <TOKEN id="token-110-2" pos="word" morph="none" start_char="6363" end_char="6365">for</TOKEN>
        <TOKEN id="token-110-3" pos="word" morph="none" start_char="6367" end_char="6373">example</TOKEN>
        <TOKEN id="token-110-4" pos="punct" morph="none" start_char="6374" end_char="6374">—</TOKEN>
        <TOKEN id="token-110-5" pos="word" morph="none" start_char="6375" end_char="6377">but</TOKEN>
        <TOKEN id="token-110-6" pos="word" morph="none" start_char="6379" end_char="6383">makes</TOKEN>
        <TOKEN id="token-110-7" pos="word" morph="none" start_char="6385" end_char="6389">clear</TOKEN>
        <TOKEN id="token-110-8" pos="word" morph="none" start_char="6391" end_char="6394">that</TOKEN>
        <TOKEN id="token-110-9" pos="word" morph="none" start_char="6396" end_char="6398">she</TOKEN>
        <TOKEN id="token-110-10" pos="word" morph="none" start_char="6400" end_char="6402">had</TOKEN>
        <TOKEN id="token-110-11" pos="word" morph="none" start_char="6404" end_char="6406">low</TOKEN>
        <TOKEN id="token-110-12" pos="word" morph="none" start_char="6408" end_char="6419">expectations</TOKEN>
        <TOKEN id="token-110-13" pos="word" morph="none" start_char="6421" end_char="6423">for</TOKEN>
        <TOKEN id="token-110-14" pos="word" morph="none" start_char="6425" end_char="6427">the</TOKEN>
      </SEG>
      <SEG id="segment-111" start_char="6429" end_char="6505">
        <ORIGINAL_TEXT>Russian-American relationship from the beginning. As she left office in 2013,</ORIGINAL_TEXT>
        <TOKEN id="token-111-0" pos="word" morph="none" start_char="6429" end_char="6435">Russian</TOKEN>
        <TOKEN id="token-111-1" pos="punct" morph="none" start_char="6436" end_char="6436">-</TOKEN>
        <TOKEN id="token-111-2" pos="word" morph="none" start_char="6437" end_char="6444">American</TOKEN>
        <TOKEN id="token-111-3" pos="word" morph="none" start_char="6446" end_char="6457">relationship</TOKEN>
        <TOKEN id="token-111-4" pos="word" morph="none" start_char="6459" end_char="6462">from</TOKEN>
        <TOKEN id="token-111-5" pos="word" morph="none" start_char="6464" end_char="6466">the</TOKEN>
        <TOKEN id="token-111-6" pos="word" morph="none" start_char="6468" end_char="6476">beginning</TOKEN>
        <TOKEN id="token-111-7" pos="punct" morph="none" start_char="6477" end_char="6477">.</TOKEN>
        <TOKEN id="token-111-8" pos="word" morph="none" start_char="6479" end_char="6480">As</TOKEN>
        <TOKEN id="token-111-9" pos="word" morph="none" start_char="6482" end_char="6484">she</TOKEN>
        <TOKEN id="token-111-10" pos="word" morph="none" start_char="6486" end_char="6489">left</TOKEN>
        <TOKEN id="token-111-11" pos="word" morph="none" start_char="6491" end_char="6496">office</TOKEN>
        <TOKEN id="token-111-12" pos="word" morph="none" start_char="6498" end_char="6499">in</TOKEN>
        <TOKEN id="token-111-13" pos="word" morph="none" start_char="6501" end_char="6504">2013</TOKEN>
        <TOKEN id="token-111-14" pos="punct" morph="none" start_char="6505" end_char="6505">,</TOKEN>
      </SEG>
      <SEG id="segment-112" start_char="6507" end_char="6575">
        <ORIGINAL_TEXT>she advised the president that “difficult days lay ahead and that our</ORIGINAL_TEXT>
        <TOKEN id="token-112-0" pos="word" morph="none" start_char="6507" end_char="6509">she</TOKEN>
        <TOKEN id="token-112-1" pos="word" morph="none" start_char="6511" end_char="6517">advised</TOKEN>
        <TOKEN id="token-112-2" pos="word" morph="none" start_char="6519" end_char="6521">the</TOKEN>
        <TOKEN id="token-112-3" pos="word" morph="none" start_char="6523" end_char="6531">president</TOKEN>
        <TOKEN id="token-112-4" pos="word" morph="none" start_char="6533" end_char="6536">that</TOKEN>
        <TOKEN id="token-112-5" pos="punct" morph="none" start_char="6538" end_char="6538">“</TOKEN>
        <TOKEN id="token-112-6" pos="word" morph="none" start_char="6539" end_char="6547">difficult</TOKEN>
        <TOKEN id="token-112-7" pos="word" morph="none" start_char="6549" end_char="6552">days</TOKEN>
        <TOKEN id="token-112-8" pos="word" morph="none" start_char="6554" end_char="6556">lay</TOKEN>
        <TOKEN id="token-112-9" pos="word" morph="none" start_char="6558" end_char="6562">ahead</TOKEN>
        <TOKEN id="token-112-10" pos="word" morph="none" start_char="6564" end_char="6566">and</TOKEN>
        <TOKEN id="token-112-11" pos="word" morph="none" start_char="6568" end_char="6571">that</TOKEN>
        <TOKEN id="token-112-12" pos="word" morph="none" start_char="6573" end_char="6575">our</TOKEN>
      </SEG>
      <SEG id="segment-113" start_char="6577" end_char="6646">
        <ORIGINAL_TEXT>relationship with Moscow would likely get worse before it got better.”</ORIGINAL_TEXT>
        <TOKEN id="token-113-0" pos="word" morph="none" start_char="6577" end_char="6588">relationship</TOKEN>
        <TOKEN id="token-113-1" pos="word" morph="none" start_char="6590" end_char="6593">with</TOKEN>
        <TOKEN id="token-113-2" pos="word" morph="none" start_char="6595" end_char="6600">Moscow</TOKEN>
        <TOKEN id="token-113-3" pos="word" morph="none" start_char="6602" end_char="6606">would</TOKEN>
        <TOKEN id="token-113-4" pos="word" morph="none" start_char="6608" end_char="6613">likely</TOKEN>
        <TOKEN id="token-113-5" pos="word" morph="none" start_char="6615" end_char="6617">get</TOKEN>
        <TOKEN id="token-113-6" pos="word" morph="none" start_char="6619" end_char="6623">worse</TOKEN>
        <TOKEN id="token-113-7" pos="word" morph="none" start_char="6625" end_char="6630">before</TOKEN>
        <TOKEN id="token-113-8" pos="word" morph="none" start_char="6632" end_char="6633">it</TOKEN>
        <TOKEN id="token-113-9" pos="word" morph="none" start_char="6635" end_char="6637">got</TOKEN>
        <TOKEN id="token-113-10" pos="word" morph="none" start_char="6639" end_char="6644">better</TOKEN>
        <TOKEN id="token-113-11" pos="punct" morph="none" start_char="6645" end_char="6646">.”</TOKEN>
      </SEG>
      <SEG id="segment-114" start_char="6648" end_char="6725">
        <ORIGINAL_TEXT>Still, even this more realistic version of events is unsatisfying, for Clinton</ORIGINAL_TEXT>
        <TOKEN id="token-114-0" pos="word" morph="none" start_char="6648" end_char="6652">Still</TOKEN>
        <TOKEN id="token-114-1" pos="punct" morph="none" start_char="6653" end_char="6653">,</TOKEN>
        <TOKEN id="token-114-2" pos="word" morph="none" start_char="6655" end_char="6658">even</TOKEN>
        <TOKEN id="token-114-3" pos="word" morph="none" start_char="6660" end_char="6663">this</TOKEN>
        <TOKEN id="token-114-4" pos="word" morph="none" start_char="6665" end_char="6668">more</TOKEN>
        <TOKEN id="token-114-5" pos="word" morph="none" start_char="6670" end_char="6678">realistic</TOKEN>
        <TOKEN id="token-114-6" pos="word" morph="none" start_char="6680" end_char="6686">version</TOKEN>
        <TOKEN id="token-114-7" pos="word" morph="none" start_char="6688" end_char="6689">of</TOKEN>
        <TOKEN id="token-114-8" pos="word" morph="none" start_char="6691" end_char="6696">events</TOKEN>
        <TOKEN id="token-114-9" pos="word" morph="none" start_char="6698" end_char="6699">is</TOKEN>
        <TOKEN id="token-114-10" pos="word" morph="none" start_char="6701" end_char="6712">unsatisfying</TOKEN>
        <TOKEN id="token-114-11" pos="punct" morph="none" start_char="6713" end_char="6713">,</TOKEN>
        <TOKEN id="token-114-12" pos="word" morph="none" start_char="6715" end_char="6717">for</TOKEN>
        <TOKEN id="token-114-13" pos="word" morph="none" start_char="6719" end_char="6725">Clinton</TOKEN>
      </SEG>
      <SEG id="segment-115" start_char="6727" end_char="6797">
        <ORIGINAL_TEXT>never digs very deeply. She offers no real analysis of Vladimir Putin’s</ORIGINAL_TEXT>
        <TOKEN id="token-115-0" pos="word" morph="none" start_char="6727" end_char="6731">never</TOKEN>
        <TOKEN id="token-115-1" pos="word" morph="none" start_char="6733" end_char="6736">digs</TOKEN>
        <TOKEN id="token-115-2" pos="word" morph="none" start_char="6738" end_char="6741">very</TOKEN>
        <TOKEN id="token-115-3" pos="word" morph="none" start_char="6743" end_char="6748">deeply</TOKEN>
        <TOKEN id="token-115-4" pos="punct" morph="none" start_char="6749" end_char="6749">.</TOKEN>
        <TOKEN id="token-115-5" pos="word" morph="none" start_char="6751" end_char="6753">She</TOKEN>
        <TOKEN id="token-115-6" pos="word" morph="none" start_char="6755" end_char="6760">offers</TOKEN>
        <TOKEN id="token-115-7" pos="word" morph="none" start_char="6762" end_char="6763">no</TOKEN>
        <TOKEN id="token-115-8" pos="word" morph="none" start_char="6765" end_char="6768">real</TOKEN>
        <TOKEN id="token-115-9" pos="word" morph="none" start_char="6770" end_char="6777">analysis</TOKEN>
        <TOKEN id="token-115-10" pos="word" morph="none" start_char="6779" end_char="6780">of</TOKEN>
        <TOKEN id="token-115-11" pos="word" morph="none" start_char="6782" end_char="6789">Vladimir</TOKEN>
        <TOKEN id="token-115-12" pos="word" morph="none" start_char="6791" end_char="6795">Putin</TOKEN>
        <TOKEN id="token-115-13" pos="punct" morph="none" start_char="6796" end_char="6796">’</TOKEN>
        <TOKEN id="token-115-14" pos="word" morph="none" start_char="6797" end_char="6797">s</TOKEN>
      </SEG>
      <SEG id="segment-116" start_char="6799" end_char="6870">
        <ORIGINAL_TEXT>motives, and never goes into the complex history of the Russian-American</ORIGINAL_TEXT>
        <TOKEN id="token-116-0" pos="word" morph="none" start_char="6799" end_char="6805">motives</TOKEN>
        <TOKEN id="token-116-1" pos="punct" morph="none" start_char="6806" end_char="6806">,</TOKEN>
        <TOKEN id="token-116-2" pos="word" morph="none" start_char="6808" end_char="6810">and</TOKEN>
        <TOKEN id="token-116-3" pos="word" morph="none" start_char="6812" end_char="6816">never</TOKEN>
        <TOKEN id="token-116-4" pos="word" morph="none" start_char="6818" end_char="6821">goes</TOKEN>
        <TOKEN id="token-116-5" pos="word" morph="none" start_char="6823" end_char="6826">into</TOKEN>
        <TOKEN id="token-116-6" pos="word" morph="none" start_char="6828" end_char="6830">the</TOKEN>
        <TOKEN id="token-116-7" pos="word" morph="none" start_char="6832" end_char="6838">complex</TOKEN>
        <TOKEN id="token-116-8" pos="word" morph="none" start_char="6840" end_char="6846">history</TOKEN>
        <TOKEN id="token-116-9" pos="word" morph="none" start_char="6848" end_char="6849">of</TOKEN>
        <TOKEN id="token-116-10" pos="word" morph="none" start_char="6851" end_char="6853">the</TOKEN>
        <TOKEN id="token-116-11" pos="word" morph="none" start_char="6855" end_char="6861">Russian</TOKEN>
        <TOKEN id="token-116-12" pos="punct" morph="none" start_char="6862" end_char="6862">-</TOKEN>
        <TOKEN id="token-116-13" pos="word" morph="none" start_char="6863" end_char="6870">American</TOKEN>
      </SEG>
      <SEG id="segment-117" start_char="6872" end_char="6943">
        <ORIGINAL_TEXT>relationship. She acknowledges that Russia does present a very difficult</ORIGINAL_TEXT>
        <TOKEN id="token-117-0" pos="word" morph="none" start_char="6872" end_char="6883">relationship</TOKEN>
        <TOKEN id="token-117-1" pos="punct" morph="none" start_char="6884" end_char="6884">.</TOKEN>
        <TOKEN id="token-117-2" pos="word" morph="none" start_char="6886" end_char="6888">She</TOKEN>
        <TOKEN id="token-117-3" pos="word" morph="none" start_char="6890" end_char="6901">acknowledges</TOKEN>
        <TOKEN id="token-117-4" pos="word" morph="none" start_char="6903" end_char="6906">that</TOKEN>
        <TOKEN id="token-117-5" pos="word" morph="none" start_char="6908" end_char="6913">Russia</TOKEN>
        <TOKEN id="token-117-6" pos="word" morph="none" start_char="6915" end_char="6918">does</TOKEN>
        <TOKEN id="token-117-7" pos="word" morph="none" start_char="6920" end_char="6926">present</TOKEN>
        <TOKEN id="token-117-8" pos="word" morph="none" start_char="6928" end_char="6928">a</TOKEN>
        <TOKEN id="token-117-9" pos="word" morph="none" start_char="6930" end_char="6933">very</TOKEN>
        <TOKEN id="token-117-10" pos="word" morph="none" start_char="6935" end_char="6943">difficult</TOKEN>
      </SEG>
      <SEG id="segment-118" start_char="6945" end_char="7017">
        <ORIGINAL_TEXT>problem: “Hard men present hard choices—none more so than Vladimir Putin,</ORIGINAL_TEXT>
        <TOKEN id="token-118-0" pos="word" morph="none" start_char="6945" end_char="6951">problem</TOKEN>
        <TOKEN id="token-118-1" pos="punct" morph="none" start_char="6952" end_char="6952">:</TOKEN>
        <TOKEN id="token-118-2" pos="punct" morph="none" start_char="6954" end_char="6954">“</TOKEN>
        <TOKEN id="token-118-3" pos="word" morph="none" start_char="6955" end_char="6958">Hard</TOKEN>
        <TOKEN id="token-118-4" pos="word" morph="none" start_char="6960" end_char="6962">men</TOKEN>
        <TOKEN id="token-118-5" pos="word" morph="none" start_char="6964" end_char="6970">present</TOKEN>
        <TOKEN id="token-118-6" pos="word" morph="none" start_char="6972" end_char="6975">hard</TOKEN>
        <TOKEN id="token-118-7" pos="word" morph="none" start_char="6977" end_char="6983">choices</TOKEN>
        <TOKEN id="token-118-8" pos="punct" morph="none" start_char="6984" end_char="6984">—</TOKEN>
        <TOKEN id="token-118-9" pos="word" morph="none" start_char="6985" end_char="6988">none</TOKEN>
        <TOKEN id="token-118-10" pos="word" morph="none" start_char="6990" end_char="6993">more</TOKEN>
        <TOKEN id="token-118-11" pos="word" morph="none" start_char="6995" end_char="6996">so</TOKEN>
        <TOKEN id="token-118-12" pos="word" morph="none" start_char="6998" end_char="7001">than</TOKEN>
        <TOKEN id="token-118-13" pos="word" morph="none" start_char="7003" end_char="7010">Vladimir</TOKEN>
        <TOKEN id="token-118-14" pos="word" morph="none" start_char="7012" end_char="7016">Putin</TOKEN>
        <TOKEN id="token-118-15" pos="punct" morph="none" start_char="7017" end_char="7017">,</TOKEN>
      </SEG>
      <SEG id="segment-119" start_char="7019" end_char="7088">
        <ORIGINAL_TEXT>the President of Russia.” But she doesn’t tell us on what basis she or</ORIGINAL_TEXT>
        <TOKEN id="token-119-0" pos="word" morph="none" start_char="7019" end_char="7021">the</TOKEN>
        <TOKEN id="token-119-1" pos="word" morph="none" start_char="7023" end_char="7031">President</TOKEN>
        <TOKEN id="token-119-2" pos="word" morph="none" start_char="7033" end_char="7034">of</TOKEN>
        <TOKEN id="token-119-3" pos="word" morph="none" start_char="7036" end_char="7041">Russia</TOKEN>
        <TOKEN id="token-119-4" pos="punct" morph="none" start_char="7042" end_char="7043">.”</TOKEN>
        <TOKEN id="token-119-5" pos="word" morph="none" start_char="7045" end_char="7047">But</TOKEN>
        <TOKEN id="token-119-6" pos="word" morph="none" start_char="7049" end_char="7051">she</TOKEN>
        <TOKEN id="token-119-7" pos="word" morph="none" start_char="7053" end_char="7057">doesn</TOKEN>
        <TOKEN id="token-119-8" pos="punct" morph="none" start_char="7058" end_char="7058">’</TOKEN>
        <TOKEN id="token-119-9" pos="word" morph="none" start_char="7059" end_char="7059">t</TOKEN>
        <TOKEN id="token-119-10" pos="word" morph="none" start_char="7061" end_char="7064">tell</TOKEN>
        <TOKEN id="token-119-11" pos="word" morph="none" start_char="7066" end_char="7067">us</TOKEN>
        <TOKEN id="token-119-12" pos="word" morph="none" start_char="7069" end_char="7070">on</TOKEN>
        <TOKEN id="token-119-13" pos="word" morph="none" start_char="7072" end_char="7075">what</TOKEN>
        <TOKEN id="token-119-14" pos="word" morph="none" start_char="7077" end_char="7081">basis</TOKEN>
        <TOKEN id="token-119-15" pos="word" morph="none" start_char="7083" end_char="7085">she</TOKEN>
        <TOKEN id="token-119-16" pos="word" morph="none" start_char="7087" end_char="7088">or</TOKEN>
      </SEG>
      <SEG id="segment-120" start_char="7090" end_char="7115">
        <ORIGINAL_TEXT>anyone else will solve it.</ORIGINAL_TEXT>
        <TOKEN id="token-120-0" pos="word" morph="none" start_char="7090" end_char="7095">anyone</TOKEN>
        <TOKEN id="token-120-1" pos="word" morph="none" start_char="7097" end_char="7100">else</TOKEN>
        <TOKEN id="token-120-2" pos="word" morph="none" start_char="7102" end_char="7105">will</TOKEN>
        <TOKEN id="token-120-3" pos="word" morph="none" start_char="7107" end_char="7111">solve</TOKEN>
        <TOKEN id="token-120-4" pos="word" morph="none" start_char="7113" end_char="7114">it</TOKEN>
        <TOKEN id="token-120-5" pos="punct" morph="none" start_char="7115" end_char="7115">.</TOKEN>
      </SEG>
      <SEG id="segment-121" start_char="7117" end_char="7120">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-121-0" pos="unknown" morph="none" start_char="7117" end_char="7120">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-122" start_char="7122" end_char="7124">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-122-0" pos="unknown" morph="none" start_char="7122" end_char="7124">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-123" start_char="7126" end_char="7200">
        <ORIGINAL_TEXT>For similar reasons, Hard Choices also cannot be called a work of political</ORIGINAL_TEXT>
        <TOKEN id="token-123-0" pos="word" morph="none" start_char="7126" end_char="7128">For</TOKEN>
        <TOKEN id="token-123-1" pos="word" morph="none" start_char="7130" end_char="7136">similar</TOKEN>
        <TOKEN id="token-123-2" pos="word" morph="none" start_char="7138" end_char="7144">reasons</TOKEN>
        <TOKEN id="token-123-3" pos="punct" morph="none" start_char="7145" end_char="7145">,</TOKEN>
        <TOKEN id="token-123-4" pos="word" morph="none" start_char="7147" end_char="7150">Hard</TOKEN>
        <TOKEN id="token-123-5" pos="word" morph="none" start_char="7152" end_char="7158">Choices</TOKEN>
        <TOKEN id="token-123-6" pos="word" morph="none" start_char="7160" end_char="7163">also</TOKEN>
        <TOKEN id="token-123-7" pos="word" morph="none" start_char="7165" end_char="7170">cannot</TOKEN>
        <TOKEN id="token-123-8" pos="word" morph="none" start_char="7172" end_char="7173">be</TOKEN>
        <TOKEN id="token-123-9" pos="word" morph="none" start_char="7175" end_char="7180">called</TOKEN>
        <TOKEN id="token-123-10" pos="word" morph="none" start_char="7182" end_char="7182">a</TOKEN>
        <TOKEN id="token-123-11" pos="word" morph="none" start_char="7184" end_char="7187">work</TOKEN>
        <TOKEN id="token-123-12" pos="word" morph="none" start_char="7189" end_char="7190">of</TOKEN>
        <TOKEN id="token-123-13" pos="word" morph="none" start_char="7192" end_char="7200">political</TOKEN>
      </SEG>
      <SEG id="segment-124" start_char="7202" end_char="7278">
        <ORIGINAL_TEXT>philosophy or political science. There is no overall argument in the book, no</ORIGINAL_TEXT>
        <TOKEN id="token-124-0" pos="word" morph="none" start_char="7202" end_char="7211">philosophy</TOKEN>
        <TOKEN id="token-124-1" pos="word" morph="none" start_char="7213" end_char="7214">or</TOKEN>
        <TOKEN id="token-124-2" pos="word" morph="none" start_char="7216" end_char="7224">political</TOKEN>
        <TOKEN id="token-124-3" pos="word" morph="none" start_char="7226" end_char="7232">science</TOKEN>
        <TOKEN id="token-124-4" pos="punct" morph="none" start_char="7233" end_char="7233">.</TOKEN>
        <TOKEN id="token-124-5" pos="word" morph="none" start_char="7235" end_char="7239">There</TOKEN>
        <TOKEN id="token-124-6" pos="word" morph="none" start_char="7241" end_char="7242">is</TOKEN>
        <TOKEN id="token-124-7" pos="word" morph="none" start_char="7244" end_char="7245">no</TOKEN>
        <TOKEN id="token-124-8" pos="word" morph="none" start_char="7247" end_char="7253">overall</TOKEN>
        <TOKEN id="token-124-9" pos="word" morph="none" start_char="7255" end_char="7262">argument</TOKEN>
        <TOKEN id="token-124-10" pos="word" morph="none" start_char="7264" end_char="7265">in</TOKEN>
        <TOKEN id="token-124-11" pos="word" morph="none" start_char="7267" end_char="7269">the</TOKEN>
        <TOKEN id="token-124-12" pos="word" morph="none" start_char="7271" end_char="7274">book</TOKEN>
        <TOKEN id="token-124-13" pos="punct" morph="none" start_char="7275" end_char="7275">,</TOKEN>
        <TOKEN id="token-124-14" pos="word" morph="none" start_char="7277" end_char="7278">no</TOKEN>
      </SEG>
      <SEG id="segment-125" start_char="7280" end_char="7347">
        <ORIGINAL_TEXT>marshaling of evidence to make a particular case or to set forward a</ORIGINAL_TEXT>
        <TOKEN id="token-125-0" pos="word" morph="none" start_char="7280" end_char="7289">marshaling</TOKEN>
        <TOKEN id="token-125-1" pos="word" morph="none" start_char="7291" end_char="7292">of</TOKEN>
        <TOKEN id="token-125-2" pos="word" morph="none" start_char="7294" end_char="7301">evidence</TOKEN>
        <TOKEN id="token-125-3" pos="word" morph="none" start_char="7303" end_char="7304">to</TOKEN>
        <TOKEN id="token-125-4" pos="word" morph="none" start_char="7306" end_char="7309">make</TOKEN>
        <TOKEN id="token-125-5" pos="word" morph="none" start_char="7311" end_char="7311">a</TOKEN>
        <TOKEN id="token-125-6" pos="word" morph="none" start_char="7313" end_char="7322">particular</TOKEN>
        <TOKEN id="token-125-7" pos="word" morph="none" start_char="7324" end_char="7327">case</TOKEN>
        <TOKEN id="token-125-8" pos="word" morph="none" start_char="7329" end_char="7330">or</TOKEN>
        <TOKEN id="token-125-9" pos="word" morph="none" start_char="7332" end_char="7333">to</TOKEN>
        <TOKEN id="token-125-10" pos="word" morph="none" start_char="7335" end_char="7337">set</TOKEN>
        <TOKEN id="token-125-11" pos="word" morph="none" start_char="7339" end_char="7345">forward</TOKEN>
        <TOKEN id="token-125-12" pos="word" morph="none" start_char="7347" end_char="7347">a</TOKEN>
      </SEG>
      <SEG id="segment-126" start_char="7349" end_char="7419">
        <ORIGINAL_TEXT>particular strategy or thesis. This is not an argument for “realism” or</ORIGINAL_TEXT>
        <TOKEN id="token-126-0" pos="word" morph="none" start_char="7349" end_char="7358">particular</TOKEN>
        <TOKEN id="token-126-1" pos="word" morph="none" start_char="7360" end_char="7367">strategy</TOKEN>
        <TOKEN id="token-126-2" pos="word" morph="none" start_char="7369" end_char="7370">or</TOKEN>
        <TOKEN id="token-126-3" pos="word" morph="none" start_char="7372" end_char="7377">thesis</TOKEN>
        <TOKEN id="token-126-4" pos="punct" morph="none" start_char="7378" end_char="7378">.</TOKEN>
        <TOKEN id="token-126-5" pos="word" morph="none" start_char="7380" end_char="7383">This</TOKEN>
        <TOKEN id="token-126-6" pos="word" morph="none" start_char="7385" end_char="7386">is</TOKEN>
        <TOKEN id="token-126-7" pos="word" morph="none" start_char="7388" end_char="7390">not</TOKEN>
        <TOKEN id="token-126-8" pos="word" morph="none" start_char="7392" end_char="7393">an</TOKEN>
        <TOKEN id="token-126-9" pos="word" morph="none" start_char="7395" end_char="7402">argument</TOKEN>
        <TOKEN id="token-126-10" pos="word" morph="none" start_char="7404" end_char="7406">for</TOKEN>
        <TOKEN id="token-126-11" pos="punct" morph="none" start_char="7408" end_char="7408">“</TOKEN>
        <TOKEN id="token-126-12" pos="word" morph="none" start_char="7409" end_char="7415">realism</TOKEN>
        <TOKEN id="token-126-13" pos="punct" morph="none" start_char="7416" end_char="7416">”</TOKEN>
        <TOKEN id="token-126-14" pos="word" morph="none" start_char="7418" end_char="7419">or</TOKEN>
      </SEG>
      <SEG id="segment-127" start_char="7421" end_char="7488">
        <ORIGINAL_TEXT>“idealism.” It is not an analysis of America’s priorities. There are</ORIGINAL_TEXT>
        <TOKEN id="token-127-0" pos="punct" morph="none" start_char="7421" end_char="7421">“</TOKEN>
        <TOKEN id="token-127-1" pos="word" morph="none" start_char="7422" end_char="7429">idealism</TOKEN>
        <TOKEN id="token-127-2" pos="punct" morph="none" start_char="7430" end_char="7431">.”</TOKEN>
        <TOKEN id="token-127-3" pos="word" morph="none" start_char="7433" end_char="7434">It</TOKEN>
        <TOKEN id="token-127-4" pos="word" morph="none" start_char="7436" end_char="7437">is</TOKEN>
        <TOKEN id="token-127-5" pos="word" morph="none" start_char="7439" end_char="7441">not</TOKEN>
        <TOKEN id="token-127-6" pos="word" morph="none" start_char="7443" end_char="7444">an</TOKEN>
        <TOKEN id="token-127-7" pos="word" morph="none" start_char="7446" end_char="7453">analysis</TOKEN>
        <TOKEN id="token-127-8" pos="word" morph="none" start_char="7455" end_char="7456">of</TOKEN>
        <TOKEN id="token-127-9" pos="word" morph="none" start_char="7458" end_char="7464">America</TOKEN>
        <TOKEN id="token-127-10" pos="punct" morph="none" start_char="7465" end_char="7465">’</TOKEN>
        <TOKEN id="token-127-11" pos="word" morph="none" start_char="7466" end_char="7466">s</TOKEN>
        <TOKEN id="token-127-12" pos="word" morph="none" start_char="7468" end_char="7477">priorities</TOKEN>
        <TOKEN id="token-127-13" pos="punct" morph="none" start_char="7478" end_char="7478">.</TOKEN>
        <TOKEN id="token-127-14" pos="word" morph="none" start_char="7480" end_char="7484">There</TOKEN>
        <TOKEN id="token-127-15" pos="word" morph="none" start_char="7486" end_char="7488">are</TOKEN>
      </SEG>
      <SEG id="segment-128" start_char="7490" end_char="7561">
        <ORIGINAL_TEXT>admirable nods to human rights, a discussion of climate change, and some</ORIGINAL_TEXT>
        <TOKEN id="token-128-0" pos="word" morph="none" start_char="7490" end_char="7498">admirable</TOKEN>
        <TOKEN id="token-128-1" pos="word" morph="none" start_char="7500" end_char="7503">nods</TOKEN>
        <TOKEN id="token-128-2" pos="word" morph="none" start_char="7505" end_char="7506">to</TOKEN>
        <TOKEN id="token-128-3" pos="word" morph="none" start_char="7508" end_char="7512">human</TOKEN>
        <TOKEN id="token-128-4" pos="word" morph="none" start_char="7514" end_char="7519">rights</TOKEN>
        <TOKEN id="token-128-5" pos="punct" morph="none" start_char="7520" end_char="7520">,</TOKEN>
        <TOKEN id="token-128-6" pos="word" morph="none" start_char="7522" end_char="7522">a</TOKEN>
        <TOKEN id="token-128-7" pos="word" morph="none" start_char="7524" end_char="7533">discussion</TOKEN>
        <TOKEN id="token-128-8" pos="word" morph="none" start_char="7535" end_char="7536">of</TOKEN>
        <TOKEN id="token-128-9" pos="word" morph="none" start_char="7538" end_char="7544">climate</TOKEN>
        <TOKEN id="token-128-10" pos="word" morph="none" start_char="7546" end_char="7551">change</TOKEN>
        <TOKEN id="token-128-11" pos="punct" morph="none" start_char="7552" end_char="7552">,</TOKEN>
        <TOKEN id="token-128-12" pos="word" morph="none" start_char="7554" end_char="7556">and</TOKEN>
        <TOKEN id="token-128-13" pos="word" morph="none" start_char="7558" end_char="7561">some</TOKEN>
      </SEG>
      <SEG id="segment-129" start_char="7563" end_char="7640">
        <ORIGINAL_TEXT>intelligent observations about diplomacy in the Internet age. But Clinton does</ORIGINAL_TEXT>
        <TOKEN id="token-129-0" pos="word" morph="none" start_char="7563" end_char="7573">intelligent</TOKEN>
        <TOKEN id="token-129-1" pos="word" morph="none" start_char="7575" end_char="7586">observations</TOKEN>
        <TOKEN id="token-129-2" pos="word" morph="none" start_char="7588" end_char="7592">about</TOKEN>
        <TOKEN id="token-129-3" pos="word" morph="none" start_char="7594" end_char="7602">diplomacy</TOKEN>
        <TOKEN id="token-129-4" pos="word" morph="none" start_char="7604" end_char="7605">in</TOKEN>
        <TOKEN id="token-129-5" pos="word" morph="none" start_char="7607" end_char="7609">the</TOKEN>
        <TOKEN id="token-129-6" pos="word" morph="none" start_char="7611" end_char="7618">Internet</TOKEN>
        <TOKEN id="token-129-7" pos="word" morph="none" start_char="7620" end_char="7622">age</TOKEN>
        <TOKEN id="token-129-8" pos="punct" morph="none" start_char="7623" end_char="7623">.</TOKEN>
        <TOKEN id="token-129-9" pos="word" morph="none" start_char="7625" end_char="7627">But</TOKEN>
        <TOKEN id="token-129-10" pos="word" morph="none" start_char="7629" end_char="7635">Clinton</TOKEN>
        <TOKEN id="token-129-11" pos="word" morph="none" start_char="7637" end_char="7640">does</TOKEN>
      </SEG>
      <SEG id="segment-130" start_char="7642" end_char="7719">
        <ORIGINAL_TEXT>not connect the dots into a larger view, clearly because does not see the need</ORIGINAL_TEXT>
        <TOKEN id="token-130-0" pos="word" morph="none" start_char="7642" end_char="7644">not</TOKEN>
        <TOKEN id="token-130-1" pos="word" morph="none" start_char="7646" end_char="7652">connect</TOKEN>
        <TOKEN id="token-130-2" pos="word" morph="none" start_char="7654" end_char="7656">the</TOKEN>
        <TOKEN id="token-130-3" pos="word" morph="none" start_char="7658" end_char="7661">dots</TOKEN>
        <TOKEN id="token-130-4" pos="word" morph="none" start_char="7663" end_char="7666">into</TOKEN>
        <TOKEN id="token-130-5" pos="word" morph="none" start_char="7668" end_char="7668">a</TOKEN>
        <TOKEN id="token-130-6" pos="word" morph="none" start_char="7670" end_char="7675">larger</TOKEN>
        <TOKEN id="token-130-7" pos="word" morph="none" start_char="7677" end_char="7680">view</TOKEN>
        <TOKEN id="token-130-8" pos="punct" morph="none" start_char="7681" end_char="7681">,</TOKEN>
        <TOKEN id="token-130-9" pos="word" morph="none" start_char="7683" end_char="7689">clearly</TOKEN>
        <TOKEN id="token-130-10" pos="word" morph="none" start_char="7691" end_char="7697">because</TOKEN>
        <TOKEN id="token-130-11" pos="word" morph="none" start_char="7699" end_char="7702">does</TOKEN>
        <TOKEN id="token-130-12" pos="word" morph="none" start_char="7704" end_char="7706">not</TOKEN>
        <TOKEN id="token-130-13" pos="word" morph="none" start_char="7708" end_char="7710">see</TOKEN>
        <TOKEN id="token-130-14" pos="word" morph="none" start_char="7712" end_char="7714">the</TOKEN>
        <TOKEN id="token-130-15" pos="word" morph="none" start_char="7716" end_char="7719">need</TOKEN>
      </SEG>
      <SEG id="segment-131" start_char="7721" end_char="7786">
        <ORIGINAL_TEXT>to. Early on, she does dismiss the “outdated” debate between “hard</ORIGINAL_TEXT>
        <TOKEN id="token-131-0" pos="word" morph="none" start_char="7721" end_char="7722">to</TOKEN>
        <TOKEN id="token-131-1" pos="punct" morph="none" start_char="7723" end_char="7723">.</TOKEN>
        <TOKEN id="token-131-2" pos="word" morph="none" start_char="7725" end_char="7729">Early</TOKEN>
        <TOKEN id="token-131-3" pos="word" morph="none" start_char="7731" end_char="7732">on</TOKEN>
        <TOKEN id="token-131-4" pos="punct" morph="none" start_char="7733" end_char="7733">,</TOKEN>
        <TOKEN id="token-131-5" pos="word" morph="none" start_char="7735" end_char="7737">she</TOKEN>
        <TOKEN id="token-131-6" pos="word" morph="none" start_char="7739" end_char="7742">does</TOKEN>
        <TOKEN id="token-131-7" pos="word" morph="none" start_char="7744" end_char="7750">dismiss</TOKEN>
        <TOKEN id="token-131-8" pos="word" morph="none" start_char="7752" end_char="7754">the</TOKEN>
        <TOKEN id="token-131-9" pos="punct" morph="none" start_char="7756" end_char="7756">“</TOKEN>
        <TOKEN id="token-131-10" pos="word" morph="none" start_char="7757" end_char="7764">outdated</TOKEN>
        <TOKEN id="token-131-11" pos="punct" morph="none" start_char="7765" end_char="7765">”</TOKEN>
        <TOKEN id="token-131-12" pos="word" morph="none" start_char="7767" end_char="7772">debate</TOKEN>
        <TOKEN id="token-131-13" pos="word" morph="none" start_char="7774" end_char="7780">between</TOKEN>
        <TOKEN id="token-131-14" pos="punct" morph="none" start_char="7782" end_char="7782">“</TOKEN>
        <TOKEN id="token-131-15" pos="word" morph="none" start_char="7783" end_char="7786">hard</TOKEN>
      </SEG>
      <SEG id="segment-132" start_char="7788" end_char="7847">
        <ORIGINAL_TEXT>power”—military force—and the “soft power” of other kinds of</ORIGINAL_TEXT>
        <TOKEN id="token-132-0" pos="word" morph="none" start_char="7788" end_char="7792">power</TOKEN>
        <TOKEN id="token-132-1" pos="punct" morph="none" start_char="7793" end_char="7794">”—</TOKEN>
        <TOKEN id="token-132-2" pos="word" morph="none" start_char="7795" end_char="7802">military</TOKEN>
        <TOKEN id="token-132-3" pos="word" morph="none" start_char="7804" end_char="7808">force</TOKEN>
        <TOKEN id="token-132-4" pos="punct" morph="none" start_char="7809" end_char="7809">—</TOKEN>
        <TOKEN id="token-132-5" pos="word" morph="none" start_char="7810" end_char="7812">and</TOKEN>
        <TOKEN id="token-132-6" pos="word" morph="none" start_char="7814" end_char="7816">the</TOKEN>
        <TOKEN id="token-132-7" pos="punct" morph="none" start_char="7818" end_char="7818">“</TOKEN>
        <TOKEN id="token-132-8" pos="word" morph="none" start_char="7819" end_char="7822">soft</TOKEN>
        <TOKEN id="token-132-9" pos="word" morph="none" start_char="7824" end_char="7828">power</TOKEN>
        <TOKEN id="token-132-10" pos="punct" morph="none" start_char="7829" end_char="7829">”</TOKEN>
        <TOKEN id="token-132-11" pos="word" morph="none" start_char="7831" end_char="7832">of</TOKEN>
        <TOKEN id="token-132-12" pos="word" morph="none" start_char="7834" end_char="7838">other</TOKEN>
        <TOKEN id="token-132-13" pos="word" morph="none" start_char="7840" end_char="7844">kinds</TOKEN>
        <TOKEN id="token-132-14" pos="word" morph="none" start_char="7846" end_char="7847">of</TOKEN>
      </SEG>
      <SEG id="segment-133" start_char="7849" end_char="7920">
        <ORIGINAL_TEXT>influence. She prefers “smart power,” which she defines as “choosing the</ORIGINAL_TEXT>
        <TOKEN id="token-133-0" pos="word" morph="none" start_char="7849" end_char="7857">influence</TOKEN>
        <TOKEN id="token-133-1" pos="punct" morph="none" start_char="7858" end_char="7858">.</TOKEN>
        <TOKEN id="token-133-2" pos="word" morph="none" start_char="7860" end_char="7862">She</TOKEN>
        <TOKEN id="token-133-3" pos="word" morph="none" start_char="7864" end_char="7870">prefers</TOKEN>
        <TOKEN id="token-133-4" pos="punct" morph="none" start_char="7872" end_char="7872">“</TOKEN>
        <TOKEN id="token-133-5" pos="word" morph="none" start_char="7873" end_char="7877">smart</TOKEN>
        <TOKEN id="token-133-6" pos="word" morph="none" start_char="7879" end_char="7883">power</TOKEN>
        <TOKEN id="token-133-7" pos="punct" morph="none" start_char="7884" end_char="7885">,”</TOKEN>
        <TOKEN id="token-133-8" pos="word" morph="none" start_char="7887" end_char="7891">which</TOKEN>
        <TOKEN id="token-133-9" pos="word" morph="none" start_char="7893" end_char="7895">she</TOKEN>
        <TOKEN id="token-133-10" pos="word" morph="none" start_char="7897" end_char="7903">defines</TOKEN>
        <TOKEN id="token-133-11" pos="word" morph="none" start_char="7905" end_char="7906">as</TOKEN>
        <TOKEN id="token-133-12" pos="punct" morph="none" start_char="7908" end_char="7908">“</TOKEN>
        <TOKEN id="token-133-13" pos="word" morph="none" start_char="7909" end_char="7916">choosing</TOKEN>
        <TOKEN id="token-133-14" pos="word" morph="none" start_char="7918" end_char="7920">the</TOKEN>
      </SEG>
      <SEG id="segment-134" start_char="7922" end_char="7997">
        <ORIGINAL_TEXT>right combination of tools—diplomatic, economic, military, political, legal,</ORIGINAL_TEXT>
        <TOKEN id="token-134-0" pos="word" morph="none" start_char="7922" end_char="7926">right</TOKEN>
        <TOKEN id="token-134-1" pos="word" morph="none" start_char="7928" end_char="7938">combination</TOKEN>
        <TOKEN id="token-134-2" pos="word" morph="none" start_char="7940" end_char="7941">of</TOKEN>
        <TOKEN id="token-134-3" pos="word" morph="none" start_char="7943" end_char="7947">tools</TOKEN>
        <TOKEN id="token-134-4" pos="punct" morph="none" start_char="7948" end_char="7948">—</TOKEN>
        <TOKEN id="token-134-5" pos="word" morph="none" start_char="7949" end_char="7958">diplomatic</TOKEN>
        <TOKEN id="token-134-6" pos="punct" morph="none" start_char="7959" end_char="7959">,</TOKEN>
        <TOKEN id="token-134-7" pos="word" morph="none" start_char="7961" end_char="7968">economic</TOKEN>
        <TOKEN id="token-134-8" pos="punct" morph="none" start_char="7969" end_char="7969">,</TOKEN>
        <TOKEN id="token-134-9" pos="word" morph="none" start_char="7971" end_char="7978">military</TOKEN>
        <TOKEN id="token-134-10" pos="punct" morph="none" start_char="7979" end_char="7979">,</TOKEN>
        <TOKEN id="token-134-11" pos="word" morph="none" start_char="7981" end_char="7989">political</TOKEN>
        <TOKEN id="token-134-12" pos="punct" morph="none" start_char="7990" end_char="7990">,</TOKEN>
        <TOKEN id="token-134-13" pos="word" morph="none" start_char="7992" end_char="7996">legal</TOKEN>
        <TOKEN id="token-134-14" pos="punct" morph="none" start_char="7997" end_char="7997">,</TOKEN>
      </SEG>
      <SEG id="segment-135" start_char="7999" end_char="8059">
        <ORIGINAL_TEXT>and cultural” in order to advance “our core national security</ORIGINAL_TEXT>
        <TOKEN id="token-135-0" pos="word" morph="none" start_char="7999" end_char="8001">and</TOKEN>
        <TOKEN id="token-135-1" pos="word" morph="none" start_char="8003" end_char="8010">cultural</TOKEN>
        <TOKEN id="token-135-2" pos="punct" morph="none" start_char="8011" end_char="8011">”</TOKEN>
        <TOKEN id="token-135-3" pos="word" morph="none" start_char="8013" end_char="8014">in</TOKEN>
        <TOKEN id="token-135-4" pos="word" morph="none" start_char="8016" end_char="8020">order</TOKEN>
        <TOKEN id="token-135-5" pos="word" morph="none" start_char="8022" end_char="8023">to</TOKEN>
        <TOKEN id="token-135-6" pos="word" morph="none" start_char="8025" end_char="8031">advance</TOKEN>
        <TOKEN id="token-135-7" pos="punct" morph="none" start_char="8033" end_char="8033">“</TOKEN>
        <TOKEN id="token-135-8" pos="word" morph="none" start_char="8034" end_char="8036">our</TOKEN>
        <TOKEN id="token-135-9" pos="word" morph="none" start_char="8038" end_char="8041">core</TOKEN>
        <TOKEN id="token-135-10" pos="word" morph="none" start_char="8043" end_char="8050">national</TOKEN>
        <TOKEN id="token-135-11" pos="word" morph="none" start_char="8052" end_char="8059">security</TOKEN>
      </SEG>
      <SEG id="segment-136" start_char="8061" end_char="8135">
        <ORIGINAL_TEXT>objectives.” Yet that is an argument about process, not about policy; about</ORIGINAL_TEXT>
        <TOKEN id="token-136-0" pos="word" morph="none" start_char="8061" end_char="8070">objectives</TOKEN>
        <TOKEN id="token-136-1" pos="punct" morph="none" start_char="8071" end_char="8072">.”</TOKEN>
        <TOKEN id="token-136-2" pos="word" morph="none" start_char="8074" end_char="8076">Yet</TOKEN>
        <TOKEN id="token-136-3" pos="word" morph="none" start_char="8078" end_char="8081">that</TOKEN>
        <TOKEN id="token-136-4" pos="word" morph="none" start_char="8083" end_char="8084">is</TOKEN>
        <TOKEN id="token-136-5" pos="word" morph="none" start_char="8086" end_char="8087">an</TOKEN>
        <TOKEN id="token-136-6" pos="word" morph="none" start_char="8089" end_char="8096">argument</TOKEN>
        <TOKEN id="token-136-7" pos="word" morph="none" start_char="8098" end_char="8102">about</TOKEN>
        <TOKEN id="token-136-8" pos="word" morph="none" start_char="8104" end_char="8110">process</TOKEN>
        <TOKEN id="token-136-9" pos="punct" morph="none" start_char="8111" end_char="8111">,</TOKEN>
        <TOKEN id="token-136-10" pos="word" morph="none" start_char="8113" end_char="8115">not</TOKEN>
        <TOKEN id="token-136-11" pos="word" morph="none" start_char="8117" end_char="8121">about</TOKEN>
        <TOKEN id="token-136-12" pos="word" morph="none" start_char="8123" end_char="8128">policy</TOKEN>
        <TOKEN id="token-136-13" pos="punct" morph="none" start_char="8129" end_char="8129">;</TOKEN>
        <TOKEN id="token-136-14" pos="word" morph="none" start_char="8131" end_char="8135">about</TOKEN>
      </SEG>
      <SEG id="segment-137" start_char="8137" end_char="8211">
        <ORIGINAL_TEXT>the means, not the ends. Most of the time Clinton prudently stays away from</ORIGINAL_TEXT>
        <TOKEN id="token-137-0" pos="word" morph="none" start_char="8137" end_char="8139">the</TOKEN>
        <TOKEN id="token-137-1" pos="word" morph="none" start_char="8141" end_char="8145">means</TOKEN>
        <TOKEN id="token-137-2" pos="punct" morph="none" start_char="8146" end_char="8146">,</TOKEN>
        <TOKEN id="token-137-3" pos="word" morph="none" start_char="8148" end_char="8150">not</TOKEN>
        <TOKEN id="token-137-4" pos="word" morph="none" start_char="8152" end_char="8154">the</TOKEN>
        <TOKEN id="token-137-5" pos="word" morph="none" start_char="8156" end_char="8159">ends</TOKEN>
        <TOKEN id="token-137-6" pos="punct" morph="none" start_char="8160" end_char="8160">.</TOKEN>
        <TOKEN id="token-137-7" pos="word" morph="none" start_char="8162" end_char="8165">Most</TOKEN>
        <TOKEN id="token-137-8" pos="word" morph="none" start_char="8167" end_char="8168">of</TOKEN>
        <TOKEN id="token-137-9" pos="word" morph="none" start_char="8170" end_char="8172">the</TOKEN>
        <TOKEN id="token-137-10" pos="word" morph="none" start_char="8174" end_char="8177">time</TOKEN>
        <TOKEN id="token-137-11" pos="word" morph="none" start_char="8179" end_char="8185">Clinton</TOKEN>
        <TOKEN id="token-137-12" pos="word" morph="none" start_char="8187" end_char="8195">prudently</TOKEN>
        <TOKEN id="token-137-13" pos="word" morph="none" start_char="8197" end_char="8201">stays</TOKEN>
        <TOKEN id="token-137-14" pos="word" morph="none" start_char="8203" end_char="8206">away</TOKEN>
        <TOKEN id="token-137-15" pos="word" morph="none" start_char="8208" end_char="8211">from</TOKEN>
      </SEG>
      <SEG id="segment-138" start_char="8213" end_char="8283">
        <ORIGINAL_TEXT>thorny debates about just what those core national interests should be.</ORIGINAL_TEXT>
        <TOKEN id="token-138-0" pos="word" morph="none" start_char="8213" end_char="8218">thorny</TOKEN>
        <TOKEN id="token-138-1" pos="word" morph="none" start_char="8220" end_char="8226">debates</TOKEN>
        <TOKEN id="token-138-2" pos="word" morph="none" start_char="8228" end_char="8232">about</TOKEN>
        <TOKEN id="token-138-3" pos="word" morph="none" start_char="8234" end_char="8237">just</TOKEN>
        <TOKEN id="token-138-4" pos="word" morph="none" start_char="8239" end_char="8242">what</TOKEN>
        <TOKEN id="token-138-5" pos="word" morph="none" start_char="8244" end_char="8248">those</TOKEN>
        <TOKEN id="token-138-6" pos="word" morph="none" start_char="8250" end_char="8253">core</TOKEN>
        <TOKEN id="token-138-7" pos="word" morph="none" start_char="8255" end_char="8262">national</TOKEN>
        <TOKEN id="token-138-8" pos="word" morph="none" start_char="8264" end_char="8272">interests</TOKEN>
        <TOKEN id="token-138-9" pos="word" morph="none" start_char="8274" end_char="8279">should</TOKEN>
        <TOKEN id="token-138-10" pos="word" morph="none" start_char="8281" end_char="8282">be</TOKEN>
        <TOKEN id="token-138-11" pos="punct" morph="none" start_char="8283" end_char="8283">.</TOKEN>
      </SEG>
      <SEG id="segment-139" start_char="8285" end_char="8288">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-139-0" pos="unknown" morph="none" start_char="8285" end_char="8288">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-140" start_char="8290" end_char="8292">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-140-0" pos="unknown" morph="none" start_char="8290" end_char="8292">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-141" start_char="8294" end_char="8366">
        <ORIGINAL_TEXT>And although the words “a memoir” appear in tiny print on the cover, this</ORIGINAL_TEXT>
        <TOKEN id="token-141-0" pos="word" morph="none" start_char="8294" end_char="8296">And</TOKEN>
        <TOKEN id="token-141-1" pos="word" morph="none" start_char="8298" end_char="8305">although</TOKEN>
        <TOKEN id="token-141-2" pos="word" morph="none" start_char="8307" end_char="8309">the</TOKEN>
        <TOKEN id="token-141-3" pos="word" morph="none" start_char="8311" end_char="8315">words</TOKEN>
        <TOKEN id="token-141-4" pos="punct" morph="none" start_char="8317" end_char="8317">“</TOKEN>
        <TOKEN id="token-141-5" pos="word" morph="none" start_char="8318" end_char="8318">a</TOKEN>
        <TOKEN id="token-141-6" pos="word" morph="none" start_char="8320" end_char="8325">memoir</TOKEN>
        <TOKEN id="token-141-7" pos="punct" morph="none" start_char="8326" end_char="8326">”</TOKEN>
        <TOKEN id="token-141-8" pos="word" morph="none" start_char="8328" end_char="8333">appear</TOKEN>
        <TOKEN id="token-141-9" pos="word" morph="none" start_char="8335" end_char="8336">in</TOKEN>
        <TOKEN id="token-141-10" pos="word" morph="none" start_char="8338" end_char="8341">tiny</TOKEN>
        <TOKEN id="token-141-11" pos="word" morph="none" start_char="8343" end_char="8347">print</TOKEN>
        <TOKEN id="token-141-12" pos="word" morph="none" start_char="8349" end_char="8350">on</TOKEN>
        <TOKEN id="token-141-13" pos="word" morph="none" start_char="8352" end_char="8354">the</TOKEN>
        <TOKEN id="token-141-14" pos="word" morph="none" start_char="8356" end_char="8360">cover</TOKEN>
        <TOKEN id="token-141-15" pos="punct" morph="none" start_char="8361" end_char="8361">,</TOKEN>
        <TOKEN id="token-141-16" pos="word" morph="none" start_char="8363" end_char="8366">this</TOKEN>
      </SEG>
      <SEG id="segment-142" start_char="8368" end_char="8442">
        <ORIGINAL_TEXT>is also not an autobiography, at least in the classic sense of the term. It</ORIGINAL_TEXT>
        <TOKEN id="token-142-0" pos="word" morph="none" start_char="8368" end_char="8369">is</TOKEN>
        <TOKEN id="token-142-1" pos="word" morph="none" start_char="8371" end_char="8374">also</TOKEN>
        <TOKEN id="token-142-2" pos="word" morph="none" start_char="8376" end_char="8378">not</TOKEN>
        <TOKEN id="token-142-3" pos="word" morph="none" start_char="8380" end_char="8381">an</TOKEN>
        <TOKEN id="token-142-4" pos="word" morph="none" start_char="8383" end_char="8395">autobiography</TOKEN>
        <TOKEN id="token-142-5" pos="punct" morph="none" start_char="8396" end_char="8396">,</TOKEN>
        <TOKEN id="token-142-6" pos="word" morph="none" start_char="8398" end_char="8399">at</TOKEN>
        <TOKEN id="token-142-7" pos="word" morph="none" start_char="8401" end_char="8405">least</TOKEN>
        <TOKEN id="token-142-8" pos="word" morph="none" start_char="8407" end_char="8408">in</TOKEN>
        <TOKEN id="token-142-9" pos="word" morph="none" start_char="8410" end_char="8412">the</TOKEN>
        <TOKEN id="token-142-10" pos="word" morph="none" start_char="8414" end_char="8420">classic</TOKEN>
        <TOKEN id="token-142-11" pos="word" morph="none" start_char="8422" end_char="8426">sense</TOKEN>
        <TOKEN id="token-142-12" pos="word" morph="none" start_char="8428" end_char="8429">of</TOKEN>
        <TOKEN id="token-142-13" pos="word" morph="none" start_char="8431" end_char="8433">the</TOKEN>
        <TOKEN id="token-142-14" pos="word" morph="none" start_char="8435" end_char="8438">term</TOKEN>
        <TOKEN id="token-142-15" pos="punct" morph="none" start_char="8439" end_char="8439">.</TOKEN>
        <TOKEN id="token-142-16" pos="word" morph="none" start_char="8441" end_char="8442">It</TOKEN>
      </SEG>
      <SEG id="segment-143" start_char="8444" end_char="8517">
        <ORIGINAL_TEXT>actively avoids any language that might be construed as “literary,” or any</ORIGINAL_TEXT>
        <TOKEN id="token-143-0" pos="word" morph="none" start_char="8444" end_char="8451">actively</TOKEN>
        <TOKEN id="token-143-1" pos="word" morph="none" start_char="8453" end_char="8458">avoids</TOKEN>
        <TOKEN id="token-143-2" pos="word" morph="none" start_char="8460" end_char="8462">any</TOKEN>
        <TOKEN id="token-143-3" pos="word" morph="none" start_char="8464" end_char="8471">language</TOKEN>
        <TOKEN id="token-143-4" pos="word" morph="none" start_char="8473" end_char="8476">that</TOKEN>
        <TOKEN id="token-143-5" pos="word" morph="none" start_char="8478" end_char="8482">might</TOKEN>
        <TOKEN id="token-143-6" pos="word" morph="none" start_char="8484" end_char="8485">be</TOKEN>
        <TOKEN id="token-143-7" pos="word" morph="none" start_char="8487" end_char="8495">construed</TOKEN>
        <TOKEN id="token-143-8" pos="word" morph="none" start_char="8497" end_char="8498">as</TOKEN>
        <TOKEN id="token-143-9" pos="punct" morph="none" start_char="8500" end_char="8500">“</TOKEN>
        <TOKEN id="token-143-10" pos="word" morph="none" start_char="8501" end_char="8508">literary</TOKEN>
        <TOKEN id="token-143-11" pos="punct" morph="none" start_char="8509" end_char="8510">,”</TOKEN>
        <TOKEN id="token-143-12" pos="word" morph="none" start_char="8512" end_char="8513">or</TOKEN>
        <TOKEN id="token-143-13" pos="word" morph="none" start_char="8515" end_char="8517">any</TOKEN>
      </SEG>
      <SEG id="segment-144" start_char="8519" end_char="8591">
        <ORIGINAL_TEXT>psychological insights of any kind. By her own account Clinton never gets</ORIGINAL_TEXT>
        <TOKEN id="token-144-0" pos="word" morph="none" start_char="8519" end_char="8531">psychological</TOKEN>
        <TOKEN id="token-144-1" pos="word" morph="none" start_char="8533" end_char="8540">insights</TOKEN>
        <TOKEN id="token-144-2" pos="word" morph="none" start_char="8542" end_char="8543">of</TOKEN>
        <TOKEN id="token-144-3" pos="word" morph="none" start_char="8545" end_char="8547">any</TOKEN>
        <TOKEN id="token-144-4" pos="word" morph="none" start_char="8549" end_char="8552">kind</TOKEN>
        <TOKEN id="token-144-5" pos="punct" morph="none" start_char="8553" end_char="8553">.</TOKEN>
        <TOKEN id="token-144-6" pos="word" morph="none" start_char="8555" end_char="8556">By</TOKEN>
        <TOKEN id="token-144-7" pos="word" morph="none" start_char="8558" end_char="8560">her</TOKEN>
        <TOKEN id="token-144-8" pos="word" morph="none" start_char="8562" end_char="8564">own</TOKEN>
        <TOKEN id="token-144-9" pos="word" morph="none" start_char="8566" end_char="8572">account</TOKEN>
        <TOKEN id="token-144-10" pos="word" morph="none" start_char="8574" end_char="8580">Clinton</TOKEN>
        <TOKEN id="token-144-11" pos="word" morph="none" start_char="8582" end_char="8586">never</TOKEN>
        <TOKEN id="token-144-12" pos="word" morph="none" start_char="8588" end_char="8591">gets</TOKEN>
      </SEG>
      <SEG id="segment-145" start_char="8593" end_char="8662">
        <ORIGINAL_TEXT>angry, although occasionally she admits that she is “exasperated.” She</ORIGINAL_TEXT>
        <TOKEN id="token-145-0" pos="word" morph="none" start_char="8593" end_char="8597">angry</TOKEN>
        <TOKEN id="token-145-1" pos="punct" morph="none" start_char="8598" end_char="8598">,</TOKEN>
        <TOKEN id="token-145-2" pos="word" morph="none" start_char="8600" end_char="8607">although</TOKEN>
        <TOKEN id="token-145-3" pos="word" morph="none" start_char="8609" end_char="8620">occasionally</TOKEN>
        <TOKEN id="token-145-4" pos="word" morph="none" start_char="8622" end_char="8624">she</TOKEN>
        <TOKEN id="token-145-5" pos="word" morph="none" start_char="8626" end_char="8631">admits</TOKEN>
        <TOKEN id="token-145-6" pos="word" morph="none" start_char="8633" end_char="8636">that</TOKEN>
        <TOKEN id="token-145-7" pos="word" morph="none" start_char="8638" end_char="8640">she</TOKEN>
        <TOKEN id="token-145-8" pos="word" morph="none" start_char="8642" end_char="8643">is</TOKEN>
        <TOKEN id="token-145-9" pos="punct" morph="none" start_char="8645" end_char="8645">“</TOKEN>
        <TOKEN id="token-145-10" pos="word" morph="none" start_char="8646" end_char="8656">exasperated</TOKEN>
        <TOKEN id="token-145-11" pos="punct" morph="none" start_char="8657" end_char="8658">.”</TOKEN>
        <TOKEN id="token-145-12" pos="word" morph="none" start_char="8660" end_char="8662">She</TOKEN>
      </SEG>
      <SEG id="segment-146" start_char="8664" end_char="8726">
        <ORIGINAL_TEXT>doesn’t get tired very often either—or if she does, she doesn’t</ORIGINAL_TEXT>
        <TOKEN id="token-146-0" pos="word" morph="none" start_char="8664" end_char="8668">doesn</TOKEN>
        <TOKEN id="token-146-1" pos="punct" morph="none" start_char="8669" end_char="8669">’</TOKEN>
        <TOKEN id="token-146-2" pos="word" morph="none" start_char="8670" end_char="8670">t</TOKEN>
        <TOKEN id="token-146-3" pos="word" morph="none" start_char="8672" end_char="8674">get</TOKEN>
        <TOKEN id="token-146-4" pos="word" morph="none" start_char="8676" end_char="8680">tired</TOKEN>
        <TOKEN id="token-146-5" pos="word" morph="none" start_char="8682" end_char="8685">very</TOKEN>
        <TOKEN id="token-146-6" pos="word" morph="none" start_char="8687" end_char="8691">often</TOKEN>
        <TOKEN id="token-146-7" pos="word" morph="none" start_char="8693" end_char="8698">either</TOKEN>
        <TOKEN id="token-146-8" pos="punct" morph="none" start_char="8699" end_char="8699">—</TOKEN>
        <TOKEN id="token-146-9" pos="word" morph="none" start_char="8700" end_char="8701">or</TOKEN>
        <TOKEN id="token-146-10" pos="word" morph="none" start_char="8703" end_char="8704">if</TOKEN>
        <TOKEN id="token-146-11" pos="word" morph="none" start_char="8706" end_char="8708">she</TOKEN>
        <TOKEN id="token-146-12" pos="word" morph="none" start_char="8710" end_char="8713">does</TOKEN>
        <TOKEN id="token-146-13" pos="punct" morph="none" start_char="8714" end_char="8714">,</TOKEN>
        <TOKEN id="token-146-14" pos="word" morph="none" start_char="8716" end_char="8718">she</TOKEN>
        <TOKEN id="token-146-15" pos="word" morph="none" start_char="8720" end_char="8724">doesn</TOKEN>
        <TOKEN id="token-146-16" pos="punct" morph="none" start_char="8725" end_char="8725">’</TOKEN>
        <TOKEN id="token-146-17" pos="word" morph="none" start_char="8726" end_char="8726">t</TOKEN>
      </SEG>
      <SEG id="segment-147" start_char="8728" end_char="8799">
        <ORIGINAL_TEXT>complain: “I drank copious cups of coffee and tea, and sometimes dug the</ORIGINAL_TEXT>
        <TOKEN id="token-147-0" pos="word" morph="none" start_char="8728" end_char="8735">complain</TOKEN>
        <TOKEN id="token-147-1" pos="punct" morph="none" start_char="8736" end_char="8736">:</TOKEN>
        <TOKEN id="token-147-2" pos="punct" morph="none" start_char="8738" end_char="8738">“</TOKEN>
        <TOKEN id="token-147-3" pos="word" morph="none" start_char="8739" end_char="8739">I</TOKEN>
        <TOKEN id="token-147-4" pos="word" morph="none" start_char="8741" end_char="8745">drank</TOKEN>
        <TOKEN id="token-147-5" pos="word" morph="none" start_char="8747" end_char="8753">copious</TOKEN>
        <TOKEN id="token-147-6" pos="word" morph="none" start_char="8755" end_char="8758">cups</TOKEN>
        <TOKEN id="token-147-7" pos="word" morph="none" start_char="8760" end_char="8761">of</TOKEN>
        <TOKEN id="token-147-8" pos="word" morph="none" start_char="8763" end_char="8768">coffee</TOKEN>
        <TOKEN id="token-147-9" pos="word" morph="none" start_char="8770" end_char="8772">and</TOKEN>
        <TOKEN id="token-147-10" pos="word" morph="none" start_char="8774" end_char="8776">tea</TOKEN>
        <TOKEN id="token-147-11" pos="punct" morph="none" start_char="8777" end_char="8777">,</TOKEN>
        <TOKEN id="token-147-12" pos="word" morph="none" start_char="8779" end_char="8781">and</TOKEN>
        <TOKEN id="token-147-13" pos="word" morph="none" start_char="8783" end_char="8791">sometimes</TOKEN>
        <TOKEN id="token-147-14" pos="word" morph="none" start_char="8793" end_char="8795">dug</TOKEN>
        <TOKEN id="token-147-15" pos="word" morph="none" start_char="8797" end_char="8799">the</TOKEN>
      </SEG>
      <SEG id="segment-148" start_char="8801" end_char="8852">
        <ORIGINAL_TEXT>fingernails of one hand into the palm of the other.”</ORIGINAL_TEXT>
        <TOKEN id="token-148-0" pos="word" morph="none" start_char="8801" end_char="8811">fingernails</TOKEN>
        <TOKEN id="token-148-1" pos="word" morph="none" start_char="8813" end_char="8814">of</TOKEN>
        <TOKEN id="token-148-2" pos="word" morph="none" start_char="8816" end_char="8818">one</TOKEN>
        <TOKEN id="token-148-3" pos="word" morph="none" start_char="8820" end_char="8823">hand</TOKEN>
        <TOKEN id="token-148-4" pos="word" morph="none" start_char="8825" end_char="8828">into</TOKEN>
        <TOKEN id="token-148-5" pos="word" morph="none" start_char="8830" end_char="8832">the</TOKEN>
        <TOKEN id="token-148-6" pos="word" morph="none" start_char="8834" end_char="8837">palm</TOKEN>
        <TOKEN id="token-148-7" pos="word" morph="none" start_char="8839" end_char="8840">of</TOKEN>
        <TOKEN id="token-148-8" pos="word" morph="none" start_char="8842" end_char="8844">the</TOKEN>
        <TOKEN id="token-148-9" pos="word" morph="none" start_char="8846" end_char="8850">other</TOKEN>
        <TOKEN id="token-148-10" pos="punct" morph="none" start_char="8851" end_char="8852">.”</TOKEN>
      </SEG>
      <SEG id="segment-149" start_char="8854" end_char="8857">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-149-0" pos="unknown" morph="none" start_char="8854" end_char="8857">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-150" start_char="8859" end_char="8861">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-150-0" pos="unknown" morph="none" start_char="8859" end_char="8861">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-151" start_char="8863" end_char="8940">
        <ORIGINAL_TEXT>Instead, her personal triumphs and tragedies, like her diplomatic triumphs and</ORIGINAL_TEXT>
        <TOKEN id="token-151-0" pos="word" morph="none" start_char="8863" end_char="8869">Instead</TOKEN>
        <TOKEN id="token-151-1" pos="punct" morph="none" start_char="8870" end_char="8870">,</TOKEN>
        <TOKEN id="token-151-2" pos="word" morph="none" start_char="8872" end_char="8874">her</TOKEN>
        <TOKEN id="token-151-3" pos="word" morph="none" start_char="8876" end_char="8883">personal</TOKEN>
        <TOKEN id="token-151-4" pos="word" morph="none" start_char="8885" end_char="8892">triumphs</TOKEN>
        <TOKEN id="token-151-5" pos="word" morph="none" start_char="8894" end_char="8896">and</TOKEN>
        <TOKEN id="token-151-6" pos="word" morph="none" start_char="8898" end_char="8906">tragedies</TOKEN>
        <TOKEN id="token-151-7" pos="punct" morph="none" start_char="8907" end_char="8907">,</TOKEN>
        <TOKEN id="token-151-8" pos="word" morph="none" start_char="8909" end_char="8912">like</TOKEN>
        <TOKEN id="token-151-9" pos="word" morph="none" start_char="8914" end_char="8916">her</TOKEN>
        <TOKEN id="token-151-10" pos="word" morph="none" start_char="8918" end_char="8927">diplomatic</TOKEN>
        <TOKEN id="token-151-11" pos="word" morph="none" start_char="8929" end_char="8936">triumphs</TOKEN>
        <TOKEN id="token-151-12" pos="word" morph="none" start_char="8938" end_char="8940">and</TOKEN>
      </SEG>
      <SEG id="segment-152" start_char="8942" end_char="9016">
        <ORIGINAL_TEXT>tragedies, are always converted into stories and more stories, usually with</ORIGINAL_TEXT>
        <TOKEN id="token-152-0" pos="word" morph="none" start_char="8942" end_char="8950">tragedies</TOKEN>
        <TOKEN id="token-152-1" pos="punct" morph="none" start_char="8951" end_char="8951">,</TOKEN>
        <TOKEN id="token-152-2" pos="word" morph="none" start_char="8953" end_char="8955">are</TOKEN>
        <TOKEN id="token-152-3" pos="word" morph="none" start_char="8957" end_char="8962">always</TOKEN>
        <TOKEN id="token-152-4" pos="word" morph="none" start_char="8964" end_char="8972">converted</TOKEN>
        <TOKEN id="token-152-5" pos="word" morph="none" start_char="8974" end_char="8977">into</TOKEN>
        <TOKEN id="token-152-6" pos="word" morph="none" start_char="8979" end_char="8985">stories</TOKEN>
        <TOKEN id="token-152-7" pos="word" morph="none" start_char="8987" end_char="8989">and</TOKEN>
        <TOKEN id="token-152-8" pos="word" morph="none" start_char="8991" end_char="8994">more</TOKEN>
        <TOKEN id="token-152-9" pos="word" morph="none" start_char="8996" end_char="9002">stories</TOKEN>
        <TOKEN id="token-152-10" pos="punct" morph="none" start_char="9003" end_char="9003">,</TOKEN>
        <TOKEN id="token-152-11" pos="word" morph="none" start_char="9005" end_char="9011">usually</TOKEN>
        <TOKEN id="token-152-12" pos="word" morph="none" start_char="9013" end_char="9016">with</TOKEN>
      </SEG>
      <SEG id="segment-153" start_char="9018" end_char="9088">
        <ORIGINAL_TEXT>moral lessons for herself, for the reader, for the nation. Her mother’s</ORIGINAL_TEXT>
        <TOKEN id="token-153-0" pos="word" morph="none" start_char="9018" end_char="9022">moral</TOKEN>
        <TOKEN id="token-153-1" pos="word" morph="none" start_char="9024" end_char="9030">lessons</TOKEN>
        <TOKEN id="token-153-2" pos="word" morph="none" start_char="9032" end_char="9034">for</TOKEN>
        <TOKEN id="token-153-3" pos="word" morph="none" start_char="9036" end_char="9042">herself</TOKEN>
        <TOKEN id="token-153-4" pos="punct" morph="none" start_char="9043" end_char="9043">,</TOKEN>
        <TOKEN id="token-153-5" pos="word" morph="none" start_char="9045" end_char="9047">for</TOKEN>
        <TOKEN id="token-153-6" pos="word" morph="none" start_char="9049" end_char="9051">the</TOKEN>
        <TOKEN id="token-153-7" pos="word" morph="none" start_char="9053" end_char="9058">reader</TOKEN>
        <TOKEN id="token-153-8" pos="punct" morph="none" start_char="9059" end_char="9059">,</TOKEN>
        <TOKEN id="token-153-9" pos="word" morph="none" start_char="9061" end_char="9063">for</TOKEN>
        <TOKEN id="token-153-10" pos="word" morph="none" start_char="9065" end_char="9067">the</TOKEN>
        <TOKEN id="token-153-11" pos="word" morph="none" start_char="9069" end_char="9074">nation</TOKEN>
        <TOKEN id="token-153-12" pos="punct" morph="none" start_char="9075" end_char="9075">.</TOKEN>
        <TOKEN id="token-153-13" pos="word" morph="none" start_char="9077" end_char="9079">Her</TOKEN>
        <TOKEN id="token-153-14" pos="word" morph="none" start_char="9081" end_char="9086">mother</TOKEN>
        <TOKEN id="token-153-15" pos="punct" morph="none" start_char="9087" end_char="9087">’</TOKEN>
        <TOKEN id="token-153-16" pos="word" morph="none" start_char="9088" end_char="9088">s</TOKEN>
      </SEG>
      <SEG id="segment-154" start_char="9090" end_char="9161">
        <ORIGINAL_TEXT>death reminds her that you must “never rest on your laurels. Never quit.</ORIGINAL_TEXT>
        <TOKEN id="token-154-0" pos="word" morph="none" start_char="9090" end_char="9094">death</TOKEN>
        <TOKEN id="token-154-1" pos="word" morph="none" start_char="9096" end_char="9102">reminds</TOKEN>
        <TOKEN id="token-154-2" pos="word" morph="none" start_char="9104" end_char="9106">her</TOKEN>
        <TOKEN id="token-154-3" pos="word" morph="none" start_char="9108" end_char="9111">that</TOKEN>
        <TOKEN id="token-154-4" pos="word" morph="none" start_char="9113" end_char="9115">you</TOKEN>
        <TOKEN id="token-154-5" pos="word" morph="none" start_char="9117" end_char="9120">must</TOKEN>
        <TOKEN id="token-154-6" pos="punct" morph="none" start_char="9122" end_char="9122">“</TOKEN>
        <TOKEN id="token-154-7" pos="word" morph="none" start_char="9123" end_char="9127">never</TOKEN>
        <TOKEN id="token-154-8" pos="word" morph="none" start_char="9129" end_char="9132">rest</TOKEN>
        <TOKEN id="token-154-9" pos="word" morph="none" start_char="9134" end_char="9135">on</TOKEN>
        <TOKEN id="token-154-10" pos="word" morph="none" start_char="9137" end_char="9140">your</TOKEN>
        <TOKEN id="token-154-11" pos="word" morph="none" start_char="9142" end_char="9148">laurels</TOKEN>
        <TOKEN id="token-154-12" pos="punct" morph="none" start_char="9149" end_char="9149">.</TOKEN>
        <TOKEN id="token-154-13" pos="word" morph="none" start_char="9151" end_char="9155">Never</TOKEN>
        <TOKEN id="token-154-14" pos="word" morph="none" start_char="9157" end_char="9160">quit</TOKEN>
        <TOKEN id="token-154-15" pos="punct" morph="none" start_char="9161" end_char="9161">.</TOKEN>
      </SEG>
      <SEG id="segment-155" start_char="9163" end_char="9233">
        <ORIGINAL_TEXT>Never stop working to make the world a better place.” Chelsea’s wedding</ORIGINAL_TEXT>
        <TOKEN id="token-155-0" pos="word" morph="none" start_char="9163" end_char="9167">Never</TOKEN>
        <TOKEN id="token-155-1" pos="word" morph="none" start_char="9169" end_char="9172">stop</TOKEN>
        <TOKEN id="token-155-2" pos="word" morph="none" start_char="9174" end_char="9180">working</TOKEN>
        <TOKEN id="token-155-3" pos="word" morph="none" start_char="9182" end_char="9183">to</TOKEN>
        <TOKEN id="token-155-4" pos="word" morph="none" start_char="9185" end_char="9188">make</TOKEN>
        <TOKEN id="token-155-5" pos="word" morph="none" start_char="9190" end_char="9192">the</TOKEN>
        <TOKEN id="token-155-6" pos="word" morph="none" start_char="9194" end_char="9198">world</TOKEN>
        <TOKEN id="token-155-7" pos="word" morph="none" start_char="9200" end_char="9200">a</TOKEN>
        <TOKEN id="token-155-8" pos="word" morph="none" start_char="9202" end_char="9207">better</TOKEN>
        <TOKEN id="token-155-9" pos="word" morph="none" start_char="9209" end_char="9213">place</TOKEN>
        <TOKEN id="token-155-10" pos="punct" morph="none" start_char="9214" end_char="9215">.”</TOKEN>
        <TOKEN id="token-155-11" pos="word" morph="none" start_char="9217" end_char="9223">Chelsea</TOKEN>
        <TOKEN id="token-155-12" pos="punct" morph="none" start_char="9224" end_char="9224">’</TOKEN>
        <TOKEN id="token-155-13" pos="word" morph="none" start_char="9225" end_char="9225">s</TOKEN>
        <TOKEN id="token-155-14" pos="word" morph="none" start_char="9227" end_char="9233">wedding</TOKEN>
      </SEG>
      <SEG id="segment-156" start_char="9235" end_char="9300">
        <ORIGINAL_TEXT>makes her think of her daughter’s “dreams and ambitions”: “This, I</ORIGINAL_TEXT>
        <TOKEN id="token-156-0" pos="word" morph="none" start_char="9235" end_char="9239">makes</TOKEN>
        <TOKEN id="token-156-1" pos="word" morph="none" start_char="9241" end_char="9243">her</TOKEN>
        <TOKEN id="token-156-2" pos="word" morph="none" start_char="9245" end_char="9249">think</TOKEN>
        <TOKEN id="token-156-3" pos="word" morph="none" start_char="9251" end_char="9252">of</TOKEN>
        <TOKEN id="token-156-4" pos="word" morph="none" start_char="9254" end_char="9256">her</TOKEN>
        <TOKEN id="token-156-5" pos="word" morph="none" start_char="9258" end_char="9265">daughter</TOKEN>
        <TOKEN id="token-156-6" pos="punct" morph="none" start_char="9266" end_char="9266">’</TOKEN>
        <TOKEN id="token-156-7" pos="word" morph="none" start_char="9267" end_char="9267">s</TOKEN>
        <TOKEN id="token-156-8" pos="punct" morph="none" start_char="9269" end_char="9269">“</TOKEN>
        <TOKEN id="token-156-9" pos="word" morph="none" start_char="9270" end_char="9275">dreams</TOKEN>
        <TOKEN id="token-156-10" pos="word" morph="none" start_char="9277" end_char="9279">and</TOKEN>
        <TOKEN id="token-156-11" pos="word" morph="none" start_char="9281" end_char="9289">ambitions</TOKEN>
        <TOKEN id="token-156-12" pos="punct" morph="none" start_char="9290" end_char="9291">”:</TOKEN>
        <TOKEN id="token-156-13" pos="punct" morph="none" start_char="9293" end_char="9293">“</TOKEN>
        <TOKEN id="token-156-14" pos="word" morph="none" start_char="9294" end_char="9297">This</TOKEN>
        <TOKEN id="token-156-15" pos="punct" morph="none" start_char="9298" end_char="9298">,</TOKEN>
        <TOKEN id="token-156-16" pos="word" morph="none" start_char="9300" end_char="9300">I</TOKEN>
      </SEG>
      <SEG id="segment-157" start_char="9302" end_char="9378">
        <ORIGINAL_TEXT>thought, is why Bill and I had worked so hard for so many years to help build</ORIGINAL_TEXT>
        <TOKEN id="token-157-0" pos="word" morph="none" start_char="9302" end_char="9308">thought</TOKEN>
        <TOKEN id="token-157-1" pos="punct" morph="none" start_char="9309" end_char="9309">,</TOKEN>
        <TOKEN id="token-157-2" pos="word" morph="none" start_char="9311" end_char="9312">is</TOKEN>
        <TOKEN id="token-157-3" pos="word" morph="none" start_char="9314" end_char="9316">why</TOKEN>
        <TOKEN id="token-157-4" pos="word" morph="none" start_char="9318" end_char="9321">Bill</TOKEN>
        <TOKEN id="token-157-5" pos="word" morph="none" start_char="9323" end_char="9325">and</TOKEN>
        <TOKEN id="token-157-6" pos="word" morph="none" start_char="9327" end_char="9327">I</TOKEN>
        <TOKEN id="token-157-7" pos="word" morph="none" start_char="9329" end_char="9331">had</TOKEN>
        <TOKEN id="token-157-8" pos="word" morph="none" start_char="9333" end_char="9338">worked</TOKEN>
        <TOKEN id="token-157-9" pos="word" morph="none" start_char="9340" end_char="9341">so</TOKEN>
        <TOKEN id="token-157-10" pos="word" morph="none" start_char="9343" end_char="9346">hard</TOKEN>
        <TOKEN id="token-157-11" pos="word" morph="none" start_char="9348" end_char="9350">for</TOKEN>
        <TOKEN id="token-157-12" pos="word" morph="none" start_char="9352" end_char="9353">so</TOKEN>
        <TOKEN id="token-157-13" pos="word" morph="none" start_char="9355" end_char="9358">many</TOKEN>
        <TOKEN id="token-157-14" pos="word" morph="none" start_char="9360" end_char="9364">years</TOKEN>
        <TOKEN id="token-157-15" pos="word" morph="none" start_char="9366" end_char="9367">to</TOKEN>
        <TOKEN id="token-157-16" pos="word" morph="none" start_char="9369" end_char="9372">help</TOKEN>
        <TOKEN id="token-157-17" pos="word" morph="none" start_char="9374" end_char="9378">build</TOKEN>
      </SEG>
      <SEG id="segment-158" start_char="9380" end_char="9452">
        <ORIGINAL_TEXT>a better world—so Chelsea could grow up safe and happy and one day have a</ORIGINAL_TEXT>
        <TOKEN id="token-158-0" pos="word" morph="none" start_char="9380" end_char="9380">a</TOKEN>
        <TOKEN id="token-158-1" pos="word" morph="none" start_char="9382" end_char="9387">better</TOKEN>
        <TOKEN id="token-158-2" pos="word" morph="none" start_char="9389" end_char="9393">world</TOKEN>
        <TOKEN id="token-158-3" pos="punct" morph="none" start_char="9394" end_char="9394">—</TOKEN>
        <TOKEN id="token-158-4" pos="word" morph="none" start_char="9395" end_char="9396">so</TOKEN>
        <TOKEN id="token-158-5" pos="word" morph="none" start_char="9398" end_char="9404">Chelsea</TOKEN>
        <TOKEN id="token-158-6" pos="word" morph="none" start_char="9406" end_char="9410">could</TOKEN>
        <TOKEN id="token-158-7" pos="word" morph="none" start_char="9412" end_char="9415">grow</TOKEN>
        <TOKEN id="token-158-8" pos="word" morph="none" start_char="9417" end_char="9418">up</TOKEN>
        <TOKEN id="token-158-9" pos="word" morph="none" start_char="9420" end_char="9423">safe</TOKEN>
        <TOKEN id="token-158-10" pos="word" morph="none" start_char="9425" end_char="9427">and</TOKEN>
        <TOKEN id="token-158-11" pos="word" morph="none" start_char="9429" end_char="9433">happy</TOKEN>
        <TOKEN id="token-158-12" pos="word" morph="none" start_char="9435" end_char="9437">and</TOKEN>
        <TOKEN id="token-158-13" pos="word" morph="none" start_char="9439" end_char="9441">one</TOKEN>
        <TOKEN id="token-158-14" pos="word" morph="none" start_char="9443" end_char="9445">day</TOKEN>
        <TOKEN id="token-158-15" pos="word" morph="none" start_char="9447" end_char="9450">have</TOKEN>
        <TOKEN id="token-158-16" pos="word" morph="none" start_char="9452" end_char="9452">a</TOKEN>
      </SEG>
      <SEG id="segment-159" start_char="9454" end_char="9529">
        <ORIGINAL_TEXT>family of her own, and so every other child would have the same chance.” The</ORIGINAL_TEXT>
        <TOKEN id="token-159-0" pos="word" morph="none" start_char="9454" end_char="9459">family</TOKEN>
        <TOKEN id="token-159-1" pos="word" morph="none" start_char="9461" end_char="9462">of</TOKEN>
        <TOKEN id="token-159-2" pos="word" morph="none" start_char="9464" end_char="9466">her</TOKEN>
        <TOKEN id="token-159-3" pos="word" morph="none" start_char="9468" end_char="9470">own</TOKEN>
        <TOKEN id="token-159-4" pos="punct" morph="none" start_char="9471" end_char="9471">,</TOKEN>
        <TOKEN id="token-159-5" pos="word" morph="none" start_char="9473" end_char="9475">and</TOKEN>
        <TOKEN id="token-159-6" pos="word" morph="none" start_char="9477" end_char="9478">so</TOKEN>
        <TOKEN id="token-159-7" pos="word" morph="none" start_char="9480" end_char="9484">every</TOKEN>
        <TOKEN id="token-159-8" pos="word" morph="none" start_char="9486" end_char="9490">other</TOKEN>
        <TOKEN id="token-159-9" pos="word" morph="none" start_char="9492" end_char="9496">child</TOKEN>
        <TOKEN id="token-159-10" pos="word" morph="none" start_char="9498" end_char="9502">would</TOKEN>
        <TOKEN id="token-159-11" pos="word" morph="none" start_char="9504" end_char="9507">have</TOKEN>
        <TOKEN id="token-159-12" pos="word" morph="none" start_char="9509" end_char="9511">the</TOKEN>
        <TOKEN id="token-159-13" pos="word" morph="none" start_char="9513" end_char="9516">same</TOKEN>
        <TOKEN id="token-159-14" pos="word" morph="none" start_char="9518" end_char="9523">chance</TOKEN>
        <TOKEN id="token-159-15" pos="punct" morph="none" start_char="9524" end_char="9525">.”</TOKEN>
        <TOKEN id="token-159-16" pos="word" morph="none" start_char="9527" end_char="9529">The</TOKEN>
      </SEG>
      <SEG id="segment-160" start_char="9531" end_char="9600">
        <ORIGINAL_TEXT>news of Chelsea’s pregnancy makes her recall “what Margaret Mead said,</ORIGINAL_TEXT>
        <TOKEN id="token-160-0" pos="word" morph="none" start_char="9531" end_char="9534">news</TOKEN>
        <TOKEN id="token-160-1" pos="word" morph="none" start_char="9536" end_char="9537">of</TOKEN>
        <TOKEN id="token-160-2" pos="word" morph="none" start_char="9539" end_char="9545">Chelsea</TOKEN>
        <TOKEN id="token-160-3" pos="punct" morph="none" start_char="9546" end_char="9546">’</TOKEN>
        <TOKEN id="token-160-4" pos="word" morph="none" start_char="9547" end_char="9547">s</TOKEN>
        <TOKEN id="token-160-5" pos="word" morph="none" start_char="9549" end_char="9557">pregnancy</TOKEN>
        <TOKEN id="token-160-6" pos="word" morph="none" start_char="9559" end_char="9563">makes</TOKEN>
        <TOKEN id="token-160-7" pos="word" morph="none" start_char="9565" end_char="9567">her</TOKEN>
        <TOKEN id="token-160-8" pos="word" morph="none" start_char="9569" end_char="9574">recall</TOKEN>
        <TOKEN id="token-160-9" pos="punct" morph="none" start_char="9576" end_char="9576">“</TOKEN>
        <TOKEN id="token-160-10" pos="word" morph="none" start_char="9577" end_char="9580">what</TOKEN>
        <TOKEN id="token-160-11" pos="word" morph="none" start_char="9582" end_char="9589">Margaret</TOKEN>
        <TOKEN id="token-160-12" pos="word" morph="none" start_char="9591" end_char="9594">Mead</TOKEN>
        <TOKEN id="token-160-13" pos="word" morph="none" start_char="9596" end_char="9599">said</TOKEN>
        <TOKEN id="token-160-14" pos="punct" morph="none" start_char="9600" end_char="9600">,</TOKEN>
      </SEG>
      <SEG id="segment-161" start_char="9602" end_char="9677">
        <ORIGINAL_TEXT>that children keep our imaginations fresh and our hearts young, and drive us</ORIGINAL_TEXT>
        <TOKEN id="token-161-0" pos="word" morph="none" start_char="9602" end_char="9605">that</TOKEN>
        <TOKEN id="token-161-1" pos="word" morph="none" start_char="9607" end_char="9614">children</TOKEN>
        <TOKEN id="token-161-2" pos="word" morph="none" start_char="9616" end_char="9619">keep</TOKEN>
        <TOKEN id="token-161-3" pos="word" morph="none" start_char="9621" end_char="9623">our</TOKEN>
        <TOKEN id="token-161-4" pos="word" morph="none" start_char="9625" end_char="9636">imaginations</TOKEN>
        <TOKEN id="token-161-5" pos="word" morph="none" start_char="9638" end_char="9642">fresh</TOKEN>
        <TOKEN id="token-161-6" pos="word" morph="none" start_char="9644" end_char="9646">and</TOKEN>
        <TOKEN id="token-161-7" pos="word" morph="none" start_char="9648" end_char="9650">our</TOKEN>
        <TOKEN id="token-161-8" pos="word" morph="none" start_char="9652" end_char="9657">hearts</TOKEN>
        <TOKEN id="token-161-9" pos="word" morph="none" start_char="9659" end_char="9663">young</TOKEN>
        <TOKEN id="token-161-10" pos="punct" morph="none" start_char="9664" end_char="9664">,</TOKEN>
        <TOKEN id="token-161-11" pos="word" morph="none" start_char="9666" end_char="9668">and</TOKEN>
        <TOKEN id="token-161-12" pos="word" morph="none" start_char="9670" end_char="9674">drive</TOKEN>
        <TOKEN id="token-161-13" pos="word" morph="none" start_char="9676" end_char="9677">us</TOKEN>
      </SEG>
      <SEG id="segment-162" start_char="9679" end_char="9707">
        <ORIGINAL_TEXT>to work for a better future.”</ORIGINAL_TEXT>
        <TOKEN id="token-162-0" pos="word" morph="none" start_char="9679" end_char="9680">to</TOKEN>
        <TOKEN id="token-162-1" pos="word" morph="none" start_char="9682" end_char="9685">work</TOKEN>
        <TOKEN id="token-162-2" pos="word" morph="none" start_char="9687" end_char="9689">for</TOKEN>
        <TOKEN id="token-162-3" pos="word" morph="none" start_char="9691" end_char="9691">a</TOKEN>
        <TOKEN id="token-162-4" pos="word" morph="none" start_char="9693" end_char="9698">better</TOKEN>
        <TOKEN id="token-162-5" pos="word" morph="none" start_char="9700" end_char="9705">future</TOKEN>
        <TOKEN id="token-162-6" pos="punct" morph="none" start_char="9706" end_char="9707">.”</TOKEN>
      </SEG>
      <SEG id="segment-163" start_char="9709" end_char="9712">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-163-0" pos="unknown" morph="none" start_char="9709" end_char="9712">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-164" start_char="9714" end_char="9716">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-164-0" pos="unknown" morph="none" start_char="9714" end_char="9716">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-165" start_char="9718" end_char="9792">
        <ORIGINAL_TEXT>Clinton carefully puts to rest any hint of conflict between herself and her</ORIGINAL_TEXT>
        <TOKEN id="token-165-0" pos="word" morph="none" start_char="9718" end_char="9724">Clinton</TOKEN>
        <TOKEN id="token-165-1" pos="word" morph="none" start_char="9726" end_char="9734">carefully</TOKEN>
        <TOKEN id="token-165-2" pos="word" morph="none" start_char="9736" end_char="9739">puts</TOKEN>
        <TOKEN id="token-165-3" pos="word" morph="none" start_char="9741" end_char="9742">to</TOKEN>
        <TOKEN id="token-165-4" pos="word" morph="none" start_char="9744" end_char="9747">rest</TOKEN>
        <TOKEN id="token-165-5" pos="word" morph="none" start_char="9749" end_char="9751">any</TOKEN>
        <TOKEN id="token-165-6" pos="word" morph="none" start_char="9753" end_char="9756">hint</TOKEN>
        <TOKEN id="token-165-7" pos="word" morph="none" start_char="9758" end_char="9759">of</TOKEN>
        <TOKEN id="token-165-8" pos="word" morph="none" start_char="9761" end_char="9768">conflict</TOKEN>
        <TOKEN id="token-165-9" pos="word" morph="none" start_char="9770" end_char="9776">between</TOKEN>
        <TOKEN id="token-165-10" pos="word" morph="none" start_char="9778" end_char="9784">herself</TOKEN>
        <TOKEN id="token-165-11" pos="word" morph="none" start_char="9786" end_char="9788">and</TOKEN>
        <TOKEN id="token-165-12" pos="word" morph="none" start_char="9790" end_char="9792">her</TOKEN>
      </SEG>
      <SEG id="segment-166" start_char="9794" end_char="9865">
        <ORIGINAL_TEXT>husband, or herself and President Obama. Instead she includes a scene of</ORIGINAL_TEXT>
        <TOKEN id="token-166-0" pos="word" morph="none" start_char="9794" end_char="9800">husband</TOKEN>
        <TOKEN id="token-166-1" pos="punct" morph="none" start_char="9801" end_char="9801">,</TOKEN>
        <TOKEN id="token-166-2" pos="word" morph="none" start_char="9803" end_char="9804">or</TOKEN>
        <TOKEN id="token-166-3" pos="word" morph="none" start_char="9806" end_char="9812">herself</TOKEN>
        <TOKEN id="token-166-4" pos="word" morph="none" start_char="9814" end_char="9816">and</TOKEN>
        <TOKEN id="token-166-5" pos="word" morph="none" start_char="9818" end_char="9826">President</TOKEN>
        <TOKEN id="token-166-6" pos="word" morph="none" start_char="9828" end_char="9832">Obama</TOKEN>
        <TOKEN id="token-166-7" pos="punct" morph="none" start_char="9833" end_char="9833">.</TOKEN>
        <TOKEN id="token-166-8" pos="word" morph="none" start_char="9835" end_char="9841">Instead</TOKEN>
        <TOKEN id="token-166-9" pos="word" morph="none" start_char="9843" end_char="9845">she</TOKEN>
        <TOKEN id="token-166-10" pos="word" morph="none" start_char="9847" end_char="9854">includes</TOKEN>
        <TOKEN id="token-166-11" pos="word" morph="none" start_char="9856" end_char="9856">a</TOKEN>
        <TOKEN id="token-166-12" pos="word" morph="none" start_char="9858" end_char="9862">scene</TOKEN>
        <TOKEN id="token-166-13" pos="word" morph="none" start_char="9864" end_char="9865">of</TOKEN>
      </SEG>
      <SEG id="segment-167" start_char="9867" end_char="9935">
        <ORIGINAL_TEXT>herself sitting in East Timor, watching ex-President Clinton nominate</ORIGINAL_TEXT>
        <TOKEN id="token-167-0" pos="word" morph="none" start_char="9867" end_char="9873">herself</TOKEN>
        <TOKEN id="token-167-1" pos="word" morph="none" start_char="9875" end_char="9881">sitting</TOKEN>
        <TOKEN id="token-167-2" pos="word" morph="none" start_char="9883" end_char="9884">in</TOKEN>
        <TOKEN id="token-167-3" pos="word" morph="none" start_char="9886" end_char="9889">East</TOKEN>
        <TOKEN id="token-167-4" pos="word" morph="none" start_char="9891" end_char="9895">Timor</TOKEN>
        <TOKEN id="token-167-5" pos="punct" morph="none" start_char="9896" end_char="9896">,</TOKEN>
        <TOKEN id="token-167-6" pos="word" morph="none" start_char="9898" end_char="9905">watching</TOKEN>
        <TOKEN id="token-167-7" pos="word" morph="none" start_char="9907" end_char="9908">ex</TOKEN>
        <TOKEN id="token-167-8" pos="punct" morph="none" start_char="9909" end_char="9909">-</TOKEN>
        <TOKEN id="token-167-9" pos="word" morph="none" start_char="9910" end_char="9918">President</TOKEN>
        <TOKEN id="token-167-10" pos="word" morph="none" start_char="9920" end_char="9926">Clinton</TOKEN>
        <TOKEN id="token-167-11" pos="word" morph="none" start_char="9928" end_char="9935">nominate</TOKEN>
      </SEG>
      <SEG id="segment-168" start_char="9937" end_char="10011">
        <ORIGINAL_TEXT>President Obama for the second time: “Watching from some ten thousand miles</ORIGINAL_TEXT>
        <TOKEN id="token-168-0" pos="word" morph="none" start_char="9937" end_char="9945">President</TOKEN>
        <TOKEN id="token-168-1" pos="word" morph="none" start_char="9947" end_char="9951">Obama</TOKEN>
        <TOKEN id="token-168-2" pos="word" morph="none" start_char="9953" end_char="9955">for</TOKEN>
        <TOKEN id="token-168-3" pos="word" morph="none" start_char="9957" end_char="9959">the</TOKEN>
        <TOKEN id="token-168-4" pos="word" morph="none" start_char="9961" end_char="9966">second</TOKEN>
        <TOKEN id="token-168-5" pos="word" morph="none" start_char="9968" end_char="9971">time</TOKEN>
        <TOKEN id="token-168-6" pos="punct" morph="none" start_char="9972" end_char="9972">:</TOKEN>
        <TOKEN id="token-168-7" pos="punct" morph="none" start_char="9974" end_char="9974">“</TOKEN>
        <TOKEN id="token-168-8" pos="word" morph="none" start_char="9975" end_char="9982">Watching</TOKEN>
        <TOKEN id="token-168-9" pos="word" morph="none" start_char="9984" end_char="9987">from</TOKEN>
        <TOKEN id="token-168-10" pos="word" morph="none" start_char="9989" end_char="9992">some</TOKEN>
        <TOKEN id="token-168-11" pos="word" morph="none" start_char="9994" end_char="9996">ten</TOKEN>
        <TOKEN id="token-168-12" pos="word" morph="none" start_char="9998" end_char="10005">thousand</TOKEN>
        <TOKEN id="token-168-13" pos="word" morph="none" start_char="10007" end_char="10011">miles</TOKEN>
      </SEG>
      <SEG id="segment-169" start_char="10013" end_char="10085">
        <ORIGINAL_TEXT>away, I was full of pride for the former President I married, the current</ORIGINAL_TEXT>
        <TOKEN id="token-169-0" pos="word" morph="none" start_char="10013" end_char="10016">away</TOKEN>
        <TOKEN id="token-169-1" pos="punct" morph="none" start_char="10017" end_char="10017">,</TOKEN>
        <TOKEN id="token-169-2" pos="word" morph="none" start_char="10019" end_char="10019">I</TOKEN>
        <TOKEN id="token-169-3" pos="word" morph="none" start_char="10021" end_char="10023">was</TOKEN>
        <TOKEN id="token-169-4" pos="word" morph="none" start_char="10025" end_char="10028">full</TOKEN>
        <TOKEN id="token-169-5" pos="word" morph="none" start_char="10030" end_char="10031">of</TOKEN>
        <TOKEN id="token-169-6" pos="word" morph="none" start_char="10033" end_char="10037">pride</TOKEN>
        <TOKEN id="token-169-7" pos="word" morph="none" start_char="10039" end_char="10041">for</TOKEN>
        <TOKEN id="token-169-8" pos="word" morph="none" start_char="10043" end_char="10045">the</TOKEN>
        <TOKEN id="token-169-9" pos="word" morph="none" start_char="10047" end_char="10052">former</TOKEN>
        <TOKEN id="token-169-10" pos="word" morph="none" start_char="10054" end_char="10062">President</TOKEN>
        <TOKEN id="token-169-11" pos="word" morph="none" start_char="10064" end_char="10064">I</TOKEN>
        <TOKEN id="token-169-12" pos="word" morph="none" start_char="10066" end_char="10072">married</TOKEN>
        <TOKEN id="token-169-13" pos="punct" morph="none" start_char="10073" end_char="10073">,</TOKEN>
        <TOKEN id="token-169-14" pos="word" morph="none" start_char="10075" end_char="10077">the</TOKEN>
        <TOKEN id="token-169-15" pos="word" morph="none" start_char="10079" end_char="10085">current</TOKEN>
      </SEG>
      <SEG id="segment-170" start_char="10087" end_char="10136">
        <ORIGINAL_TEXT>president I served, and the country we all loved.”</ORIGINAL_TEXT>
        <TOKEN id="token-170-0" pos="word" morph="none" start_char="10087" end_char="10095">president</TOKEN>
        <TOKEN id="token-170-1" pos="word" morph="none" start_char="10097" end_char="10097">I</TOKEN>
        <TOKEN id="token-170-2" pos="word" morph="none" start_char="10099" end_char="10104">served</TOKEN>
        <TOKEN id="token-170-3" pos="punct" morph="none" start_char="10105" end_char="10105">,</TOKEN>
        <TOKEN id="token-170-4" pos="word" morph="none" start_char="10107" end_char="10109">and</TOKEN>
        <TOKEN id="token-170-5" pos="word" morph="none" start_char="10111" end_char="10113">the</TOKEN>
        <TOKEN id="token-170-6" pos="word" morph="none" start_char="10115" end_char="10121">country</TOKEN>
        <TOKEN id="token-170-7" pos="word" morph="none" start_char="10123" end_char="10124">we</TOKEN>
        <TOKEN id="token-170-8" pos="word" morph="none" start_char="10126" end_char="10128">all</TOKEN>
        <TOKEN id="token-170-9" pos="word" morph="none" start_char="10130" end_char="10134">loved</TOKEN>
        <TOKEN id="token-170-10" pos="punct" morph="none" start_char="10135" end_char="10136">.”</TOKEN>
      </SEG>
      <SEG id="segment-171" start_char="10138" end_char="10141">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-171-0" pos="unknown" morph="none" start_char="10138" end_char="10141">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-172" start_char="10143" end_char="10145">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-172-0" pos="unknown" morph="none" start_char="10143" end_char="10145">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-173" start_char="10147" end_char="10216">
        <ORIGINAL_TEXT>Of course Hard Choices could be shelved alongside the memoirs of other</ORIGINAL_TEXT>
        <TOKEN id="token-173-0" pos="word" morph="none" start_char="10147" end_char="10148">Of</TOKEN>
        <TOKEN id="token-173-1" pos="word" morph="none" start_char="10150" end_char="10155">course</TOKEN>
        <TOKEN id="token-173-2" pos="word" morph="none" start_char="10157" end_char="10160">Hard</TOKEN>
        <TOKEN id="token-173-3" pos="word" morph="none" start_char="10162" end_char="10168">Choices</TOKEN>
        <TOKEN id="token-173-4" pos="word" morph="none" start_char="10170" end_char="10174">could</TOKEN>
        <TOKEN id="token-173-5" pos="word" morph="none" start_char="10176" end_char="10177">be</TOKEN>
        <TOKEN id="token-173-6" pos="word" morph="none" start_char="10179" end_char="10185">shelved</TOKEN>
        <TOKEN id="token-173-7" pos="word" morph="none" start_char="10187" end_char="10195">alongside</TOKEN>
        <TOKEN id="token-173-8" pos="word" morph="none" start_char="10197" end_char="10199">the</TOKEN>
        <TOKEN id="token-173-9" pos="word" morph="none" start_char="10201" end_char="10207">memoirs</TOKEN>
        <TOKEN id="token-173-10" pos="word" morph="none" start_char="10209" end_char="10210">of</TOKEN>
        <TOKEN id="token-173-11" pos="word" morph="none" start_char="10212" end_char="10216">other</TOKEN>
      </SEG>
      <SEG id="segment-174" start_char="10218" end_char="10288">
        <ORIGINAL_TEXT>statesmen— Henry Kissinger, say, or Margaret Thatcher. But those books,</ORIGINAL_TEXT>
        <TOKEN id="token-174-0" pos="word" morph="none" start_char="10218" end_char="10226">statesmen</TOKEN>
        <TOKEN id="token-174-1" pos="punct" morph="none" start_char="10227" end_char="10227">—</TOKEN>
        <TOKEN id="token-174-2" pos="word" morph="none" start_char="10229" end_char="10233">Henry</TOKEN>
        <TOKEN id="token-174-3" pos="word" morph="none" start_char="10235" end_char="10243">Kissinger</TOKEN>
        <TOKEN id="token-174-4" pos="punct" morph="none" start_char="10244" end_char="10244">,</TOKEN>
        <TOKEN id="token-174-5" pos="word" morph="none" start_char="10246" end_char="10248">say</TOKEN>
        <TOKEN id="token-174-6" pos="punct" morph="none" start_char="10249" end_char="10249">,</TOKEN>
        <TOKEN id="token-174-7" pos="word" morph="none" start_char="10251" end_char="10252">or</TOKEN>
        <TOKEN id="token-174-8" pos="word" morph="none" start_char="10254" end_char="10261">Margaret</TOKEN>
        <TOKEN id="token-174-9" pos="word" morph="none" start_char="10263" end_char="10270">Thatcher</TOKEN>
        <TOKEN id="token-174-10" pos="punct" morph="none" start_char="10271" end_char="10271">.</TOKEN>
        <TOKEN id="token-174-11" pos="word" morph="none" start_char="10273" end_char="10275">But</TOKEN>
        <TOKEN id="token-174-12" pos="word" morph="none" start_char="10277" end_char="10281">those</TOKEN>
        <TOKEN id="token-174-13" pos="word" morph="none" start_char="10283" end_char="10287">books</TOKEN>
        <TOKEN id="token-174-14" pos="punct" morph="none" start_char="10288" end_char="10288">,</TOKEN>
      </SEG>
      <SEG id="segment-175" start_char="10290" end_char="10364">
        <ORIGINAL_TEXT>while also painting the world in colors designed to flatter the author, are</ORIGINAL_TEXT>
        <TOKEN id="token-175-0" pos="word" morph="none" start_char="10290" end_char="10294">while</TOKEN>
        <TOKEN id="token-175-1" pos="word" morph="none" start_char="10296" end_char="10299">also</TOKEN>
        <TOKEN id="token-175-2" pos="word" morph="none" start_char="10301" end_char="10308">painting</TOKEN>
        <TOKEN id="token-175-3" pos="word" morph="none" start_char="10310" end_char="10312">the</TOKEN>
        <TOKEN id="token-175-4" pos="word" morph="none" start_char="10314" end_char="10318">world</TOKEN>
        <TOKEN id="token-175-5" pos="word" morph="none" start_char="10320" end_char="10321">in</TOKEN>
        <TOKEN id="token-175-6" pos="word" morph="none" start_char="10323" end_char="10328">colors</TOKEN>
        <TOKEN id="token-175-7" pos="word" morph="none" start_char="10330" end_char="10337">designed</TOKEN>
        <TOKEN id="token-175-8" pos="word" morph="none" start_char="10339" end_char="10340">to</TOKEN>
        <TOKEN id="token-175-9" pos="word" morph="none" start_char="10342" end_char="10348">flatter</TOKEN>
        <TOKEN id="token-175-10" pos="word" morph="none" start_char="10350" end_char="10352">the</TOKEN>
        <TOKEN id="token-175-11" pos="word" morph="none" start_char="10354" end_char="10359">author</TOKEN>
        <TOKEN id="token-175-12" pos="punct" morph="none" start_char="10360" end_char="10360">,</TOKEN>
        <TOKEN id="token-175-13" pos="word" morph="none" start_char="10362" end_char="10364">are</TOKEN>
      </SEG>
      <SEG id="segment-176" start_char="10366" end_char="10443">
        <ORIGINAL_TEXT>generally composed by people who did not anticipate a further career in public</ORIGINAL_TEXT>
        <TOKEN id="token-176-0" pos="word" morph="none" start_char="10366" end_char="10374">generally</TOKEN>
        <TOKEN id="token-176-1" pos="word" morph="none" start_char="10376" end_char="10383">composed</TOKEN>
        <TOKEN id="token-176-2" pos="word" morph="none" start_char="10385" end_char="10386">by</TOKEN>
        <TOKEN id="token-176-3" pos="word" morph="none" start_char="10388" end_char="10393">people</TOKEN>
        <TOKEN id="token-176-4" pos="word" morph="none" start_char="10395" end_char="10397">who</TOKEN>
        <TOKEN id="token-176-5" pos="word" morph="none" start_char="10399" end_char="10401">did</TOKEN>
        <TOKEN id="token-176-6" pos="word" morph="none" start_char="10403" end_char="10405">not</TOKEN>
        <TOKEN id="token-176-7" pos="word" morph="none" start_char="10407" end_char="10416">anticipate</TOKEN>
        <TOKEN id="token-176-8" pos="word" morph="none" start_char="10418" end_char="10418">a</TOKEN>
        <TOKEN id="token-176-9" pos="word" morph="none" start_char="10420" end_char="10426">further</TOKEN>
        <TOKEN id="token-176-10" pos="word" morph="none" start_char="10428" end_char="10433">career</TOKEN>
        <TOKEN id="token-176-11" pos="word" morph="none" start_char="10435" end_char="10436">in</TOKEN>
        <TOKEN id="token-176-12" pos="word" morph="none" start_char="10438" end_char="10443">public</TOKEN>
      </SEG>
      <SEG id="segment-177" start_char="10445" end_char="10516">
        <ORIGINAL_TEXT>life. Clinton’s book, by contrast, does not seek merely to establish the</ORIGINAL_TEXT>
        <TOKEN id="token-177-0" pos="word" morph="none" start_char="10445" end_char="10448">life</TOKEN>
        <TOKEN id="token-177-1" pos="punct" morph="none" start_char="10449" end_char="10449">.</TOKEN>
        <TOKEN id="token-177-2" pos="word" morph="none" start_char="10451" end_char="10457">Clinton</TOKEN>
        <TOKEN id="token-177-3" pos="punct" morph="none" start_char="10458" end_char="10458">’</TOKEN>
        <TOKEN id="token-177-4" pos="word" morph="none" start_char="10459" end_char="10459">s</TOKEN>
        <TOKEN id="token-177-5" pos="word" morph="none" start_char="10461" end_char="10464">book</TOKEN>
        <TOKEN id="token-177-6" pos="punct" morph="none" start_char="10465" end_char="10465">,</TOKEN>
        <TOKEN id="token-177-7" pos="word" morph="none" start_char="10467" end_char="10468">by</TOKEN>
        <TOKEN id="token-177-8" pos="word" morph="none" start_char="10470" end_char="10477">contrast</TOKEN>
        <TOKEN id="token-177-9" pos="punct" morph="none" start_char="10478" end_char="10478">,</TOKEN>
        <TOKEN id="token-177-10" pos="word" morph="none" start_char="10480" end_char="10483">does</TOKEN>
        <TOKEN id="token-177-11" pos="word" morph="none" start_char="10485" end_char="10487">not</TOKEN>
        <TOKEN id="token-177-12" pos="word" morph="none" start_char="10489" end_char="10492">seek</TOKEN>
        <TOKEN id="token-177-13" pos="word" morph="none" start_char="10494" end_char="10499">merely</TOKEN>
        <TOKEN id="token-177-14" pos="word" morph="none" start_char="10501" end_char="10502">to</TOKEN>
        <TOKEN id="token-177-15" pos="word" morph="none" start_char="10504" end_char="10512">establish</TOKEN>
        <TOKEN id="token-177-16" pos="word" morph="none" start_char="10514" end_char="10516">the</TOKEN>
      </SEG>
      <SEG id="segment-178" start_char="10518" end_char="10590">
        <ORIGINAL_TEXT>author’s place in the nation’s past; it is designed also to establish her</ORIGINAL_TEXT>
        <TOKEN id="token-178-0" pos="word" morph="none" start_char="10518" end_char="10523">author</TOKEN>
        <TOKEN id="token-178-1" pos="punct" morph="none" start_char="10524" end_char="10524">’</TOKEN>
        <TOKEN id="token-178-2" pos="word" morph="none" start_char="10525" end_char="10525">s</TOKEN>
        <TOKEN id="token-178-3" pos="word" morph="none" start_char="10527" end_char="10531">place</TOKEN>
        <TOKEN id="token-178-4" pos="word" morph="none" start_char="10533" end_char="10534">in</TOKEN>
        <TOKEN id="token-178-5" pos="word" morph="none" start_char="10536" end_char="10538">the</TOKEN>
        <TOKEN id="token-178-6" pos="word" morph="none" start_char="10540" end_char="10545">nation</TOKEN>
        <TOKEN id="token-178-7" pos="punct" morph="none" start_char="10546" end_char="10546">’</TOKEN>
        <TOKEN id="token-178-8" pos="word" morph="none" start_char="10547" end_char="10547">s</TOKEN>
        <TOKEN id="token-178-9" pos="word" morph="none" start_char="10549" end_char="10552">past</TOKEN>
        <TOKEN id="token-178-10" pos="punct" morph="none" start_char="10553" end_char="10553">;</TOKEN>
        <TOKEN id="token-178-11" pos="word" morph="none" start_char="10555" end_char="10556">it</TOKEN>
        <TOKEN id="token-178-12" pos="word" morph="none" start_char="10558" end_char="10559">is</TOKEN>
        <TOKEN id="token-178-13" pos="word" morph="none" start_char="10561" end_char="10568">designed</TOKEN>
        <TOKEN id="token-178-14" pos="word" morph="none" start_char="10570" end_char="10573">also</TOKEN>
        <TOKEN id="token-178-15" pos="word" morph="none" start_char="10575" end_char="10576">to</TOKEN>
        <TOKEN id="token-178-16" pos="word" morph="none" start_char="10578" end_char="10586">establish</TOKEN>
        <TOKEN id="token-178-17" pos="word" morph="none" start_char="10588" end_char="10590">her</TOKEN>
      </SEG>
      <SEG id="segment-179" start_char="10592" end_char="10666">
        <ORIGINAL_TEXT>place in the nation’s future. This is clear to the reader from the cultural</ORIGINAL_TEXT>
        <TOKEN id="token-179-0" pos="word" morph="none" start_char="10592" end_char="10596">place</TOKEN>
        <TOKEN id="token-179-1" pos="word" morph="none" start_char="10598" end_char="10599">in</TOKEN>
        <TOKEN id="token-179-2" pos="word" morph="none" start_char="10601" end_char="10603">the</TOKEN>
        <TOKEN id="token-179-3" pos="word" morph="none" start_char="10605" end_char="10610">nation</TOKEN>
        <TOKEN id="token-179-4" pos="punct" morph="none" start_char="10611" end_char="10611">’</TOKEN>
        <TOKEN id="token-179-5" pos="word" morph="none" start_char="10612" end_char="10612">s</TOKEN>
        <TOKEN id="token-179-6" pos="word" morph="none" start_char="10614" end_char="10619">future</TOKEN>
        <TOKEN id="token-179-7" pos="punct" morph="none" start_char="10620" end_char="10620">.</TOKEN>
        <TOKEN id="token-179-8" pos="word" morph="none" start_char="10622" end_char="10625">This</TOKEN>
        <TOKEN id="token-179-9" pos="word" morph="none" start_char="10627" end_char="10628">is</TOKEN>
        <TOKEN id="token-179-10" pos="word" morph="none" start_char="10630" end_char="10634">clear</TOKEN>
        <TOKEN id="token-179-11" pos="word" morph="none" start_char="10636" end_char="10637">to</TOKEN>
        <TOKEN id="token-179-12" pos="word" morph="none" start_char="10639" end_char="10641">the</TOKEN>
        <TOKEN id="token-179-13" pos="word" morph="none" start_char="10643" end_char="10648">reader</TOKEN>
        <TOKEN id="token-179-14" pos="word" morph="none" start_char="10650" end_char="10653">from</TOKEN>
        <TOKEN id="token-179-15" pos="word" morph="none" start_char="10655" end_char="10657">the</TOKEN>
        <TOKEN id="token-179-16" pos="word" morph="none" start_char="10659" end_char="10666">cultural</TOKEN>
      </SEG>
      <SEG id="segment-180" start_char="10668" end_char="10735">
        <ORIGINAL_TEXT>context—from Diane Sawyer and NPR and Fox—but also from the volume’s</ORIGINAL_TEXT>
        <TOKEN id="token-180-0" pos="word" morph="none" start_char="10668" end_char="10674">context</TOKEN>
        <TOKEN id="token-180-1" pos="punct" morph="none" start_char="10675" end_char="10675">—</TOKEN>
        <TOKEN id="token-180-2" pos="word" morph="none" start_char="10676" end_char="10679">from</TOKEN>
        <TOKEN id="token-180-3" pos="word" morph="none" start_char="10681" end_char="10685">Diane</TOKEN>
        <TOKEN id="token-180-4" pos="word" morph="none" start_char="10687" end_char="10692">Sawyer</TOKEN>
        <TOKEN id="token-180-5" pos="word" morph="none" start_char="10694" end_char="10696">and</TOKEN>
        <TOKEN id="token-180-6" pos="word" morph="none" start_char="10698" end_char="10700">NPR</TOKEN>
        <TOKEN id="token-180-7" pos="word" morph="none" start_char="10702" end_char="10704">and</TOKEN>
        <TOKEN id="token-180-8" pos="word" morph="none" start_char="10706" end_char="10708">Fox</TOKEN>
        <TOKEN id="token-180-9" pos="punct" morph="none" start_char="10709" end_char="10709">—</TOKEN>
        <TOKEN id="token-180-10" pos="word" morph="none" start_char="10710" end_char="10712">but</TOKEN>
        <TOKEN id="token-180-11" pos="word" morph="none" start_char="10714" end_char="10717">also</TOKEN>
        <TOKEN id="token-180-12" pos="word" morph="none" start_char="10719" end_char="10722">from</TOKEN>
        <TOKEN id="token-180-13" pos="word" morph="none" start_char="10724" end_char="10726">the</TOKEN>
        <TOKEN id="token-180-14" pos="word" morph="none" start_char="10728" end_char="10733">volume</TOKEN>
        <TOKEN id="token-180-15" pos="punct" morph="none" start_char="10734" end_char="10734">’</TOKEN>
        <TOKEN id="token-180-16" pos="word" morph="none" start_char="10735" end_char="10735">s</TOKEN>
      </SEG>
      <SEG id="segment-181" start_char="10737" end_char="10814">
        <ORIGINAL_TEXT>enigmatic conclusion. After 593 pages of writing about foreign policy, Clinton</ORIGINAL_TEXT>
        <TOKEN id="token-181-0" pos="word" morph="none" start_char="10737" end_char="10745">enigmatic</TOKEN>
        <TOKEN id="token-181-1" pos="word" morph="none" start_char="10747" end_char="10756">conclusion</TOKEN>
        <TOKEN id="token-181-2" pos="punct" morph="none" start_char="10757" end_char="10757">.</TOKEN>
        <TOKEN id="token-181-3" pos="word" morph="none" start_char="10759" end_char="10763">After</TOKEN>
        <TOKEN id="token-181-4" pos="number" morph="none" start_char="10765" end_char="10767">593</TOKEN>
        <TOKEN id="token-181-5" pos="word" morph="none" start_char="10769" end_char="10773">pages</TOKEN>
        <TOKEN id="token-181-6" pos="word" morph="none" start_char="10775" end_char="10776">of</TOKEN>
        <TOKEN id="token-181-7" pos="word" morph="none" start_char="10778" end_char="10784">writing</TOKEN>
        <TOKEN id="token-181-8" pos="word" morph="none" start_char="10786" end_char="10790">about</TOKEN>
        <TOKEN id="token-181-9" pos="word" morph="none" start_char="10792" end_char="10798">foreign</TOKEN>
        <TOKEN id="token-181-10" pos="word" morph="none" start_char="10800" end_char="10805">policy</TOKEN>
        <TOKEN id="token-181-11" pos="punct" morph="none" start_char="10806" end_char="10806">,</TOKEN>
        <TOKEN id="token-181-12" pos="word" morph="none" start_char="10808" end_char="10814">Clinton</TOKEN>
      </SEG>
      <SEG id="segment-182" start_char="10816" end_char="10884">
        <ORIGINAL_TEXT>suddenly shifts gear. “Our strength abroad depends on our resolve and</ORIGINAL_TEXT>
        <TOKEN id="token-182-0" pos="word" morph="none" start_char="10816" end_char="10823">suddenly</TOKEN>
        <TOKEN id="token-182-1" pos="word" morph="none" start_char="10825" end_char="10830">shifts</TOKEN>
        <TOKEN id="token-182-2" pos="word" morph="none" start_char="10832" end_char="10835">gear</TOKEN>
        <TOKEN id="token-182-3" pos="punct" morph="none" start_char="10836" end_char="10836">.</TOKEN>
        <TOKEN id="token-182-4" pos="punct" morph="none" start_char="10838" end_char="10838">“</TOKEN>
        <TOKEN id="token-182-5" pos="word" morph="none" start_char="10839" end_char="10841">Our</TOKEN>
        <TOKEN id="token-182-6" pos="word" morph="none" start_char="10843" end_char="10850">strength</TOKEN>
        <TOKEN id="token-182-7" pos="word" morph="none" start_char="10852" end_char="10857">abroad</TOKEN>
        <TOKEN id="token-182-8" pos="word" morph="none" start_char="10859" end_char="10865">depends</TOKEN>
        <TOKEN id="token-182-9" pos="word" morph="none" start_char="10867" end_char="10868">on</TOKEN>
        <TOKEN id="token-182-10" pos="word" morph="none" start_char="10870" end_char="10872">our</TOKEN>
        <TOKEN id="token-182-11" pos="word" morph="none" start_char="10874" end_char="10880">resolve</TOKEN>
        <TOKEN id="token-182-12" pos="word" morph="none" start_char="10882" end_char="10884">and</TOKEN>
      </SEG>
      <SEG id="segment-183" start_char="10886" end_char="10957">
        <ORIGINAL_TEXT>resilience at home,” she declares in her epilogue. “Citizens and leaders</ORIGINAL_TEXT>
        <TOKEN id="token-183-0" pos="word" morph="none" start_char="10886" end_char="10895">resilience</TOKEN>
        <TOKEN id="token-183-1" pos="word" morph="none" start_char="10897" end_char="10898">at</TOKEN>
        <TOKEN id="token-183-2" pos="word" morph="none" start_char="10900" end_char="10903">home</TOKEN>
        <TOKEN id="token-183-3" pos="punct" morph="none" start_char="10904" end_char="10905">,”</TOKEN>
        <TOKEN id="token-183-4" pos="word" morph="none" start_char="10907" end_char="10909">she</TOKEN>
        <TOKEN id="token-183-5" pos="word" morph="none" start_char="10911" end_char="10918">declares</TOKEN>
        <TOKEN id="token-183-6" pos="word" morph="none" start_char="10920" end_char="10921">in</TOKEN>
        <TOKEN id="token-183-7" pos="word" morph="none" start_char="10923" end_char="10925">her</TOKEN>
        <TOKEN id="token-183-8" pos="word" morph="none" start_char="10927" end_char="10934">epilogue</TOKEN>
        <TOKEN id="token-183-9" pos="punct" morph="none" start_char="10935" end_char="10935">.</TOKEN>
        <TOKEN id="token-183-10" pos="punct" morph="none" start_char="10937" end_char="10937">“</TOKEN>
        <TOKEN id="token-183-11" pos="word" morph="none" start_char="10938" end_char="10945">Citizens</TOKEN>
        <TOKEN id="token-183-12" pos="word" morph="none" start_char="10947" end_char="10949">and</TOKEN>
        <TOKEN id="token-183-13" pos="word" morph="none" start_char="10951" end_char="10957">leaders</TOKEN>
      </SEG>
      <SEG id="segment-184" start_char="10959" end_char="11034">
        <ORIGINAL_TEXT>alike have choices to make about the country we want to live in and leave to</ORIGINAL_TEXT>
        <TOKEN id="token-184-0" pos="word" morph="none" start_char="10959" end_char="10963">alike</TOKEN>
        <TOKEN id="token-184-1" pos="word" morph="none" start_char="10965" end_char="10968">have</TOKEN>
        <TOKEN id="token-184-2" pos="word" morph="none" start_char="10970" end_char="10976">choices</TOKEN>
        <TOKEN id="token-184-3" pos="word" morph="none" start_char="10978" end_char="10979">to</TOKEN>
        <TOKEN id="token-184-4" pos="word" morph="none" start_char="10981" end_char="10984">make</TOKEN>
        <TOKEN id="token-184-5" pos="word" morph="none" start_char="10986" end_char="10990">about</TOKEN>
        <TOKEN id="token-184-6" pos="word" morph="none" start_char="10992" end_char="10994">the</TOKEN>
        <TOKEN id="token-184-7" pos="word" morph="none" start_char="10996" end_char="11002">country</TOKEN>
        <TOKEN id="token-184-8" pos="word" morph="none" start_char="11004" end_char="11005">we</TOKEN>
        <TOKEN id="token-184-9" pos="word" morph="none" start_char="11007" end_char="11010">want</TOKEN>
        <TOKEN id="token-184-10" pos="word" morph="none" start_char="11012" end_char="11013">to</TOKEN>
        <TOKEN id="token-184-11" pos="word" morph="none" start_char="11015" end_char="11018">live</TOKEN>
        <TOKEN id="token-184-12" pos="word" morph="none" start_char="11020" end_char="11021">in</TOKEN>
        <TOKEN id="token-184-13" pos="word" morph="none" start_char="11023" end_char="11025">and</TOKEN>
        <TOKEN id="token-184-14" pos="word" morph="none" start_char="11027" end_char="11031">leave</TOKEN>
        <TOKEN id="token-184-15" pos="word" morph="none" start_char="11033" end_char="11034">to</TOKEN>
      </SEG>
      <SEG id="segment-185" start_char="11036" end_char="11109">
        <ORIGINAL_TEXT>the next generation. ... We need more good jobs that reward hard work with</ORIGINAL_TEXT>
        <TOKEN id="token-185-0" pos="word" morph="none" start_char="11036" end_char="11038">the</TOKEN>
        <TOKEN id="token-185-1" pos="word" morph="none" start_char="11040" end_char="11043">next</TOKEN>
        <TOKEN id="token-185-2" pos="word" morph="none" start_char="11045" end_char="11054">generation</TOKEN>
        <TOKEN id="token-185-3" pos="punct" morph="none" start_char="11055" end_char="11055">.</TOKEN>
        <TOKEN id="token-185-4" pos="unknown" morph="none" start_char="11057" end_char="11059">...</TOKEN>
        <TOKEN id="token-185-5" pos="word" morph="none" start_char="11061" end_char="11062">We</TOKEN>
        <TOKEN id="token-185-6" pos="word" morph="none" start_char="11064" end_char="11067">need</TOKEN>
        <TOKEN id="token-185-7" pos="word" morph="none" start_char="11069" end_char="11072">more</TOKEN>
        <TOKEN id="token-185-8" pos="word" morph="none" start_char="11074" end_char="11077">good</TOKEN>
        <TOKEN id="token-185-9" pos="word" morph="none" start_char="11079" end_char="11082">jobs</TOKEN>
        <TOKEN id="token-185-10" pos="word" morph="none" start_char="11084" end_char="11087">that</TOKEN>
        <TOKEN id="token-185-11" pos="word" morph="none" start_char="11089" end_char="11094">reward</TOKEN>
        <TOKEN id="token-185-12" pos="word" morph="none" start_char="11096" end_char="11099">hard</TOKEN>
        <TOKEN id="token-185-13" pos="word" morph="none" start_char="11101" end_char="11104">work</TOKEN>
        <TOKEN id="token-185-14" pos="word" morph="none" start_char="11106" end_char="11109">with</TOKEN>
      </SEG>
      <SEG id="segment-186" start_char="11111" end_char="11164">
        <ORIGINAL_TEXT>rising wages, dignity, and a ladder to a better life.”</ORIGINAL_TEXT>
        <TOKEN id="token-186-0" pos="word" morph="none" start_char="11111" end_char="11116">rising</TOKEN>
        <TOKEN id="token-186-1" pos="word" morph="none" start_char="11118" end_char="11122">wages</TOKEN>
        <TOKEN id="token-186-2" pos="punct" morph="none" start_char="11123" end_char="11123">,</TOKEN>
        <TOKEN id="token-186-3" pos="word" morph="none" start_char="11125" end_char="11131">dignity</TOKEN>
        <TOKEN id="token-186-4" pos="punct" morph="none" start_char="11132" end_char="11132">,</TOKEN>
        <TOKEN id="token-186-5" pos="word" morph="none" start_char="11134" end_char="11136">and</TOKEN>
        <TOKEN id="token-186-6" pos="word" morph="none" start_char="11138" end_char="11138">a</TOKEN>
        <TOKEN id="token-186-7" pos="word" morph="none" start_char="11140" end_char="11145">ladder</TOKEN>
        <TOKEN id="token-186-8" pos="word" morph="none" start_char="11147" end_char="11148">to</TOKEN>
        <TOKEN id="token-186-9" pos="word" morph="none" start_char="11150" end_char="11150">a</TOKEN>
        <TOKEN id="token-186-10" pos="word" morph="none" start_char="11152" end_char="11157">better</TOKEN>
        <TOKEN id="token-186-11" pos="word" morph="none" start_char="11159" end_char="11162">life</TOKEN>
        <TOKEN id="token-186-12" pos="punct" morph="none" start_char="11163" end_char="11164">.”</TOKEN>
      </SEG>
      <SEG id="segment-187" start_char="11166" end_char="11169">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-187-0" pos="unknown" morph="none" start_char="11166" end_char="11169">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-188" start_char="11171" end_char="11173">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-188-0" pos="unknown" morph="none" start_char="11171" end_char="11173">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-189" start_char="11175" end_char="11250">
        <ORIGINAL_TEXT>We know why she has made this gear shift—and she knows that we know. But she</ORIGINAL_TEXT>
        <TOKEN id="token-189-0" pos="word" morph="none" start_char="11175" end_char="11176">We</TOKEN>
        <TOKEN id="token-189-1" pos="word" morph="none" start_char="11178" end_char="11181">know</TOKEN>
        <TOKEN id="token-189-2" pos="word" morph="none" start_char="11183" end_char="11185">why</TOKEN>
        <TOKEN id="token-189-3" pos="word" morph="none" start_char="11187" end_char="11189">she</TOKEN>
        <TOKEN id="token-189-4" pos="word" morph="none" start_char="11191" end_char="11193">has</TOKEN>
        <TOKEN id="token-189-5" pos="word" morph="none" start_char="11195" end_char="11198">made</TOKEN>
        <TOKEN id="token-189-6" pos="word" morph="none" start_char="11200" end_char="11203">this</TOKEN>
        <TOKEN id="token-189-7" pos="word" morph="none" start_char="11205" end_char="11208">gear</TOKEN>
        <TOKEN id="token-189-8" pos="word" morph="none" start_char="11210" end_char="11214">shift</TOKEN>
        <TOKEN id="token-189-9" pos="punct" morph="none" start_char="11215" end_char="11215">—</TOKEN>
        <TOKEN id="token-189-10" pos="word" morph="none" start_char="11216" end_char="11218">and</TOKEN>
        <TOKEN id="token-189-11" pos="word" morph="none" start_char="11220" end_char="11222">she</TOKEN>
        <TOKEN id="token-189-12" pos="word" morph="none" start_char="11224" end_char="11228">knows</TOKEN>
        <TOKEN id="token-189-13" pos="word" morph="none" start_char="11230" end_char="11233">that</TOKEN>
        <TOKEN id="token-189-14" pos="word" morph="none" start_char="11235" end_char="11236">we</TOKEN>
        <TOKEN id="token-189-15" pos="word" morph="none" start_char="11238" end_char="11241">know</TOKEN>
        <TOKEN id="token-189-16" pos="punct" morph="none" start_char="11242" end_char="11242">.</TOKEN>
        <TOKEN id="token-189-17" pos="word" morph="none" start_char="11244" end_char="11246">But</TOKEN>
        <TOKEN id="token-189-18" pos="word" morph="none" start_char="11248" end_char="11250">she</TOKEN>
      </SEG>
      <SEG id="segment-190" start_char="11252" end_char="11324">
        <ORIGINAL_TEXT>tells us anyway: “Over the past year, as I’ve traveled around the country</ORIGINAL_TEXT>
        <TOKEN id="token-190-0" pos="word" morph="none" start_char="11252" end_char="11256">tells</TOKEN>
        <TOKEN id="token-190-1" pos="word" morph="none" start_char="11258" end_char="11259">us</TOKEN>
        <TOKEN id="token-190-2" pos="word" morph="none" start_char="11261" end_char="11266">anyway</TOKEN>
        <TOKEN id="token-190-3" pos="punct" morph="none" start_char="11267" end_char="11267">:</TOKEN>
        <TOKEN id="token-190-4" pos="punct" morph="none" start_char="11269" end_char="11269">“</TOKEN>
        <TOKEN id="token-190-5" pos="word" morph="none" start_char="11270" end_char="11273">Over</TOKEN>
        <TOKEN id="token-190-6" pos="word" morph="none" start_char="11275" end_char="11277">the</TOKEN>
        <TOKEN id="token-190-7" pos="word" morph="none" start_char="11279" end_char="11282">past</TOKEN>
        <TOKEN id="token-190-8" pos="word" morph="none" start_char="11284" end_char="11287">year</TOKEN>
        <TOKEN id="token-190-9" pos="punct" morph="none" start_char="11288" end_char="11288">,</TOKEN>
        <TOKEN id="token-190-10" pos="word" morph="none" start_char="11290" end_char="11291">as</TOKEN>
        <TOKEN id="token-190-11" pos="word" morph="none" start_char="11293" end_char="11293">I</TOKEN>
        <TOKEN id="token-190-12" pos="punct" morph="none" start_char="11294" end_char="11294">’</TOKEN>
        <TOKEN id="token-190-13" pos="word" morph="none" start_char="11295" end_char="11296">ve</TOKEN>
        <TOKEN id="token-190-14" pos="word" morph="none" start_char="11298" end_char="11305">traveled</TOKEN>
        <TOKEN id="token-190-15" pos="word" morph="none" start_char="11307" end_char="11312">around</TOKEN>
        <TOKEN id="token-190-16" pos="word" morph="none" start_char="11314" end_char="11316">the</TOKEN>
        <TOKEN id="token-190-17" pos="word" morph="none" start_char="11318" end_char="11324">country</TOKEN>
      </SEG>
      <SEG id="segment-191" start_char="11326" end_char="11398">
        <ORIGINAL_TEXT>once again, the one question I’m asked more than any other is: Will I run</ORIGINAL_TEXT>
        <TOKEN id="token-191-0" pos="word" morph="none" start_char="11326" end_char="11329">once</TOKEN>
        <TOKEN id="token-191-1" pos="word" morph="none" start_char="11331" end_char="11335">again</TOKEN>
        <TOKEN id="token-191-2" pos="punct" morph="none" start_char="11336" end_char="11336">,</TOKEN>
        <TOKEN id="token-191-3" pos="word" morph="none" start_char="11338" end_char="11340">the</TOKEN>
        <TOKEN id="token-191-4" pos="word" morph="none" start_char="11342" end_char="11344">one</TOKEN>
        <TOKEN id="token-191-5" pos="word" morph="none" start_char="11346" end_char="11353">question</TOKEN>
        <TOKEN id="token-191-6" pos="word" morph="none" start_char="11355" end_char="11355">I</TOKEN>
        <TOKEN id="token-191-7" pos="punct" morph="none" start_char="11356" end_char="11356">’</TOKEN>
        <TOKEN id="token-191-8" pos="word" morph="none" start_char="11357" end_char="11357">m</TOKEN>
        <TOKEN id="token-191-9" pos="word" morph="none" start_char="11359" end_char="11363">asked</TOKEN>
        <TOKEN id="token-191-10" pos="word" morph="none" start_char="11365" end_char="11368">more</TOKEN>
        <TOKEN id="token-191-11" pos="word" morph="none" start_char="11370" end_char="11373">than</TOKEN>
        <TOKEN id="token-191-12" pos="word" morph="none" start_char="11375" end_char="11377">any</TOKEN>
        <TOKEN id="token-191-13" pos="word" morph="none" start_char="11379" end_char="11383">other</TOKEN>
        <TOKEN id="token-191-14" pos="word" morph="none" start_char="11385" end_char="11386">is</TOKEN>
        <TOKEN id="token-191-15" pos="punct" morph="none" start_char="11387" end_char="11387">:</TOKEN>
        <TOKEN id="token-191-16" pos="word" morph="none" start_char="11389" end_char="11392">Will</TOKEN>
        <TOKEN id="token-191-17" pos="word" morph="none" start_char="11394" end_char="11394">I</TOKEN>
        <TOKEN id="token-191-18" pos="word" morph="none" start_char="11396" end_char="11398">run</TOKEN>
      </SEG>
      <SEG id="segment-192" start_char="11400" end_char="11467">
        <ORIGINAL_TEXT>for President in 2016?” And the answer? “I haven’t decided yet.” She</ORIGINAL_TEXT>
        <TOKEN id="token-192-0" pos="word" morph="none" start_char="11400" end_char="11402">for</TOKEN>
        <TOKEN id="token-192-1" pos="word" morph="none" start_char="11404" end_char="11412">President</TOKEN>
        <TOKEN id="token-192-2" pos="word" morph="none" start_char="11414" end_char="11415">in</TOKEN>
        <TOKEN id="token-192-3" pos="word" morph="none" start_char="11417" end_char="11420">2016</TOKEN>
        <TOKEN id="token-192-4" pos="punct" morph="none" start_char="11421" end_char="11422">?”</TOKEN>
        <TOKEN id="token-192-5" pos="word" morph="none" start_char="11424" end_char="11426">And</TOKEN>
        <TOKEN id="token-192-6" pos="word" morph="none" start_char="11428" end_char="11430">the</TOKEN>
        <TOKEN id="token-192-7" pos="word" morph="none" start_char="11432" end_char="11437">answer</TOKEN>
        <TOKEN id="token-192-8" pos="punct" morph="none" start_char="11438" end_char="11438">?</TOKEN>
        <TOKEN id="token-192-9" pos="punct" morph="none" start_char="11440" end_char="11440">“</TOKEN>
        <TOKEN id="token-192-10" pos="word" morph="none" start_char="11441" end_char="11441">I</TOKEN>
        <TOKEN id="token-192-11" pos="word" morph="none" start_char="11443" end_char="11447">haven</TOKEN>
        <TOKEN id="token-192-12" pos="punct" morph="none" start_char="11448" end_char="11448">’</TOKEN>
        <TOKEN id="token-192-13" pos="word" morph="none" start_char="11449" end_char="11449">t</TOKEN>
        <TOKEN id="token-192-14" pos="word" morph="none" start_char="11451" end_char="11457">decided</TOKEN>
        <TOKEN id="token-192-15" pos="word" morph="none" start_char="11459" end_char="11461">yet</TOKEN>
        <TOKEN id="token-192-16" pos="punct" morph="none" start_char="11462" end_char="11463">.”</TOKEN>
        <TOKEN id="token-192-17" pos="word" morph="none" start_char="11465" end_char="11467">She</TOKEN>
      </SEG>
      <SEG id="segment-193" start_char="11469" end_char="11477">
        <ORIGINAL_TEXT>explains:</ORIGINAL_TEXT>
        <TOKEN id="token-193-0" pos="word" morph="none" start_char="11469" end_char="11476">explains</TOKEN>
        <TOKEN id="token-193-1" pos="punct" morph="none" start_char="11477" end_char="11477">:</TOKEN>
      </SEG>
      <SEG id="segment-194" start_char="11479" end_char="11482">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-194-0" pos="unknown" morph="none" start_char="11479" end_char="11482">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-195" start_char="11484" end_char="11486">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-195-0" pos="unknown" morph="none" start_char="11484" end_char="11486">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-196" start_char="11488" end_char="11559">
        <ORIGINAL_TEXT>Whatever I decide, I will always be thankful for the chance to represent</ORIGINAL_TEXT>
        <TOKEN id="token-196-0" pos="word" morph="none" start_char="11488" end_char="11495">Whatever</TOKEN>
        <TOKEN id="token-196-1" pos="word" morph="none" start_char="11497" end_char="11497">I</TOKEN>
        <TOKEN id="token-196-2" pos="word" morph="none" start_char="11499" end_char="11504">decide</TOKEN>
        <TOKEN id="token-196-3" pos="punct" morph="none" start_char="11505" end_char="11505">,</TOKEN>
        <TOKEN id="token-196-4" pos="word" morph="none" start_char="11507" end_char="11507">I</TOKEN>
        <TOKEN id="token-196-5" pos="word" morph="none" start_char="11509" end_char="11512">will</TOKEN>
        <TOKEN id="token-196-6" pos="word" morph="none" start_char="11514" end_char="11519">always</TOKEN>
        <TOKEN id="token-196-7" pos="word" morph="none" start_char="11521" end_char="11522">be</TOKEN>
        <TOKEN id="token-196-8" pos="word" morph="none" start_char="11524" end_char="11531">thankful</TOKEN>
        <TOKEN id="token-196-9" pos="word" morph="none" start_char="11533" end_char="11535">for</TOKEN>
        <TOKEN id="token-196-10" pos="word" morph="none" start_char="11537" end_char="11539">the</TOKEN>
        <TOKEN id="token-196-11" pos="word" morph="none" start_char="11541" end_char="11546">chance</TOKEN>
        <TOKEN id="token-196-12" pos="word" morph="none" start_char="11548" end_char="11549">to</TOKEN>
        <TOKEN id="token-196-13" pos="word" morph="none" start_char="11551" end_char="11559">represent</TOKEN>
      </SEG>
      <SEG id="segment-197" start_char="11561" end_char="11636">
        <ORIGINAL_TEXT>America around the world. I have learned anew the goodness of our people and</ORIGINAL_TEXT>
        <TOKEN id="token-197-0" pos="word" morph="none" start_char="11561" end_char="11567">America</TOKEN>
        <TOKEN id="token-197-1" pos="word" morph="none" start_char="11569" end_char="11574">around</TOKEN>
        <TOKEN id="token-197-2" pos="word" morph="none" start_char="11576" end_char="11578">the</TOKEN>
        <TOKEN id="token-197-3" pos="word" morph="none" start_char="11580" end_char="11584">world</TOKEN>
        <TOKEN id="token-197-4" pos="punct" morph="none" start_char="11585" end_char="11585">.</TOKEN>
        <TOKEN id="token-197-5" pos="word" morph="none" start_char="11587" end_char="11587">I</TOKEN>
        <TOKEN id="token-197-6" pos="word" morph="none" start_char="11589" end_char="11592">have</TOKEN>
        <TOKEN id="token-197-7" pos="word" morph="none" start_char="11594" end_char="11600">learned</TOKEN>
        <TOKEN id="token-197-8" pos="word" morph="none" start_char="11602" end_char="11605">anew</TOKEN>
        <TOKEN id="token-197-9" pos="word" morph="none" start_char="11607" end_char="11609">the</TOKEN>
        <TOKEN id="token-197-10" pos="word" morph="none" start_char="11611" end_char="11618">goodness</TOKEN>
        <TOKEN id="token-197-11" pos="word" morph="none" start_char="11620" end_char="11621">of</TOKEN>
        <TOKEN id="token-197-12" pos="word" morph="none" start_char="11623" end_char="11625">our</TOKEN>
        <TOKEN id="token-197-13" pos="word" morph="none" start_char="11627" end_char="11632">people</TOKEN>
        <TOKEN id="token-197-14" pos="word" morph="none" start_char="11634" end_char="11636">and</TOKEN>
      </SEG>
      <SEG id="segment-198" start_char="11638" end_char="11711">
        <ORIGINAL_TEXT>the greatness of our nation. I feel blessed and grateful. Our future is so</ORIGINAL_TEXT>
        <TOKEN id="token-198-0" pos="word" morph="none" start_char="11638" end_char="11640">the</TOKEN>
        <TOKEN id="token-198-1" pos="word" morph="none" start_char="11642" end_char="11650">greatness</TOKEN>
        <TOKEN id="token-198-2" pos="word" morph="none" start_char="11652" end_char="11653">of</TOKEN>
        <TOKEN id="token-198-3" pos="word" morph="none" start_char="11655" end_char="11657">our</TOKEN>
        <TOKEN id="token-198-4" pos="word" morph="none" start_char="11659" end_char="11664">nation</TOKEN>
        <TOKEN id="token-198-5" pos="punct" morph="none" start_char="11665" end_char="11665">.</TOKEN>
        <TOKEN id="token-198-6" pos="word" morph="none" start_char="11667" end_char="11667">I</TOKEN>
        <TOKEN id="token-198-7" pos="word" morph="none" start_char="11669" end_char="11672">feel</TOKEN>
        <TOKEN id="token-198-8" pos="word" morph="none" start_char="11674" end_char="11680">blessed</TOKEN>
        <TOKEN id="token-198-9" pos="word" morph="none" start_char="11682" end_char="11684">and</TOKEN>
        <TOKEN id="token-198-10" pos="word" morph="none" start_char="11686" end_char="11693">grateful</TOKEN>
        <TOKEN id="token-198-11" pos="punct" morph="none" start_char="11694" end_char="11694">.</TOKEN>
        <TOKEN id="token-198-12" pos="word" morph="none" start_char="11696" end_char="11698">Our</TOKEN>
        <TOKEN id="token-198-13" pos="word" morph="none" start_char="11700" end_char="11705">future</TOKEN>
        <TOKEN id="token-198-14" pos="word" morph="none" start_char="11707" end_char="11708">is</TOKEN>
        <TOKEN id="token-198-15" pos="word" morph="none" start_char="11710" end_char="11711">so</TOKEN>
      </SEG>
      <SEG id="segment-199" start_char="11713" end_char="11790">
        <ORIGINAL_TEXT>full of possibility. And for me and my family that includes looking forward to</ORIGINAL_TEXT>
        <TOKEN id="token-199-0" pos="word" morph="none" start_char="11713" end_char="11716">full</TOKEN>
        <TOKEN id="token-199-1" pos="word" morph="none" start_char="11718" end_char="11719">of</TOKEN>
        <TOKEN id="token-199-2" pos="word" morph="none" start_char="11721" end_char="11731">possibility</TOKEN>
        <TOKEN id="token-199-3" pos="punct" morph="none" start_char="11732" end_char="11732">.</TOKEN>
        <TOKEN id="token-199-4" pos="word" morph="none" start_char="11734" end_char="11736">And</TOKEN>
        <TOKEN id="token-199-5" pos="word" morph="none" start_char="11738" end_char="11740">for</TOKEN>
        <TOKEN id="token-199-6" pos="word" morph="none" start_char="11742" end_char="11743">me</TOKEN>
        <TOKEN id="token-199-7" pos="word" morph="none" start_char="11745" end_char="11747">and</TOKEN>
        <TOKEN id="token-199-8" pos="word" morph="none" start_char="11749" end_char="11750">my</TOKEN>
        <TOKEN id="token-199-9" pos="word" morph="none" start_char="11752" end_char="11757">family</TOKEN>
        <TOKEN id="token-199-10" pos="word" morph="none" start_char="11759" end_char="11762">that</TOKEN>
        <TOKEN id="token-199-11" pos="word" morph="none" start_char="11764" end_char="11771">includes</TOKEN>
        <TOKEN id="token-199-12" pos="word" morph="none" start_char="11773" end_char="11779">looking</TOKEN>
        <TOKEN id="token-199-13" pos="word" morph="none" start_char="11781" end_char="11787">forward</TOKEN>
        <TOKEN id="token-199-14" pos="word" morph="none" start_char="11789" end_char="11790">to</TOKEN>
      </SEG>
      <SEG id="segment-200" start_char="11792" end_char="11864">
        <ORIGINAL_TEXT>a new addition— another American who deserves the best possible future we</ORIGINAL_TEXT>
        <TOKEN id="token-200-0" pos="word" morph="none" start_char="11792" end_char="11792">a</TOKEN>
        <TOKEN id="token-200-1" pos="word" morph="none" start_char="11794" end_char="11796">new</TOKEN>
        <TOKEN id="token-200-2" pos="word" morph="none" start_char="11798" end_char="11805">addition</TOKEN>
        <TOKEN id="token-200-3" pos="punct" morph="none" start_char="11806" end_char="11806">—</TOKEN>
        <TOKEN id="token-200-4" pos="word" morph="none" start_char="11808" end_char="11814">another</TOKEN>
        <TOKEN id="token-200-5" pos="word" morph="none" start_char="11816" end_char="11823">American</TOKEN>
        <TOKEN id="token-200-6" pos="word" morph="none" start_char="11825" end_char="11827">who</TOKEN>
        <TOKEN id="token-200-7" pos="word" morph="none" start_char="11829" end_char="11836">deserves</TOKEN>
        <TOKEN id="token-200-8" pos="word" morph="none" start_char="11838" end_char="11840">the</TOKEN>
        <TOKEN id="token-200-9" pos="word" morph="none" start_char="11842" end_char="11845">best</TOKEN>
        <TOKEN id="token-200-10" pos="word" morph="none" start_char="11847" end_char="11854">possible</TOKEN>
        <TOKEN id="token-200-11" pos="word" morph="none" start_char="11856" end_char="11861">future</TOKEN>
        <TOKEN id="token-200-12" pos="word" morph="none" start_char="11863" end_char="11864">we</TOKEN>
      </SEG>
      <SEG id="segment-201" start_char="11866" end_char="11943">
        <ORIGINAL_TEXT>can offer. ... There have been too few quiet moments like this over the years.</ORIGINAL_TEXT>
        <TOKEN id="token-201-0" pos="word" morph="none" start_char="11866" end_char="11868">can</TOKEN>
        <TOKEN id="token-201-1" pos="word" morph="none" start_char="11870" end_char="11874">offer</TOKEN>
        <TOKEN id="token-201-2" pos="punct" morph="none" start_char="11875" end_char="11875">.</TOKEN>
        <TOKEN id="token-201-3" pos="unknown" morph="none" start_char="11877" end_char="11879">...</TOKEN>
        <TOKEN id="token-201-4" pos="word" morph="none" start_char="11881" end_char="11885">There</TOKEN>
        <TOKEN id="token-201-5" pos="word" morph="none" start_char="11887" end_char="11890">have</TOKEN>
        <TOKEN id="token-201-6" pos="word" morph="none" start_char="11892" end_char="11895">been</TOKEN>
        <TOKEN id="token-201-7" pos="word" morph="none" start_char="11897" end_char="11899">too</TOKEN>
        <TOKEN id="token-201-8" pos="word" morph="none" start_char="11901" end_char="11903">few</TOKEN>
        <TOKEN id="token-201-9" pos="word" morph="none" start_char="11905" end_char="11909">quiet</TOKEN>
        <TOKEN id="token-201-10" pos="word" morph="none" start_char="11911" end_char="11917">moments</TOKEN>
        <TOKEN id="token-201-11" pos="word" morph="none" start_char="11919" end_char="11922">like</TOKEN>
        <TOKEN id="token-201-12" pos="word" morph="none" start_char="11924" end_char="11927">this</TOKEN>
        <TOKEN id="token-201-13" pos="word" morph="none" start_char="11929" end_char="11932">over</TOKEN>
        <TOKEN id="token-201-14" pos="word" morph="none" start_char="11934" end_char="11936">the</TOKEN>
        <TOKEN id="token-201-15" pos="word" morph="none" start_char="11938" end_char="11942">years</TOKEN>
        <TOKEN id="token-201-16" pos="punct" morph="none" start_char="11943" end_char="11943">.</TOKEN>
      </SEG>
      <SEG id="segment-202" start_char="11945" end_char="12017">
        <ORIGINAL_TEXT>And I want to savor them. The time for another hard choice will come soon</ORIGINAL_TEXT>
        <TOKEN id="token-202-0" pos="word" morph="none" start_char="11945" end_char="11947">And</TOKEN>
        <TOKEN id="token-202-1" pos="word" morph="none" start_char="11949" end_char="11949">I</TOKEN>
        <TOKEN id="token-202-2" pos="word" morph="none" start_char="11951" end_char="11954">want</TOKEN>
        <TOKEN id="token-202-3" pos="word" morph="none" start_char="11956" end_char="11957">to</TOKEN>
        <TOKEN id="token-202-4" pos="word" morph="none" start_char="11959" end_char="11963">savor</TOKEN>
        <TOKEN id="token-202-5" pos="word" morph="none" start_char="11965" end_char="11968">them</TOKEN>
        <TOKEN id="token-202-6" pos="punct" morph="none" start_char="11969" end_char="11969">.</TOKEN>
        <TOKEN id="token-202-7" pos="word" morph="none" start_char="11971" end_char="11973">The</TOKEN>
        <TOKEN id="token-202-8" pos="word" morph="none" start_char="11975" end_char="11978">time</TOKEN>
        <TOKEN id="token-202-9" pos="word" morph="none" start_char="11980" end_char="11982">for</TOKEN>
        <TOKEN id="token-202-10" pos="word" morph="none" start_char="11984" end_char="11990">another</TOKEN>
        <TOKEN id="token-202-11" pos="word" morph="none" start_char="11992" end_char="11995">hard</TOKEN>
        <TOKEN id="token-202-12" pos="word" morph="none" start_char="11997" end_char="12002">choice</TOKEN>
        <TOKEN id="token-202-13" pos="word" morph="none" start_char="12004" end_char="12007">will</TOKEN>
        <TOKEN id="token-202-14" pos="word" morph="none" start_char="12009" end_char="12012">come</TOKEN>
        <TOKEN id="token-202-15" pos="word" morph="none" start_char="12014" end_char="12017">soon</TOKEN>
      </SEG>
      <SEG id="segment-203" start_char="12019" end_char="12025">
        <ORIGINAL_TEXT>enough.</ORIGINAL_TEXT>
        <TOKEN id="token-203-0" pos="word" morph="none" start_char="12019" end_char="12024">enough</TOKEN>
        <TOKEN id="token-203-1" pos="punct" morph="none" start_char="12025" end_char="12025">.</TOKEN>
      </SEG>
      <SEG id="segment-204" start_char="12027" end_char="12030">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-204-0" pos="unknown" morph="none" start_char="12027" end_char="12030">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-205" start_char="12032" end_char="12034">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-205-0" pos="unknown" morph="none" start_char="12032" end_char="12034">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-206" start_char="12036" end_char="12111">
        <ORIGINAL_TEXT>And thus, having spent 595 pages eschewing anything that might look remotely</ORIGINAL_TEXT>
        <TOKEN id="token-206-0" pos="word" morph="none" start_char="12036" end_char="12038">And</TOKEN>
        <TOKEN id="token-206-1" pos="word" morph="none" start_char="12040" end_char="12043">thus</TOKEN>
        <TOKEN id="token-206-2" pos="punct" morph="none" start_char="12044" end_char="12044">,</TOKEN>
        <TOKEN id="token-206-3" pos="word" morph="none" start_char="12046" end_char="12051">having</TOKEN>
        <TOKEN id="token-206-4" pos="word" morph="none" start_char="12053" end_char="12057">spent</TOKEN>
        <TOKEN id="token-206-5" pos="number" morph="none" start_char="12059" end_char="12061">595</TOKEN>
        <TOKEN id="token-206-6" pos="word" morph="none" start_char="12063" end_char="12067">pages</TOKEN>
        <TOKEN id="token-206-7" pos="word" morph="none" start_char="12069" end_char="12077">eschewing</TOKEN>
        <TOKEN id="token-206-8" pos="word" morph="none" start_char="12079" end_char="12086">anything</TOKEN>
        <TOKEN id="token-206-9" pos="word" morph="none" start_char="12088" end_char="12091">that</TOKEN>
        <TOKEN id="token-206-10" pos="word" morph="none" start_char="12093" end_char="12097">might</TOKEN>
        <TOKEN id="token-206-11" pos="word" morph="none" start_char="12099" end_char="12102">look</TOKEN>
        <TOKEN id="token-206-12" pos="word" morph="none" start_char="12104" end_char="12111">remotely</TOKEN>
      </SEG>
      <SEG id="segment-207" start_char="12113" end_char="12189">
        <ORIGINAL_TEXT>like a literary device, Clinton finally resorts to the oldest one of all: the</ORIGINAL_TEXT>
        <TOKEN id="token-207-0" pos="word" morph="none" start_char="12113" end_char="12116">like</TOKEN>
        <TOKEN id="token-207-1" pos="word" morph="none" start_char="12118" end_char="12118">a</TOKEN>
        <TOKEN id="token-207-2" pos="word" morph="none" start_char="12120" end_char="12127">literary</TOKEN>
        <TOKEN id="token-207-3" pos="word" morph="none" start_char="12129" end_char="12134">device</TOKEN>
        <TOKEN id="token-207-4" pos="punct" morph="none" start_char="12135" end_char="12135">,</TOKEN>
        <TOKEN id="token-207-5" pos="word" morph="none" start_char="12137" end_char="12143">Clinton</TOKEN>
        <TOKEN id="token-207-6" pos="word" morph="none" start_char="12145" end_char="12151">finally</TOKEN>
        <TOKEN id="token-207-7" pos="word" morph="none" start_char="12153" end_char="12159">resorts</TOKEN>
        <TOKEN id="token-207-8" pos="word" morph="none" start_char="12161" end_char="12162">to</TOKEN>
        <TOKEN id="token-207-9" pos="word" morph="none" start_char="12164" end_char="12166">the</TOKEN>
        <TOKEN id="token-207-10" pos="word" morph="none" start_char="12168" end_char="12173">oldest</TOKEN>
        <TOKEN id="token-207-11" pos="word" morph="none" start_char="12175" end_char="12177">one</TOKEN>
        <TOKEN id="token-207-12" pos="word" morph="none" start_char="12179" end_char="12180">of</TOKEN>
        <TOKEN id="token-207-13" pos="word" morph="none" start_char="12182" end_char="12184">all</TOKEN>
        <TOKEN id="token-207-14" pos="punct" morph="none" start_char="12185" end_char="12185">:</TOKEN>
        <TOKEN id="token-207-15" pos="word" morph="none" start_char="12187" end_char="12189">the</TOKEN>
      </SEG>
      <SEG id="segment-208" start_char="12191" end_char="12202">
        <ORIGINAL_TEXT>cliffhanger.</ORIGINAL_TEXT>
        <TOKEN id="token-208-0" pos="word" morph="none" start_char="12191" end_char="12201">cliffhanger</TOKEN>
        <TOKEN id="token-208-1" pos="punct" morph="none" start_char="12202" end_char="12202">.</TOKEN>
      </SEG>
      <SEG id="segment-209" start_char="12204" end_char="12207">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-209-0" pos="unknown" morph="none" start_char="12204" end_char="12207">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-210" start_char="12209" end_char="12211">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-210-0" pos="unknown" morph="none" start_char="12209" end_char="12211">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-211" start_char="12213" end_char="12289">
        <ORIGINAL_TEXT>In the end Hard Choices is not history, and not political philosophy, and not</ORIGINAL_TEXT>
        <TOKEN id="token-211-0" pos="word" morph="none" start_char="12213" end_char="12214">In</TOKEN>
        <TOKEN id="token-211-1" pos="word" morph="none" start_char="12216" end_char="12218">the</TOKEN>
        <TOKEN id="token-211-2" pos="word" morph="none" start_char="12220" end_char="12222">end</TOKEN>
        <TOKEN id="token-211-3" pos="word" morph="none" start_char="12224" end_char="12227">Hard</TOKEN>
        <TOKEN id="token-211-4" pos="word" morph="none" start_char="12229" end_char="12235">Choices</TOKEN>
        <TOKEN id="token-211-5" pos="word" morph="none" start_char="12237" end_char="12238">is</TOKEN>
        <TOKEN id="token-211-6" pos="word" morph="none" start_char="12240" end_char="12242">not</TOKEN>
        <TOKEN id="token-211-7" pos="word" morph="none" start_char="12244" end_char="12250">history</TOKEN>
        <TOKEN id="token-211-8" pos="punct" morph="none" start_char="12251" end_char="12251">,</TOKEN>
        <TOKEN id="token-211-9" pos="word" morph="none" start_char="12253" end_char="12255">and</TOKEN>
        <TOKEN id="token-211-10" pos="word" morph="none" start_char="12257" end_char="12259">not</TOKEN>
        <TOKEN id="token-211-11" pos="word" morph="none" start_char="12261" end_char="12269">political</TOKEN>
        <TOKEN id="token-211-12" pos="word" morph="none" start_char="12271" end_char="12280">philosophy</TOKEN>
        <TOKEN id="token-211-13" pos="punct" morph="none" start_char="12281" end_char="12281">,</TOKEN>
        <TOKEN id="token-211-14" pos="word" morph="none" start_char="12283" end_char="12285">and</TOKEN>
        <TOKEN id="token-211-15" pos="word" morph="none" start_char="12287" end_char="12289">not</TOKEN>
      </SEG>
      <SEG id="segment-212" start_char="12291" end_char="12359">
        <ORIGINAL_TEXT>auto-biography. It belongs to an altogether narrower genre. Like Mitt</ORIGINAL_TEXT>
        <TOKEN id="token-212-0" pos="word" morph="none" start_char="12291" end_char="12294">auto</TOKEN>
        <TOKEN id="token-212-1" pos="punct" morph="none" start_char="12295" end_char="12295">-</TOKEN>
        <TOKEN id="token-212-2" pos="word" morph="none" start_char="12296" end_char="12304">biography</TOKEN>
        <TOKEN id="token-212-3" pos="punct" morph="none" start_char="12305" end_char="12305">.</TOKEN>
        <TOKEN id="token-212-4" pos="word" morph="none" start_char="12307" end_char="12308">It</TOKEN>
        <TOKEN id="token-212-5" pos="word" morph="none" start_char="12310" end_char="12316">belongs</TOKEN>
        <TOKEN id="token-212-6" pos="word" morph="none" start_char="12318" end_char="12319">to</TOKEN>
        <TOKEN id="token-212-7" pos="word" morph="none" start_char="12321" end_char="12322">an</TOKEN>
        <TOKEN id="token-212-8" pos="word" morph="none" start_char="12324" end_char="12333">altogether</TOKEN>
        <TOKEN id="token-212-9" pos="word" morph="none" start_char="12335" end_char="12342">narrower</TOKEN>
        <TOKEN id="token-212-10" pos="word" morph="none" start_char="12344" end_char="12348">genre</TOKEN>
        <TOKEN id="token-212-11" pos="punct" morph="none" start_char="12349" end_char="12349">.</TOKEN>
        <TOKEN id="token-212-12" pos="word" morph="none" start_char="12351" end_char="12354">Like</TOKEN>
        <TOKEN id="token-212-13" pos="word" morph="none" start_char="12356" end_char="12359">Mitt</TOKEN>
      </SEG>
      <SEG id="segment-213" start_char="12361" end_char="12432">
        <ORIGINAL_TEXT>Romney’s No Apology: The Case for American Greatness, Barack Obama’s The</ORIGINAL_TEXT>
        <TOKEN id="token-213-0" pos="word" morph="none" start_char="12361" end_char="12366">Romney</TOKEN>
        <TOKEN id="token-213-1" pos="punct" morph="none" start_char="12367" end_char="12367">’</TOKEN>
        <TOKEN id="token-213-2" pos="word" morph="none" start_char="12368" end_char="12368">s</TOKEN>
        <TOKEN id="token-213-3" pos="word" morph="none" start_char="12370" end_char="12371">No</TOKEN>
        <TOKEN id="token-213-4" pos="word" morph="none" start_char="12373" end_char="12379">Apology</TOKEN>
        <TOKEN id="token-213-5" pos="punct" morph="none" start_char="12380" end_char="12380">:</TOKEN>
        <TOKEN id="token-213-6" pos="word" morph="none" start_char="12382" end_char="12384">The</TOKEN>
        <TOKEN id="token-213-7" pos="word" morph="none" start_char="12386" end_char="12389">Case</TOKEN>
        <TOKEN id="token-213-8" pos="word" morph="none" start_char="12391" end_char="12393">for</TOKEN>
        <TOKEN id="token-213-9" pos="word" morph="none" start_char="12395" end_char="12402">American</TOKEN>
        <TOKEN id="token-213-10" pos="word" morph="none" start_char="12404" end_char="12412">Greatness</TOKEN>
        <TOKEN id="token-213-11" pos="punct" morph="none" start_char="12413" end_char="12413">,</TOKEN>
        <TOKEN id="token-213-12" pos="word" morph="none" start_char="12415" end_char="12420">Barack</TOKEN>
        <TOKEN id="token-213-13" pos="word" morph="none" start_char="12422" end_char="12426">Obama</TOKEN>
        <TOKEN id="token-213-14" pos="punct" morph="none" start_char="12427" end_char="12427">’</TOKEN>
        <TOKEN id="token-213-15" pos="word" morph="none" start_char="12428" end_char="12428">s</TOKEN>
        <TOKEN id="token-213-16" pos="word" morph="none" start_char="12430" end_char="12432">The</TOKEN>
      </SEG>
      <SEG id="segment-214" start_char="12434" end_char="12509">
        <ORIGINAL_TEXT>Audacity of Hope: Thoughts on Reclaiming the American Dream, Newt Gingrich’s</ORIGINAL_TEXT>
        <TOKEN id="token-214-0" pos="word" morph="none" start_char="12434" end_char="12441">Audacity</TOKEN>
        <TOKEN id="token-214-1" pos="word" morph="none" start_char="12443" end_char="12444">of</TOKEN>
        <TOKEN id="token-214-2" pos="word" morph="none" start_char="12446" end_char="12449">Hope</TOKEN>
        <TOKEN id="token-214-3" pos="punct" morph="none" start_char="12450" end_char="12450">:</TOKEN>
        <TOKEN id="token-214-4" pos="word" morph="none" start_char="12452" end_char="12459">Thoughts</TOKEN>
        <TOKEN id="token-214-5" pos="word" morph="none" start_char="12461" end_char="12462">on</TOKEN>
        <TOKEN id="token-214-6" pos="word" morph="none" start_char="12464" end_char="12473">Reclaiming</TOKEN>
        <TOKEN id="token-214-7" pos="word" morph="none" start_char="12475" end_char="12477">the</TOKEN>
        <TOKEN id="token-214-8" pos="word" morph="none" start_char="12479" end_char="12486">American</TOKEN>
        <TOKEN id="token-214-9" pos="word" morph="none" start_char="12488" end_char="12492">Dream</TOKEN>
        <TOKEN id="token-214-10" pos="punct" morph="none" start_char="12493" end_char="12493">,</TOKEN>
        <TOKEN id="token-214-11" pos="word" morph="none" start_char="12495" end_char="12498">Newt</TOKEN>
        <TOKEN id="token-214-12" pos="word" morph="none" start_char="12500" end_char="12507">Gingrich</TOKEN>
        <TOKEN id="token-214-13" pos="punct" morph="none" start_char="12508" end_char="12508">’</TOKEN>
        <TOKEN id="token-214-14" pos="word" morph="none" start_char="12509" end_char="12509">s</TOKEN>
      </SEG>
      <SEG id="segment-215" start_char="12511" end_char="12579">
        <ORIGINAL_TEXT>A Nation Like No Other: Why American Exceptionalism Matters, and John</ORIGINAL_TEXT>
        <TOKEN id="token-215-0" pos="word" morph="none" start_char="12511" end_char="12511">A</TOKEN>
        <TOKEN id="token-215-1" pos="word" morph="none" start_char="12513" end_char="12518">Nation</TOKEN>
        <TOKEN id="token-215-2" pos="word" morph="none" start_char="12520" end_char="12523">Like</TOKEN>
        <TOKEN id="token-215-3" pos="word" morph="none" start_char="12525" end_char="12526">No</TOKEN>
        <TOKEN id="token-215-4" pos="word" morph="none" start_char="12528" end_char="12532">Other</TOKEN>
        <TOKEN id="token-215-5" pos="punct" morph="none" start_char="12533" end_char="12533">:</TOKEN>
        <TOKEN id="token-215-6" pos="word" morph="none" start_char="12535" end_char="12537">Why</TOKEN>
        <TOKEN id="token-215-7" pos="word" morph="none" start_char="12539" end_char="12546">American</TOKEN>
        <TOKEN id="token-215-8" pos="word" morph="none" start_char="12548" end_char="12561">Exceptionalism</TOKEN>
        <TOKEN id="token-215-9" pos="word" morph="none" start_char="12563" end_char="12569">Matters</TOKEN>
        <TOKEN id="token-215-10" pos="punct" morph="none" start_char="12570" end_char="12570">,</TOKEN>
        <TOKEN id="token-215-11" pos="word" morph="none" start_char="12572" end_char="12574">and</TOKEN>
        <TOKEN id="token-215-12" pos="word" morph="none" start_char="12576" end_char="12579">John</TOKEN>
      </SEG>
      <SEG id="segment-216" start_char="12581" end_char="12655">
        <ORIGINAL_TEXT>Kerry’s A Call to Service: My Vision for a Better America, Hard Choices is,</ORIGINAL_TEXT>
        <TOKEN id="token-216-0" pos="word" morph="none" start_char="12581" end_char="12585">Kerry</TOKEN>
        <TOKEN id="token-216-1" pos="punct" morph="none" start_char="12586" end_char="12586">’</TOKEN>
        <TOKEN id="token-216-2" pos="word" morph="none" start_char="12587" end_char="12587">s</TOKEN>
        <TOKEN id="token-216-3" pos="word" morph="none" start_char="12589" end_char="12589">A</TOKEN>
        <TOKEN id="token-216-4" pos="word" morph="none" start_char="12591" end_char="12594">Call</TOKEN>
        <TOKEN id="token-216-5" pos="word" morph="none" start_char="12596" end_char="12597">to</TOKEN>
        <TOKEN id="token-216-6" pos="word" morph="none" start_char="12599" end_char="12605">Service</TOKEN>
        <TOKEN id="token-216-7" pos="punct" morph="none" start_char="12606" end_char="12606">:</TOKEN>
        <TOKEN id="token-216-8" pos="word" morph="none" start_char="12608" end_char="12609">My</TOKEN>
        <TOKEN id="token-216-9" pos="word" morph="none" start_char="12611" end_char="12616">Vision</TOKEN>
        <TOKEN id="token-216-10" pos="word" morph="none" start_char="12618" end_char="12620">for</TOKEN>
        <TOKEN id="token-216-11" pos="word" morph="none" start_char="12622" end_char="12622">a</TOKEN>
        <TOKEN id="token-216-12" pos="word" morph="none" start_char="12624" end_char="12629">Better</TOKEN>
        <TOKEN id="token-216-13" pos="word" morph="none" start_char="12631" end_char="12637">America</TOKEN>
        <TOKEN id="token-216-14" pos="punct" morph="none" start_char="12638" end_char="12638">,</TOKEN>
        <TOKEN id="token-216-15" pos="word" morph="none" start_char="12640" end_char="12643">Hard</TOKEN>
        <TOKEN id="token-216-16" pos="word" morph="none" start_char="12645" end_char="12651">Choices</TOKEN>
        <TOKEN id="token-216-17" pos="word" morph="none" start_char="12653" end_char="12654">is</TOKEN>
        <TOKEN id="token-216-18" pos="punct" morph="none" start_char="12655" end_char="12655">,</TOKEN>
      </SEG>
      <SEG id="segment-217" start_char="12657" end_char="12732">
        <ORIGINAL_TEXT>quite simply, one of those books that people write when they are running for</ORIGINAL_TEXT>
        <TOKEN id="token-217-0" pos="word" morph="none" start_char="12657" end_char="12661">quite</TOKEN>
        <TOKEN id="token-217-1" pos="word" morph="none" start_char="12663" end_char="12668">simply</TOKEN>
        <TOKEN id="token-217-2" pos="punct" morph="none" start_char="12669" end_char="12669">,</TOKEN>
        <TOKEN id="token-217-3" pos="word" morph="none" start_char="12671" end_char="12673">one</TOKEN>
        <TOKEN id="token-217-4" pos="word" morph="none" start_char="12675" end_char="12676">of</TOKEN>
        <TOKEN id="token-217-5" pos="word" morph="none" start_char="12678" end_char="12682">those</TOKEN>
        <TOKEN id="token-217-6" pos="word" morph="none" start_char="12684" end_char="12688">books</TOKEN>
        <TOKEN id="token-217-7" pos="word" morph="none" start_char="12690" end_char="12693">that</TOKEN>
        <TOKEN id="token-217-8" pos="word" morph="none" start_char="12695" end_char="12700">people</TOKEN>
        <TOKEN id="token-217-9" pos="word" morph="none" start_char="12702" end_char="12706">write</TOKEN>
        <TOKEN id="token-217-10" pos="word" morph="none" start_char="12708" end_char="12711">when</TOKEN>
        <TOKEN id="token-217-11" pos="word" morph="none" start_char="12713" end_char="12716">they</TOKEN>
        <TOKEN id="token-217-12" pos="word" morph="none" start_char="12718" end_char="12720">are</TOKEN>
        <TOKEN id="token-217-13" pos="word" morph="none" start_char="12722" end_char="12728">running</TOKEN>
        <TOKEN id="token-217-14" pos="word" morph="none" start_char="12730" end_char="12732">for</TOKEN>
      </SEG>
      <SEG id="segment-218" start_char="12734" end_char="12807">
        <ORIGINAL_TEXT>president. Since it calls itself a “memoir,” and focuses on her four years</ORIGINAL_TEXT>
        <TOKEN id="token-218-0" pos="word" morph="none" start_char="12734" end_char="12742">president</TOKEN>
        <TOKEN id="token-218-1" pos="punct" morph="none" start_char="12743" end_char="12743">.</TOKEN>
        <TOKEN id="token-218-2" pos="word" morph="none" start_char="12745" end_char="12749">Since</TOKEN>
        <TOKEN id="token-218-3" pos="word" morph="none" start_char="12751" end_char="12752">it</TOKEN>
        <TOKEN id="token-218-4" pos="word" morph="none" start_char="12754" end_char="12758">calls</TOKEN>
        <TOKEN id="token-218-5" pos="word" morph="none" start_char="12760" end_char="12765">itself</TOKEN>
        <TOKEN id="token-218-6" pos="word" morph="none" start_char="12767" end_char="12767">a</TOKEN>
        <TOKEN id="token-218-7" pos="punct" morph="none" start_char="12769" end_char="12769">“</TOKEN>
        <TOKEN id="token-218-8" pos="word" morph="none" start_char="12770" end_char="12775">memoir</TOKEN>
        <TOKEN id="token-218-9" pos="punct" morph="none" start_char="12776" end_char="12777">,”</TOKEN>
        <TOKEN id="token-218-10" pos="word" morph="none" start_char="12779" end_char="12781">and</TOKEN>
        <TOKEN id="token-218-11" pos="word" morph="none" start_char="12783" end_char="12789">focuses</TOKEN>
        <TOKEN id="token-218-12" pos="word" morph="none" start_char="12791" end_char="12792">on</TOKEN>
        <TOKEN id="token-218-13" pos="word" morph="none" start_char="12794" end_char="12796">her</TOKEN>
        <TOKEN id="token-218-14" pos="word" morph="none" start_char="12798" end_char="12801">four</TOKEN>
        <TOKEN id="token-218-15" pos="word" morph="none" start_char="12803" end_char="12807">years</TOKEN>
      </SEG>
      <SEG id="segment-219" start_char="12809" end_char="12879">
        <ORIGINAL_TEXT>as secretary of state, and since it does not have the word “America” in</ORIGINAL_TEXT>
        <TOKEN id="token-219-0" pos="word" morph="none" start_char="12809" end_char="12810">as</TOKEN>
        <TOKEN id="token-219-1" pos="word" morph="none" start_char="12812" end_char="12820">secretary</TOKEN>
        <TOKEN id="token-219-2" pos="word" morph="none" start_char="12822" end_char="12823">of</TOKEN>
        <TOKEN id="token-219-3" pos="word" morph="none" start_char="12825" end_char="12829">state</TOKEN>
        <TOKEN id="token-219-4" pos="punct" morph="none" start_char="12830" end_char="12830">,</TOKEN>
        <TOKEN id="token-219-5" pos="word" morph="none" start_char="12832" end_char="12834">and</TOKEN>
        <TOKEN id="token-219-6" pos="word" morph="none" start_char="12836" end_char="12840">since</TOKEN>
        <TOKEN id="token-219-7" pos="word" morph="none" start_char="12842" end_char="12843">it</TOKEN>
        <TOKEN id="token-219-8" pos="word" morph="none" start_char="12845" end_char="12848">does</TOKEN>
        <TOKEN id="token-219-9" pos="word" morph="none" start_char="12850" end_char="12852">not</TOKEN>
        <TOKEN id="token-219-10" pos="word" morph="none" start_char="12854" end_char="12857">have</TOKEN>
        <TOKEN id="token-219-11" pos="word" morph="none" start_char="12859" end_char="12861">the</TOKEN>
        <TOKEN id="token-219-12" pos="word" morph="none" start_char="12863" end_char="12866">word</TOKEN>
        <TOKEN id="token-219-13" pos="punct" morph="none" start_char="12868" end_char="12868">“</TOKEN>
        <TOKEN id="token-219-14" pos="word" morph="none" start_char="12869" end_char="12875">America</TOKEN>
        <TOKEN id="token-219-15" pos="punct" morph="none" start_char="12876" end_char="12876">”</TOKEN>
        <TOKEN id="token-219-16" pos="word" morph="none" start_char="12878" end_char="12879">in</TOKEN>
      </SEG>
      <SEG id="segment-220" start_char="12881" end_char="12951">
        <ORIGINAL_TEXT>the title, Clinton’s version is a little different from the others. But</ORIGINAL_TEXT>
        <TOKEN id="token-220-0" pos="word" morph="none" start_char="12881" end_char="12883">the</TOKEN>
        <TOKEN id="token-220-1" pos="word" morph="none" start_char="12885" end_char="12889">title</TOKEN>
        <TOKEN id="token-220-2" pos="punct" morph="none" start_char="12890" end_char="12890">,</TOKEN>
        <TOKEN id="token-220-3" pos="word" morph="none" start_char="12892" end_char="12898">Clinton</TOKEN>
        <TOKEN id="token-220-4" pos="punct" morph="none" start_char="12899" end_char="12899">’</TOKEN>
        <TOKEN id="token-220-5" pos="word" morph="none" start_char="12900" end_char="12900">s</TOKEN>
        <TOKEN id="token-220-6" pos="word" morph="none" start_char="12902" end_char="12908">version</TOKEN>
        <TOKEN id="token-220-7" pos="word" morph="none" start_char="12910" end_char="12911">is</TOKEN>
        <TOKEN id="token-220-8" pos="word" morph="none" start_char="12913" end_char="12913">a</TOKEN>
        <TOKEN id="token-220-9" pos="word" morph="none" start_char="12915" end_char="12920">little</TOKEN>
        <TOKEN id="token-220-10" pos="word" morph="none" start_char="12922" end_char="12930">different</TOKEN>
        <TOKEN id="token-220-11" pos="word" morph="none" start_char="12932" end_char="12935">from</TOKEN>
        <TOKEN id="token-220-12" pos="word" morph="none" start_char="12937" end_char="12939">the</TOKEN>
        <TOKEN id="token-220-13" pos="word" morph="none" start_char="12941" end_char="12946">others</TOKEN>
        <TOKEN id="token-220-14" pos="punct" morph="none" start_char="12947" end_char="12947">.</TOKEN>
        <TOKEN id="token-220-15" pos="word" morph="none" start_char="12949" end_char="12951">But</TOKEN>
      </SEG>
      <SEG id="segment-221" start_char="12953" end_char="13015">
        <ORIGINAL_TEXT>really there can be no doubt that this is a campaign book in an</ORIGINAL_TEXT>
        <TOKEN id="token-221-0" pos="word" morph="none" start_char="12953" end_char="12958">really</TOKEN>
        <TOKEN id="token-221-1" pos="word" morph="none" start_char="12960" end_char="12964">there</TOKEN>
        <TOKEN id="token-221-2" pos="word" morph="none" start_char="12966" end_char="12968">can</TOKEN>
        <TOKEN id="token-221-3" pos="word" morph="none" start_char="12970" end_char="12971">be</TOKEN>
        <TOKEN id="token-221-4" pos="word" morph="none" start_char="12973" end_char="12974">no</TOKEN>
        <TOKEN id="token-221-5" pos="word" morph="none" start_char="12976" end_char="12980">doubt</TOKEN>
        <TOKEN id="token-221-6" pos="word" morph="none" start_char="12982" end_char="12985">that</TOKEN>
        <TOKEN id="token-221-7" pos="word" morph="none" start_char="12987" end_char="12990">this</TOKEN>
        <TOKEN id="token-221-8" pos="word" morph="none" start_char="12992" end_char="12993">is</TOKEN>
        <TOKEN id="token-221-9" pos="word" morph="none" start_char="12995" end_char="12995">a</TOKEN>
        <TOKEN id="token-221-10" pos="word" morph="none" start_char="12997" end_char="13004">campaign</TOKEN>
        <TOKEN id="token-221-11" pos="word" morph="none" start_char="13006" end_char="13009">book</TOKEN>
        <TOKEN id="token-221-12" pos="word" morph="none" start_char="13011" end_char="13012">in</TOKEN>
        <TOKEN id="token-221-13" pos="word" morph="none" start_char="13014" end_char="13015">an</TOKEN>
      </SEG>
      <SEG id="segment-222" start_char="13017" end_char="13060">
        <ORIGINAL_TEXT>autobiographical and statesmanlike disguise.</ORIGINAL_TEXT>
        <TOKEN id="token-222-0" pos="word" morph="none" start_char="13017" end_char="13032">autobiographical</TOKEN>
        <TOKEN id="token-222-1" pos="word" morph="none" start_char="13034" end_char="13036">and</TOKEN>
        <TOKEN id="token-222-2" pos="word" morph="none" start_char="13038" end_char="13050">statesmanlike</TOKEN>
        <TOKEN id="token-222-3" pos="word" morph="none" start_char="13052" end_char="13059">disguise</TOKEN>
        <TOKEN id="token-222-4" pos="punct" morph="none" start_char="13060" end_char="13060">.</TOKEN>
      </SEG>
      <SEG id="segment-223" start_char="13062" end_char="13065">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-223-0" pos="unknown" morph="none" start_char="13062" end_char="13065">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-224" start_char="13067" end_char="13069">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-224-0" pos="unknown" morph="none" start_char="13067" end_char="13069">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-225" start_char="13071" end_char="13148">
        <ORIGINAL_TEXT>I am not sure when it became de rigueur for presidential candidates to publish</ORIGINAL_TEXT>
        <TOKEN id="token-225-0" pos="word" morph="none" start_char="13071" end_char="13071">I</TOKEN>
        <TOKEN id="token-225-1" pos="word" morph="none" start_char="13073" end_char="13074">am</TOKEN>
        <TOKEN id="token-225-2" pos="word" morph="none" start_char="13076" end_char="13078">not</TOKEN>
        <TOKEN id="token-225-3" pos="word" morph="none" start_char="13080" end_char="13083">sure</TOKEN>
        <TOKEN id="token-225-4" pos="word" morph="none" start_char="13085" end_char="13088">when</TOKEN>
        <TOKEN id="token-225-5" pos="word" morph="none" start_char="13090" end_char="13091">it</TOKEN>
        <TOKEN id="token-225-6" pos="word" morph="none" start_char="13093" end_char="13098">became</TOKEN>
        <TOKEN id="token-225-7" pos="word" morph="none" start_char="13100" end_char="13101">de</TOKEN>
        <TOKEN id="token-225-8" pos="word" morph="none" start_char="13103" end_char="13109">rigueur</TOKEN>
        <TOKEN id="token-225-9" pos="word" morph="none" start_char="13111" end_char="13113">for</TOKEN>
        <TOKEN id="token-225-10" pos="word" morph="none" start_char="13115" end_char="13126">presidential</TOKEN>
        <TOKEN id="token-225-11" pos="word" morph="none" start_char="13128" end_char="13137">candidates</TOKEN>
        <TOKEN id="token-225-12" pos="word" morph="none" start_char="13139" end_char="13140">to</TOKEN>
        <TOKEN id="token-225-13" pos="word" morph="none" start_char="13142" end_char="13148">publish</TOKEN>
      </SEG>
      <SEG id="segment-226" start_char="13150" end_char="13227">
        <ORIGINAL_TEXT>a work between hard covers, but nobody now runs for high office without having</ORIGINAL_TEXT>
        <TOKEN id="token-226-0" pos="word" morph="none" start_char="13150" end_char="13150">a</TOKEN>
        <TOKEN id="token-226-1" pos="word" morph="none" start_char="13152" end_char="13155">work</TOKEN>
        <TOKEN id="token-226-2" pos="word" morph="none" start_char="13157" end_char="13163">between</TOKEN>
        <TOKEN id="token-226-3" pos="word" morph="none" start_char="13165" end_char="13168">hard</TOKEN>
        <TOKEN id="token-226-4" pos="word" morph="none" start_char="13170" end_char="13175">covers</TOKEN>
        <TOKEN id="token-226-5" pos="punct" morph="none" start_char="13176" end_char="13176">,</TOKEN>
        <TOKEN id="token-226-6" pos="word" morph="none" start_char="13178" end_char="13180">but</TOKEN>
        <TOKEN id="token-226-7" pos="word" morph="none" start_char="13182" end_char="13187">nobody</TOKEN>
        <TOKEN id="token-226-8" pos="word" morph="none" start_char="13189" end_char="13191">now</TOKEN>
        <TOKEN id="token-226-9" pos="word" morph="none" start_char="13193" end_char="13196">runs</TOKEN>
        <TOKEN id="token-226-10" pos="word" morph="none" start_char="13198" end_char="13200">for</TOKEN>
        <TOKEN id="token-226-11" pos="word" morph="none" start_char="13202" end_char="13205">high</TOKEN>
        <TOKEN id="token-226-12" pos="word" morph="none" start_char="13207" end_char="13212">office</TOKEN>
        <TOKEN id="token-226-13" pos="word" morph="none" start_char="13214" end_char="13220">without</TOKEN>
        <TOKEN id="token-226-14" pos="word" morph="none" start_char="13222" end_char="13227">having</TOKEN>
      </SEG>
      <SEG id="segment-227" start_char="13229" end_char="13303">
        <ORIGINAL_TEXT>written, or having arranged for the ghostwriting of, a very large book. The</ORIGINAL_TEXT>
        <TOKEN id="token-227-0" pos="word" morph="none" start_char="13229" end_char="13235">written</TOKEN>
        <TOKEN id="token-227-1" pos="punct" morph="none" start_char="13236" end_char="13236">,</TOKEN>
        <TOKEN id="token-227-2" pos="word" morph="none" start_char="13238" end_char="13239">or</TOKEN>
        <TOKEN id="token-227-3" pos="word" morph="none" start_char="13241" end_char="13246">having</TOKEN>
        <TOKEN id="token-227-4" pos="word" morph="none" start_char="13248" end_char="13255">arranged</TOKEN>
        <TOKEN id="token-227-5" pos="word" morph="none" start_char="13257" end_char="13259">for</TOKEN>
        <TOKEN id="token-227-6" pos="word" morph="none" start_char="13261" end_char="13263">the</TOKEN>
        <TOKEN id="token-227-7" pos="word" morph="none" start_char="13265" end_char="13276">ghostwriting</TOKEN>
        <TOKEN id="token-227-8" pos="word" morph="none" start_char="13278" end_char="13279">of</TOKEN>
        <TOKEN id="token-227-9" pos="punct" morph="none" start_char="13280" end_char="13280">,</TOKEN>
        <TOKEN id="token-227-10" pos="word" morph="none" start_char="13282" end_char="13282">a</TOKEN>
        <TOKEN id="token-227-11" pos="word" morph="none" start_char="13284" end_char="13287">very</TOKEN>
        <TOKEN id="token-227-12" pos="word" morph="none" start_char="13289" end_char="13293">large</TOKEN>
        <TOKEN id="token-227-13" pos="word" morph="none" start_char="13295" end_char="13298">book</TOKEN>
        <TOKEN id="token-227-14" pos="punct" morph="none" start_char="13299" end_char="13299">.</TOKEN>
        <TOKEN id="token-227-15" pos="word" morph="none" start_char="13301" end_char="13303">The</TOKEN>
      </SEG>
      <SEG id="segment-228" start_char="13305" end_char="13380">
        <ORIGINAL_TEXT>advantages are obvious. Such books provide some vignettes for voters to chew</ORIGINAL_TEXT>
        <TOKEN id="token-228-0" pos="word" morph="none" start_char="13305" end_char="13314">advantages</TOKEN>
        <TOKEN id="token-228-1" pos="word" morph="none" start_char="13316" end_char="13318">are</TOKEN>
        <TOKEN id="token-228-2" pos="word" morph="none" start_char="13320" end_char="13326">obvious</TOKEN>
        <TOKEN id="token-228-3" pos="punct" morph="none" start_char="13327" end_char="13327">.</TOKEN>
        <TOKEN id="token-228-4" pos="word" morph="none" start_char="13329" end_char="13332">Such</TOKEN>
        <TOKEN id="token-228-5" pos="word" morph="none" start_char="13334" end_char="13338">books</TOKEN>
        <TOKEN id="token-228-6" pos="word" morph="none" start_char="13340" end_char="13346">provide</TOKEN>
        <TOKEN id="token-228-7" pos="word" morph="none" start_char="13348" end_char="13351">some</TOKEN>
        <TOKEN id="token-228-8" pos="word" morph="none" start_char="13353" end_char="13361">vignettes</TOKEN>
        <TOKEN id="token-228-9" pos="word" morph="none" start_char="13363" end_char="13365">for</TOKEN>
        <TOKEN id="token-228-10" pos="word" morph="none" start_char="13367" end_char="13372">voters</TOKEN>
        <TOKEN id="token-228-11" pos="word" morph="none" start_char="13374" end_char="13375">to</TOKEN>
        <TOKEN id="token-228-12" pos="word" morph="none" start_char="13377" end_char="13380">chew</TOKEN>
      </SEG>
      <SEG id="segment-229" start_char="13382" end_char="13459">
        <ORIGINAL_TEXT>over, and some pre-approved quotes for the press. They offer a narrative about</ORIGINAL_TEXT>
        <TOKEN id="token-229-0" pos="word" morph="none" start_char="13382" end_char="13385">over</TOKEN>
        <TOKEN id="token-229-1" pos="punct" morph="none" start_char="13386" end_char="13386">,</TOKEN>
        <TOKEN id="token-229-2" pos="word" morph="none" start_char="13388" end_char="13390">and</TOKEN>
        <TOKEN id="token-229-3" pos="word" morph="none" start_char="13392" end_char="13395">some</TOKEN>
        <TOKEN id="token-229-4" pos="word" morph="none" start_char="13397" end_char="13399">pre</TOKEN>
        <TOKEN id="token-229-5" pos="punct" morph="none" start_char="13400" end_char="13400">-</TOKEN>
        <TOKEN id="token-229-6" pos="word" morph="none" start_char="13401" end_char="13408">approved</TOKEN>
        <TOKEN id="token-229-7" pos="word" morph="none" start_char="13410" end_char="13415">quotes</TOKEN>
        <TOKEN id="token-229-8" pos="word" morph="none" start_char="13417" end_char="13419">for</TOKEN>
        <TOKEN id="token-229-9" pos="word" morph="none" start_char="13421" end_char="13423">the</TOKEN>
        <TOKEN id="token-229-10" pos="word" morph="none" start_char="13425" end_char="13429">press</TOKEN>
        <TOKEN id="token-229-11" pos="punct" morph="none" start_char="13430" end_char="13430">.</TOKEN>
        <TOKEN id="token-229-12" pos="word" morph="none" start_char="13432" end_char="13435">They</TOKEN>
        <TOKEN id="token-229-13" pos="word" morph="none" start_char="13437" end_char="13441">offer</TOKEN>
        <TOKEN id="token-229-14" pos="word" morph="none" start_char="13443" end_char="13443">a</TOKEN>
        <TOKEN id="token-229-15" pos="word" morph="none" start_char="13445" end_char="13453">narrative</TOKEN>
        <TOKEN id="token-229-16" pos="word" morph="none" start_char="13455" end_char="13459">about</TOKEN>
      </SEG>
      <SEG id="segment-230" start_char="13461" end_char="13535">
        <ORIGINAL_TEXT>the candidate that is entirely of the candidate’s own construction, a story</ORIGINAL_TEXT>
        <TOKEN id="token-230-0" pos="word" morph="none" start_char="13461" end_char="13463">the</TOKEN>
        <TOKEN id="token-230-1" pos="word" morph="none" start_char="13465" end_char="13473">candidate</TOKEN>
        <TOKEN id="token-230-2" pos="word" morph="none" start_char="13475" end_char="13478">that</TOKEN>
        <TOKEN id="token-230-3" pos="word" morph="none" start_char="13480" end_char="13481">is</TOKEN>
        <TOKEN id="token-230-4" pos="word" morph="none" start_char="13483" end_char="13490">entirely</TOKEN>
        <TOKEN id="token-230-5" pos="word" morph="none" start_char="13492" end_char="13493">of</TOKEN>
        <TOKEN id="token-230-6" pos="word" morph="none" start_char="13495" end_char="13497">the</TOKEN>
        <TOKEN id="token-230-7" pos="word" morph="none" start_char="13499" end_char="13507">candidate</TOKEN>
        <TOKEN id="token-230-8" pos="punct" morph="none" start_char="13508" end_char="13508">’</TOKEN>
        <TOKEN id="token-230-9" pos="word" morph="none" start_char="13509" end_char="13509">s</TOKEN>
        <TOKEN id="token-230-10" pos="word" morph="none" start_char="13511" end_char="13513">own</TOKEN>
        <TOKEN id="token-230-11" pos="word" morph="none" start_char="13515" end_char="13526">construction</TOKEN>
        <TOKEN id="token-230-12" pos="punct" morph="none" start_char="13527" end_char="13527">,</TOKEN>
        <TOKEN id="token-230-13" pos="word" morph="none" start_char="13529" end_char="13529">a</TOKEN>
        <TOKEN id="token-230-14" pos="word" morph="none" start_char="13531" end_char="13535">story</TOKEN>
      </SEG>
      <SEG id="segment-231" start_char="13537" end_char="13611">
        <ORIGINAL_TEXT>that Hillary or Mitt or Barack can control from start to finish. Above all,</ORIGINAL_TEXT>
        <TOKEN id="token-231-0" pos="word" morph="none" start_char="13537" end_char="13540">that</TOKEN>
        <TOKEN id="token-231-1" pos="word" morph="none" start_char="13542" end_char="13548">Hillary</TOKEN>
        <TOKEN id="token-231-2" pos="word" morph="none" start_char="13550" end_char="13551">or</TOKEN>
        <TOKEN id="token-231-3" pos="word" morph="none" start_char="13553" end_char="13556">Mitt</TOKEN>
        <TOKEN id="token-231-4" pos="word" morph="none" start_char="13558" end_char="13559">or</TOKEN>
        <TOKEN id="token-231-5" pos="word" morph="none" start_char="13561" end_char="13566">Barack</TOKEN>
        <TOKEN id="token-231-6" pos="word" morph="none" start_char="13568" end_char="13570">can</TOKEN>
        <TOKEN id="token-231-7" pos="word" morph="none" start_char="13572" end_char="13578">control</TOKEN>
        <TOKEN id="token-231-8" pos="word" morph="none" start_char="13580" end_char="13583">from</TOKEN>
        <TOKEN id="token-231-9" pos="word" morph="none" start_char="13585" end_char="13589">start</TOKEN>
        <TOKEN id="token-231-10" pos="word" morph="none" start_char="13591" end_char="13592">to</TOKEN>
        <TOKEN id="token-231-11" pos="word" morph="none" start_char="13594" end_char="13599">finish</TOKEN>
        <TOKEN id="token-231-12" pos="punct" morph="none" start_char="13600" end_char="13600">.</TOKEN>
        <TOKEN id="token-231-13" pos="word" morph="none" start_char="13602" end_char="13606">Above</TOKEN>
        <TOKEN id="token-231-14" pos="word" morph="none" start_char="13608" end_char="13610">all</TOKEN>
        <TOKEN id="token-231-15" pos="punct" morph="none" start_char="13611" end_char="13611">,</TOKEN>
      </SEG>
      <SEG id="segment-232" start_char="13613" end_char="13688">
        <ORIGINAL_TEXT>the publication of a book, if judiciously planned, can provide an excuse for</ORIGINAL_TEXT>
        <TOKEN id="token-232-0" pos="word" morph="none" start_char="13613" end_char="13615">the</TOKEN>
        <TOKEN id="token-232-1" pos="word" morph="none" start_char="13617" end_char="13627">publication</TOKEN>
        <TOKEN id="token-232-2" pos="word" morph="none" start_char="13629" end_char="13630">of</TOKEN>
        <TOKEN id="token-232-3" pos="word" morph="none" start_char="13632" end_char="13632">a</TOKEN>
        <TOKEN id="token-232-4" pos="word" morph="none" start_char="13634" end_char="13637">book</TOKEN>
        <TOKEN id="token-232-5" pos="punct" morph="none" start_char="13638" end_char="13638">,</TOKEN>
        <TOKEN id="token-232-6" pos="word" morph="none" start_char="13640" end_char="13641">if</TOKEN>
        <TOKEN id="token-232-7" pos="word" morph="none" start_char="13643" end_char="13653">judiciously</TOKEN>
        <TOKEN id="token-232-8" pos="word" morph="none" start_char="13655" end_char="13661">planned</TOKEN>
        <TOKEN id="token-232-9" pos="punct" morph="none" start_char="13662" end_char="13662">,</TOKEN>
        <TOKEN id="token-232-10" pos="word" morph="none" start_char="13664" end_char="13666">can</TOKEN>
        <TOKEN id="token-232-11" pos="word" morph="none" start_char="13668" end_char="13674">provide</TOKEN>
        <TOKEN id="token-232-12" pos="word" morph="none" start_char="13676" end_char="13677">an</TOKEN>
        <TOKEN id="token-232-13" pos="word" morph="none" start_char="13679" end_char="13684">excuse</TOKEN>
        <TOKEN id="token-232-14" pos="word" morph="none" start_char="13686" end_char="13688">for</TOKEN>
      </SEG>
      <SEG id="segment-233" start_char="13690" end_char="13764">
        <ORIGINAL_TEXT>interviews, a book tour, and quite a lot of highbrow media, and all of this</ORIGINAL_TEXT>
        <TOKEN id="token-233-0" pos="word" morph="none" start_char="13690" end_char="13699">interviews</TOKEN>
        <TOKEN id="token-233-1" pos="punct" morph="none" start_char="13700" end_char="13700">,</TOKEN>
        <TOKEN id="token-233-2" pos="word" morph="none" start_char="13702" end_char="13702">a</TOKEN>
        <TOKEN id="token-233-3" pos="word" morph="none" start_char="13704" end_char="13707">book</TOKEN>
        <TOKEN id="token-233-4" pos="word" morph="none" start_char="13709" end_char="13712">tour</TOKEN>
        <TOKEN id="token-233-5" pos="punct" morph="none" start_char="13713" end_char="13713">,</TOKEN>
        <TOKEN id="token-233-6" pos="word" morph="none" start_char="13715" end_char="13717">and</TOKEN>
        <TOKEN id="token-233-7" pos="word" morph="none" start_char="13719" end_char="13723">quite</TOKEN>
        <TOKEN id="token-233-8" pos="word" morph="none" start_char="13725" end_char="13725">a</TOKEN>
        <TOKEN id="token-233-9" pos="word" morph="none" start_char="13727" end_char="13729">lot</TOKEN>
        <TOKEN id="token-233-10" pos="word" morph="none" start_char="13731" end_char="13732">of</TOKEN>
        <TOKEN id="token-233-11" pos="word" morph="none" start_char="13734" end_char="13741">highbrow</TOKEN>
        <TOKEN id="token-233-12" pos="word" morph="none" start_char="13743" end_char="13747">media</TOKEN>
        <TOKEN id="token-233-13" pos="punct" morph="none" start_char="13748" end_char="13748">,</TOKEN>
        <TOKEN id="token-233-14" pos="word" morph="none" start_char="13750" end_char="13752">and</TOKEN>
        <TOKEN id="token-233-15" pos="word" morph="none" start_char="13754" end_char="13756">all</TOKEN>
        <TOKEN id="token-233-16" pos="word" morph="none" start_char="13758" end_char="13759">of</TOKEN>
        <TOKEN id="token-233-17" pos="word" morph="none" start_char="13761" end_char="13764">this</TOKEN>
      </SEG>
      <SEG id="segment-234" start_char="13766" end_char="13841">
        <ORIGINAL_TEXT>many months or even years before the candidate begins the tedious process of</ORIGINAL_TEXT>
        <TOKEN id="token-234-0" pos="word" morph="none" start_char="13766" end_char="13769">many</TOKEN>
        <TOKEN id="token-234-1" pos="word" morph="none" start_char="13771" end_char="13776">months</TOKEN>
        <TOKEN id="token-234-2" pos="word" morph="none" start_char="13778" end_char="13779">or</TOKEN>
        <TOKEN id="token-234-3" pos="word" morph="none" start_char="13781" end_char="13784">even</TOKEN>
        <TOKEN id="token-234-4" pos="word" morph="none" start_char="13786" end_char="13790">years</TOKEN>
        <TOKEN id="token-234-5" pos="word" morph="none" start_char="13792" end_char="13797">before</TOKEN>
        <TOKEN id="token-234-6" pos="word" morph="none" start_char="13799" end_char="13801">the</TOKEN>
        <TOKEN id="token-234-7" pos="word" morph="none" start_char="13803" end_char="13811">candidate</TOKEN>
        <TOKEN id="token-234-8" pos="word" morph="none" start_char="13813" end_char="13818">begins</TOKEN>
        <TOKEN id="token-234-9" pos="word" morph="none" start_char="13820" end_char="13822">the</TOKEN>
        <TOKEN id="token-234-10" pos="word" morph="none" start_char="13824" end_char="13830">tedious</TOKEN>
        <TOKEN id="token-234-11" pos="word" morph="none" start_char="13832" end_char="13838">process</TOKEN>
        <TOKEN id="token-234-12" pos="word" morph="none" start_char="13840" end_char="13841">of</TOKEN>
      </SEG>
      <SEG id="segment-235" start_char="13843" end_char="13913">
        <ORIGINAL_TEXT>running an actual campaign. If the candidate proves really adept at the</ORIGINAL_TEXT>
        <TOKEN id="token-235-0" pos="word" morph="none" start_char="13843" end_char="13849">running</TOKEN>
        <TOKEN id="token-235-1" pos="word" morph="none" start_char="13851" end_char="13852">an</TOKEN>
        <TOKEN id="token-235-2" pos="word" morph="none" start_char="13854" end_char="13859">actual</TOKEN>
        <TOKEN id="token-235-3" pos="word" morph="none" start_char="13861" end_char="13868">campaign</TOKEN>
        <TOKEN id="token-235-4" pos="punct" morph="none" start_char="13869" end_char="13869">.</TOKEN>
        <TOKEN id="token-235-5" pos="word" morph="none" start_char="13871" end_char="13872">If</TOKEN>
        <TOKEN id="token-235-6" pos="word" morph="none" start_char="13874" end_char="13876">the</TOKEN>
        <TOKEN id="token-235-7" pos="word" morph="none" start_char="13878" end_char="13886">candidate</TOKEN>
        <TOKEN id="token-235-8" pos="word" morph="none" start_char="13888" end_char="13893">proves</TOKEN>
        <TOKEN id="token-235-9" pos="word" morph="none" start_char="13895" end_char="13900">really</TOKEN>
        <TOKEN id="token-235-10" pos="word" morph="none" start_char="13902" end_char="13906">adept</TOKEN>
        <TOKEN id="token-235-11" pos="word" morph="none" start_char="13908" end_char="13909">at</TOKEN>
        <TOKEN id="token-235-12" pos="word" morph="none" start_char="13911" end_char="13913">the</TOKEN>
      </SEG>
      <SEG id="segment-236" start_char="13915" end_char="13987">
        <ORIGINAL_TEXT>writing/ghostwriting/marketing of the thing, he or she can even make some</ORIGINAL_TEXT>
        <TOKEN id="token-236-0" pos="unknown" morph="none" start_char="13915" end_char="13944">writing/ghostwriting/marketing</TOKEN>
        <TOKEN id="token-236-1" pos="word" morph="none" start_char="13946" end_char="13947">of</TOKEN>
        <TOKEN id="token-236-2" pos="word" morph="none" start_char="13949" end_char="13951">the</TOKEN>
        <TOKEN id="token-236-3" pos="word" morph="none" start_char="13953" end_char="13957">thing</TOKEN>
        <TOKEN id="token-236-4" pos="punct" morph="none" start_char="13958" end_char="13958">,</TOKEN>
        <TOKEN id="token-236-5" pos="word" morph="none" start_char="13960" end_char="13961">he</TOKEN>
        <TOKEN id="token-236-6" pos="word" morph="none" start_char="13963" end_char="13964">or</TOKEN>
        <TOKEN id="token-236-7" pos="word" morph="none" start_char="13966" end_char="13968">she</TOKEN>
        <TOKEN id="token-236-8" pos="word" morph="none" start_char="13970" end_char="13972">can</TOKEN>
        <TOKEN id="token-236-9" pos="word" morph="none" start_char="13974" end_char="13977">even</TOKEN>
        <TOKEN id="token-236-10" pos="word" morph="none" start_char="13979" end_char="13982">make</TOKEN>
        <TOKEN id="token-236-11" pos="word" morph="none" start_char="13984" end_char="13987">some</TOKEN>
      </SEG>
      <SEG id="segment-237" start_char="13989" end_char="13994">
        <ORIGINAL_TEXT>money.</ORIGINAL_TEXT>
        <TOKEN id="token-237-0" pos="word" morph="none" start_char="13989" end_char="13993">money</TOKEN>
        <TOKEN id="token-237-1" pos="punct" morph="none" start_char="13994" end_char="13994">.</TOKEN>
      </SEG>
      <SEG id="segment-238" start_char="13996" end_char="13999">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-238-0" pos="unknown" morph="none" start_char="13996" end_char="13999">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-239" start_char="14001" end_char="14003">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-239-0" pos="unknown" morph="none" start_char="14001" end_char="14003">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-240" start_char="14005" end_char="14078">
        <ORIGINAL_TEXT>But once the reviewer understands that Hard Choices belongs to this genre,</ORIGINAL_TEXT>
        <TOKEN id="token-240-0" pos="word" morph="none" start_char="14005" end_char="14007">But</TOKEN>
        <TOKEN id="token-240-1" pos="word" morph="none" start_char="14009" end_char="14012">once</TOKEN>
        <TOKEN id="token-240-2" pos="word" morph="none" start_char="14014" end_char="14016">the</TOKEN>
        <TOKEN id="token-240-3" pos="word" morph="none" start_char="14018" end_char="14025">reviewer</TOKEN>
        <TOKEN id="token-240-4" pos="word" morph="none" start_char="14027" end_char="14037">understands</TOKEN>
        <TOKEN id="token-240-5" pos="word" morph="none" start_char="14039" end_char="14042">that</TOKEN>
        <TOKEN id="token-240-6" pos="word" morph="none" start_char="14044" end_char="14047">Hard</TOKEN>
        <TOKEN id="token-240-7" pos="word" morph="none" start_char="14049" end_char="14055">Choices</TOKEN>
        <TOKEN id="token-240-8" pos="word" morph="none" start_char="14057" end_char="14063">belongs</TOKEN>
        <TOKEN id="token-240-9" pos="word" morph="none" start_char="14065" end_char="14066">to</TOKEN>
        <TOKEN id="token-240-10" pos="word" morph="none" start_char="14068" end_char="14071">this</TOKEN>
        <TOKEN id="token-240-11" pos="word" morph="none" start_char="14073" end_char="14077">genre</TOKEN>
        <TOKEN id="token-240-12" pos="punct" morph="none" start_char="14078" end_char="14078">,</TOKEN>
      </SEG>
      <SEG id="segment-241" start_char="14080" end_char="14153">
        <ORIGINAL_TEXT>then its positive attributes become much clearer. If you leaf through this</ORIGINAL_TEXT>
        <TOKEN id="token-241-0" pos="word" morph="none" start_char="14080" end_char="14083">then</TOKEN>
        <TOKEN id="token-241-1" pos="word" morph="none" start_char="14085" end_char="14087">its</TOKEN>
        <TOKEN id="token-241-2" pos="word" morph="none" start_char="14089" end_char="14096">positive</TOKEN>
        <TOKEN id="token-241-3" pos="word" morph="none" start_char="14098" end_char="14107">attributes</TOKEN>
        <TOKEN id="token-241-4" pos="word" morph="none" start_char="14109" end_char="14114">become</TOKEN>
        <TOKEN id="token-241-5" pos="word" morph="none" start_char="14116" end_char="14119">much</TOKEN>
        <TOKEN id="token-241-6" pos="word" morph="none" start_char="14121" end_char="14127">clearer</TOKEN>
        <TOKEN id="token-241-7" pos="punct" morph="none" start_char="14128" end_char="14128">.</TOKEN>
        <TOKEN id="token-241-8" pos="word" morph="none" start_char="14130" end_char="14131">If</TOKEN>
        <TOKEN id="token-241-9" pos="word" morph="none" start_char="14133" end_char="14135">you</TOKEN>
        <TOKEN id="token-241-10" pos="word" morph="none" start_char="14137" end_char="14140">leaf</TOKEN>
        <TOKEN id="token-241-11" pos="word" morph="none" start_char="14142" end_char="14148">through</TOKEN>
        <TOKEN id="token-241-12" pos="word" morph="none" start_char="14150" end_char="14153">this</TOKEN>
      </SEG>
      <SEG id="segment-242" start_char="14155" end_char="14225">
        <ORIGINAL_TEXT>book, as I initially did, looking for insight into particular people or</ORIGINAL_TEXT>
        <TOKEN id="token-242-0" pos="word" morph="none" start_char="14155" end_char="14158">book</TOKEN>
        <TOKEN id="token-242-1" pos="punct" morph="none" start_char="14159" end_char="14159">,</TOKEN>
        <TOKEN id="token-242-2" pos="word" morph="none" start_char="14161" end_char="14162">as</TOKEN>
        <TOKEN id="token-242-3" pos="word" morph="none" start_char="14164" end_char="14164">I</TOKEN>
        <TOKEN id="token-242-4" pos="word" morph="none" start_char="14166" end_char="14174">initially</TOKEN>
        <TOKEN id="token-242-5" pos="word" morph="none" start_char="14176" end_char="14178">did</TOKEN>
        <TOKEN id="token-242-6" pos="punct" morph="none" start_char="14179" end_char="14179">,</TOKEN>
        <TOKEN id="token-242-7" pos="word" morph="none" start_char="14181" end_char="14187">looking</TOKEN>
        <TOKEN id="token-242-8" pos="word" morph="none" start_char="14189" end_char="14191">for</TOKEN>
        <TOKEN id="token-242-9" pos="word" morph="none" start_char="14193" end_char="14199">insight</TOKEN>
        <TOKEN id="token-242-10" pos="word" morph="none" start_char="14201" end_char="14204">into</TOKEN>
        <TOKEN id="token-242-11" pos="word" morph="none" start_char="14206" end_char="14215">particular</TOKEN>
        <TOKEN id="token-242-12" pos="word" morph="none" start_char="14217" end_char="14222">people</TOKEN>
        <TOKEN id="token-242-13" pos="word" morph="none" start_char="14224" end_char="14225">or</TOKEN>
      </SEG>
      <SEG id="segment-243" start_char="14227" end_char="14302">
        <ORIGINAL_TEXT>events, you will be disappointed. If you look for a grand strategy, you will</ORIGINAL_TEXT>
        <TOKEN id="token-243-0" pos="word" morph="none" start_char="14227" end_char="14232">events</TOKEN>
        <TOKEN id="token-243-1" pos="punct" morph="none" start_char="14233" end_char="14233">,</TOKEN>
        <TOKEN id="token-243-2" pos="word" morph="none" start_char="14235" end_char="14237">you</TOKEN>
        <TOKEN id="token-243-3" pos="word" morph="none" start_char="14239" end_char="14242">will</TOKEN>
        <TOKEN id="token-243-4" pos="word" morph="none" start_char="14244" end_char="14245">be</TOKEN>
        <TOKEN id="token-243-5" pos="word" morph="none" start_char="14247" end_char="14258">disappointed</TOKEN>
        <TOKEN id="token-243-6" pos="punct" morph="none" start_char="14259" end_char="14259">.</TOKEN>
        <TOKEN id="token-243-7" pos="word" morph="none" start_char="14261" end_char="14262">If</TOKEN>
        <TOKEN id="token-243-8" pos="word" morph="none" start_char="14264" end_char="14266">you</TOKEN>
        <TOKEN id="token-243-9" pos="word" morph="none" start_char="14268" end_char="14271">look</TOKEN>
        <TOKEN id="token-243-10" pos="word" morph="none" start_char="14273" end_char="14275">for</TOKEN>
        <TOKEN id="token-243-11" pos="word" morph="none" start_char="14277" end_char="14277">a</TOKEN>
        <TOKEN id="token-243-12" pos="word" morph="none" start_char="14279" end_char="14283">grand</TOKEN>
        <TOKEN id="token-243-13" pos="word" morph="none" start_char="14285" end_char="14292">strategy</TOKEN>
        <TOKEN id="token-243-14" pos="punct" morph="none" start_char="14293" end_char="14293">,</TOKEN>
        <TOKEN id="token-243-15" pos="word" morph="none" start_char="14295" end_char="14297">you</TOKEN>
        <TOKEN id="token-243-16" pos="word" morph="none" start_char="14299" end_char="14302">will</TOKEN>
      </SEG>
      <SEG id="segment-244" start_char="14304" end_char="14379">
        <ORIGINAL_TEXT>be similarly let down. But if instead you peruse the book in search of clues</ORIGINAL_TEXT>
        <TOKEN id="token-244-0" pos="word" morph="none" start_char="14304" end_char="14305">be</TOKEN>
        <TOKEN id="token-244-1" pos="word" morph="none" start_char="14307" end_char="14315">similarly</TOKEN>
        <TOKEN id="token-244-2" pos="word" morph="none" start_char="14317" end_char="14319">let</TOKEN>
        <TOKEN id="token-244-3" pos="word" morph="none" start_char="14321" end_char="14324">down</TOKEN>
        <TOKEN id="token-244-4" pos="punct" morph="none" start_char="14325" end_char="14325">.</TOKEN>
        <TOKEN id="token-244-5" pos="word" morph="none" start_char="14327" end_char="14329">But</TOKEN>
        <TOKEN id="token-244-6" pos="word" morph="none" start_char="14331" end_char="14332">if</TOKEN>
        <TOKEN id="token-244-7" pos="word" morph="none" start_char="14334" end_char="14340">instead</TOKEN>
        <TOKEN id="token-244-8" pos="word" morph="none" start_char="14342" end_char="14344">you</TOKEN>
        <TOKEN id="token-244-9" pos="word" morph="none" start_char="14346" end_char="14351">peruse</TOKEN>
        <TOKEN id="token-244-10" pos="word" morph="none" start_char="14353" end_char="14355">the</TOKEN>
        <TOKEN id="token-244-11" pos="word" morph="none" start_char="14357" end_char="14360">book</TOKEN>
        <TOKEN id="token-244-12" pos="word" morph="none" start_char="14362" end_char="14363">in</TOKEN>
        <TOKEN id="token-244-13" pos="word" morph="none" start_char="14365" end_char="14370">search</TOKEN>
        <TOKEN id="token-244-14" pos="word" morph="none" start_char="14372" end_char="14373">of</TOKEN>
        <TOKEN id="token-244-15" pos="word" morph="none" start_char="14375" end_char="14379">clues</TOKEN>
      </SEG>
      <SEG id="segment-245" start_char="14381" end_char="14453">
        <ORIGINAL_TEXT>as to how candidate Clinton is going to portray herself over the next two</ORIGINAL_TEXT>
        <TOKEN id="token-245-0" pos="word" morph="none" start_char="14381" end_char="14382">as</TOKEN>
        <TOKEN id="token-245-1" pos="word" morph="none" start_char="14384" end_char="14385">to</TOKEN>
        <TOKEN id="token-245-2" pos="word" morph="none" start_char="14387" end_char="14389">how</TOKEN>
        <TOKEN id="token-245-3" pos="word" morph="none" start_char="14391" end_char="14399">candidate</TOKEN>
        <TOKEN id="token-245-4" pos="word" morph="none" start_char="14401" end_char="14407">Clinton</TOKEN>
        <TOKEN id="token-245-5" pos="word" morph="none" start_char="14409" end_char="14410">is</TOKEN>
        <TOKEN id="token-245-6" pos="word" morph="none" start_char="14412" end_char="14416">going</TOKEN>
        <TOKEN id="token-245-7" pos="word" morph="none" start_char="14418" end_char="14419">to</TOKEN>
        <TOKEN id="token-245-8" pos="word" morph="none" start_char="14421" end_char="14427">portray</TOKEN>
        <TOKEN id="token-245-9" pos="word" morph="none" start_char="14429" end_char="14435">herself</TOKEN>
        <TOKEN id="token-245-10" pos="word" morph="none" start_char="14437" end_char="14440">over</TOKEN>
        <TOKEN id="token-245-11" pos="word" morph="none" start_char="14442" end_char="14444">the</TOKEN>
        <TOKEN id="token-245-12" pos="word" morph="none" start_char="14446" end_char="14449">next</TOKEN>
        <TOKEN id="token-245-13" pos="word" morph="none" start_char="14451" end_char="14453">two</TOKEN>
      </SEG>
      <SEG id="segment-246" start_char="14455" end_char="14521">
        <ORIGINAL_TEXT>years, then it becomes somewhat interesting, even downright useful.</ORIGINAL_TEXT>
        <TOKEN id="token-246-0" pos="word" morph="none" start_char="14455" end_char="14459">years</TOKEN>
        <TOKEN id="token-246-1" pos="punct" morph="none" start_char="14460" end_char="14460">,</TOKEN>
        <TOKEN id="token-246-2" pos="word" morph="none" start_char="14462" end_char="14465">then</TOKEN>
        <TOKEN id="token-246-3" pos="word" morph="none" start_char="14467" end_char="14468">it</TOKEN>
        <TOKEN id="token-246-4" pos="word" morph="none" start_char="14470" end_char="14476">becomes</TOKEN>
        <TOKEN id="token-246-5" pos="word" morph="none" start_char="14478" end_char="14485">somewhat</TOKEN>
        <TOKEN id="token-246-6" pos="word" morph="none" start_char="14487" end_char="14497">interesting</TOKEN>
        <TOKEN id="token-246-7" pos="punct" morph="none" start_char="14498" end_char="14498">,</TOKEN>
        <TOKEN id="token-246-8" pos="word" morph="none" start_char="14500" end_char="14503">even</TOKEN>
        <TOKEN id="token-246-9" pos="word" morph="none" start_char="14505" end_char="14513">downright</TOKEN>
        <TOKEN id="token-246-10" pos="word" morph="none" start_char="14515" end_char="14520">useful</TOKEN>
        <TOKEN id="token-246-11" pos="punct" morph="none" start_char="14521" end_char="14521">.</TOKEN>
      </SEG>
      <SEG id="segment-247" start_char="14523" end_char="14526">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-247-0" pos="unknown" morph="none" start_char="14523" end_char="14526">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-248" start_char="14528" end_char="14530">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-248-0" pos="unknown" morph="none" start_char="14528" end_char="14530">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-249" start_char="14532" end_char="14608">
        <ORIGINAL_TEXT>It is impossible not to notice, for example, that throughout the book Clinton</ORIGINAL_TEXT>
        <TOKEN id="token-249-0" pos="word" morph="none" start_char="14532" end_char="14533">It</TOKEN>
        <TOKEN id="token-249-1" pos="word" morph="none" start_char="14535" end_char="14536">is</TOKEN>
        <TOKEN id="token-249-2" pos="word" morph="none" start_char="14538" end_char="14547">impossible</TOKEN>
        <TOKEN id="token-249-3" pos="word" morph="none" start_char="14549" end_char="14551">not</TOKEN>
        <TOKEN id="token-249-4" pos="word" morph="none" start_char="14553" end_char="14554">to</TOKEN>
        <TOKEN id="token-249-5" pos="word" morph="none" start_char="14556" end_char="14561">notice</TOKEN>
        <TOKEN id="token-249-6" pos="punct" morph="none" start_char="14562" end_char="14562">,</TOKEN>
        <TOKEN id="token-249-7" pos="word" morph="none" start_char="14564" end_char="14566">for</TOKEN>
        <TOKEN id="token-249-8" pos="word" morph="none" start_char="14568" end_char="14574">example</TOKEN>
        <TOKEN id="token-249-9" pos="punct" morph="none" start_char="14575" end_char="14575">,</TOKEN>
        <TOKEN id="token-249-10" pos="word" morph="none" start_char="14577" end_char="14580">that</TOKEN>
        <TOKEN id="token-249-11" pos="word" morph="none" start_char="14582" end_char="14591">throughout</TOKEN>
        <TOKEN id="token-249-12" pos="word" morph="none" start_char="14593" end_char="14595">the</TOKEN>
        <TOKEN id="token-249-13" pos="word" morph="none" start_char="14597" end_char="14600">book</TOKEN>
        <TOKEN id="token-249-14" pos="word" morph="none" start_char="14602" end_char="14608">Clinton</TOKEN>
      </SEG>
      <SEG id="segment-250" start_char="14610" end_char="14686">
        <ORIGINAL_TEXT>emphasizes very particular personality traits. She returns again and again to</ORIGINAL_TEXT>
        <TOKEN id="token-250-0" pos="word" morph="none" start_char="14610" end_char="14619">emphasizes</TOKEN>
        <TOKEN id="token-250-1" pos="word" morph="none" start_char="14621" end_char="14624">very</TOKEN>
        <TOKEN id="token-250-2" pos="word" morph="none" start_char="14626" end_char="14635">particular</TOKEN>
        <TOKEN id="token-250-3" pos="word" morph="none" start_char="14637" end_char="14647">personality</TOKEN>
        <TOKEN id="token-250-4" pos="word" morph="none" start_char="14649" end_char="14654">traits</TOKEN>
        <TOKEN id="token-250-5" pos="punct" morph="none" start_char="14655" end_char="14655">.</TOKEN>
        <TOKEN id="token-250-6" pos="word" morph="none" start_char="14657" end_char="14659">She</TOKEN>
        <TOKEN id="token-250-7" pos="word" morph="none" start_char="14661" end_char="14667">returns</TOKEN>
        <TOKEN id="token-250-8" pos="word" morph="none" start_char="14669" end_char="14673">again</TOKEN>
        <TOKEN id="token-250-9" pos="word" morph="none" start_char="14675" end_char="14677">and</TOKEN>
        <TOKEN id="token-250-10" pos="word" morph="none" start_char="14679" end_char="14683">again</TOKEN>
        <TOKEN id="token-250-11" pos="word" morph="none" start_char="14685" end_char="14686">to</TOKEN>
      </SEG>
      <SEG id="segment-251" start_char="14688" end_char="14760">
        <ORIGINAL_TEXT>the ethic of service that her parents bequeathed to her. At one point she</ORIGINAL_TEXT>
        <TOKEN id="token-251-0" pos="word" morph="none" start_char="14688" end_char="14690">the</TOKEN>
        <TOKEN id="token-251-1" pos="word" morph="none" start_char="14692" end_char="14696">ethic</TOKEN>
        <TOKEN id="token-251-2" pos="word" morph="none" start_char="14698" end_char="14699">of</TOKEN>
        <TOKEN id="token-251-3" pos="word" morph="none" start_char="14701" end_char="14707">service</TOKEN>
        <TOKEN id="token-251-4" pos="word" morph="none" start_char="14709" end_char="14712">that</TOKEN>
        <TOKEN id="token-251-5" pos="word" morph="none" start_char="14714" end_char="14716">her</TOKEN>
        <TOKEN id="token-251-6" pos="word" morph="none" start_char="14718" end_char="14724">parents</TOKEN>
        <TOKEN id="token-251-7" pos="word" morph="none" start_char="14726" end_char="14735">bequeathed</TOKEN>
        <TOKEN id="token-251-8" pos="word" morph="none" start_char="14737" end_char="14738">to</TOKEN>
        <TOKEN id="token-251-9" pos="word" morph="none" start_char="14740" end_char="14742">her</TOKEN>
        <TOKEN id="token-251-10" pos="punct" morph="none" start_char="14743" end_char="14743">.</TOKEN>
        <TOKEN id="token-251-11" pos="word" morph="none" start_char="14745" end_char="14746">At</TOKEN>
        <TOKEN id="token-251-12" pos="word" morph="none" start_char="14748" end_char="14750">one</TOKEN>
        <TOKEN id="token-251-13" pos="word" morph="none" start_char="14752" end_char="14756">point</TOKEN>
        <TOKEN id="token-251-14" pos="word" morph="none" start_char="14758" end_char="14760">she</TOKEN>
      </SEG>
      <SEG id="segment-252" start_char="14762" end_char="14833">
        <ORIGINAL_TEXT>speaks of her “ ‘service gene,’ that voice telling me there is no higher</ORIGINAL_TEXT>
        <TOKEN id="token-252-0" pos="word" morph="none" start_char="14762" end_char="14767">speaks</TOKEN>
        <TOKEN id="token-252-1" pos="word" morph="none" start_char="14769" end_char="14770">of</TOKEN>
        <TOKEN id="token-252-2" pos="word" morph="none" start_char="14772" end_char="14774">her</TOKEN>
        <TOKEN id="token-252-3" pos="unknown" morph="none" start_char="14776" end_char="14776">“</TOKEN>
        <TOKEN id="token-252-4" pos="punct" morph="none" start_char="14778" end_char="14778">‘</TOKEN>
        <TOKEN id="token-252-5" pos="word" morph="none" start_char="14779" end_char="14785">service</TOKEN>
        <TOKEN id="token-252-6" pos="word" morph="none" start_char="14787" end_char="14790">gene</TOKEN>
        <TOKEN id="token-252-7" pos="punct" morph="none" start_char="14791" end_char="14792">,’</TOKEN>
        <TOKEN id="token-252-8" pos="word" morph="none" start_char="14794" end_char="14797">that</TOKEN>
        <TOKEN id="token-252-9" pos="word" morph="none" start_char="14799" end_char="14803">voice</TOKEN>
        <TOKEN id="token-252-10" pos="word" morph="none" start_char="14805" end_char="14811">telling</TOKEN>
        <TOKEN id="token-252-11" pos="word" morph="none" start_char="14813" end_char="14814">me</TOKEN>
        <TOKEN id="token-252-12" pos="word" morph="none" start_char="14816" end_char="14820">there</TOKEN>
        <TOKEN id="token-252-13" pos="word" morph="none" start_char="14822" end_char="14823">is</TOKEN>
        <TOKEN id="token-252-14" pos="word" morph="none" start_char="14825" end_char="14826">no</TOKEN>
        <TOKEN id="token-252-15" pos="word" morph="none" start_char="14828" end_char="14833">higher</TOKEN>
      </SEG>
      <SEG id="segment-253" start_char="14835" end_char="14910">
        <ORIGINAL_TEXT>calling or more noble purpose than serving your country.” Clinton also hints</ORIGINAL_TEXT>
        <TOKEN id="token-253-0" pos="word" morph="none" start_char="14835" end_char="14841">calling</TOKEN>
        <TOKEN id="token-253-1" pos="word" morph="none" start_char="14843" end_char="14844">or</TOKEN>
        <TOKEN id="token-253-2" pos="word" morph="none" start_char="14846" end_char="14849">more</TOKEN>
        <TOKEN id="token-253-3" pos="word" morph="none" start_char="14851" end_char="14855">noble</TOKEN>
        <TOKEN id="token-253-4" pos="word" morph="none" start_char="14857" end_char="14863">purpose</TOKEN>
        <TOKEN id="token-253-5" pos="word" morph="none" start_char="14865" end_char="14868">than</TOKEN>
        <TOKEN id="token-253-6" pos="word" morph="none" start_char="14870" end_char="14876">serving</TOKEN>
        <TOKEN id="token-253-7" pos="word" morph="none" start_char="14878" end_char="14881">your</TOKEN>
        <TOKEN id="token-253-8" pos="word" morph="none" start_char="14883" end_char="14889">country</TOKEN>
        <TOKEN id="token-253-9" pos="punct" morph="none" start_char="14890" end_char="14891">.”</TOKEN>
        <TOKEN id="token-253-10" pos="word" morph="none" start_char="14893" end_char="14899">Clinton</TOKEN>
        <TOKEN id="token-253-11" pos="word" morph="none" start_char="14901" end_char="14904">also</TOKEN>
        <TOKEN id="token-253-12" pos="word" morph="none" start_char="14906" end_char="14910">hints</TOKEN>
      </SEG>
      <SEG id="segment-254" start_char="14912" end_char="14987">
        <ORIGINAL_TEXT>at personal sacrifices: “When I chose to leave a career as a young lawyer in</ORIGINAL_TEXT>
        <TOKEN id="token-254-0" pos="word" morph="none" start_char="14912" end_char="14913">at</TOKEN>
        <TOKEN id="token-254-1" pos="word" morph="none" start_char="14915" end_char="14922">personal</TOKEN>
        <TOKEN id="token-254-2" pos="word" morph="none" start_char="14924" end_char="14933">sacrifices</TOKEN>
        <TOKEN id="token-254-3" pos="punct" morph="none" start_char="14934" end_char="14934">:</TOKEN>
        <TOKEN id="token-254-4" pos="punct" morph="none" start_char="14936" end_char="14936">“</TOKEN>
        <TOKEN id="token-254-5" pos="word" morph="none" start_char="14937" end_char="14940">When</TOKEN>
        <TOKEN id="token-254-6" pos="word" morph="none" start_char="14942" end_char="14942">I</TOKEN>
        <TOKEN id="token-254-7" pos="word" morph="none" start_char="14944" end_char="14948">chose</TOKEN>
        <TOKEN id="token-254-8" pos="word" morph="none" start_char="14950" end_char="14951">to</TOKEN>
        <TOKEN id="token-254-9" pos="word" morph="none" start_char="14953" end_char="14957">leave</TOKEN>
        <TOKEN id="token-254-10" pos="word" morph="none" start_char="14959" end_char="14959">a</TOKEN>
        <TOKEN id="token-254-11" pos="word" morph="none" start_char="14961" end_char="14966">career</TOKEN>
        <TOKEN id="token-254-12" pos="word" morph="none" start_char="14968" end_char="14969">as</TOKEN>
        <TOKEN id="token-254-13" pos="word" morph="none" start_char="14971" end_char="14971">a</TOKEN>
        <TOKEN id="token-254-14" pos="word" morph="none" start_char="14973" end_char="14977">young</TOKEN>
        <TOKEN id="token-254-15" pos="word" morph="none" start_char="14979" end_char="14984">lawyer</TOKEN>
        <TOKEN id="token-254-16" pos="word" morph="none" start_char="14986" end_char="14987">in</TOKEN>
      </SEG>
      <SEG id="segment-255" start_char="14989" end_char="15063">
        <ORIGINAL_TEXT>Washington to move to Arkansas to marry Bill and start a family, my friends</ORIGINAL_TEXT>
        <TOKEN id="token-255-0" pos="word" morph="none" start_char="14989" end_char="14998">Washington</TOKEN>
        <TOKEN id="token-255-1" pos="word" morph="none" start_char="15000" end_char="15001">to</TOKEN>
        <TOKEN id="token-255-2" pos="word" morph="none" start_char="15003" end_char="15006">move</TOKEN>
        <TOKEN id="token-255-3" pos="word" morph="none" start_char="15008" end_char="15009">to</TOKEN>
        <TOKEN id="token-255-4" pos="word" morph="none" start_char="15011" end_char="15018">Arkansas</TOKEN>
        <TOKEN id="token-255-5" pos="word" morph="none" start_char="15020" end_char="15021">to</TOKEN>
        <TOKEN id="token-255-6" pos="word" morph="none" start_char="15023" end_char="15027">marry</TOKEN>
        <TOKEN id="token-255-7" pos="word" morph="none" start_char="15029" end_char="15032">Bill</TOKEN>
        <TOKEN id="token-255-8" pos="word" morph="none" start_char="15034" end_char="15036">and</TOKEN>
        <TOKEN id="token-255-9" pos="word" morph="none" start_char="15038" end_char="15042">start</TOKEN>
        <TOKEN id="token-255-10" pos="word" morph="none" start_char="15044" end_char="15044">a</TOKEN>
        <TOKEN id="token-255-11" pos="word" morph="none" start_char="15046" end_char="15051">family</TOKEN>
        <TOKEN id="token-255-12" pos="punct" morph="none" start_char="15052" end_char="15052">,</TOKEN>
        <TOKEN id="token-255-13" pos="word" morph="none" start_char="15054" end_char="15055">my</TOKEN>
        <TOKEN id="token-255-14" pos="word" morph="none" start_char="15057" end_char="15063">friends</TOKEN>
      </SEG>
      <SEG id="segment-256" start_char="15065" end_char="15136">
        <ORIGINAL_TEXT>asked, ‘Are you out of your mind?’ I heard similar questions when I took</ORIGINAL_TEXT>
        <TOKEN id="token-256-0" pos="word" morph="none" start_char="15065" end_char="15069">asked</TOKEN>
        <TOKEN id="token-256-1" pos="punct" morph="none" start_char="15070" end_char="15070">,</TOKEN>
        <TOKEN id="token-256-2" pos="punct" morph="none" start_char="15072" end_char="15072">‘</TOKEN>
        <TOKEN id="token-256-3" pos="word" morph="none" start_char="15073" end_char="15075">Are</TOKEN>
        <TOKEN id="token-256-4" pos="word" morph="none" start_char="15077" end_char="15079">you</TOKEN>
        <TOKEN id="token-256-5" pos="word" morph="none" start_char="15081" end_char="15083">out</TOKEN>
        <TOKEN id="token-256-6" pos="word" morph="none" start_char="15085" end_char="15086">of</TOKEN>
        <TOKEN id="token-256-7" pos="word" morph="none" start_char="15088" end_char="15091">your</TOKEN>
        <TOKEN id="token-256-8" pos="word" morph="none" start_char="15093" end_char="15096">mind</TOKEN>
        <TOKEN id="token-256-9" pos="punct" morph="none" start_char="15097" end_char="15098">?’</TOKEN>
        <TOKEN id="token-256-10" pos="word" morph="none" start_char="15100" end_char="15100">I</TOKEN>
        <TOKEN id="token-256-11" pos="word" morph="none" start_char="15102" end_char="15106">heard</TOKEN>
        <TOKEN id="token-256-12" pos="word" morph="none" start_char="15108" end_char="15114">similar</TOKEN>
        <TOKEN id="token-256-13" pos="word" morph="none" start_char="15116" end_char="15124">questions</TOKEN>
        <TOKEN id="token-256-14" pos="word" morph="none" start_char="15126" end_char="15129">when</TOKEN>
        <TOKEN id="token-256-15" pos="word" morph="none" start_char="15131" end_char="15131">I</TOKEN>
        <TOKEN id="token-256-16" pos="word" morph="none" start_char="15133" end_char="15136">took</TOKEN>
      </SEG>
      <SEG id="segment-257" start_char="15138" end_char="15209">
        <ORIGINAL_TEXT>on health care reform as First Lady, ran for office myself, and accepted</ORIGINAL_TEXT>
        <TOKEN id="token-257-0" pos="word" morph="none" start_char="15138" end_char="15139">on</TOKEN>
        <TOKEN id="token-257-1" pos="word" morph="none" start_char="15141" end_char="15146">health</TOKEN>
        <TOKEN id="token-257-2" pos="word" morph="none" start_char="15148" end_char="15151">care</TOKEN>
        <TOKEN id="token-257-3" pos="word" morph="none" start_char="15153" end_char="15158">reform</TOKEN>
        <TOKEN id="token-257-4" pos="word" morph="none" start_char="15160" end_char="15161">as</TOKEN>
        <TOKEN id="token-257-5" pos="word" morph="none" start_char="15163" end_char="15167">First</TOKEN>
        <TOKEN id="token-257-6" pos="word" morph="none" start_char="15169" end_char="15172">Lady</TOKEN>
        <TOKEN id="token-257-7" pos="punct" morph="none" start_char="15173" end_char="15173">,</TOKEN>
        <TOKEN id="token-257-8" pos="word" morph="none" start_char="15175" end_char="15177">ran</TOKEN>
        <TOKEN id="token-257-9" pos="word" morph="none" start_char="15179" end_char="15181">for</TOKEN>
        <TOKEN id="token-257-10" pos="word" morph="none" start_char="15183" end_char="15188">office</TOKEN>
        <TOKEN id="token-257-11" pos="word" morph="none" start_char="15190" end_char="15195">myself</TOKEN>
        <TOKEN id="token-257-12" pos="punct" morph="none" start_char="15196" end_char="15196">,</TOKEN>
        <TOKEN id="token-257-13" pos="word" morph="none" start_char="15198" end_char="15200">and</TOKEN>
        <TOKEN id="token-257-14" pos="word" morph="none" start_char="15202" end_char="15209">accepted</TOKEN>
      </SEG>
      <SEG id="segment-258" start_char="15211" end_char="15281">
        <ORIGINAL_TEXT>President Barack Obama’s offer to represent our country as Secretary of</ORIGINAL_TEXT>
        <TOKEN id="token-258-0" pos="word" morph="none" start_char="15211" end_char="15219">President</TOKEN>
        <TOKEN id="token-258-1" pos="word" morph="none" start_char="15221" end_char="15226">Barack</TOKEN>
        <TOKEN id="token-258-2" pos="word" morph="none" start_char="15228" end_char="15232">Obama</TOKEN>
        <TOKEN id="token-258-3" pos="punct" morph="none" start_char="15233" end_char="15233">’</TOKEN>
        <TOKEN id="token-258-4" pos="word" morph="none" start_char="15234" end_char="15234">s</TOKEN>
        <TOKEN id="token-258-5" pos="word" morph="none" start_char="15236" end_char="15240">offer</TOKEN>
        <TOKEN id="token-258-6" pos="word" morph="none" start_char="15242" end_char="15243">to</TOKEN>
        <TOKEN id="token-258-7" pos="word" morph="none" start_char="15245" end_char="15253">represent</TOKEN>
        <TOKEN id="token-258-8" pos="word" morph="none" start_char="15255" end_char="15257">our</TOKEN>
        <TOKEN id="token-258-9" pos="word" morph="none" start_char="15259" end_char="15265">country</TOKEN>
        <TOKEN id="token-258-10" pos="word" morph="none" start_char="15267" end_char="15268">as</TOKEN>
        <TOKEN id="token-258-11" pos="word" morph="none" start_char="15270" end_char="15278">Secretary</TOKEN>
        <TOKEN id="token-258-12" pos="word" morph="none" start_char="15280" end_char="15281">of</TOKEN>
      </SEG>
      <SEG id="segment-259" start_char="15283" end_char="15289">
        <ORIGINAL_TEXT>State.”</ORIGINAL_TEXT>
        <TOKEN id="token-259-0" pos="word" morph="none" start_char="15283" end_char="15287">State</TOKEN>
        <TOKEN id="token-259-1" pos="punct" morph="none" start_char="15288" end_char="15289">.”</TOKEN>
      </SEG>
      <SEG id="segment-260" start_char="15291" end_char="15294">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-260-0" pos="unknown" morph="none" start_char="15291" end_char="15294">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-261" start_char="15296" end_char="15298">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-261-0" pos="unknown" morph="none" start_char="15296" end_char="15298">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-262" start_char="15300" end_char="15375">
        <ORIGINAL_TEXT>That is a clear message: Clinton is not enjoying all of this, and she is not</ORIGINAL_TEXT>
        <TOKEN id="token-262-0" pos="word" morph="none" start_char="15300" end_char="15303">That</TOKEN>
        <TOKEN id="token-262-1" pos="word" morph="none" start_char="15305" end_char="15306">is</TOKEN>
        <TOKEN id="token-262-2" pos="word" morph="none" start_char="15308" end_char="15308">a</TOKEN>
        <TOKEN id="token-262-3" pos="word" morph="none" start_char="15310" end_char="15314">clear</TOKEN>
        <TOKEN id="token-262-4" pos="word" morph="none" start_char="15316" end_char="15322">message</TOKEN>
        <TOKEN id="token-262-5" pos="punct" morph="none" start_char="15323" end_char="15323">:</TOKEN>
        <TOKEN id="token-262-6" pos="word" morph="none" start_char="15325" end_char="15331">Clinton</TOKEN>
        <TOKEN id="token-262-7" pos="word" morph="none" start_char="15333" end_char="15334">is</TOKEN>
        <TOKEN id="token-262-8" pos="word" morph="none" start_char="15336" end_char="15338">not</TOKEN>
        <TOKEN id="token-262-9" pos="word" morph="none" start_char="15340" end_char="15347">enjoying</TOKEN>
        <TOKEN id="token-262-10" pos="word" morph="none" start_char="15349" end_char="15351">all</TOKEN>
        <TOKEN id="token-262-11" pos="word" morph="none" start_char="15353" end_char="15354">of</TOKEN>
        <TOKEN id="token-262-12" pos="word" morph="none" start_char="15356" end_char="15359">this</TOKEN>
        <TOKEN id="token-262-13" pos="punct" morph="none" start_char="15360" end_char="15360">,</TOKEN>
        <TOKEN id="token-262-14" pos="word" morph="none" start_char="15362" end_char="15364">and</TOKEN>
        <TOKEN id="token-262-15" pos="word" morph="none" start_char="15366" end_char="15368">she</TOKEN>
        <TOKEN id="token-262-16" pos="word" morph="none" start_char="15370" end_char="15371">is</TOKEN>
        <TOKEN id="token-262-17" pos="word" morph="none" start_char="15373" end_char="15375">not</TOKEN>
      </SEG>
      <SEG id="segment-263" start_char="15377" end_char="15448">
        <ORIGINAL_TEXT>going to pretend otherwise. She didn’t move to Arkansas or tackle health</ORIGINAL_TEXT>
        <TOKEN id="token-263-0" pos="word" morph="none" start_char="15377" end_char="15381">going</TOKEN>
        <TOKEN id="token-263-1" pos="word" morph="none" start_char="15383" end_char="15384">to</TOKEN>
        <TOKEN id="token-263-2" pos="word" morph="none" start_char="15386" end_char="15392">pretend</TOKEN>
        <TOKEN id="token-263-3" pos="word" morph="none" start_char="15394" end_char="15402">otherwise</TOKEN>
        <TOKEN id="token-263-4" pos="punct" morph="none" start_char="15403" end_char="15403">.</TOKEN>
        <TOKEN id="token-263-5" pos="word" morph="none" start_char="15405" end_char="15407">She</TOKEN>
        <TOKEN id="token-263-6" pos="word" morph="none" start_char="15409" end_char="15412">didn</TOKEN>
        <TOKEN id="token-263-7" pos="punct" morph="none" start_char="15413" end_char="15413">’</TOKEN>
        <TOKEN id="token-263-8" pos="word" morph="none" start_char="15414" end_char="15414">t</TOKEN>
        <TOKEN id="token-263-9" pos="word" morph="none" start_char="15416" end_char="15419">move</TOKEN>
        <TOKEN id="token-263-10" pos="word" morph="none" start_char="15421" end_char="15422">to</TOKEN>
        <TOKEN id="token-263-11" pos="word" morph="none" start_char="15424" end_char="15431">Arkansas</TOKEN>
        <TOKEN id="token-263-12" pos="word" morph="none" start_char="15433" end_char="15434">or</TOKEN>
        <TOKEN id="token-263-13" pos="word" morph="none" start_char="15436" end_char="15441">tackle</TOKEN>
        <TOKEN id="token-263-14" pos="word" morph="none" start_char="15443" end_char="15448">health</TOKEN>
      </SEG>
      <SEG id="segment-264" start_char="15450" end_char="15527">
        <ORIGINAL_TEXT>care reform or become secretary of state because those were pleasurable things</ORIGINAL_TEXT>
        <TOKEN id="token-264-0" pos="word" morph="none" start_char="15450" end_char="15453">care</TOKEN>
        <TOKEN id="token-264-1" pos="word" morph="none" start_char="15455" end_char="15460">reform</TOKEN>
        <TOKEN id="token-264-2" pos="word" morph="none" start_char="15462" end_char="15463">or</TOKEN>
        <TOKEN id="token-264-3" pos="word" morph="none" start_char="15465" end_char="15470">become</TOKEN>
        <TOKEN id="token-264-4" pos="word" morph="none" start_char="15472" end_char="15480">secretary</TOKEN>
        <TOKEN id="token-264-5" pos="word" morph="none" start_char="15482" end_char="15483">of</TOKEN>
        <TOKEN id="token-264-6" pos="word" morph="none" start_char="15485" end_char="15489">state</TOKEN>
        <TOKEN id="token-264-7" pos="word" morph="none" start_char="15491" end_char="15497">because</TOKEN>
        <TOKEN id="token-264-8" pos="word" morph="none" start_char="15499" end_char="15503">those</TOKEN>
        <TOKEN id="token-264-9" pos="word" morph="none" start_char="15505" end_char="15508">were</TOKEN>
        <TOKEN id="token-264-10" pos="word" morph="none" start_char="15510" end_char="15520">pleasurable</TOKEN>
        <TOKEN id="token-264-11" pos="word" morph="none" start_char="15522" end_char="15527">things</TOKEN>
      </SEG>
      <SEG id="segment-265" start_char="15529" end_char="15601">
        <ORIGINAL_TEXT>to do. She was not seeking personal gratification—on the contrary. Unlike</ORIGINAL_TEXT>
        <TOKEN id="token-265-0" pos="word" morph="none" start_char="15529" end_char="15530">to</TOKEN>
        <TOKEN id="token-265-1" pos="word" morph="none" start_char="15532" end_char="15533">do</TOKEN>
        <TOKEN id="token-265-2" pos="punct" morph="none" start_char="15534" end_char="15534">.</TOKEN>
        <TOKEN id="token-265-3" pos="word" morph="none" start_char="15536" end_char="15538">She</TOKEN>
        <TOKEN id="token-265-4" pos="word" morph="none" start_char="15540" end_char="15542">was</TOKEN>
        <TOKEN id="token-265-5" pos="word" morph="none" start_char="15544" end_char="15546">not</TOKEN>
        <TOKEN id="token-265-6" pos="word" morph="none" start_char="15548" end_char="15554">seeking</TOKEN>
        <TOKEN id="token-265-7" pos="word" morph="none" start_char="15556" end_char="15563">personal</TOKEN>
        <TOKEN id="token-265-8" pos="word" morph="none" start_char="15565" end_char="15577">gratification</TOKEN>
        <TOKEN id="token-265-9" pos="punct" morph="none" start_char="15578" end_char="15578">—</TOKEN>
        <TOKEN id="token-265-10" pos="word" morph="none" start_char="15579" end_char="15580">on</TOKEN>
        <TOKEN id="token-265-11" pos="word" morph="none" start_char="15582" end_char="15584">the</TOKEN>
        <TOKEN id="token-265-12" pos="word" morph="none" start_char="15586" end_char="15593">contrary</TOKEN>
        <TOKEN id="token-265-13" pos="punct" morph="none" start_char="15594" end_char="15594">.</TOKEN>
        <TOKEN id="token-265-14" pos="word" morph="none" start_char="15596" end_char="15601">Unlike</TOKEN>
      </SEG>
      <SEG id="segment-266" start_char="15603" end_char="15680">
        <ORIGINAL_TEXT>some of the men who have been or will be her competitors, she is not motivated</ORIGINAL_TEXT>
        <TOKEN id="token-266-0" pos="word" morph="none" start_char="15603" end_char="15606">some</TOKEN>
        <TOKEN id="token-266-1" pos="word" morph="none" start_char="15608" end_char="15609">of</TOKEN>
        <TOKEN id="token-266-2" pos="word" morph="none" start_char="15611" end_char="15613">the</TOKEN>
        <TOKEN id="token-266-3" pos="word" morph="none" start_char="15615" end_char="15617">men</TOKEN>
        <TOKEN id="token-266-4" pos="word" morph="none" start_char="15619" end_char="15621">who</TOKEN>
        <TOKEN id="token-266-5" pos="word" morph="none" start_char="15623" end_char="15626">have</TOKEN>
        <TOKEN id="token-266-6" pos="word" morph="none" start_char="15628" end_char="15631">been</TOKEN>
        <TOKEN id="token-266-7" pos="word" morph="none" start_char="15633" end_char="15634">or</TOKEN>
        <TOKEN id="token-266-8" pos="word" morph="none" start_char="15636" end_char="15639">will</TOKEN>
        <TOKEN id="token-266-9" pos="word" morph="none" start_char="15641" end_char="15642">be</TOKEN>
        <TOKEN id="token-266-10" pos="word" morph="none" start_char="15644" end_char="15646">her</TOKEN>
        <TOKEN id="token-266-11" pos="word" morph="none" start_char="15648" end_char="15658">competitors</TOKEN>
        <TOKEN id="token-266-12" pos="punct" morph="none" start_char="15659" end_char="15659">,</TOKEN>
        <TOKEN id="token-266-13" pos="word" morph="none" start_char="15661" end_char="15663">she</TOKEN>
        <TOKEN id="token-266-14" pos="word" morph="none" start_char="15665" end_char="15666">is</TOKEN>
        <TOKEN id="token-266-15" pos="word" morph="none" start_char="15668" end_char="15670">not</TOKEN>
        <TOKEN id="token-266-16" pos="word" morph="none" start_char="15672" end_char="15680">motivated</TOKEN>
      </SEG>
      <SEG id="segment-267" start_char="15682" end_char="15751">
        <ORIGINAL_TEXT>by narcissism, arrogance, and egotism. She is animated entirely by her</ORIGINAL_TEXT>
        <TOKEN id="token-267-0" pos="word" morph="none" start_char="15682" end_char="15683">by</TOKEN>
        <TOKEN id="token-267-1" pos="word" morph="none" start_char="15685" end_char="15694">narcissism</TOKEN>
        <TOKEN id="token-267-2" pos="punct" morph="none" start_char="15695" end_char="15695">,</TOKEN>
        <TOKEN id="token-267-3" pos="word" morph="none" start_char="15697" end_char="15705">arrogance</TOKEN>
        <TOKEN id="token-267-4" pos="punct" morph="none" start_char="15706" end_char="15706">,</TOKEN>
        <TOKEN id="token-267-5" pos="word" morph="none" start_char="15708" end_char="15710">and</TOKEN>
        <TOKEN id="token-267-6" pos="word" morph="none" start_char="15712" end_char="15718">egotism</TOKEN>
        <TOKEN id="token-267-7" pos="punct" morph="none" start_char="15719" end_char="15719">.</TOKEN>
        <TOKEN id="token-267-8" pos="word" morph="none" start_char="15721" end_char="15723">She</TOKEN>
        <TOKEN id="token-267-9" pos="word" morph="none" start_char="15725" end_char="15726">is</TOKEN>
        <TOKEN id="token-267-10" pos="word" morph="none" start_char="15728" end_char="15735">animated</TOKEN>
        <TOKEN id="token-267-11" pos="word" morph="none" start_char="15737" end_char="15744">entirely</TOKEN>
        <TOKEN id="token-267-12" pos="word" morph="none" start_char="15746" end_char="15747">by</TOKEN>
        <TOKEN id="token-267-13" pos="word" morph="none" start_char="15749" end_char="15751">her</TOKEN>
      </SEG>
      <SEG id="segment-268" start_char="15753" end_char="15767">
        <ORIGINAL_TEXT>“service gene.”</ORIGINAL_TEXT>
        <TOKEN id="token-268-0" pos="punct" morph="none" start_char="15753" end_char="15753">“</TOKEN>
        <TOKEN id="token-268-1" pos="word" morph="none" start_char="15754" end_char="15760">service</TOKEN>
        <TOKEN id="token-268-2" pos="word" morph="none" start_char="15762" end_char="15765">gene</TOKEN>
        <TOKEN id="token-268-3" pos="punct" morph="none" start_char="15766" end_char="15767">.”</TOKEN>
      </SEG>
      <SEG id="segment-269" start_char="15769" end_char="15772">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-269-0" pos="unknown" morph="none" start_char="15769" end_char="15772">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-270" start_char="15774" end_char="15776">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-270-0" pos="unknown" morph="none" start_char="15774" end_char="15776">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-271" start_char="15778" end_char="15851">
        <ORIGINAL_TEXT>And also by her work ethic. She lets us know that she travels doggedly and</ORIGINAL_TEXT>
        <TOKEN id="token-271-0" pos="word" morph="none" start_char="15778" end_char="15780">And</TOKEN>
        <TOKEN id="token-271-1" pos="word" morph="none" start_char="15782" end_char="15785">also</TOKEN>
        <TOKEN id="token-271-2" pos="word" morph="none" start_char="15787" end_char="15788">by</TOKEN>
        <TOKEN id="token-271-3" pos="word" morph="none" start_char="15790" end_char="15792">her</TOKEN>
        <TOKEN id="token-271-4" pos="word" morph="none" start_char="15794" end_char="15797">work</TOKEN>
        <TOKEN id="token-271-5" pos="word" morph="none" start_char="15799" end_char="15803">ethic</TOKEN>
        <TOKEN id="token-271-6" pos="punct" morph="none" start_char="15804" end_char="15804">.</TOKEN>
        <TOKEN id="token-271-7" pos="word" morph="none" start_char="15806" end_char="15808">She</TOKEN>
        <TOKEN id="token-271-8" pos="word" morph="none" start_char="15810" end_char="15813">lets</TOKEN>
        <TOKEN id="token-271-9" pos="word" morph="none" start_char="15815" end_char="15816">us</TOKEN>
        <TOKEN id="token-271-10" pos="word" morph="none" start_char="15818" end_char="15821">know</TOKEN>
        <TOKEN id="token-271-11" pos="word" morph="none" start_char="15823" end_char="15826">that</TOKEN>
        <TOKEN id="token-271-12" pos="word" morph="none" start_char="15828" end_char="15830">she</TOKEN>
        <TOKEN id="token-271-13" pos="word" morph="none" start_char="15832" end_char="15838">travels</TOKEN>
        <TOKEN id="token-271-14" pos="word" morph="none" start_char="15840" end_char="15847">doggedly</TOKEN>
        <TOKEN id="token-271-15" pos="word" morph="none" start_char="15849" end_char="15851">and</TOKEN>
      </SEG>
      <SEG id="segment-272" start_char="15853" end_char="15926">
        <ORIGINAL_TEXT>works obsessively, almost to the point of making herself ill. She tells us</ORIGINAL_TEXT>
        <TOKEN id="token-272-0" pos="word" morph="none" start_char="15853" end_char="15857">works</TOKEN>
        <TOKEN id="token-272-1" pos="word" morph="none" start_char="15859" end_char="15869">obsessively</TOKEN>
        <TOKEN id="token-272-2" pos="punct" morph="none" start_char="15870" end_char="15870">,</TOKEN>
        <TOKEN id="token-272-3" pos="word" morph="none" start_char="15872" end_char="15877">almost</TOKEN>
        <TOKEN id="token-272-4" pos="word" morph="none" start_char="15879" end_char="15880">to</TOKEN>
        <TOKEN id="token-272-5" pos="word" morph="none" start_char="15882" end_char="15884">the</TOKEN>
        <TOKEN id="token-272-6" pos="word" morph="none" start_char="15886" end_char="15890">point</TOKEN>
        <TOKEN id="token-272-7" pos="word" morph="none" start_char="15892" end_char="15893">of</TOKEN>
        <TOKEN id="token-272-8" pos="word" morph="none" start_char="15895" end_char="15900">making</TOKEN>
        <TOKEN id="token-272-9" pos="word" morph="none" start_char="15902" end_char="15908">herself</TOKEN>
        <TOKEN id="token-272-10" pos="word" morph="none" start_char="15910" end_char="15912">ill</TOKEN>
        <TOKEN id="token-272-11" pos="punct" morph="none" start_char="15913" end_char="15913">.</TOKEN>
        <TOKEN id="token-272-12" pos="word" morph="none" start_char="15915" end_char="15917">She</TOKEN>
        <TOKEN id="token-272-13" pos="word" morph="none" start_char="15919" end_char="15923">tells</TOKEN>
        <TOKEN id="token-272-14" pos="word" morph="none" start_char="15925" end_char="15926">us</TOKEN>
      </SEG>
      <SEG id="segment-273" start_char="15928" end_char="16003">
        <ORIGINAL_TEXT>more than once how many countries (112) she visited while secretary of state</ORIGINAL_TEXT>
        <TOKEN id="token-273-0" pos="word" morph="none" start_char="15928" end_char="15931">more</TOKEN>
        <TOKEN id="token-273-1" pos="word" morph="none" start_char="15933" end_char="15936">than</TOKEN>
        <TOKEN id="token-273-2" pos="word" morph="none" start_char="15938" end_char="15941">once</TOKEN>
        <TOKEN id="token-273-3" pos="word" morph="none" start_char="15943" end_char="15945">how</TOKEN>
        <TOKEN id="token-273-4" pos="word" morph="none" start_char="15947" end_char="15950">many</TOKEN>
        <TOKEN id="token-273-5" pos="word" morph="none" start_char="15952" end_char="15960">countries</TOKEN>
        <TOKEN id="token-273-6" pos="punct" morph="none" start_char="15962" end_char="15962">(</TOKEN>
        <TOKEN id="token-273-7" pos="word" morph="none" start_char="15963" end_char="15965">112</TOKEN>
        <TOKEN id="token-273-8" pos="punct" morph="none" start_char="15966" end_char="15966">)</TOKEN>
        <TOKEN id="token-273-9" pos="word" morph="none" start_char="15968" end_char="15970">she</TOKEN>
        <TOKEN id="token-273-10" pos="word" morph="none" start_char="15972" end_char="15978">visited</TOKEN>
        <TOKEN id="token-273-11" pos="word" morph="none" start_char="15980" end_char="15984">while</TOKEN>
        <TOKEN id="token-273-12" pos="word" morph="none" start_char="15986" end_char="15994">secretary</TOKEN>
        <TOKEN id="token-273-13" pos="word" morph="none" start_char="15996" end_char="15997">of</TOKEN>
        <TOKEN id="token-273-14" pos="word" morph="none" start_char="15999" end_char="16003">state</TOKEN>
      </SEG>
      <SEG id="segment-274" start_char="16005" end_char="16075">
        <ORIGINAL_TEXT>and how many miles (nearly a million) she clocked up. She says that she</ORIGINAL_TEXT>
        <TOKEN id="token-274-0" pos="word" morph="none" start_char="16005" end_char="16007">and</TOKEN>
        <TOKEN id="token-274-1" pos="word" morph="none" start_char="16009" end_char="16011">how</TOKEN>
        <TOKEN id="token-274-2" pos="word" morph="none" start_char="16013" end_char="16016">many</TOKEN>
        <TOKEN id="token-274-3" pos="word" morph="none" start_char="16018" end_char="16022">miles</TOKEN>
        <TOKEN id="token-274-4" pos="punct" morph="none" start_char="16024" end_char="16024">(</TOKEN>
        <TOKEN id="token-274-5" pos="word" morph="none" start_char="16025" end_char="16030">nearly</TOKEN>
        <TOKEN id="token-274-6" pos="word" morph="none" start_char="16032" end_char="16032">a</TOKEN>
        <TOKEN id="token-274-7" pos="word" morph="none" start_char="16034" end_char="16040">million</TOKEN>
        <TOKEN id="token-274-8" pos="punct" morph="none" start_char="16041" end_char="16041">)</TOKEN>
        <TOKEN id="token-274-9" pos="word" morph="none" start_char="16043" end_char="16045">she</TOKEN>
        <TOKEN id="token-274-10" pos="word" morph="none" start_char="16047" end_char="16053">clocked</TOKEN>
        <TOKEN id="token-274-11" pos="word" morph="none" start_char="16055" end_char="16056">up</TOKEN>
        <TOKEN id="token-274-12" pos="punct" morph="none" start_char="16057" end_char="16057">.</TOKEN>
        <TOKEN id="token-274-13" pos="word" morph="none" start_char="16059" end_char="16061">She</TOKEN>
        <TOKEN id="token-274-14" pos="word" morph="none" start_char="16063" end_char="16066">says</TOKEN>
        <TOKEN id="token-274-15" pos="word" morph="none" start_char="16068" end_char="16071">that</TOKEN>
        <TOKEN id="token-274-16" pos="word" morph="none" start_char="16073" end_char="16075">she</TOKEN>
      </SEG>
      <SEG id="segment-275" start_char="16077" end_char="16148">
        <ORIGINAL_TEXT>encouraged her staff to “do whatever they could to stay sane and healthy</ORIGINAL_TEXT>
        <TOKEN id="token-275-0" pos="word" morph="none" start_char="16077" end_char="16086">encouraged</TOKEN>
        <TOKEN id="token-275-1" pos="word" morph="none" start_char="16088" end_char="16090">her</TOKEN>
        <TOKEN id="token-275-2" pos="word" morph="none" start_char="16092" end_char="16096">staff</TOKEN>
        <TOKEN id="token-275-3" pos="word" morph="none" start_char="16098" end_char="16099">to</TOKEN>
        <TOKEN id="token-275-4" pos="punct" morph="none" start_char="16101" end_char="16101">“</TOKEN>
        <TOKEN id="token-275-5" pos="word" morph="none" start_char="16102" end_char="16103">do</TOKEN>
        <TOKEN id="token-275-6" pos="word" morph="none" start_char="16105" end_char="16112">whatever</TOKEN>
        <TOKEN id="token-275-7" pos="word" morph="none" start_char="16114" end_char="16117">they</TOKEN>
        <TOKEN id="token-275-8" pos="word" morph="none" start_char="16119" end_char="16123">could</TOKEN>
        <TOKEN id="token-275-9" pos="word" morph="none" start_char="16125" end_char="16126">to</TOKEN>
        <TOKEN id="token-275-10" pos="word" morph="none" start_char="16128" end_char="16131">stay</TOKEN>
        <TOKEN id="token-275-11" pos="word" morph="none" start_char="16133" end_char="16136">sane</TOKEN>
        <TOKEN id="token-275-12" pos="word" morph="none" start_char="16138" end_char="16140">and</TOKEN>
        <TOKEN id="token-275-13" pos="word" morph="none" start_char="16142" end_char="16148">healthy</TOKEN>
      </SEG>
      <SEG id="segment-276" start_char="16150" end_char="16223">
        <ORIGINAL_TEXT>amid the rigors of a grueling schedule.” Diplomats who have dealt with her</ORIGINAL_TEXT>
        <TOKEN id="token-276-0" pos="word" morph="none" start_char="16150" end_char="16153">amid</TOKEN>
        <TOKEN id="token-276-1" pos="word" morph="none" start_char="16155" end_char="16157">the</TOKEN>
        <TOKEN id="token-276-2" pos="word" morph="none" start_char="16159" end_char="16164">rigors</TOKEN>
        <TOKEN id="token-276-3" pos="word" morph="none" start_char="16166" end_char="16167">of</TOKEN>
        <TOKEN id="token-276-4" pos="word" morph="none" start_char="16169" end_char="16169">a</TOKEN>
        <TOKEN id="token-276-5" pos="word" morph="none" start_char="16171" end_char="16178">grueling</TOKEN>
        <TOKEN id="token-276-6" pos="word" morph="none" start_char="16180" end_char="16187">schedule</TOKEN>
        <TOKEN id="token-276-7" pos="punct" morph="none" start_char="16188" end_char="16189">.”</TOKEN>
        <TOKEN id="token-276-8" pos="word" morph="none" start_char="16191" end_char="16199">Diplomats</TOKEN>
        <TOKEN id="token-276-9" pos="word" morph="none" start_char="16201" end_char="16203">who</TOKEN>
        <TOKEN id="token-276-10" pos="word" morph="none" start_char="16205" end_char="16208">have</TOKEN>
        <TOKEN id="token-276-11" pos="word" morph="none" start_char="16210" end_char="16214">dealt</TOKEN>
        <TOKEN id="token-276-12" pos="word" morph="none" start_char="16216" end_char="16219">with</TOKEN>
        <TOKEN id="token-276-13" pos="word" morph="none" start_char="16221" end_char="16223">her</TOKEN>
      </SEG>
      <SEG id="segment-277" start_char="16225" end_char="16300">
        <ORIGINAL_TEXT>do indeed testify that she really was always well-briefed and well-prepared.</ORIGINAL_TEXT>
        <TOKEN id="token-277-0" pos="word" morph="none" start_char="16225" end_char="16226">do</TOKEN>
        <TOKEN id="token-277-1" pos="word" morph="none" start_char="16228" end_char="16233">indeed</TOKEN>
        <TOKEN id="token-277-2" pos="word" morph="none" start_char="16235" end_char="16241">testify</TOKEN>
        <TOKEN id="token-277-3" pos="word" morph="none" start_char="16243" end_char="16246">that</TOKEN>
        <TOKEN id="token-277-4" pos="word" morph="none" start_char="16248" end_char="16250">she</TOKEN>
        <TOKEN id="token-277-5" pos="word" morph="none" start_char="16252" end_char="16257">really</TOKEN>
        <TOKEN id="token-277-6" pos="word" morph="none" start_char="16259" end_char="16261">was</TOKEN>
        <TOKEN id="token-277-7" pos="word" morph="none" start_char="16263" end_char="16268">always</TOKEN>
        <TOKEN id="token-277-8" pos="word" morph="none" start_char="16270" end_char="16273">well</TOKEN>
        <TOKEN id="token-277-9" pos="punct" morph="none" start_char="16274" end_char="16274">-</TOKEN>
        <TOKEN id="token-277-10" pos="word" morph="none" start_char="16275" end_char="16281">briefed</TOKEN>
        <TOKEN id="token-277-11" pos="word" morph="none" start_char="16283" end_char="16285">and</TOKEN>
        <TOKEN id="token-277-12" pos="word" morph="none" start_char="16287" end_char="16290">well</TOKEN>
        <TOKEN id="token-277-13" pos="punct" morph="none" start_char="16291" end_char="16291">-</TOKEN>
        <TOKEN id="token-277-14" pos="word" morph="none" start_char="16292" end_char="16299">prepared</TOKEN>
        <TOKEN id="token-277-15" pos="punct" morph="none" start_char="16300" end_char="16300">.</TOKEN>
      </SEG>
      <SEG id="segment-278" start_char="16302" end_char="16377">
        <ORIGINAL_TEXT>Whichever of those 112 countries she happened to be in, she always knew what</ORIGINAL_TEXT>
        <TOKEN id="token-278-0" pos="word" morph="none" start_char="16302" end_char="16310">Whichever</TOKEN>
        <TOKEN id="token-278-1" pos="word" morph="none" start_char="16312" end_char="16313">of</TOKEN>
        <TOKEN id="token-278-2" pos="word" morph="none" start_char="16315" end_char="16319">those</TOKEN>
        <TOKEN id="token-278-3" pos="number" morph="none" start_char="16321" end_char="16323">112</TOKEN>
        <TOKEN id="token-278-4" pos="word" morph="none" start_char="16325" end_char="16333">countries</TOKEN>
        <TOKEN id="token-278-5" pos="word" morph="none" start_char="16335" end_char="16337">she</TOKEN>
        <TOKEN id="token-278-6" pos="word" morph="none" start_char="16339" end_char="16346">happened</TOKEN>
        <TOKEN id="token-278-7" pos="word" morph="none" start_char="16348" end_char="16349">to</TOKEN>
        <TOKEN id="token-278-8" pos="word" morph="none" start_char="16351" end_char="16352">be</TOKEN>
        <TOKEN id="token-278-9" pos="word" morph="none" start_char="16354" end_char="16355">in</TOKEN>
        <TOKEN id="token-278-10" pos="punct" morph="none" start_char="16356" end_char="16356">,</TOKEN>
        <TOKEN id="token-278-11" pos="word" morph="none" start_char="16358" end_char="16360">she</TOKEN>
        <TOKEN id="token-278-12" pos="word" morph="none" start_char="16362" end_char="16367">always</TOKEN>
        <TOKEN id="token-278-13" pos="word" morph="none" start_char="16369" end_char="16372">knew</TOKEN>
        <TOKEN id="token-278-14" pos="word" morph="none" start_char="16374" end_char="16377">what</TOKEN>
      </SEG>
      <SEG id="segment-279" start_char="16379" end_char="16456">
        <ORIGINAL_TEXT>the issues were, and she always understood to whom she was talking. Unlike Joe</ORIGINAL_TEXT>
        <TOKEN id="token-279-0" pos="word" morph="none" start_char="16379" end_char="16381">the</TOKEN>
        <TOKEN id="token-279-1" pos="word" morph="none" start_char="16383" end_char="16388">issues</TOKEN>
        <TOKEN id="token-279-2" pos="word" morph="none" start_char="16390" end_char="16393">were</TOKEN>
        <TOKEN id="token-279-3" pos="punct" morph="none" start_char="16394" end_char="16394">,</TOKEN>
        <TOKEN id="token-279-4" pos="word" morph="none" start_char="16396" end_char="16398">and</TOKEN>
        <TOKEN id="token-279-5" pos="word" morph="none" start_char="16400" end_char="16402">she</TOKEN>
        <TOKEN id="token-279-6" pos="word" morph="none" start_char="16404" end_char="16409">always</TOKEN>
        <TOKEN id="token-279-7" pos="word" morph="none" start_char="16411" end_char="16420">understood</TOKEN>
        <TOKEN id="token-279-8" pos="word" morph="none" start_char="16422" end_char="16423">to</TOKEN>
        <TOKEN id="token-279-9" pos="word" morph="none" start_char="16425" end_char="16428">whom</TOKEN>
        <TOKEN id="token-279-10" pos="word" morph="none" start_char="16430" end_char="16432">she</TOKEN>
        <TOKEN id="token-279-11" pos="word" morph="none" start_char="16434" end_char="16436">was</TOKEN>
        <TOKEN id="token-279-12" pos="word" morph="none" start_char="16438" end_char="16444">talking</TOKEN>
        <TOKEN id="token-279-13" pos="punct" morph="none" start_char="16445" end_char="16445">.</TOKEN>
        <TOKEN id="token-279-14" pos="word" morph="none" start_char="16447" end_char="16452">Unlike</TOKEN>
        <TOKEN id="token-279-15" pos="word" morph="none" start_char="16454" end_char="16456">Joe</TOKEN>
      </SEG>
      <SEG id="segment-280" start_char="16458" end_char="16520">
        <ORIGINAL_TEXT>Biden, she never mixed up the president and the prime minister.</ORIGINAL_TEXT>
        <TOKEN id="token-280-0" pos="word" morph="none" start_char="16458" end_char="16462">Biden</TOKEN>
        <TOKEN id="token-280-1" pos="punct" morph="none" start_char="16463" end_char="16463">,</TOKEN>
        <TOKEN id="token-280-2" pos="word" morph="none" start_char="16465" end_char="16467">she</TOKEN>
        <TOKEN id="token-280-3" pos="word" morph="none" start_char="16469" end_char="16473">never</TOKEN>
        <TOKEN id="token-280-4" pos="word" morph="none" start_char="16475" end_char="16479">mixed</TOKEN>
        <TOKEN id="token-280-5" pos="word" morph="none" start_char="16481" end_char="16482">up</TOKEN>
        <TOKEN id="token-280-6" pos="word" morph="none" start_char="16484" end_char="16486">the</TOKEN>
        <TOKEN id="token-280-7" pos="word" morph="none" start_char="16488" end_char="16496">president</TOKEN>
        <TOKEN id="token-280-8" pos="word" morph="none" start_char="16498" end_char="16500">and</TOKEN>
        <TOKEN id="token-280-9" pos="word" morph="none" start_char="16502" end_char="16504">the</TOKEN>
        <TOKEN id="token-280-10" pos="word" morph="none" start_char="16506" end_char="16510">prime</TOKEN>
        <TOKEN id="token-280-11" pos="word" morph="none" start_char="16512" end_char="16519">minister</TOKEN>
        <TOKEN id="token-280-12" pos="punct" morph="none" start_char="16520" end_char="16520">.</TOKEN>
      </SEG>
      <SEG id="segment-281" start_char="16522" end_char="16525">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-281-0" pos="unknown" morph="none" start_char="16522" end_char="16525">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-282" start_char="16527" end_char="16529">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-282-0" pos="unknown" morph="none" start_char="16527" end_char="16529">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-283" start_char="16531" end_char="16600">
        <ORIGINAL_TEXT>This necessarily meant that she relied on the State Department and its</ORIGINAL_TEXT>
        <TOKEN id="token-283-0" pos="word" morph="none" start_char="16531" end_char="16534">This</TOKEN>
        <TOKEN id="token-283-1" pos="word" morph="none" start_char="16536" end_char="16546">necessarily</TOKEN>
        <TOKEN id="token-283-2" pos="word" morph="none" start_char="16548" end_char="16552">meant</TOKEN>
        <TOKEN id="token-283-3" pos="word" morph="none" start_char="16554" end_char="16557">that</TOKEN>
        <TOKEN id="token-283-4" pos="word" morph="none" start_char="16559" end_char="16561">she</TOKEN>
        <TOKEN id="token-283-5" pos="word" morph="none" start_char="16563" end_char="16568">relied</TOKEN>
        <TOKEN id="token-283-6" pos="word" morph="none" start_char="16570" end_char="16571">on</TOKEN>
        <TOKEN id="token-283-7" pos="word" morph="none" start_char="16573" end_char="16575">the</TOKEN>
        <TOKEN id="token-283-8" pos="word" morph="none" start_char="16577" end_char="16581">State</TOKEN>
        <TOKEN id="token-283-9" pos="word" morph="none" start_char="16583" end_char="16592">Department</TOKEN>
        <TOKEN id="token-283-10" pos="word" morph="none" start_char="16594" end_char="16596">and</TOKEN>
        <TOKEN id="token-283-11" pos="word" morph="none" start_char="16598" end_char="16600">its</TOKEN>
      </SEG>
      <SEG id="segment-284" start_char="16602" end_char="16672">
        <ORIGINAL_TEXT>employees rather than on her own relatively narrow knowledge of foreign</ORIGINAL_TEXT>
        <TOKEN id="token-284-0" pos="word" morph="none" start_char="16602" end_char="16610">employees</TOKEN>
        <TOKEN id="token-284-1" pos="word" morph="none" start_char="16612" end_char="16617">rather</TOKEN>
        <TOKEN id="token-284-2" pos="word" morph="none" start_char="16619" end_char="16622">than</TOKEN>
        <TOKEN id="token-284-3" pos="word" morph="none" start_char="16624" end_char="16625">on</TOKEN>
        <TOKEN id="token-284-4" pos="word" morph="none" start_char="16627" end_char="16629">her</TOKEN>
        <TOKEN id="token-284-5" pos="word" morph="none" start_char="16631" end_char="16633">own</TOKEN>
        <TOKEN id="token-284-6" pos="word" morph="none" start_char="16635" end_char="16644">relatively</TOKEN>
        <TOKEN id="token-284-7" pos="word" morph="none" start_char="16646" end_char="16651">narrow</TOKEN>
        <TOKEN id="token-284-8" pos="word" morph="none" start_char="16653" end_char="16661">knowledge</TOKEN>
        <TOKEN id="token-284-9" pos="word" morph="none" start_char="16663" end_char="16664">of</TOKEN>
        <TOKEN id="token-284-10" pos="word" morph="none" start_char="16666" end_char="16672">foreign</TOKEN>
      </SEG>
      <SEG id="segment-285" start_char="16674" end_char="16748">
        <ORIGINAL_TEXT>countries—and this, frankly, is a lot better than winging it. Indeed, there</ORIGINAL_TEXT>
        <TOKEN id="token-285-0" pos="word" morph="none" start_char="16674" end_char="16682">countries</TOKEN>
        <TOKEN id="token-285-1" pos="punct" morph="none" start_char="16683" end_char="16683">—</TOKEN>
        <TOKEN id="token-285-2" pos="word" morph="none" start_char="16684" end_char="16686">and</TOKEN>
        <TOKEN id="token-285-3" pos="word" morph="none" start_char="16688" end_char="16691">this</TOKEN>
        <TOKEN id="token-285-4" pos="punct" morph="none" start_char="16692" end_char="16692">,</TOKEN>
        <TOKEN id="token-285-5" pos="word" morph="none" start_char="16694" end_char="16700">frankly</TOKEN>
        <TOKEN id="token-285-6" pos="punct" morph="none" start_char="16701" end_char="16701">,</TOKEN>
        <TOKEN id="token-285-7" pos="word" morph="none" start_char="16703" end_char="16704">is</TOKEN>
        <TOKEN id="token-285-8" pos="word" morph="none" start_char="16706" end_char="16706">a</TOKEN>
        <TOKEN id="token-285-9" pos="word" morph="none" start_char="16708" end_char="16710">lot</TOKEN>
        <TOKEN id="token-285-10" pos="word" morph="none" start_char="16712" end_char="16717">better</TOKEN>
        <TOKEN id="token-285-11" pos="word" morph="none" start_char="16719" end_char="16722">than</TOKEN>
        <TOKEN id="token-285-12" pos="word" morph="none" start_char="16724" end_char="16730">winging</TOKEN>
        <TOKEN id="token-285-13" pos="word" morph="none" start_char="16732" end_char="16733">it</TOKEN>
        <TOKEN id="token-285-14" pos="punct" morph="none" start_char="16734" end_char="16734">.</TOKEN>
        <TOKEN id="token-285-15" pos="word" morph="none" start_char="16736" end_char="16741">Indeed</TOKEN>
        <TOKEN id="token-285-16" pos="punct" morph="none" start_char="16742" end_char="16742">,</TOKEN>
        <TOKEN id="token-285-17" pos="word" morph="none" start_char="16744" end_char="16748">there</TOKEN>
      </SEG>
      <SEG id="segment-286" start_char="16750" end_char="16824">
        <ORIGINAL_TEXT>is more than a hint of the technocrat about Clinton. She doesn’t delve into</ORIGINAL_TEXT>
        <TOKEN id="token-286-0" pos="word" morph="none" start_char="16750" end_char="16751">is</TOKEN>
        <TOKEN id="token-286-1" pos="word" morph="none" start_char="16753" end_char="16756">more</TOKEN>
        <TOKEN id="token-286-2" pos="word" morph="none" start_char="16758" end_char="16761">than</TOKEN>
        <TOKEN id="token-286-3" pos="word" morph="none" start_char="16763" end_char="16763">a</TOKEN>
        <TOKEN id="token-286-4" pos="word" morph="none" start_char="16765" end_char="16768">hint</TOKEN>
        <TOKEN id="token-286-5" pos="word" morph="none" start_char="16770" end_char="16771">of</TOKEN>
        <TOKEN id="token-286-6" pos="word" morph="none" start_char="16773" end_char="16775">the</TOKEN>
        <TOKEN id="token-286-7" pos="word" morph="none" start_char="16777" end_char="16786">technocrat</TOKEN>
        <TOKEN id="token-286-8" pos="word" morph="none" start_char="16788" end_char="16792">about</TOKEN>
        <TOKEN id="token-286-9" pos="word" morph="none" start_char="16794" end_char="16800">Clinton</TOKEN>
        <TOKEN id="token-286-10" pos="punct" morph="none" start_char="16801" end_char="16801">.</TOKEN>
        <TOKEN id="token-286-11" pos="word" morph="none" start_char="16803" end_char="16805">She</TOKEN>
        <TOKEN id="token-286-12" pos="word" morph="none" start_char="16807" end_char="16811">doesn</TOKEN>
        <TOKEN id="token-286-13" pos="punct" morph="none" start_char="16812" end_char="16812">’</TOKEN>
        <TOKEN id="token-286-14" pos="word" morph="none" start_char="16813" end_char="16813">t</TOKEN>
        <TOKEN id="token-286-15" pos="word" morph="none" start_char="16815" end_char="16819">delve</TOKEN>
        <TOKEN id="token-286-16" pos="word" morph="none" start_char="16821" end_char="16824">into</TOKEN>
      </SEG>
      <SEG id="segment-287" start_char="16826" end_char="16897">
        <ORIGINAL_TEXT>policy debates much herself, at least not in this book, but she likes to</ORIGINAL_TEXT>
        <TOKEN id="token-287-0" pos="word" morph="none" start_char="16826" end_char="16831">policy</TOKEN>
        <TOKEN id="token-287-1" pos="word" morph="none" start_char="16833" end_char="16839">debates</TOKEN>
        <TOKEN id="token-287-2" pos="word" morph="none" start_char="16841" end_char="16844">much</TOKEN>
        <TOKEN id="token-287-3" pos="word" morph="none" start_char="16846" end_char="16852">herself</TOKEN>
        <TOKEN id="token-287-4" pos="punct" morph="none" start_char="16853" end_char="16853">,</TOKEN>
        <TOKEN id="token-287-5" pos="word" morph="none" start_char="16855" end_char="16856">at</TOKEN>
        <TOKEN id="token-287-6" pos="word" morph="none" start_char="16858" end_char="16862">least</TOKEN>
        <TOKEN id="token-287-7" pos="word" morph="none" start_char="16864" end_char="16866">not</TOKEN>
        <TOKEN id="token-287-8" pos="word" morph="none" start_char="16868" end_char="16869">in</TOKEN>
        <TOKEN id="token-287-9" pos="word" morph="none" start_char="16871" end_char="16874">this</TOKEN>
        <TOKEN id="token-287-10" pos="word" morph="none" start_char="16876" end_char="16879">book</TOKEN>
        <TOKEN id="token-287-11" pos="punct" morph="none" start_char="16880" end_char="16880">,</TOKEN>
        <TOKEN id="token-287-12" pos="word" morph="none" start_char="16882" end_char="16884">but</TOKEN>
        <TOKEN id="token-287-13" pos="word" morph="none" start_char="16886" end_char="16888">she</TOKEN>
        <TOKEN id="token-287-14" pos="word" morph="none" start_char="16890" end_char="16894">likes</TOKEN>
        <TOKEN id="token-287-15" pos="word" morph="none" start_char="16896" end_char="16897">to</TOKEN>
      </SEG>
      <SEG id="segment-288" start_char="16899" end_char="16970">
        <ORIGINAL_TEXT>surround herself (along with her retinue of loyalists and handlers) with</ORIGINAL_TEXT>
        <TOKEN id="token-288-0" pos="word" morph="none" start_char="16899" end_char="16906">surround</TOKEN>
        <TOKEN id="token-288-1" pos="word" morph="none" start_char="16908" end_char="16914">herself</TOKEN>
        <TOKEN id="token-288-2" pos="punct" morph="none" start_char="16916" end_char="16916">(</TOKEN>
        <TOKEN id="token-288-3" pos="word" morph="none" start_char="16917" end_char="16921">along</TOKEN>
        <TOKEN id="token-288-4" pos="word" morph="none" start_char="16923" end_char="16926">with</TOKEN>
        <TOKEN id="token-288-5" pos="word" morph="none" start_char="16928" end_char="16930">her</TOKEN>
        <TOKEN id="token-288-6" pos="word" morph="none" start_char="16932" end_char="16938">retinue</TOKEN>
        <TOKEN id="token-288-7" pos="word" morph="none" start_char="16940" end_char="16941">of</TOKEN>
        <TOKEN id="token-288-8" pos="word" morph="none" start_char="16943" end_char="16951">loyalists</TOKEN>
        <TOKEN id="token-288-9" pos="word" morph="none" start_char="16953" end_char="16955">and</TOKEN>
        <TOKEN id="token-288-10" pos="word" morph="none" start_char="16957" end_char="16964">handlers</TOKEN>
        <TOKEN id="token-288-11" pos="punct" morph="none" start_char="16965" end_char="16965">)</TOKEN>
        <TOKEN id="token-288-12" pos="word" morph="none" start_char="16967" end_char="16970">with</TOKEN>
      </SEG>
      <SEG id="segment-289" start_char="16972" end_char="17044">
        <ORIGINAL_TEXT>people who know about things, and she has the technocrat’s desire to find</ORIGINAL_TEXT>
        <TOKEN id="token-289-0" pos="word" morph="none" start_char="16972" end_char="16977">people</TOKEN>
        <TOKEN id="token-289-1" pos="word" morph="none" start_char="16979" end_char="16981">who</TOKEN>
        <TOKEN id="token-289-2" pos="word" morph="none" start_char="16983" end_char="16986">know</TOKEN>
        <TOKEN id="token-289-3" pos="word" morph="none" start_char="16988" end_char="16992">about</TOKEN>
        <TOKEN id="token-289-4" pos="word" morph="none" start_char="16994" end_char="16999">things</TOKEN>
        <TOKEN id="token-289-5" pos="punct" morph="none" start_char="17000" end_char="17000">,</TOKEN>
        <TOKEN id="token-289-6" pos="word" morph="none" start_char="17002" end_char="17004">and</TOKEN>
        <TOKEN id="token-289-7" pos="word" morph="none" start_char="17006" end_char="17008">she</TOKEN>
        <TOKEN id="token-289-8" pos="word" morph="none" start_char="17010" end_char="17012">has</TOKEN>
        <TOKEN id="token-289-9" pos="word" morph="none" start_char="17014" end_char="17016">the</TOKEN>
        <TOKEN id="token-289-10" pos="word" morph="none" start_char="17018" end_char="17027">technocrat</TOKEN>
        <TOKEN id="token-289-11" pos="punct" morph="none" start_char="17028" end_char="17028">’</TOKEN>
        <TOKEN id="token-289-12" pos="word" morph="none" start_char="17029" end_char="17029">s</TOKEN>
        <TOKEN id="token-289-13" pos="word" morph="none" start_char="17031" end_char="17036">desire</TOKEN>
        <TOKEN id="token-289-14" pos="word" morph="none" start_char="17038" end_char="17039">to</TOKEN>
        <TOKEN id="token-289-15" pos="word" morph="none" start_char="17041" end_char="17044">find</TOKEN>
      </SEG>
      <SEG id="segment-290" start_char="17046" end_char="17121">
        <ORIGINAL_TEXT>the best solution to the problem, whatever its origin. She studiously avoids</ORIGINAL_TEXT>
        <TOKEN id="token-290-0" pos="word" morph="none" start_char="17046" end_char="17048">the</TOKEN>
        <TOKEN id="token-290-1" pos="word" morph="none" start_char="17050" end_char="17053">best</TOKEN>
        <TOKEN id="token-290-2" pos="word" morph="none" start_char="17055" end_char="17062">solution</TOKEN>
        <TOKEN id="token-290-3" pos="word" morph="none" start_char="17064" end_char="17065">to</TOKEN>
        <TOKEN id="token-290-4" pos="word" morph="none" start_char="17067" end_char="17069">the</TOKEN>
        <TOKEN id="token-290-5" pos="word" morph="none" start_char="17071" end_char="17077">problem</TOKEN>
        <TOKEN id="token-290-6" pos="punct" morph="none" start_char="17078" end_char="17078">,</TOKEN>
        <TOKEN id="token-290-7" pos="word" morph="none" start_char="17080" end_char="17087">whatever</TOKEN>
        <TOKEN id="token-290-8" pos="word" morph="none" start_char="17089" end_char="17091">its</TOKEN>
        <TOKEN id="token-290-9" pos="word" morph="none" start_char="17093" end_char="17098">origin</TOKEN>
        <TOKEN id="token-290-10" pos="punct" morph="none" start_char="17099" end_char="17099">.</TOKEN>
        <TOKEN id="token-290-11" pos="word" morph="none" start_char="17101" end_char="17103">She</TOKEN>
        <TOKEN id="token-290-12" pos="word" morph="none" start_char="17105" end_char="17114">studiously</TOKEN>
        <TOKEN id="token-290-13" pos="word" morph="none" start_char="17116" end_char="17121">avoids</TOKEN>
      </SEG>
      <SEG id="segment-291" start_char="17123" end_char="17189">
        <ORIGINAL_TEXT>anything that could be misconstrued as “ideological,” or even as an</ORIGINAL_TEXT>
        <TOKEN id="token-291-0" pos="word" morph="none" start_char="17123" end_char="17130">anything</TOKEN>
        <TOKEN id="token-291-1" pos="word" morph="none" start_char="17132" end_char="17135">that</TOKEN>
        <TOKEN id="token-291-2" pos="word" morph="none" start_char="17137" end_char="17141">could</TOKEN>
        <TOKEN id="token-291-3" pos="word" morph="none" start_char="17143" end_char="17144">be</TOKEN>
        <TOKEN id="token-291-4" pos="word" morph="none" start_char="17146" end_char="17157">misconstrued</TOKEN>
        <TOKEN id="token-291-5" pos="word" morph="none" start_char="17159" end_char="17160">as</TOKEN>
        <TOKEN id="token-291-6" pos="punct" morph="none" start_char="17162" end_char="17162">“</TOKEN>
        <TOKEN id="token-291-7" pos="word" morph="none" start_char="17163" end_char="17173">ideological</TOKEN>
        <TOKEN id="token-291-8" pos="punct" morph="none" start_char="17174" end_char="17175">,”</TOKEN>
        <TOKEN id="token-291-9" pos="word" morph="none" start_char="17177" end_char="17178">or</TOKEN>
        <TOKEN id="token-291-10" pos="word" morph="none" start_char="17180" end_char="17183">even</TOKEN>
        <TOKEN id="token-291-11" pos="word" morph="none" start_char="17185" end_char="17186">as</TOKEN>
        <TOKEN id="token-291-12" pos="word" morph="none" start_char="17188" end_char="17189">an</TOKEN>
      </SEG>
      <SEG id="segment-292" start_char="17191" end_char="17259">
        <ORIGINAL_TEXT>“idea.” She admires experience, preferring the sage advice of Richard</ORIGINAL_TEXT>
        <TOKEN id="token-292-0" pos="punct" morph="none" start_char="17191" end_char="17191">“</TOKEN>
        <TOKEN id="token-292-1" pos="word" morph="none" start_char="17192" end_char="17195">idea</TOKEN>
        <TOKEN id="token-292-2" pos="punct" morph="none" start_char="17196" end_char="17197">.”</TOKEN>
        <TOKEN id="token-292-3" pos="word" morph="none" start_char="17199" end_char="17201">She</TOKEN>
        <TOKEN id="token-292-4" pos="word" morph="none" start_char="17203" end_char="17209">admires</TOKEN>
        <TOKEN id="token-292-5" pos="word" morph="none" start_char="17211" end_char="17220">experience</TOKEN>
        <TOKEN id="token-292-6" pos="punct" morph="none" start_char="17221" end_char="17221">,</TOKEN>
        <TOKEN id="token-292-7" pos="word" morph="none" start_char="17223" end_char="17232">preferring</TOKEN>
        <TOKEN id="token-292-8" pos="word" morph="none" start_char="17234" end_char="17236">the</TOKEN>
        <TOKEN id="token-292-9" pos="word" morph="none" start_char="17238" end_char="17241">sage</TOKEN>
        <TOKEN id="token-292-10" pos="word" morph="none" start_char="17243" end_char="17248">advice</TOKEN>
        <TOKEN id="token-292-11" pos="word" morph="none" start_char="17250" end_char="17251">of</TOKEN>
        <TOKEN id="token-292-12" pos="word" morph="none" start_char="17253" end_char="17259">Richard</TOKEN>
      </SEG>
      <SEG id="segment-293" start_char="17261" end_char="17333">
        <ORIGINAL_TEXT>Holbrooke over the “younger White House aides” who rolled their eyes when</ORIGINAL_TEXT>
        <TOKEN id="token-293-0" pos="word" morph="none" start_char="17261" end_char="17269">Holbrooke</TOKEN>
        <TOKEN id="token-293-1" pos="word" morph="none" start_char="17271" end_char="17274">over</TOKEN>
        <TOKEN id="token-293-2" pos="word" morph="none" start_char="17276" end_char="17278">the</TOKEN>
        <TOKEN id="token-293-3" pos="punct" morph="none" start_char="17280" end_char="17280">“</TOKEN>
        <TOKEN id="token-293-4" pos="word" morph="none" start_char="17281" end_char="17287">younger</TOKEN>
        <TOKEN id="token-293-5" pos="word" morph="none" start_char="17289" end_char="17293">White</TOKEN>
        <TOKEN id="token-293-6" pos="word" morph="none" start_char="17295" end_char="17299">House</TOKEN>
        <TOKEN id="token-293-7" pos="word" morph="none" start_char="17301" end_char="17305">aides</TOKEN>
        <TOKEN id="token-293-8" pos="punct" morph="none" start_char="17306" end_char="17306">”</TOKEN>
        <TOKEN id="token-293-9" pos="word" morph="none" start_char="17308" end_char="17310">who</TOKEN>
        <TOKEN id="token-293-10" pos="word" morph="none" start_char="17312" end_char="17317">rolled</TOKEN>
        <TOKEN id="token-293-11" pos="word" morph="none" start_char="17319" end_char="17323">their</TOKEN>
        <TOKEN id="token-293-12" pos="word" morph="none" start_char="17325" end_char="17328">eyes</TOKEN>
        <TOKEN id="token-293-13" pos="word" morph="none" start_char="17330" end_char="17333">when</TOKEN>
      </SEG>
      <SEG id="segment-294" start_char="17335" end_char="17406">
        <ORIGINAL_TEXT>he spoke. What she seems to mean by “smart power” is policies that work.</ORIGINAL_TEXT>
        <TOKEN id="token-294-0" pos="word" morph="none" start_char="17335" end_char="17336">he</TOKEN>
        <TOKEN id="token-294-1" pos="word" morph="none" start_char="17338" end_char="17342">spoke</TOKEN>
        <TOKEN id="token-294-2" pos="punct" morph="none" start_char="17343" end_char="17343">.</TOKEN>
        <TOKEN id="token-294-3" pos="word" morph="none" start_char="17345" end_char="17348">What</TOKEN>
        <TOKEN id="token-294-4" pos="word" morph="none" start_char="17350" end_char="17352">she</TOKEN>
        <TOKEN id="token-294-5" pos="word" morph="none" start_char="17354" end_char="17358">seems</TOKEN>
        <TOKEN id="token-294-6" pos="word" morph="none" start_char="17360" end_char="17361">to</TOKEN>
        <TOKEN id="token-294-7" pos="word" morph="none" start_char="17363" end_char="17366">mean</TOKEN>
        <TOKEN id="token-294-8" pos="word" morph="none" start_char="17368" end_char="17369">by</TOKEN>
        <TOKEN id="token-294-9" pos="punct" morph="none" start_char="17371" end_char="17371">“</TOKEN>
        <TOKEN id="token-294-10" pos="word" morph="none" start_char="17372" end_char="17376">smart</TOKEN>
        <TOKEN id="token-294-11" pos="word" morph="none" start_char="17378" end_char="17382">power</TOKEN>
        <TOKEN id="token-294-12" pos="punct" morph="none" start_char="17383" end_char="17383">”</TOKEN>
        <TOKEN id="token-294-13" pos="word" morph="none" start_char="17385" end_char="17386">is</TOKEN>
        <TOKEN id="token-294-14" pos="word" morph="none" start_char="17388" end_char="17395">policies</TOKEN>
        <TOKEN id="token-294-15" pos="word" morph="none" start_char="17397" end_char="17400">that</TOKEN>
        <TOKEN id="token-294-16" pos="word" morph="none" start_char="17402" end_char="17405">work</TOKEN>
        <TOKEN id="token-294-17" pos="punct" morph="none" start_char="17406" end_char="17406">.</TOKEN>
      </SEG>
      <SEG id="segment-295" start_char="17408" end_char="17411">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-295-0" pos="unknown" morph="none" start_char="17408" end_char="17411">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-296" start_char="17413" end_char="17415">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-296-0" pos="unknown" morph="none" start_char="17413" end_char="17415">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-297" start_char="17417" end_char="17494">
        <ORIGINAL_TEXT>From all of this, it is possible to make a few good guesses about what kind of</ORIGINAL_TEXT>
        <TOKEN id="token-297-0" pos="word" morph="none" start_char="17417" end_char="17420">From</TOKEN>
        <TOKEN id="token-297-1" pos="word" morph="none" start_char="17422" end_char="17424">all</TOKEN>
        <TOKEN id="token-297-2" pos="word" morph="none" start_char="17426" end_char="17427">of</TOKEN>
        <TOKEN id="token-297-3" pos="word" morph="none" start_char="17429" end_char="17432">this</TOKEN>
        <TOKEN id="token-297-4" pos="punct" morph="none" start_char="17433" end_char="17433">,</TOKEN>
        <TOKEN id="token-297-5" pos="word" morph="none" start_char="17435" end_char="17436">it</TOKEN>
        <TOKEN id="token-297-6" pos="word" morph="none" start_char="17438" end_char="17439">is</TOKEN>
        <TOKEN id="token-297-7" pos="word" morph="none" start_char="17441" end_char="17448">possible</TOKEN>
        <TOKEN id="token-297-8" pos="word" morph="none" start_char="17450" end_char="17451">to</TOKEN>
        <TOKEN id="token-297-9" pos="word" morph="none" start_char="17453" end_char="17456">make</TOKEN>
        <TOKEN id="token-297-10" pos="word" morph="none" start_char="17458" end_char="17458">a</TOKEN>
        <TOKEN id="token-297-11" pos="word" morph="none" start_char="17460" end_char="17462">few</TOKEN>
        <TOKEN id="token-297-12" pos="word" morph="none" start_char="17464" end_char="17467">good</TOKEN>
        <TOKEN id="token-297-13" pos="word" morph="none" start_char="17469" end_char="17475">guesses</TOKEN>
        <TOKEN id="token-297-14" pos="word" morph="none" start_char="17477" end_char="17481">about</TOKEN>
        <TOKEN id="token-297-15" pos="word" morph="none" start_char="17483" end_char="17486">what</TOKEN>
        <TOKEN id="token-297-16" pos="word" morph="none" start_char="17488" end_char="17491">kind</TOKEN>
        <TOKEN id="token-297-17" pos="word" morph="none" start_char="17493" end_char="17494">of</TOKEN>
      </SEG>
      <SEG id="segment-298" start_char="17496" end_char="17573">
        <ORIGINAL_TEXT>candidate Clinton hopes to be: deeply non-ideological, a centrist. She intends</ORIGINAL_TEXT>
        <TOKEN id="token-298-0" pos="word" morph="none" start_char="17496" end_char="17504">candidate</TOKEN>
        <TOKEN id="token-298-1" pos="word" morph="none" start_char="17506" end_char="17512">Clinton</TOKEN>
        <TOKEN id="token-298-2" pos="word" morph="none" start_char="17514" end_char="17518">hopes</TOKEN>
        <TOKEN id="token-298-3" pos="word" morph="none" start_char="17520" end_char="17521">to</TOKEN>
        <TOKEN id="token-298-4" pos="word" morph="none" start_char="17523" end_char="17524">be</TOKEN>
        <TOKEN id="token-298-5" pos="punct" morph="none" start_char="17525" end_char="17525">:</TOKEN>
        <TOKEN id="token-298-6" pos="word" morph="none" start_char="17527" end_char="17532">deeply</TOKEN>
        <TOKEN id="token-298-7" pos="word" morph="none" start_char="17534" end_char="17536">non</TOKEN>
        <TOKEN id="token-298-8" pos="punct" morph="none" start_char="17537" end_char="17537">-</TOKEN>
        <TOKEN id="token-298-9" pos="word" morph="none" start_char="17538" end_char="17548">ideological</TOKEN>
        <TOKEN id="token-298-10" pos="punct" morph="none" start_char="17549" end_char="17549">,</TOKEN>
        <TOKEN id="token-298-11" pos="word" morph="none" start_char="17551" end_char="17551">a</TOKEN>
        <TOKEN id="token-298-12" pos="word" morph="none" start_char="17553" end_char="17560">centrist</TOKEN>
        <TOKEN id="token-298-13" pos="punct" morph="none" start_char="17561" end_char="17561">.</TOKEN>
        <TOKEN id="token-298-14" pos="word" morph="none" start_char="17563" end_char="17565">She</TOKEN>
        <TOKEN id="token-298-15" pos="word" morph="none" start_char="17567" end_char="17573">intends</TOKEN>
      </SEG>
      <SEG id="segment-299" start_char="17575" end_char="17650">
        <ORIGINAL_TEXT>to run as a hard-working, fact-oriented pragmatist—someone who finds ways to</ORIGINAL_TEXT>
        <TOKEN id="token-299-0" pos="word" morph="none" start_char="17575" end_char="17576">to</TOKEN>
        <TOKEN id="token-299-1" pos="word" morph="none" start_char="17578" end_char="17580">run</TOKEN>
        <TOKEN id="token-299-2" pos="word" morph="none" start_char="17582" end_char="17583">as</TOKEN>
        <TOKEN id="token-299-3" pos="word" morph="none" start_char="17585" end_char="17585">a</TOKEN>
        <TOKEN id="token-299-4" pos="word" morph="none" start_char="17587" end_char="17590">hard</TOKEN>
        <TOKEN id="token-299-5" pos="punct" morph="none" start_char="17591" end_char="17591">-</TOKEN>
        <TOKEN id="token-299-6" pos="word" morph="none" start_char="17592" end_char="17598">working</TOKEN>
        <TOKEN id="token-299-7" pos="punct" morph="none" start_char="17599" end_char="17599">,</TOKEN>
        <TOKEN id="token-299-8" pos="word" morph="none" start_char="17601" end_char="17604">fact</TOKEN>
        <TOKEN id="token-299-9" pos="punct" morph="none" start_char="17605" end_char="17605">-</TOKEN>
        <TOKEN id="token-299-10" pos="word" morph="none" start_char="17606" end_char="17613">oriented</TOKEN>
        <TOKEN id="token-299-11" pos="word" morph="none" start_char="17615" end_char="17624">pragmatist</TOKEN>
        <TOKEN id="token-299-12" pos="punct" morph="none" start_char="17625" end_char="17625">—</TOKEN>
        <TOKEN id="token-299-13" pos="word" morph="none" start_char="17626" end_char="17632">someone</TOKEN>
        <TOKEN id="token-299-14" pos="word" morph="none" start_char="17634" end_char="17636">who</TOKEN>
        <TOKEN id="token-299-15" pos="word" morph="none" start_char="17638" end_char="17642">finds</TOKEN>
        <TOKEN id="token-299-16" pos="word" morph="none" start_char="17644" end_char="17647">ways</TOKEN>
        <TOKEN id="token-299-17" pos="word" morph="none" start_char="17649" end_char="17650">to</TOKEN>
      </SEG>
      <SEG id="segment-300" start_char="17652" end_char="17729">
        <ORIGINAL_TEXT>work with difficult opponents, and not only faces up to difficult problems but</ORIGINAL_TEXT>
        <TOKEN id="token-300-0" pos="word" morph="none" start_char="17652" end_char="17655">work</TOKEN>
        <TOKEN id="token-300-1" pos="word" morph="none" start_char="17657" end_char="17660">with</TOKEN>
        <TOKEN id="token-300-2" pos="word" morph="none" start_char="17662" end_char="17670">difficult</TOKEN>
        <TOKEN id="token-300-3" pos="word" morph="none" start_char="17672" end_char="17680">opponents</TOKEN>
        <TOKEN id="token-300-4" pos="punct" morph="none" start_char="17681" end_char="17681">,</TOKEN>
        <TOKEN id="token-300-5" pos="word" morph="none" start_char="17683" end_char="17685">and</TOKEN>
        <TOKEN id="token-300-6" pos="word" morph="none" start_char="17687" end_char="17689">not</TOKEN>
        <TOKEN id="token-300-7" pos="word" morph="none" start_char="17691" end_char="17694">only</TOKEN>
        <TOKEN id="token-300-8" pos="word" morph="none" start_char="17696" end_char="17700">faces</TOKEN>
        <TOKEN id="token-300-9" pos="word" morph="none" start_char="17702" end_char="17703">up</TOKEN>
        <TOKEN id="token-300-10" pos="word" morph="none" start_char="17705" end_char="17706">to</TOKEN>
        <TOKEN id="token-300-11" pos="word" morph="none" start_char="17708" end_char="17716">difficult</TOKEN>
        <TOKEN id="token-300-12" pos="word" morph="none" start_char="17718" end_char="17725">problems</TOKEN>
        <TOKEN id="token-300-13" pos="word" morph="none" start_char="17727" end_char="17729">but</TOKEN>
      </SEG>
      <SEG id="segment-301" start_char="17731" end_char="17807">
        <ORIGINAL_TEXT>also makes the compromises needed to solve them. Again and again she portrays</ORIGINAL_TEXT>
        <TOKEN id="token-301-0" pos="word" morph="none" start_char="17731" end_char="17734">also</TOKEN>
        <TOKEN id="token-301-1" pos="word" morph="none" start_char="17736" end_char="17740">makes</TOKEN>
        <TOKEN id="token-301-2" pos="word" morph="none" start_char="17742" end_char="17744">the</TOKEN>
        <TOKEN id="token-301-3" pos="word" morph="none" start_char="17746" end_char="17756">compromises</TOKEN>
        <TOKEN id="token-301-4" pos="word" morph="none" start_char="17758" end_char="17763">needed</TOKEN>
        <TOKEN id="token-301-5" pos="word" morph="none" start_char="17765" end_char="17766">to</TOKEN>
        <TOKEN id="token-301-6" pos="word" morph="none" start_char="17768" end_char="17772">solve</TOKEN>
        <TOKEN id="token-301-7" pos="word" morph="none" start_char="17774" end_char="17777">them</TOKEN>
        <TOKEN id="token-301-8" pos="punct" morph="none" start_char="17778" end_char="17778">.</TOKEN>
        <TOKEN id="token-301-9" pos="word" morph="none" start_char="17780" end_char="17784">Again</TOKEN>
        <TOKEN id="token-301-10" pos="word" morph="none" start_char="17786" end_char="17788">and</TOKEN>
        <TOKEN id="token-301-11" pos="word" morph="none" start_char="17790" end_char="17794">again</TOKEN>
        <TOKEN id="token-301-12" pos="word" morph="none" start_char="17796" end_char="17798">she</TOKEN>
        <TOKEN id="token-301-13" pos="word" morph="none" start_char="17800" end_char="17807">portrays</TOKEN>
      </SEG>
      <SEG id="segment-302" start_char="17809" end_char="17885">
        <ORIGINAL_TEXT>herself sitting across the table from Dai Bingguo or President Putin, working</ORIGINAL_TEXT>
        <TOKEN id="token-302-0" pos="word" morph="none" start_char="17809" end_char="17815">herself</TOKEN>
        <TOKEN id="token-302-1" pos="word" morph="none" start_char="17817" end_char="17823">sitting</TOKEN>
        <TOKEN id="token-302-2" pos="word" morph="none" start_char="17825" end_char="17830">across</TOKEN>
        <TOKEN id="token-302-3" pos="word" morph="none" start_char="17832" end_char="17834">the</TOKEN>
        <TOKEN id="token-302-4" pos="word" morph="none" start_char="17836" end_char="17840">table</TOKEN>
        <TOKEN id="token-302-5" pos="word" morph="none" start_char="17842" end_char="17845">from</TOKEN>
        <TOKEN id="token-302-6" pos="word" morph="none" start_char="17847" end_char="17849">Dai</TOKEN>
        <TOKEN id="token-302-7" pos="word" morph="none" start_char="17851" end_char="17857">Bingguo</TOKEN>
        <TOKEN id="token-302-8" pos="word" morph="none" start_char="17859" end_char="17860">or</TOKEN>
        <TOKEN id="token-302-9" pos="word" morph="none" start_char="17862" end_char="17870">President</TOKEN>
        <TOKEN id="token-302-10" pos="word" morph="none" start_char="17872" end_char="17876">Putin</TOKEN>
        <TOKEN id="token-302-11" pos="punct" morph="none" start_char="17877" end_char="17877">,</TOKEN>
        <TOKEN id="token-302-12" pos="word" morph="none" start_char="17879" end_char="17885">working</TOKEN>
      </SEG>
      <SEG id="segment-303" start_char="17887" end_char="17964">
        <ORIGINAL_TEXT>hard, searching for a way forward. Similar methods, presumably, can be applied</ORIGINAL_TEXT>
        <TOKEN id="token-303-0" pos="word" morph="none" start_char="17887" end_char="17890">hard</TOKEN>
        <TOKEN id="token-303-1" pos="punct" morph="none" start_char="17891" end_char="17891">,</TOKEN>
        <TOKEN id="token-303-2" pos="word" morph="none" start_char="17893" end_char="17901">searching</TOKEN>
        <TOKEN id="token-303-3" pos="word" morph="none" start_char="17903" end_char="17905">for</TOKEN>
        <TOKEN id="token-303-4" pos="word" morph="none" start_char="17907" end_char="17907">a</TOKEN>
        <TOKEN id="token-303-5" pos="word" morph="none" start_char="17909" end_char="17911">way</TOKEN>
        <TOKEN id="token-303-6" pos="word" morph="none" start_char="17913" end_char="17919">forward</TOKEN>
        <TOKEN id="token-303-7" pos="punct" morph="none" start_char="17920" end_char="17920">.</TOKEN>
        <TOKEN id="token-303-8" pos="word" morph="none" start_char="17922" end_char="17928">Similar</TOKEN>
        <TOKEN id="token-303-9" pos="word" morph="none" start_char="17930" end_char="17936">methods</TOKEN>
        <TOKEN id="token-303-10" pos="punct" morph="none" start_char="17937" end_char="17937">,</TOKEN>
        <TOKEN id="token-303-11" pos="word" morph="none" start_char="17939" end_char="17948">presumably</TOKEN>
        <TOKEN id="token-303-12" pos="punct" morph="none" start_char="17949" end_char="17949">,</TOKEN>
        <TOKEN id="token-303-13" pos="word" morph="none" start_char="17951" end_char="17953">can</TOKEN>
        <TOKEN id="token-303-14" pos="word" morph="none" start_char="17955" end_char="17956">be</TOKEN>
        <TOKEN id="token-303-15" pos="word" morph="none" start_char="17958" end_char="17964">applied</TOKEN>
      </SEG>
      <SEG id="segment-304" start_char="17966" end_char="17994">
        <ORIGINAL_TEXT>to the Republican leadership.</ORIGINAL_TEXT>
        <TOKEN id="token-304-0" pos="word" morph="none" start_char="17966" end_char="17967">to</TOKEN>
        <TOKEN id="token-304-1" pos="word" morph="none" start_char="17969" end_char="17971">the</TOKEN>
        <TOKEN id="token-304-2" pos="word" morph="none" start_char="17973" end_char="17982">Republican</TOKEN>
        <TOKEN id="token-304-3" pos="word" morph="none" start_char="17984" end_char="17993">leadership</TOKEN>
        <TOKEN id="token-304-4" pos="punct" morph="none" start_char="17994" end_char="17994">.</TOKEN>
      </SEG>
      <SEG id="segment-305" start_char="17996" end_char="17999">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-305-0" pos="unknown" morph="none" start_char="17996" end_char="17999">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-306" start_char="18001" end_char="18003">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-306-0" pos="unknown" morph="none" start_char="18001" end_char="18003">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-307" start_char="18005" end_char="18082">
        <ORIGINAL_TEXT>Though pretty stultifying to anyone who wants a bit of moral uplift from their</ORIGINAL_TEXT>
        <TOKEN id="token-307-0" pos="word" morph="none" start_char="18005" end_char="18010">Though</TOKEN>
        <TOKEN id="token-307-1" pos="word" morph="none" start_char="18012" end_char="18017">pretty</TOKEN>
        <TOKEN id="token-307-2" pos="word" morph="none" start_char="18019" end_char="18029">stultifying</TOKEN>
        <TOKEN id="token-307-3" pos="word" morph="none" start_char="18031" end_char="18032">to</TOKEN>
        <TOKEN id="token-307-4" pos="word" morph="none" start_char="18034" end_char="18039">anyone</TOKEN>
        <TOKEN id="token-307-5" pos="word" morph="none" start_char="18041" end_char="18043">who</TOKEN>
        <TOKEN id="token-307-6" pos="word" morph="none" start_char="18045" end_char="18049">wants</TOKEN>
        <TOKEN id="token-307-7" pos="word" morph="none" start_char="18051" end_char="18051">a</TOKEN>
        <TOKEN id="token-307-8" pos="word" morph="none" start_char="18053" end_char="18055">bit</TOKEN>
        <TOKEN id="token-307-9" pos="word" morph="none" start_char="18057" end_char="18058">of</TOKEN>
        <TOKEN id="token-307-10" pos="word" morph="none" start_char="18060" end_char="18064">moral</TOKEN>
        <TOKEN id="token-307-11" pos="word" morph="none" start_char="18066" end_char="18071">uplift</TOKEN>
        <TOKEN id="token-307-12" pos="word" morph="none" start_char="18073" end_char="18076">from</TOKEN>
        <TOKEN id="token-307-13" pos="word" morph="none" start_char="18078" end_char="18082">their</TOKEN>
      </SEG>
      <SEG id="segment-308" start_char="18084" end_char="18159">
        <ORIGINAL_TEXT>presidential candidate, this might well be a brilliant campaign strategy. It</ORIGINAL_TEXT>
        <TOKEN id="token-308-0" pos="word" morph="none" start_char="18084" end_char="18095">presidential</TOKEN>
        <TOKEN id="token-308-1" pos="word" morph="none" start_char="18097" end_char="18105">candidate</TOKEN>
        <TOKEN id="token-308-2" pos="punct" morph="none" start_char="18106" end_char="18106">,</TOKEN>
        <TOKEN id="token-308-3" pos="word" morph="none" start_char="18108" end_char="18111">this</TOKEN>
        <TOKEN id="token-308-4" pos="word" morph="none" start_char="18113" end_char="18117">might</TOKEN>
        <TOKEN id="token-308-5" pos="word" morph="none" start_char="18119" end_char="18122">well</TOKEN>
        <TOKEN id="token-308-6" pos="word" morph="none" start_char="18124" end_char="18125">be</TOKEN>
        <TOKEN id="token-308-7" pos="word" morph="none" start_char="18127" end_char="18127">a</TOKEN>
        <TOKEN id="token-308-8" pos="word" morph="none" start_char="18129" end_char="18137">brilliant</TOKEN>
        <TOKEN id="token-308-9" pos="word" morph="none" start_char="18139" end_char="18146">campaign</TOKEN>
        <TOKEN id="token-308-10" pos="word" morph="none" start_char="18148" end_char="18155">strategy</TOKEN>
        <TOKEN id="token-308-11" pos="punct" morph="none" start_char="18156" end_char="18156">.</TOKEN>
        <TOKEN id="token-308-12" pos="word" morph="none" start_char="18158" end_char="18159">It</TOKEN>
      </SEG>
      <SEG id="segment-309" start_char="18161" end_char="18232">
        <ORIGINAL_TEXT>might even be a brilliant presidential strategy. Clinton wants to be the</ORIGINAL_TEXT>
        <TOKEN id="token-309-0" pos="word" morph="none" start_char="18161" end_char="18165">might</TOKEN>
        <TOKEN id="token-309-1" pos="word" morph="none" start_char="18167" end_char="18170">even</TOKEN>
        <TOKEN id="token-309-2" pos="word" morph="none" start_char="18172" end_char="18173">be</TOKEN>
        <TOKEN id="token-309-3" pos="word" morph="none" start_char="18175" end_char="18175">a</TOKEN>
        <TOKEN id="token-309-4" pos="word" morph="none" start_char="18177" end_char="18185">brilliant</TOKEN>
        <TOKEN id="token-309-5" pos="word" morph="none" start_char="18187" end_char="18198">presidential</TOKEN>
        <TOKEN id="token-309-6" pos="word" morph="none" start_char="18200" end_char="18207">strategy</TOKEN>
        <TOKEN id="token-309-7" pos="punct" morph="none" start_char="18208" end_char="18208">.</TOKEN>
        <TOKEN id="token-309-8" pos="word" morph="none" start_char="18210" end_char="18216">Clinton</TOKEN>
        <TOKEN id="token-309-9" pos="word" morph="none" start_char="18218" end_char="18222">wants</TOKEN>
        <TOKEN id="token-309-10" pos="word" morph="none" start_char="18224" end_char="18225">to</TOKEN>
        <TOKEN id="token-309-11" pos="word" morph="none" start_char="18227" end_char="18228">be</TOKEN>
        <TOKEN id="token-309-12" pos="word" morph="none" start_char="18230" end_char="18232">the</TOKEN>
      </SEG>
      <SEG id="segment-310" start_char="18234" end_char="18309">
        <ORIGINAL_TEXT>politician who will rise above the partisanship that has hamstrung the Obama</ORIGINAL_TEXT>
        <TOKEN id="token-310-0" pos="word" morph="none" start_char="18234" end_char="18243">politician</TOKEN>
        <TOKEN id="token-310-1" pos="word" morph="none" start_char="18245" end_char="18247">who</TOKEN>
        <TOKEN id="token-310-2" pos="word" morph="none" start_char="18249" end_char="18252">will</TOKEN>
        <TOKEN id="token-310-3" pos="word" morph="none" start_char="18254" end_char="18257">rise</TOKEN>
        <TOKEN id="token-310-4" pos="word" morph="none" start_char="18259" end_char="18263">above</TOKEN>
        <TOKEN id="token-310-5" pos="word" morph="none" start_char="18265" end_char="18267">the</TOKEN>
        <TOKEN id="token-310-6" pos="word" morph="none" start_char="18269" end_char="18280">partisanship</TOKEN>
        <TOKEN id="token-310-7" pos="word" morph="none" start_char="18282" end_char="18285">that</TOKEN>
        <TOKEN id="token-310-8" pos="word" morph="none" start_char="18287" end_char="18289">has</TOKEN>
        <TOKEN id="token-310-9" pos="word" morph="none" start_char="18291" end_char="18299">hamstrung</TOKEN>
        <TOKEN id="token-310-10" pos="word" morph="none" start_char="18301" end_char="18303">the</TOKEN>
        <TOKEN id="token-310-11" pos="word" morph="none" start_char="18305" end_char="18309">Obama</TOKEN>
      </SEG>
      <SEG id="segment-311" start_char="18311" end_char="18386">
        <ORIGINAL_TEXT>administration, end the gridlock in Washington, cut deals, and move forward.</ORIGINAL_TEXT>
        <TOKEN id="token-311-0" pos="word" morph="none" start_char="18311" end_char="18324">administration</TOKEN>
        <TOKEN id="token-311-1" pos="punct" morph="none" start_char="18325" end_char="18325">,</TOKEN>
        <TOKEN id="token-311-2" pos="word" morph="none" start_char="18327" end_char="18329">end</TOKEN>
        <TOKEN id="token-311-3" pos="word" morph="none" start_char="18331" end_char="18333">the</TOKEN>
        <TOKEN id="token-311-4" pos="word" morph="none" start_char="18335" end_char="18342">gridlock</TOKEN>
        <TOKEN id="token-311-5" pos="word" morph="none" start_char="18344" end_char="18345">in</TOKEN>
        <TOKEN id="token-311-6" pos="word" morph="none" start_char="18347" end_char="18356">Washington</TOKEN>
        <TOKEN id="token-311-7" pos="punct" morph="none" start_char="18357" end_char="18357">,</TOKEN>
        <TOKEN id="token-311-8" pos="word" morph="none" start_char="18359" end_char="18361">cut</TOKEN>
        <TOKEN id="token-311-9" pos="word" morph="none" start_char="18363" end_char="18367">deals</TOKEN>
        <TOKEN id="token-311-10" pos="punct" morph="none" start_char="18368" end_char="18368">,</TOKEN>
        <TOKEN id="token-311-11" pos="word" morph="none" start_char="18370" end_char="18372">and</TOKEN>
        <TOKEN id="token-311-12" pos="word" morph="none" start_char="18374" end_char="18377">move</TOKEN>
        <TOKEN id="token-311-13" pos="word" morph="none" start_char="18379" end_char="18385">forward</TOKEN>
        <TOKEN id="token-311-14" pos="punct" morph="none" start_char="18386" end_char="18386">.</TOKEN>
      </SEG>
      <SEG id="segment-312" start_char="18388" end_char="18391">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-312-0" pos="unknown" morph="none" start_char="18388" end_char="18391">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-313" start_char="18393" end_char="18395">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-313-0" pos="unknown" morph="none" start_char="18393" end_char="18395">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-314" start_char="18397" end_char="18467">
        <ORIGINAL_TEXT>In order to do this, she will transform herself into a figure of benign</ORIGINAL_TEXT>
        <TOKEN id="token-314-0" pos="word" morph="none" start_char="18397" end_char="18398">In</TOKEN>
        <TOKEN id="token-314-1" pos="word" morph="none" start_char="18400" end_char="18404">order</TOKEN>
        <TOKEN id="token-314-2" pos="word" morph="none" start_char="18406" end_char="18407">to</TOKEN>
        <TOKEN id="token-314-3" pos="word" morph="none" start_char="18409" end_char="18410">do</TOKEN>
        <TOKEN id="token-314-4" pos="word" morph="none" start_char="18412" end_char="18415">this</TOKEN>
        <TOKEN id="token-314-5" pos="punct" morph="none" start_char="18416" end_char="18416">,</TOKEN>
        <TOKEN id="token-314-6" pos="word" morph="none" start_char="18418" end_char="18420">she</TOKEN>
        <TOKEN id="token-314-7" pos="word" morph="none" start_char="18422" end_char="18425">will</TOKEN>
        <TOKEN id="token-314-8" pos="word" morph="none" start_char="18427" end_char="18435">transform</TOKEN>
        <TOKEN id="token-314-9" pos="word" morph="none" start_char="18437" end_char="18443">herself</TOKEN>
        <TOKEN id="token-314-10" pos="word" morph="none" start_char="18445" end_char="18448">into</TOKEN>
        <TOKEN id="token-314-11" pos="word" morph="none" start_char="18450" end_char="18450">a</TOKEN>
        <TOKEN id="token-314-12" pos="word" morph="none" start_char="18452" end_char="18457">figure</TOKEN>
        <TOKEN id="token-314-13" pos="word" morph="none" start_char="18459" end_char="18460">of</TOKEN>
        <TOKEN id="token-314-14" pos="word" morph="none" start_char="18462" end_char="18467">benign</TOKEN>
      </SEG>
      <SEG id="segment-315" start_char="18469" end_char="18545">
        <ORIGINAL_TEXT>neutrality. Unlike Obama, she will not inspire, but she will also not enrage.</ORIGINAL_TEXT>
        <TOKEN id="token-315-0" pos="word" morph="none" start_char="18469" end_char="18478">neutrality</TOKEN>
        <TOKEN id="token-315-1" pos="punct" morph="none" start_char="18479" end_char="18479">.</TOKEN>
        <TOKEN id="token-315-2" pos="word" morph="none" start_char="18481" end_char="18486">Unlike</TOKEN>
        <TOKEN id="token-315-3" pos="word" morph="none" start_char="18488" end_char="18492">Obama</TOKEN>
        <TOKEN id="token-315-4" pos="punct" morph="none" start_char="18493" end_char="18493">,</TOKEN>
        <TOKEN id="token-315-5" pos="word" morph="none" start_char="18495" end_char="18497">she</TOKEN>
        <TOKEN id="token-315-6" pos="word" morph="none" start_char="18499" end_char="18502">will</TOKEN>
        <TOKEN id="token-315-7" pos="word" morph="none" start_char="18504" end_char="18506">not</TOKEN>
        <TOKEN id="token-315-8" pos="word" morph="none" start_char="18508" end_char="18514">inspire</TOKEN>
        <TOKEN id="token-315-9" pos="punct" morph="none" start_char="18515" end_char="18515">,</TOKEN>
        <TOKEN id="token-315-10" pos="word" morph="none" start_char="18517" end_char="18519">but</TOKEN>
        <TOKEN id="token-315-11" pos="word" morph="none" start_char="18521" end_char="18523">she</TOKEN>
        <TOKEN id="token-315-12" pos="word" morph="none" start_char="18525" end_char="18528">will</TOKEN>
        <TOKEN id="token-315-13" pos="word" morph="none" start_char="18530" end_char="18533">also</TOKEN>
        <TOKEN id="token-315-14" pos="word" morph="none" start_char="18535" end_char="18537">not</TOKEN>
        <TOKEN id="token-315-15" pos="word" morph="none" start_char="18539" end_char="18544">enrage</TOKEN>
        <TOKEN id="token-315-16" pos="punct" morph="none" start_char="18545" end_char="18545">.</TOKEN>
      </SEG>
      <SEG id="segment-316" start_char="18547" end_char="18622">
        <ORIGINAL_TEXT>Perhaps she provoked angry passions as First Lady, but that is all behind us</ORIGINAL_TEXT>
        <TOKEN id="token-316-0" pos="word" morph="none" start_char="18547" end_char="18553">Perhaps</TOKEN>
        <TOKEN id="token-316-1" pos="word" morph="none" start_char="18555" end_char="18557">she</TOKEN>
        <TOKEN id="token-316-2" pos="word" morph="none" start_char="18559" end_char="18566">provoked</TOKEN>
        <TOKEN id="token-316-3" pos="word" morph="none" start_char="18568" end_char="18572">angry</TOKEN>
        <TOKEN id="token-316-4" pos="word" morph="none" start_char="18574" end_char="18581">passions</TOKEN>
        <TOKEN id="token-316-5" pos="word" morph="none" start_char="18583" end_char="18584">as</TOKEN>
        <TOKEN id="token-316-6" pos="word" morph="none" start_char="18586" end_char="18590">First</TOKEN>
        <TOKEN id="token-316-7" pos="word" morph="none" start_char="18592" end_char="18595">Lady</TOKEN>
        <TOKEN id="token-316-8" pos="punct" morph="none" start_char="18596" end_char="18596">,</TOKEN>
        <TOKEN id="token-316-9" pos="word" morph="none" start_char="18598" end_char="18600">but</TOKEN>
        <TOKEN id="token-316-10" pos="word" morph="none" start_char="18602" end_char="18605">that</TOKEN>
        <TOKEN id="token-316-11" pos="word" morph="none" start_char="18607" end_char="18608">is</TOKEN>
        <TOKEN id="token-316-12" pos="word" morph="none" start_char="18610" end_char="18612">all</TOKEN>
        <TOKEN id="token-316-13" pos="word" morph="none" start_char="18614" end_char="18619">behind</TOKEN>
        <TOKEN id="token-316-14" pos="word" morph="none" start_char="18621" end_char="18622">us</TOKEN>
      </SEG>
      <SEG id="segment-317" start_char="18624" end_char="18699">
        <ORIGINAL_TEXT>now. Hillary Clinton circa 2016 will promote not the left and not the right,</ORIGINAL_TEXT>
        <TOKEN id="token-317-0" pos="word" morph="none" start_char="18624" end_char="18626">now</TOKEN>
        <TOKEN id="token-317-1" pos="punct" morph="none" start_char="18627" end_char="18627">.</TOKEN>
        <TOKEN id="token-317-2" pos="word" morph="none" start_char="18629" end_char="18635">Hillary</TOKEN>
        <TOKEN id="token-317-3" pos="word" morph="none" start_char="18637" end_char="18643">Clinton</TOKEN>
        <TOKEN id="token-317-4" pos="word" morph="none" start_char="18645" end_char="18649">circa</TOKEN>
        <TOKEN id="token-317-5" pos="number" morph="none" start_char="18651" end_char="18654">2016</TOKEN>
        <TOKEN id="token-317-6" pos="word" morph="none" start_char="18656" end_char="18659">will</TOKEN>
        <TOKEN id="token-317-7" pos="word" morph="none" start_char="18661" end_char="18667">promote</TOKEN>
        <TOKEN id="token-317-8" pos="word" morph="none" start_char="18669" end_char="18671">not</TOKEN>
        <TOKEN id="token-317-9" pos="word" morph="none" start_char="18673" end_char="18675">the</TOKEN>
        <TOKEN id="token-317-10" pos="word" morph="none" start_char="18677" end_char="18680">left</TOKEN>
        <TOKEN id="token-317-11" pos="word" morph="none" start_char="18682" end_char="18684">and</TOKEN>
        <TOKEN id="token-317-12" pos="word" morph="none" start_char="18686" end_char="18688">not</TOKEN>
        <TOKEN id="token-317-13" pos="word" morph="none" start_char="18690" end_char="18692">the</TOKEN>
        <TOKEN id="token-317-14" pos="word" morph="none" start_char="18694" end_char="18698">right</TOKEN>
        <TOKEN id="token-317-15" pos="punct" morph="none" start_char="18699" end_char="18699">,</TOKEN>
      </SEG>
      <SEG id="segment-318" start_char="18701" end_char="18725">
        <ORIGINAL_TEXT>she will promote America.</ORIGINAL_TEXT>
        <TOKEN id="token-318-0" pos="word" morph="none" start_char="18701" end_char="18703">she</TOKEN>
        <TOKEN id="token-318-1" pos="word" morph="none" start_char="18705" end_char="18708">will</TOKEN>
        <TOKEN id="token-318-2" pos="word" morph="none" start_char="18710" end_char="18716">promote</TOKEN>
        <TOKEN id="token-318-3" pos="word" morph="none" start_char="18718" end_char="18724">America</TOKEN>
        <TOKEN id="token-318-4" pos="punct" morph="none" start_char="18725" end_char="18725">.</TOKEN>
      </SEG>
      <SEG id="segment-319" start_char="18727" end_char="18730">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-319-0" pos="unknown" morph="none" start_char="18727" end_char="18730">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-320" start_char="18732" end_char="18734">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-320-0" pos="unknown" morph="none" start_char="18732" end_char="18734">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-321" start_char="18736" end_char="18812">
        <ORIGINAL_TEXT>To anyone whose memory stretches back beyond the two most recent presidential</ORIGINAL_TEXT>
        <TOKEN id="token-321-0" pos="word" morph="none" start_char="18736" end_char="18737">To</TOKEN>
        <TOKEN id="token-321-1" pos="word" morph="none" start_char="18739" end_char="18744">anyone</TOKEN>
        <TOKEN id="token-321-2" pos="word" morph="none" start_char="18746" end_char="18750">whose</TOKEN>
        <TOKEN id="token-321-3" pos="word" morph="none" start_char="18752" end_char="18757">memory</TOKEN>
        <TOKEN id="token-321-4" pos="word" morph="none" start_char="18759" end_char="18767">stretches</TOKEN>
        <TOKEN id="token-321-5" pos="word" morph="none" start_char="18769" end_char="18772">back</TOKEN>
        <TOKEN id="token-321-6" pos="word" morph="none" start_char="18774" end_char="18779">beyond</TOKEN>
        <TOKEN id="token-321-7" pos="word" morph="none" start_char="18781" end_char="18783">the</TOKEN>
        <TOKEN id="token-321-8" pos="word" morph="none" start_char="18785" end_char="18787">two</TOKEN>
        <TOKEN id="token-321-9" pos="word" morph="none" start_char="18789" end_char="18792">most</TOKEN>
        <TOKEN id="token-321-10" pos="word" morph="none" start_char="18794" end_char="18799">recent</TOKEN>
        <TOKEN id="token-321-11" pos="word" morph="none" start_char="18801" end_char="18812">presidential</TOKEN>
      </SEG>
      <SEG id="segment-322" start_char="18814" end_char="18886">
        <ORIGINAL_TEXT>administrations, this may sound familiar. In the Bill Clinton years, this</ORIGINAL_TEXT>
        <TOKEN id="token-322-0" pos="word" morph="none" start_char="18814" end_char="18828">administrations</TOKEN>
        <TOKEN id="token-322-1" pos="punct" morph="none" start_char="18829" end_char="18829">,</TOKEN>
        <TOKEN id="token-322-2" pos="word" morph="none" start_char="18831" end_char="18834">this</TOKEN>
        <TOKEN id="token-322-3" pos="word" morph="none" start_char="18836" end_char="18838">may</TOKEN>
        <TOKEN id="token-322-4" pos="word" morph="none" start_char="18840" end_char="18844">sound</TOKEN>
        <TOKEN id="token-322-5" pos="word" morph="none" start_char="18846" end_char="18853">familiar</TOKEN>
        <TOKEN id="token-322-6" pos="punct" morph="none" start_char="18854" end_char="18854">.</TOKEN>
        <TOKEN id="token-322-7" pos="word" morph="none" start_char="18856" end_char="18857">In</TOKEN>
        <TOKEN id="token-322-8" pos="word" morph="none" start_char="18859" end_char="18861">the</TOKEN>
        <TOKEN id="token-322-9" pos="word" morph="none" start_char="18863" end_char="18866">Bill</TOKEN>
        <TOKEN id="token-322-10" pos="word" morph="none" start_char="18868" end_char="18874">Clinton</TOKEN>
        <TOKEN id="token-322-11" pos="word" morph="none" start_char="18876" end_char="18880">years</TOKEN>
        <TOKEN id="token-322-12" pos="punct" morph="none" start_char="18881" end_char="18881">,</TOKEN>
        <TOKEN id="token-322-13" pos="word" morph="none" start_char="18883" end_char="18886">this</TOKEN>
      </SEG>
      <SEG id="segment-323" start_char="18888" end_char="18961">
        <ORIGINAL_TEXT>stance was called “triangulation,” and it meant that the president kept an</ORIGINAL_TEXT>
        <TOKEN id="token-323-0" pos="word" morph="none" start_char="18888" end_char="18893">stance</TOKEN>
        <TOKEN id="token-323-1" pos="word" morph="none" start_char="18895" end_char="18897">was</TOKEN>
        <TOKEN id="token-323-2" pos="word" morph="none" start_char="18899" end_char="18904">called</TOKEN>
        <TOKEN id="token-323-3" pos="punct" morph="none" start_char="18906" end_char="18906">“</TOKEN>
        <TOKEN id="token-323-4" pos="word" morph="none" start_char="18907" end_char="18919">triangulation</TOKEN>
        <TOKEN id="token-323-5" pos="punct" morph="none" start_char="18920" end_char="18921">,”</TOKEN>
        <TOKEN id="token-323-6" pos="word" morph="none" start_char="18923" end_char="18925">and</TOKEN>
        <TOKEN id="token-323-7" pos="word" morph="none" start_char="18927" end_char="18928">it</TOKEN>
        <TOKEN id="token-323-8" pos="word" morph="none" start_char="18930" end_char="18934">meant</TOKEN>
        <TOKEN id="token-323-9" pos="word" morph="none" start_char="18936" end_char="18939">that</TOKEN>
        <TOKEN id="token-323-10" pos="word" morph="none" start_char="18941" end_char="18943">the</TOKEN>
        <TOKEN id="token-323-11" pos="word" morph="none" start_char="18945" end_char="18953">president</TOKEN>
        <TOKEN id="token-323-12" pos="word" morph="none" start_char="18955" end_char="18958">kept</TOKEN>
        <TOKEN id="token-323-13" pos="word" morph="none" start_char="18960" end_char="18961">an</TOKEN>
      </SEG>
      <SEG id="segment-324" start_char="18963" end_char="19039">
        <ORIGINAL_TEXT>equal distance from both the Republicans and the Democrats in Congress. Those</ORIGINAL_TEXT>
        <TOKEN id="token-324-0" pos="word" morph="none" start_char="18963" end_char="18967">equal</TOKEN>
        <TOKEN id="token-324-1" pos="word" morph="none" start_char="18969" end_char="18976">distance</TOKEN>
        <TOKEN id="token-324-2" pos="word" morph="none" start_char="18978" end_char="18981">from</TOKEN>
        <TOKEN id="token-324-3" pos="word" morph="none" start_char="18983" end_char="18986">both</TOKEN>
        <TOKEN id="token-324-4" pos="word" morph="none" start_char="18988" end_char="18990">the</TOKEN>
        <TOKEN id="token-324-5" pos="word" morph="none" start_char="18992" end_char="19002">Republicans</TOKEN>
        <TOKEN id="token-324-6" pos="word" morph="none" start_char="19004" end_char="19006">and</TOKEN>
        <TOKEN id="token-324-7" pos="word" morph="none" start_char="19008" end_char="19010">the</TOKEN>
        <TOKEN id="token-324-8" pos="word" morph="none" start_char="19012" end_char="19020">Democrats</TOKEN>
        <TOKEN id="token-324-9" pos="word" morph="none" start_char="19022" end_char="19023">in</TOKEN>
        <TOKEN id="token-324-10" pos="word" morph="none" start_char="19025" end_char="19032">Congress</TOKEN>
        <TOKEN id="token-324-11" pos="punct" morph="none" start_char="19033" end_char="19033">.</TOKEN>
        <TOKEN id="token-324-12" pos="word" morph="none" start_char="19035" end_char="19039">Those</TOKEN>
      </SEG>
      <SEG id="segment-325" start_char="19041" end_char="19113">
        <ORIGINAL_TEXT>who didn’t like it complained that, in practice, triangulation required a</ORIGINAL_TEXT>
        <TOKEN id="token-325-0" pos="word" morph="none" start_char="19041" end_char="19043">who</TOKEN>
        <TOKEN id="token-325-1" pos="word" morph="none" start_char="19045" end_char="19048">didn</TOKEN>
        <TOKEN id="token-325-2" pos="punct" morph="none" start_char="19049" end_char="19049">’</TOKEN>
        <TOKEN id="token-325-3" pos="word" morph="none" start_char="19050" end_char="19050">t</TOKEN>
        <TOKEN id="token-325-4" pos="word" morph="none" start_char="19052" end_char="19055">like</TOKEN>
        <TOKEN id="token-325-5" pos="word" morph="none" start_char="19057" end_char="19058">it</TOKEN>
        <TOKEN id="token-325-6" pos="word" morph="none" start_char="19060" end_char="19069">complained</TOKEN>
        <TOKEN id="token-325-7" pos="word" morph="none" start_char="19071" end_char="19074">that</TOKEN>
        <TOKEN id="token-325-8" pos="punct" morph="none" start_char="19075" end_char="19075">,</TOKEN>
        <TOKEN id="token-325-9" pos="word" morph="none" start_char="19077" end_char="19078">in</TOKEN>
        <TOKEN id="token-325-10" pos="word" morph="none" start_char="19080" end_char="19087">practice</TOKEN>
        <TOKEN id="token-325-11" pos="punct" morph="none" start_char="19088" end_char="19088">,</TOKEN>
        <TOKEN id="token-325-12" pos="word" morph="none" start_char="19090" end_char="19102">triangulation</TOKEN>
        <TOKEN id="token-325-13" pos="word" morph="none" start_char="19104" end_char="19111">required</TOKEN>
        <TOKEN id="token-325-14" pos="word" morph="none" start_char="19113" end_char="19113">a</TOKEN>
      </SEG>
      <SEG id="segment-326" start_char="19115" end_char="19181">
        <ORIGINAL_TEXT>rejection of anything that looked like political principle or moral</ORIGINAL_TEXT>
        <TOKEN id="token-326-0" pos="word" morph="none" start_char="19115" end_char="19123">rejection</TOKEN>
        <TOKEN id="token-326-1" pos="word" morph="none" start_char="19125" end_char="19126">of</TOKEN>
        <TOKEN id="token-326-2" pos="word" morph="none" start_char="19128" end_char="19135">anything</TOKEN>
        <TOKEN id="token-326-3" pos="word" morph="none" start_char="19137" end_char="19140">that</TOKEN>
        <TOKEN id="token-326-4" pos="word" morph="none" start_char="19142" end_char="19147">looked</TOKEN>
        <TOKEN id="token-326-5" pos="word" morph="none" start_char="19149" end_char="19152">like</TOKEN>
        <TOKEN id="token-326-6" pos="word" morph="none" start_char="19154" end_char="19162">political</TOKEN>
        <TOKEN id="token-326-7" pos="word" morph="none" start_char="19164" end_char="19172">principle</TOKEN>
        <TOKEN id="token-326-8" pos="word" morph="none" start_char="19174" end_char="19175">or</TOKEN>
        <TOKEN id="token-326-9" pos="word" morph="none" start_char="19177" end_char="19181">moral</TOKEN>
      </SEG>
      <SEG id="segment-327" start_char="19183" end_char="19257">
        <ORIGINAL_TEXT>consistency in favor of whatever policies might be politically feasible. On</ORIGINAL_TEXT>
        <TOKEN id="token-327-0" pos="word" morph="none" start_char="19183" end_char="19193">consistency</TOKEN>
        <TOKEN id="token-327-1" pos="word" morph="none" start_char="19195" end_char="19196">in</TOKEN>
        <TOKEN id="token-327-2" pos="word" morph="none" start_char="19198" end_char="19202">favor</TOKEN>
        <TOKEN id="token-327-3" pos="word" morph="none" start_char="19204" end_char="19205">of</TOKEN>
        <TOKEN id="token-327-4" pos="word" morph="none" start_char="19207" end_char="19214">whatever</TOKEN>
        <TOKEN id="token-327-5" pos="word" morph="none" start_char="19216" end_char="19223">policies</TOKEN>
        <TOKEN id="token-327-6" pos="word" morph="none" start_char="19225" end_char="19229">might</TOKEN>
        <TOKEN id="token-327-7" pos="word" morph="none" start_char="19231" end_char="19232">be</TOKEN>
        <TOKEN id="token-327-8" pos="word" morph="none" start_char="19234" end_char="19244">politically</TOKEN>
        <TOKEN id="token-327-9" pos="word" morph="none" start_char="19246" end_char="19253">feasible</TOKEN>
        <TOKEN id="token-327-10" pos="punct" morph="none" start_char="19254" end_char="19254">.</TOKEN>
        <TOKEN id="token-327-11" pos="word" morph="none" start_char="19256" end_char="19257">On</TOKEN>
      </SEG>
      <SEG id="segment-328" start_char="19259" end_char="19330">
        <ORIGINAL_TEXT>the other hand, a decade’s worth of bitter partisanship hasn’t gotten us</ORIGINAL_TEXT>
        <TOKEN id="token-328-0" pos="word" morph="none" start_char="19259" end_char="19261">the</TOKEN>
        <TOKEN id="token-328-1" pos="word" morph="none" start_char="19263" end_char="19267">other</TOKEN>
        <TOKEN id="token-328-2" pos="word" morph="none" start_char="19269" end_char="19272">hand</TOKEN>
        <TOKEN id="token-328-3" pos="punct" morph="none" start_char="19273" end_char="19273">,</TOKEN>
        <TOKEN id="token-328-4" pos="word" morph="none" start_char="19275" end_char="19275">a</TOKEN>
        <TOKEN id="token-328-5" pos="word" morph="none" start_char="19277" end_char="19282">decade</TOKEN>
        <TOKEN id="token-328-6" pos="punct" morph="none" start_char="19283" end_char="19283">’</TOKEN>
        <TOKEN id="token-328-7" pos="word" morph="none" start_char="19284" end_char="19284">s</TOKEN>
        <TOKEN id="token-328-8" pos="word" morph="none" start_char="19286" end_char="19290">worth</TOKEN>
        <TOKEN id="token-328-9" pos="word" morph="none" start_char="19292" end_char="19293">of</TOKEN>
        <TOKEN id="token-328-10" pos="word" morph="none" start_char="19295" end_char="19300">bitter</TOKEN>
        <TOKEN id="token-328-11" pos="word" morph="none" start_char="19302" end_char="19313">partisanship</TOKEN>
        <TOKEN id="token-328-12" pos="word" morph="none" start_char="19315" end_char="19318">hasn</TOKEN>
        <TOKEN id="token-328-13" pos="punct" morph="none" start_char="19319" end_char="19319">’</TOKEN>
        <TOKEN id="token-328-14" pos="word" morph="none" start_char="19320" end_char="19320">t</TOKEN>
        <TOKEN id="token-328-15" pos="word" morph="none" start_char="19322" end_char="19327">gotten</TOKEN>
        <TOKEN id="token-328-16" pos="word" morph="none" start_char="19329" end_char="19330">us</TOKEN>
      </SEG>
      <SEG id="segment-329" start_char="19332" end_char="19403">
        <ORIGINAL_TEXT>anywhere, either. After eight years of Bush and eight more of Obama, the</ORIGINAL_TEXT>
        <TOKEN id="token-329-0" pos="word" morph="none" start_char="19332" end_char="19339">anywhere</TOKEN>
        <TOKEN id="token-329-1" pos="punct" morph="none" start_char="19340" end_char="19340">,</TOKEN>
        <TOKEN id="token-329-2" pos="word" morph="none" start_char="19342" end_char="19347">either</TOKEN>
        <TOKEN id="token-329-3" pos="punct" morph="none" start_char="19348" end_char="19348">.</TOKEN>
        <TOKEN id="token-329-4" pos="word" morph="none" start_char="19350" end_char="19354">After</TOKEN>
        <TOKEN id="token-329-5" pos="word" morph="none" start_char="19356" end_char="19360">eight</TOKEN>
        <TOKEN id="token-329-6" pos="word" morph="none" start_char="19362" end_char="19366">years</TOKEN>
        <TOKEN id="token-329-7" pos="word" morph="none" start_char="19368" end_char="19369">of</TOKEN>
        <TOKEN id="token-329-8" pos="word" morph="none" start_char="19371" end_char="19374">Bush</TOKEN>
        <TOKEN id="token-329-9" pos="word" morph="none" start_char="19376" end_char="19378">and</TOKEN>
        <TOKEN id="token-329-10" pos="word" morph="none" start_char="19380" end_char="19384">eight</TOKEN>
        <TOKEN id="token-329-11" pos="word" morph="none" start_char="19386" end_char="19389">more</TOKEN>
        <TOKEN id="token-329-12" pos="word" morph="none" start_char="19391" end_char="19392">of</TOKEN>
        <TOKEN id="token-329-13" pos="word" morph="none" start_char="19394" end_char="19398">Obama</TOKEN>
        <TOKEN id="token-329-14" pos="punct" morph="none" start_char="19399" end_char="19399">,</TOKEN>
        <TOKEN id="token-329-15" pos="word" morph="none" start_char="19401" end_char="19403">the</TOKEN>
      </SEG>
      <SEG id="segment-330" start_char="19405" end_char="19471">
        <ORIGINAL_TEXT>nation might well be tired of Big Ideas, and might well prefer some</ORIGINAL_TEXT>
        <TOKEN id="token-330-0" pos="word" morph="none" start_char="19405" end_char="19410">nation</TOKEN>
        <TOKEN id="token-330-1" pos="word" morph="none" start_char="19412" end_char="19416">might</TOKEN>
        <TOKEN id="token-330-2" pos="word" morph="none" start_char="19418" end_char="19421">well</TOKEN>
        <TOKEN id="token-330-3" pos="word" morph="none" start_char="19423" end_char="19424">be</TOKEN>
        <TOKEN id="token-330-4" pos="word" morph="none" start_char="19426" end_char="19430">tired</TOKEN>
        <TOKEN id="token-330-5" pos="word" morph="none" start_char="19432" end_char="19433">of</TOKEN>
        <TOKEN id="token-330-6" pos="word" morph="none" start_char="19435" end_char="19437">Big</TOKEN>
        <TOKEN id="token-330-7" pos="word" morph="none" start_char="19439" end_char="19443">Ideas</TOKEN>
        <TOKEN id="token-330-8" pos="punct" morph="none" start_char="19444" end_char="19444">,</TOKEN>
        <TOKEN id="token-330-9" pos="word" morph="none" start_char="19446" end_char="19448">and</TOKEN>
        <TOKEN id="token-330-10" pos="word" morph="none" start_char="19450" end_char="19454">might</TOKEN>
        <TOKEN id="token-330-11" pos="word" morph="none" start_char="19456" end_char="19459">well</TOKEN>
        <TOKEN id="token-330-12" pos="word" morph="none" start_char="19461" end_char="19466">prefer</TOKEN>
        <TOKEN id="token-330-13" pos="word" morph="none" start_char="19468" end_char="19471">some</TOKEN>
      </SEG>
      <SEG id="segment-331" start_char="19473" end_char="19515">
        <ORIGINAL_TEXT>old-fashioned wheeling and dealing instead.</ORIGINAL_TEXT>
        <TOKEN id="token-331-0" pos="word" morph="none" start_char="19473" end_char="19475">old</TOKEN>
        <TOKEN id="token-331-1" pos="punct" morph="none" start_char="19476" end_char="19476">-</TOKEN>
        <TOKEN id="token-331-2" pos="word" morph="none" start_char="19477" end_char="19485">fashioned</TOKEN>
        <TOKEN id="token-331-3" pos="word" morph="none" start_char="19487" end_char="19494">wheeling</TOKEN>
        <TOKEN id="token-331-4" pos="word" morph="none" start_char="19496" end_char="19498">and</TOKEN>
        <TOKEN id="token-331-5" pos="word" morph="none" start_char="19500" end_char="19506">dealing</TOKEN>
        <TOKEN id="token-331-6" pos="word" morph="none" start_char="19508" end_char="19514">instead</TOKEN>
        <TOKEN id="token-331-7" pos="punct" morph="none" start_char="19515" end_char="19515">.</TOKEN>
      </SEG>
      <SEG id="segment-332" start_char="19517" end_char="19520">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-332-0" pos="unknown" morph="none" start_char="19517" end_char="19520">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-333" start_char="19522" end_char="19524">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-333-0" pos="unknown" morph="none" start_char="19522" end_char="19524">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-334" start_char="19526" end_char="19601">
        <ORIGINAL_TEXT>As for Clinton’s lack of emotion, and the reliance on stiff formulations and</ORIGINAL_TEXT>
        <TOKEN id="token-334-0" pos="word" morph="none" start_char="19526" end_char="19527">As</TOKEN>
        <TOKEN id="token-334-1" pos="word" morph="none" start_char="19529" end_char="19531">for</TOKEN>
        <TOKEN id="token-334-2" pos="word" morph="none" start_char="19533" end_char="19539">Clinton</TOKEN>
        <TOKEN id="token-334-3" pos="punct" morph="none" start_char="19540" end_char="19540">’</TOKEN>
        <TOKEN id="token-334-4" pos="word" morph="none" start_char="19541" end_char="19541">s</TOKEN>
        <TOKEN id="token-334-5" pos="word" morph="none" start_char="19543" end_char="19546">lack</TOKEN>
        <TOKEN id="token-334-6" pos="word" morph="none" start_char="19548" end_char="19549">of</TOKEN>
        <TOKEN id="token-334-7" pos="word" morph="none" start_char="19551" end_char="19557">emotion</TOKEN>
        <TOKEN id="token-334-8" pos="punct" morph="none" start_char="19558" end_char="19558">,</TOKEN>
        <TOKEN id="token-334-9" pos="word" morph="none" start_char="19560" end_char="19562">and</TOKEN>
        <TOKEN id="token-334-10" pos="word" morph="none" start_char="19564" end_char="19566">the</TOKEN>
        <TOKEN id="token-334-11" pos="word" morph="none" start_char="19568" end_char="19575">reliance</TOKEN>
        <TOKEN id="token-334-12" pos="word" morph="none" start_char="19577" end_char="19578">on</TOKEN>
        <TOKEN id="token-334-13" pos="word" morph="none" start_char="19580" end_char="19584">stiff</TOKEN>
        <TOKEN id="token-334-14" pos="word" morph="none" start_char="19586" end_char="19597">formulations</TOKEN>
        <TOKEN id="token-334-15" pos="word" morph="none" start_char="19599" end_char="19601">and</TOKEN>
      </SEG>
      <SEG id="segment-335" start_char="19603" end_char="19677">
        <ORIGINAL_TEXT>cliché— well, we might as well get used to it. For there is another message</ORIGINAL_TEXT>
        <TOKEN id="token-335-0" pos="word" morph="none" start_char="19603" end_char="19608">cliché</TOKEN>
        <TOKEN id="token-335-1" pos="punct" morph="none" start_char="19609" end_char="19609">—</TOKEN>
        <TOKEN id="token-335-2" pos="word" morph="none" start_char="19611" end_char="19614">well</TOKEN>
        <TOKEN id="token-335-3" pos="punct" morph="none" start_char="19615" end_char="19615">,</TOKEN>
        <TOKEN id="token-335-4" pos="word" morph="none" start_char="19617" end_char="19618">we</TOKEN>
        <TOKEN id="token-335-5" pos="word" morph="none" start_char="19620" end_char="19624">might</TOKEN>
        <TOKEN id="token-335-6" pos="word" morph="none" start_char="19626" end_char="19627">as</TOKEN>
        <TOKEN id="token-335-7" pos="word" morph="none" start_char="19629" end_char="19632">well</TOKEN>
        <TOKEN id="token-335-8" pos="word" morph="none" start_char="19634" end_char="19636">get</TOKEN>
        <TOKEN id="token-335-9" pos="word" morph="none" start_char="19638" end_char="19641">used</TOKEN>
        <TOKEN id="token-335-10" pos="word" morph="none" start_char="19643" end_char="19644">to</TOKEN>
        <TOKEN id="token-335-11" pos="word" morph="none" start_char="19646" end_char="19647">it</TOKEN>
        <TOKEN id="token-335-12" pos="punct" morph="none" start_char="19648" end_char="19648">.</TOKEN>
        <TOKEN id="token-335-13" pos="word" morph="none" start_char="19650" end_char="19652">For</TOKEN>
        <TOKEN id="token-335-14" pos="word" morph="none" start_char="19654" end_char="19658">there</TOKEN>
        <TOKEN id="token-335-15" pos="word" morph="none" start_char="19660" end_char="19661">is</TOKEN>
        <TOKEN id="token-335-16" pos="word" morph="none" start_char="19663" end_char="19669">another</TOKEN>
        <TOKEN id="token-335-17" pos="word" morph="none" start_char="19671" end_char="19677">message</TOKEN>
      </SEG>
      <SEG id="segment-336" start_char="19679" end_char="19749">
        <ORIGINAL_TEXT>in Hard Choices: by writing the kind of book that she wrote, Clinton is</ORIGINAL_TEXT>
        <TOKEN id="token-336-0" pos="word" morph="none" start_char="19679" end_char="19680">in</TOKEN>
        <TOKEN id="token-336-1" pos="word" morph="none" start_char="19682" end_char="19685">Hard</TOKEN>
        <TOKEN id="token-336-2" pos="word" morph="none" start_char="19687" end_char="19693">Choices</TOKEN>
        <TOKEN id="token-336-3" pos="punct" morph="none" start_char="19694" end_char="19694">:</TOKEN>
        <TOKEN id="token-336-4" pos="word" morph="none" start_char="19696" end_char="19697">by</TOKEN>
        <TOKEN id="token-336-5" pos="word" morph="none" start_char="19699" end_char="19705">writing</TOKEN>
        <TOKEN id="token-336-6" pos="word" morph="none" start_char="19707" end_char="19709">the</TOKEN>
        <TOKEN id="token-336-7" pos="word" morph="none" start_char="19711" end_char="19714">kind</TOKEN>
        <TOKEN id="token-336-8" pos="word" morph="none" start_char="19716" end_char="19717">of</TOKEN>
        <TOKEN id="token-336-9" pos="word" morph="none" start_char="19719" end_char="19722">book</TOKEN>
        <TOKEN id="token-336-10" pos="word" morph="none" start_char="19724" end_char="19727">that</TOKEN>
        <TOKEN id="token-336-11" pos="word" morph="none" start_char="19729" end_char="19731">she</TOKEN>
        <TOKEN id="token-336-12" pos="word" morph="none" start_char="19733" end_char="19737">wrote</TOKEN>
        <TOKEN id="token-336-13" pos="punct" morph="none" start_char="19738" end_char="19738">,</TOKEN>
        <TOKEN id="token-336-14" pos="word" morph="none" start_char="19740" end_char="19746">Clinton</TOKEN>
        <TOKEN id="token-336-15" pos="word" morph="none" start_char="19748" end_char="19749">is</TOKEN>
      </SEG>
      <SEG id="segment-337" start_char="19751" end_char="19824">
        <ORIGINAL_TEXT>indicating that she is not going to open up and reveal herself in some new</ORIGINAL_TEXT>
        <TOKEN id="token-337-0" pos="word" morph="none" start_char="19751" end_char="19760">indicating</TOKEN>
        <TOKEN id="token-337-1" pos="word" morph="none" start_char="19762" end_char="19765">that</TOKEN>
        <TOKEN id="token-337-2" pos="word" morph="none" start_char="19767" end_char="19769">she</TOKEN>
        <TOKEN id="token-337-3" pos="word" morph="none" start_char="19771" end_char="19772">is</TOKEN>
        <TOKEN id="token-337-4" pos="word" morph="none" start_char="19774" end_char="19776">not</TOKEN>
        <TOKEN id="token-337-5" pos="word" morph="none" start_char="19778" end_char="19782">going</TOKEN>
        <TOKEN id="token-337-6" pos="word" morph="none" start_char="19784" end_char="19785">to</TOKEN>
        <TOKEN id="token-337-7" pos="word" morph="none" start_char="19787" end_char="19790">open</TOKEN>
        <TOKEN id="token-337-8" pos="word" morph="none" start_char="19792" end_char="19793">up</TOKEN>
        <TOKEN id="token-337-9" pos="word" morph="none" start_char="19795" end_char="19797">and</TOKEN>
        <TOKEN id="token-337-10" pos="word" morph="none" start_char="19799" end_char="19804">reveal</TOKEN>
        <TOKEN id="token-337-11" pos="word" morph="none" start_char="19806" end_char="19812">herself</TOKEN>
        <TOKEN id="token-337-12" pos="word" morph="none" start_char="19814" end_char="19815">in</TOKEN>
        <TOKEN id="token-337-13" pos="word" morph="none" start_char="19817" end_char="19820">some</TOKEN>
        <TOKEN id="token-337-14" pos="word" morph="none" start_char="19822" end_char="19824">new</TOKEN>
      </SEG>
      <SEG id="segment-338" start_char="19826" end_char="19900">
        <ORIGINAL_TEXT>way—ever. If there is more depth beneath the surface, if she is less stolid</ORIGINAL_TEXT>
        <TOKEN id="token-338-0" pos="word" morph="none" start_char="19826" end_char="19828">way</TOKEN>
        <TOKEN id="token-338-1" pos="punct" morph="none" start_char="19829" end_char="19829">—</TOKEN>
        <TOKEN id="token-338-2" pos="word" morph="none" start_char="19830" end_char="19833">ever</TOKEN>
        <TOKEN id="token-338-3" pos="punct" morph="none" start_char="19834" end_char="19834">.</TOKEN>
        <TOKEN id="token-338-4" pos="word" morph="none" start_char="19836" end_char="19837">If</TOKEN>
        <TOKEN id="token-338-5" pos="word" morph="none" start_char="19839" end_char="19843">there</TOKEN>
        <TOKEN id="token-338-6" pos="word" morph="none" start_char="19845" end_char="19846">is</TOKEN>
        <TOKEN id="token-338-7" pos="word" morph="none" start_char="19848" end_char="19851">more</TOKEN>
        <TOKEN id="token-338-8" pos="word" morph="none" start_char="19853" end_char="19857">depth</TOKEN>
        <TOKEN id="token-338-9" pos="word" morph="none" start_char="19859" end_char="19865">beneath</TOKEN>
        <TOKEN id="token-338-10" pos="word" morph="none" start_char="19867" end_char="19869">the</TOKEN>
        <TOKEN id="token-338-11" pos="word" morph="none" start_char="19871" end_char="19877">surface</TOKEN>
        <TOKEN id="token-338-12" pos="punct" morph="none" start_char="19878" end_char="19878">,</TOKEN>
        <TOKEN id="token-338-13" pos="word" morph="none" start_char="19880" end_char="19881">if</TOKEN>
        <TOKEN id="token-338-14" pos="word" morph="none" start_char="19883" end_char="19885">she</TOKEN>
        <TOKEN id="token-338-15" pos="word" morph="none" start_char="19887" end_char="19888">is</TOKEN>
        <TOKEN id="token-338-16" pos="word" morph="none" start_char="19890" end_char="19893">less</TOKEN>
        <TOKEN id="token-338-17" pos="word" morph="none" start_char="19895" end_char="19900">stolid</TOKEN>
      </SEG>
      <SEG id="segment-339" start_char="19902" end_char="19974">
        <ORIGINAL_TEXT>and lackluster than she appears to be, then we aren’t going to know about</ORIGINAL_TEXT>
        <TOKEN id="token-339-0" pos="word" morph="none" start_char="19902" end_char="19904">and</TOKEN>
        <TOKEN id="token-339-1" pos="word" morph="none" start_char="19906" end_char="19915">lackluster</TOKEN>
        <TOKEN id="token-339-2" pos="word" morph="none" start_char="19917" end_char="19920">than</TOKEN>
        <TOKEN id="token-339-3" pos="word" morph="none" start_char="19922" end_char="19924">she</TOKEN>
        <TOKEN id="token-339-4" pos="word" morph="none" start_char="19926" end_char="19932">appears</TOKEN>
        <TOKEN id="token-339-5" pos="word" morph="none" start_char="19934" end_char="19935">to</TOKEN>
        <TOKEN id="token-339-6" pos="word" morph="none" start_char="19937" end_char="19938">be</TOKEN>
        <TOKEN id="token-339-7" pos="punct" morph="none" start_char="19939" end_char="19939">,</TOKEN>
        <TOKEN id="token-339-8" pos="word" morph="none" start_char="19941" end_char="19944">then</TOKEN>
        <TOKEN id="token-339-9" pos="word" morph="none" start_char="19946" end_char="19947">we</TOKEN>
        <TOKEN id="token-339-10" pos="word" morph="none" start_char="19949" end_char="19952">aren</TOKEN>
        <TOKEN id="token-339-11" pos="punct" morph="none" start_char="19953" end_char="19953">’</TOKEN>
        <TOKEN id="token-339-12" pos="word" morph="none" start_char="19954" end_char="19954">t</TOKEN>
        <TOKEN id="token-339-13" pos="word" morph="none" start_char="19956" end_char="19960">going</TOKEN>
        <TOKEN id="token-339-14" pos="word" morph="none" start_char="19962" end_char="19963">to</TOKEN>
        <TOKEN id="token-339-15" pos="word" morph="none" start_char="19965" end_char="19968">know</TOKEN>
        <TOKEN id="token-339-16" pos="word" morph="none" start_char="19970" end_char="19974">about</TOKEN>
      </SEG>
      <SEG id="segment-340" start_char="19976" end_char="20052">
        <ORIGINAL_TEXT>it. This is a woman who is aware that every outfit she wears, every hairstyle</ORIGINAL_TEXT>
        <TOKEN id="token-340-0" pos="word" morph="none" start_char="19976" end_char="19977">it</TOKEN>
        <TOKEN id="token-340-1" pos="punct" morph="none" start_char="19978" end_char="19978">.</TOKEN>
        <TOKEN id="token-340-2" pos="word" morph="none" start_char="19980" end_char="19983">This</TOKEN>
        <TOKEN id="token-340-3" pos="word" morph="none" start_char="19985" end_char="19986">is</TOKEN>
        <TOKEN id="token-340-4" pos="word" morph="none" start_char="19988" end_char="19988">a</TOKEN>
        <TOKEN id="token-340-5" pos="word" morph="none" start_char="19990" end_char="19994">woman</TOKEN>
        <TOKEN id="token-340-6" pos="word" morph="none" start_char="19996" end_char="19998">who</TOKEN>
        <TOKEN id="token-340-7" pos="word" morph="none" start_char="20000" end_char="20001">is</TOKEN>
        <TOKEN id="token-340-8" pos="word" morph="none" start_char="20003" end_char="20007">aware</TOKEN>
        <TOKEN id="token-340-9" pos="word" morph="none" start_char="20009" end_char="20012">that</TOKEN>
        <TOKEN id="token-340-10" pos="word" morph="none" start_char="20014" end_char="20018">every</TOKEN>
        <TOKEN id="token-340-11" pos="word" morph="none" start_char="20020" end_char="20025">outfit</TOKEN>
        <TOKEN id="token-340-12" pos="word" morph="none" start_char="20027" end_char="20029">she</TOKEN>
        <TOKEN id="token-340-13" pos="word" morph="none" start_char="20031" end_char="20035">wears</TOKEN>
        <TOKEN id="token-340-14" pos="punct" morph="none" start_char="20036" end_char="20036">,</TOKEN>
        <TOKEN id="token-340-15" pos="word" morph="none" start_char="20038" end_char="20042">every</TOKEN>
        <TOKEN id="token-340-16" pos="word" morph="none" start_char="20044" end_char="20052">hairstyle</TOKEN>
      </SEG>
      <SEG id="segment-341" start_char="20054" end_char="20130">
        <ORIGINAL_TEXT>she adopts, every word she utters can create an international debate, and she</ORIGINAL_TEXT>
        <TOKEN id="token-341-0" pos="word" morph="none" start_char="20054" end_char="20056">she</TOKEN>
        <TOKEN id="token-341-1" pos="word" morph="none" start_char="20058" end_char="20063">adopts</TOKEN>
        <TOKEN id="token-341-2" pos="punct" morph="none" start_char="20064" end_char="20064">,</TOKEN>
        <TOKEN id="token-341-3" pos="word" morph="none" start_char="20066" end_char="20070">every</TOKEN>
        <TOKEN id="token-341-4" pos="word" morph="none" start_char="20072" end_char="20075">word</TOKEN>
        <TOKEN id="token-341-5" pos="word" morph="none" start_char="20077" end_char="20079">she</TOKEN>
        <TOKEN id="token-341-6" pos="word" morph="none" start_char="20081" end_char="20086">utters</TOKEN>
        <TOKEN id="token-341-7" pos="word" morph="none" start_char="20088" end_char="20090">can</TOKEN>
        <TOKEN id="token-341-8" pos="word" morph="none" start_char="20092" end_char="20097">create</TOKEN>
        <TOKEN id="token-341-9" pos="word" morph="none" start_char="20099" end_char="20100">an</TOKEN>
        <TOKEN id="token-341-10" pos="word" morph="none" start_char="20102" end_char="20114">international</TOKEN>
        <TOKEN id="token-341-11" pos="word" morph="none" start_char="20116" end_char="20121">debate</TOKEN>
        <TOKEN id="token-341-12" pos="punct" morph="none" start_char="20122" end_char="20122">,</TOKEN>
        <TOKEN id="token-341-13" pos="word" morph="none" start_char="20124" end_char="20126">and</TOKEN>
        <TOKEN id="token-341-14" pos="word" morph="none" start_char="20128" end_char="20130">she</TOKEN>
      </SEG>
      <SEG id="segment-342" start_char="20132" end_char="20206">
        <ORIGINAL_TEXT>intends to control as much of that conversation as she can. If, once upon a</ORIGINAL_TEXT>
        <TOKEN id="token-342-0" pos="word" morph="none" start_char="20132" end_char="20138">intends</TOKEN>
        <TOKEN id="token-342-1" pos="word" morph="none" start_char="20140" end_char="20141">to</TOKEN>
        <TOKEN id="token-342-2" pos="word" morph="none" start_char="20143" end_char="20149">control</TOKEN>
        <TOKEN id="token-342-3" pos="word" morph="none" start_char="20151" end_char="20152">as</TOKEN>
        <TOKEN id="token-342-4" pos="word" morph="none" start_char="20154" end_char="20157">much</TOKEN>
        <TOKEN id="token-342-5" pos="word" morph="none" start_char="20159" end_char="20160">of</TOKEN>
        <TOKEN id="token-342-6" pos="word" morph="none" start_char="20162" end_char="20165">that</TOKEN>
        <TOKEN id="token-342-7" pos="word" morph="none" start_char="20167" end_char="20178">conversation</TOKEN>
        <TOKEN id="token-342-8" pos="word" morph="none" start_char="20180" end_char="20181">as</TOKEN>
        <TOKEN id="token-342-9" pos="word" morph="none" start_char="20183" end_char="20185">she</TOKEN>
        <TOKEN id="token-342-10" pos="word" morph="none" start_char="20187" end_char="20189">can</TOKEN>
        <TOKEN id="token-342-11" pos="punct" morph="none" start_char="20190" end_char="20190">.</TOKEN>
        <TOKEN id="token-342-12" pos="word" morph="none" start_char="20192" end_char="20193">If</TOKEN>
        <TOKEN id="token-342-13" pos="punct" morph="none" start_char="20194" end_char="20194">,</TOKEN>
        <TOKEN id="token-342-14" pos="word" morph="none" start_char="20196" end_char="20199">once</TOKEN>
        <TOKEN id="token-342-15" pos="word" morph="none" start_char="20201" end_char="20204">upon</TOKEN>
        <TOKEN id="token-342-16" pos="word" morph="none" start_char="20206" end_char="20206">a</TOKEN>
      </SEG>
      <SEG id="segment-343" start_char="20208" end_char="20282">
        <ORIGINAL_TEXT>time, there ever was a spontaneous Hillary Clinton who said what she really</ORIGINAL_TEXT>
        <TOKEN id="token-343-0" pos="word" morph="none" start_char="20208" end_char="20211">time</TOKEN>
        <TOKEN id="token-343-1" pos="punct" morph="none" start_char="20212" end_char="20212">,</TOKEN>
        <TOKEN id="token-343-2" pos="word" morph="none" start_char="20214" end_char="20218">there</TOKEN>
        <TOKEN id="token-343-3" pos="word" morph="none" start_char="20220" end_char="20223">ever</TOKEN>
        <TOKEN id="token-343-4" pos="word" morph="none" start_char="20225" end_char="20227">was</TOKEN>
        <TOKEN id="token-343-5" pos="word" morph="none" start_char="20229" end_char="20229">a</TOKEN>
        <TOKEN id="token-343-6" pos="word" morph="none" start_char="20231" end_char="20241">spontaneous</TOKEN>
        <TOKEN id="token-343-7" pos="word" morph="none" start_char="20243" end_char="20249">Hillary</TOKEN>
        <TOKEN id="token-343-8" pos="word" morph="none" start_char="20251" end_char="20257">Clinton</TOKEN>
        <TOKEN id="token-343-9" pos="word" morph="none" start_char="20259" end_char="20261">who</TOKEN>
        <TOKEN id="token-343-10" pos="word" morph="none" start_char="20263" end_char="20266">said</TOKEN>
        <TOKEN id="token-343-11" pos="word" morph="none" start_char="20268" end_char="20271">what</TOKEN>
        <TOKEN id="token-343-12" pos="word" morph="none" start_char="20273" end_char="20275">she</TOKEN>
        <TOKEN id="token-343-13" pos="word" morph="none" start_char="20277" end_char="20282">really</TOKEN>
      </SEG>
      <SEG id="segment-344" start_char="20284" end_char="20358">
        <ORIGINAL_TEXT>thinks and did not worry about how the media would respond, that person was</ORIGINAL_TEXT>
        <TOKEN id="token-344-0" pos="word" morph="none" start_char="20284" end_char="20289">thinks</TOKEN>
        <TOKEN id="token-344-1" pos="word" morph="none" start_char="20291" end_char="20293">and</TOKEN>
        <TOKEN id="token-344-2" pos="word" morph="none" start_char="20295" end_char="20297">did</TOKEN>
        <TOKEN id="token-344-3" pos="word" morph="none" start_char="20299" end_char="20301">not</TOKEN>
        <TOKEN id="token-344-4" pos="word" morph="none" start_char="20303" end_char="20307">worry</TOKEN>
        <TOKEN id="token-344-5" pos="word" morph="none" start_char="20309" end_char="20313">about</TOKEN>
        <TOKEN id="token-344-6" pos="word" morph="none" start_char="20315" end_char="20317">how</TOKEN>
        <TOKEN id="token-344-7" pos="word" morph="none" start_char="20319" end_char="20321">the</TOKEN>
        <TOKEN id="token-344-8" pos="word" morph="none" start_char="20323" end_char="20327">media</TOKEN>
        <TOKEN id="token-344-9" pos="word" morph="none" start_char="20329" end_char="20333">would</TOKEN>
        <TOKEN id="token-344-10" pos="word" morph="none" start_char="20335" end_char="20341">respond</TOKEN>
        <TOKEN id="token-344-11" pos="punct" morph="none" start_char="20342" end_char="20342">,</TOKEN>
        <TOKEN id="token-344-12" pos="word" morph="none" start_char="20344" end_char="20347">that</TOKEN>
        <TOKEN id="token-344-13" pos="word" morph="none" start_char="20349" end_char="20354">person</TOKEN>
        <TOKEN id="token-344-14" pos="word" morph="none" start_char="20356" end_char="20358">was</TOKEN>
      </SEG>
      <SEG id="segment-345" start_char="20360" end_char="20379">
        <ORIGINAL_TEXT>suppressed long ago.</ORIGINAL_TEXT>
        <TOKEN id="token-345-0" pos="word" morph="none" start_char="20360" end_char="20369">suppressed</TOKEN>
        <TOKEN id="token-345-1" pos="word" morph="none" start_char="20371" end_char="20374">long</TOKEN>
        <TOKEN id="token-345-2" pos="word" morph="none" start_char="20376" end_char="20378">ago</TOKEN>
        <TOKEN id="token-345-3" pos="punct" morph="none" start_char="20379" end_char="20379">.</TOKEN>
      </SEG>
      <SEG id="segment-346" start_char="20381" end_char="20384">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-346-0" pos="unknown" morph="none" start_char="20381" end_char="20384">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-347" start_char="20386" end_char="20388">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-347-0" pos="unknown" morph="none" start_char="20386" end_char="20388">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-348" start_char="20390" end_char="20466">
        <ORIGINAL_TEXT>Maybe, if she really wants to be president, she was right to have done so. It</ORIGINAL_TEXT>
        <TOKEN id="token-348-0" pos="word" morph="none" start_char="20390" end_char="20394">Maybe</TOKEN>
        <TOKEN id="token-348-1" pos="punct" morph="none" start_char="20395" end_char="20395">,</TOKEN>
        <TOKEN id="token-348-2" pos="word" morph="none" start_char="20397" end_char="20398">if</TOKEN>
        <TOKEN id="token-348-3" pos="word" morph="none" start_char="20400" end_char="20402">she</TOKEN>
        <TOKEN id="token-348-4" pos="word" morph="none" start_char="20404" end_char="20409">really</TOKEN>
        <TOKEN id="token-348-5" pos="word" morph="none" start_char="20411" end_char="20415">wants</TOKEN>
        <TOKEN id="token-348-6" pos="word" morph="none" start_char="20417" end_char="20418">to</TOKEN>
        <TOKEN id="token-348-7" pos="word" morph="none" start_char="20420" end_char="20421">be</TOKEN>
        <TOKEN id="token-348-8" pos="word" morph="none" start_char="20423" end_char="20431">president</TOKEN>
        <TOKEN id="token-348-9" pos="punct" morph="none" start_char="20432" end_char="20432">,</TOKEN>
        <TOKEN id="token-348-10" pos="word" morph="none" start_char="20434" end_char="20436">she</TOKEN>
        <TOKEN id="token-348-11" pos="word" morph="none" start_char="20438" end_char="20440">was</TOKEN>
        <TOKEN id="token-348-12" pos="word" morph="none" start_char="20442" end_char="20446">right</TOKEN>
        <TOKEN id="token-348-13" pos="word" morph="none" start_char="20448" end_char="20449">to</TOKEN>
        <TOKEN id="token-348-14" pos="word" morph="none" start_char="20451" end_char="20454">have</TOKEN>
        <TOKEN id="token-348-15" pos="word" morph="none" start_char="20456" end_char="20459">done</TOKEN>
        <TOKEN id="token-348-16" pos="word" morph="none" start_char="20461" end_char="20462">so</TOKEN>
        <TOKEN id="token-348-17" pos="punct" morph="none" start_char="20463" end_char="20463">.</TOKEN>
        <TOKEN id="token-348-18" pos="word" morph="none" start_char="20465" end_char="20466">It</TOKEN>
      </SEG>
      <SEG id="segment-349" start_char="20468" end_char="20543">
        <ORIGINAL_TEXT>really is true that one slip of the tongue could end Clinton’s career. It is</ORIGINAL_TEXT>
        <TOKEN id="token-349-0" pos="word" morph="none" start_char="20468" end_char="20473">really</TOKEN>
        <TOKEN id="token-349-1" pos="word" morph="none" start_char="20475" end_char="20476">is</TOKEN>
        <TOKEN id="token-349-2" pos="word" morph="none" start_char="20478" end_char="20481">true</TOKEN>
        <TOKEN id="token-349-3" pos="word" morph="none" start_char="20483" end_char="20486">that</TOKEN>
        <TOKEN id="token-349-4" pos="word" morph="none" start_char="20488" end_char="20490">one</TOKEN>
        <TOKEN id="token-349-5" pos="word" morph="none" start_char="20492" end_char="20495">slip</TOKEN>
        <TOKEN id="token-349-6" pos="word" morph="none" start_char="20497" end_char="20498">of</TOKEN>
        <TOKEN id="token-349-7" pos="word" morph="none" start_char="20500" end_char="20502">the</TOKEN>
        <TOKEN id="token-349-8" pos="word" morph="none" start_char="20504" end_char="20509">tongue</TOKEN>
        <TOKEN id="token-349-9" pos="word" morph="none" start_char="20511" end_char="20515">could</TOKEN>
        <TOKEN id="token-349-10" pos="word" morph="none" start_char="20517" end_char="20519">end</TOKEN>
        <TOKEN id="token-349-11" pos="word" morph="none" start_char="20521" end_char="20527">Clinton</TOKEN>
        <TOKEN id="token-349-12" pos="punct" morph="none" start_char="20528" end_char="20528">’</TOKEN>
        <TOKEN id="token-349-13" pos="word" morph="none" start_char="20529" end_char="20529">s</TOKEN>
        <TOKEN id="token-349-14" pos="word" morph="none" start_char="20531" end_char="20536">career</TOKEN>
        <TOKEN id="token-349-15" pos="punct" morph="none" start_char="20537" end_char="20537">.</TOKEN>
        <TOKEN id="token-349-16" pos="word" morph="none" start_char="20539" end_char="20540">It</TOKEN>
        <TOKEN id="token-349-17" pos="word" morph="none" start_char="20542" end_char="20543">is</TOKEN>
      </SEG>
      <SEG id="segment-350" start_char="20545" end_char="20620">
        <ORIGINAL_TEXT>also true that the stories with edifying morals, the glossy photographs, the</ORIGINAL_TEXT>
        <TOKEN id="token-350-0" pos="word" morph="none" start_char="20545" end_char="20548">also</TOKEN>
        <TOKEN id="token-350-1" pos="word" morph="none" start_char="20550" end_char="20553">true</TOKEN>
        <TOKEN id="token-350-2" pos="word" morph="none" start_char="20555" end_char="20558">that</TOKEN>
        <TOKEN id="token-350-3" pos="word" morph="none" start_char="20560" end_char="20562">the</TOKEN>
        <TOKEN id="token-350-4" pos="word" morph="none" start_char="20564" end_char="20570">stories</TOKEN>
        <TOKEN id="token-350-5" pos="word" morph="none" start_char="20572" end_char="20575">with</TOKEN>
        <TOKEN id="token-350-6" pos="word" morph="none" start_char="20577" end_char="20584">edifying</TOKEN>
        <TOKEN id="token-350-7" pos="word" morph="none" start_char="20586" end_char="20591">morals</TOKEN>
        <TOKEN id="token-350-8" pos="punct" morph="none" start_char="20592" end_char="20592">,</TOKEN>
        <TOKEN id="token-350-9" pos="word" morph="none" start_char="20594" end_char="20596">the</TOKEN>
        <TOKEN id="token-350-10" pos="word" morph="none" start_char="20598" end_char="20603">glossy</TOKEN>
        <TOKEN id="token-350-11" pos="word" morph="none" start_char="20605" end_char="20615">photographs</TOKEN>
        <TOKEN id="token-350-12" pos="punct" morph="none" start_char="20616" end_char="20616">,</TOKEN>
        <TOKEN id="token-350-13" pos="word" morph="none" start_char="20618" end_char="20620">the</TOKEN>
      </SEG>
      <SEG id="segment-351" start_char="20622" end_char="20691">
        <ORIGINAL_TEXT>promise of bipartisanship, the work ethic, the devotion to service and</ORIGINAL_TEXT>
        <TOKEN id="token-351-0" pos="word" morph="none" start_char="20622" end_char="20628">promise</TOKEN>
        <TOKEN id="token-351-1" pos="word" morph="none" start_char="20630" end_char="20631">of</TOKEN>
        <TOKEN id="token-351-2" pos="word" morph="none" start_char="20633" end_char="20646">bipartisanship</TOKEN>
        <TOKEN id="token-351-3" pos="punct" morph="none" start_char="20647" end_char="20647">,</TOKEN>
        <TOKEN id="token-351-4" pos="word" morph="none" start_char="20649" end_char="20651">the</TOKEN>
        <TOKEN id="token-351-5" pos="word" morph="none" start_char="20653" end_char="20656">work</TOKEN>
        <TOKEN id="token-351-6" pos="word" morph="none" start_char="20658" end_char="20662">ethic</TOKEN>
        <TOKEN id="token-351-7" pos="punct" morph="none" start_char="20663" end_char="20663">,</TOKEN>
        <TOKEN id="token-351-8" pos="word" morph="none" start_char="20665" end_char="20667">the</TOKEN>
        <TOKEN id="token-351-9" pos="word" morph="none" start_char="20669" end_char="20676">devotion</TOKEN>
        <TOKEN id="token-351-10" pos="word" morph="none" start_char="20678" end_char="20679">to</TOKEN>
        <TOKEN id="token-351-11" pos="word" morph="none" start_char="20681" end_char="20687">service</TOKEN>
        <TOKEN id="token-351-12" pos="word" morph="none" start_char="20689" end_char="20691">and</TOKEN>
      </SEG>
      <SEG id="segment-352" start_char="20693" end_char="20768">
        <ORIGINAL_TEXT>duty—all of this makes sense in the context of a national campaign: a lot of</ORIGINAL_TEXT>
        <TOKEN id="token-352-0" pos="word" morph="none" start_char="20693" end_char="20696">duty</TOKEN>
        <TOKEN id="token-352-1" pos="punct" morph="none" start_char="20697" end_char="20697">—</TOKEN>
        <TOKEN id="token-352-2" pos="word" morph="none" start_char="20698" end_char="20700">all</TOKEN>
        <TOKEN id="token-352-3" pos="word" morph="none" start_char="20702" end_char="20703">of</TOKEN>
        <TOKEN id="token-352-4" pos="word" morph="none" start_char="20705" end_char="20708">this</TOKEN>
        <TOKEN id="token-352-5" pos="word" morph="none" start_char="20710" end_char="20714">makes</TOKEN>
        <TOKEN id="token-352-6" pos="word" morph="none" start_char="20716" end_char="20720">sense</TOKEN>
        <TOKEN id="token-352-7" pos="word" morph="none" start_char="20722" end_char="20723">in</TOKEN>
        <TOKEN id="token-352-8" pos="word" morph="none" start_char="20725" end_char="20727">the</TOKEN>
        <TOKEN id="token-352-9" pos="word" morph="none" start_char="20729" end_char="20735">context</TOKEN>
        <TOKEN id="token-352-10" pos="word" morph="none" start_char="20737" end_char="20738">of</TOKEN>
        <TOKEN id="token-352-11" pos="word" morph="none" start_char="20740" end_char="20740">a</TOKEN>
        <TOKEN id="token-352-12" pos="word" morph="none" start_char="20742" end_char="20749">national</TOKEN>
        <TOKEN id="token-352-13" pos="word" morph="none" start_char="20751" end_char="20758">campaign</TOKEN>
        <TOKEN id="token-352-14" pos="punct" morph="none" start_char="20759" end_char="20759">:</TOKEN>
        <TOKEN id="token-352-15" pos="word" morph="none" start_char="20761" end_char="20761">a</TOKEN>
        <TOKEN id="token-352-16" pos="word" morph="none" start_char="20763" end_char="20765">lot</TOKEN>
        <TOKEN id="token-352-17" pos="word" morph="none" start_char="20767" end_char="20768">of</TOKEN>
      </SEG>
      <SEG id="segment-353" start_char="20770" end_char="20846">
        <ORIGINAL_TEXT>people who are only remotely, or not at all, interested in the nuances of the</ORIGINAL_TEXT>
        <TOKEN id="token-353-0" pos="word" morph="none" start_char="20770" end_char="20775">people</TOKEN>
        <TOKEN id="token-353-1" pos="word" morph="none" start_char="20777" end_char="20779">who</TOKEN>
        <TOKEN id="token-353-2" pos="word" morph="none" start_char="20781" end_char="20783">are</TOKEN>
        <TOKEN id="token-353-3" pos="word" morph="none" start_char="20785" end_char="20788">only</TOKEN>
        <TOKEN id="token-353-4" pos="word" morph="none" start_char="20790" end_char="20797">remotely</TOKEN>
        <TOKEN id="token-353-5" pos="punct" morph="none" start_char="20798" end_char="20798">,</TOKEN>
        <TOKEN id="token-353-6" pos="word" morph="none" start_char="20800" end_char="20801">or</TOKEN>
        <TOKEN id="token-353-7" pos="word" morph="none" start_char="20803" end_char="20805">not</TOKEN>
        <TOKEN id="token-353-8" pos="word" morph="none" start_char="20807" end_char="20808">at</TOKEN>
        <TOKEN id="token-353-9" pos="word" morph="none" start_char="20810" end_char="20812">all</TOKEN>
        <TOKEN id="token-353-10" pos="punct" morph="none" start_char="20813" end_char="20813">,</TOKEN>
        <TOKEN id="token-353-11" pos="word" morph="none" start_char="20815" end_char="20824">interested</TOKEN>
        <TOKEN id="token-353-12" pos="word" morph="none" start_char="20826" end_char="20827">in</TOKEN>
        <TOKEN id="token-353-13" pos="word" morph="none" start_char="20829" end_char="20831">the</TOKEN>
        <TOKEN id="token-353-14" pos="word" morph="none" start_char="20833" end_char="20839">nuances</TOKEN>
        <TOKEN id="token-353-15" pos="word" morph="none" start_char="20841" end_char="20842">of</TOKEN>
        <TOKEN id="token-353-16" pos="word" morph="none" start_char="20844" end_char="20846">the</TOKEN>
      </SEG>
      <SEG id="segment-354" start_char="20848" end_char="20920">
        <ORIGINAL_TEXT>Russian-American relationship can identify with this package very easily.</ORIGINAL_TEXT>
        <TOKEN id="token-354-0" pos="word" morph="none" start_char="20848" end_char="20854">Russian</TOKEN>
        <TOKEN id="token-354-1" pos="punct" morph="none" start_char="20855" end_char="20855">-</TOKEN>
        <TOKEN id="token-354-2" pos="word" morph="none" start_char="20856" end_char="20863">American</TOKEN>
        <TOKEN id="token-354-3" pos="word" morph="none" start_char="20865" end_char="20876">relationship</TOKEN>
        <TOKEN id="token-354-4" pos="word" morph="none" start_char="20878" end_char="20880">can</TOKEN>
        <TOKEN id="token-354-5" pos="word" morph="none" start_char="20882" end_char="20889">identify</TOKEN>
        <TOKEN id="token-354-6" pos="word" morph="none" start_char="20891" end_char="20894">with</TOKEN>
        <TOKEN id="token-354-7" pos="word" morph="none" start_char="20896" end_char="20899">this</TOKEN>
        <TOKEN id="token-354-8" pos="word" morph="none" start_char="20901" end_char="20907">package</TOKEN>
        <TOKEN id="token-354-9" pos="word" morph="none" start_char="20909" end_char="20912">very</TOKEN>
        <TOKEN id="token-354-10" pos="word" morph="none" start_char="20914" end_char="20919">easily</TOKEN>
        <TOKEN id="token-354-11" pos="punct" morph="none" start_char="20920" end_char="20920">.</TOKEN>
      </SEG>
      <SEG id="segment-355" start_char="20922" end_char="20999">
        <ORIGINAL_TEXT>Those who do not want or do not need a grand strategy for America, at home and</ORIGINAL_TEXT>
        <TOKEN id="token-355-0" pos="word" morph="none" start_char="20922" end_char="20926">Those</TOKEN>
        <TOKEN id="token-355-1" pos="word" morph="none" start_char="20928" end_char="20930">who</TOKEN>
        <TOKEN id="token-355-2" pos="word" morph="none" start_char="20932" end_char="20933">do</TOKEN>
        <TOKEN id="token-355-3" pos="word" morph="none" start_char="20935" end_char="20937">not</TOKEN>
        <TOKEN id="token-355-4" pos="word" morph="none" start_char="20939" end_char="20942">want</TOKEN>
        <TOKEN id="token-355-5" pos="word" morph="none" start_char="20944" end_char="20945">or</TOKEN>
        <TOKEN id="token-355-6" pos="word" morph="none" start_char="20947" end_char="20948">do</TOKEN>
        <TOKEN id="token-355-7" pos="word" morph="none" start_char="20950" end_char="20952">not</TOKEN>
        <TOKEN id="token-355-8" pos="word" morph="none" start_char="20954" end_char="20957">need</TOKEN>
        <TOKEN id="token-355-9" pos="word" morph="none" start_char="20959" end_char="20959">a</TOKEN>
        <TOKEN id="token-355-10" pos="word" morph="none" start_char="20961" end_char="20965">grand</TOKEN>
        <TOKEN id="token-355-11" pos="word" morph="none" start_char="20967" end_char="20974">strategy</TOKEN>
        <TOKEN id="token-355-12" pos="word" morph="none" start_char="20976" end_char="20978">for</TOKEN>
        <TOKEN id="token-355-13" pos="word" morph="none" start_char="20980" end_char="20986">America</TOKEN>
        <TOKEN id="token-355-14" pos="punct" morph="none" start_char="20987" end_char="20987">,</TOKEN>
        <TOKEN id="token-355-15" pos="word" morph="none" start_char="20989" end_char="20990">at</TOKEN>
        <TOKEN id="token-355-16" pos="word" morph="none" start_char="20992" end_char="20995">home</TOKEN>
        <TOKEN id="token-355-17" pos="word" morph="none" start_char="20997" end_char="20999">and</TOKEN>
      </SEG>
      <SEG id="segment-356" start_char="21001" end_char="21073">
        <ORIGINAL_TEXT>abroad, may find her “journey” very compelling. And many people will like</ORIGINAL_TEXT>
        <TOKEN id="token-356-0" pos="word" morph="none" start_char="21001" end_char="21006">abroad</TOKEN>
        <TOKEN id="token-356-1" pos="punct" morph="none" start_char="21007" end_char="21007">,</TOKEN>
        <TOKEN id="token-356-2" pos="word" morph="none" start_char="21009" end_char="21011">may</TOKEN>
        <TOKEN id="token-356-3" pos="word" morph="none" start_char="21013" end_char="21016">find</TOKEN>
        <TOKEN id="token-356-4" pos="word" morph="none" start_char="21018" end_char="21020">her</TOKEN>
        <TOKEN id="token-356-5" pos="punct" morph="none" start_char="21022" end_char="21022">“</TOKEN>
        <TOKEN id="token-356-6" pos="word" morph="none" start_char="21023" end_char="21029">journey</TOKEN>
        <TOKEN id="token-356-7" pos="punct" morph="none" start_char="21030" end_char="21030">”</TOKEN>
        <TOKEN id="token-356-8" pos="word" morph="none" start_char="21032" end_char="21035">very</TOKEN>
        <TOKEN id="token-356-9" pos="word" morph="none" start_char="21037" end_char="21046">compelling</TOKEN>
        <TOKEN id="token-356-10" pos="punct" morph="none" start_char="21047" end_char="21047">.</TOKEN>
        <TOKEN id="token-356-11" pos="word" morph="none" start_char="21049" end_char="21051">And</TOKEN>
        <TOKEN id="token-356-12" pos="word" morph="none" start_char="21053" end_char="21056">many</TOKEN>
        <TOKEN id="token-356-13" pos="word" morph="none" start_char="21058" end_char="21063">people</TOKEN>
        <TOKEN id="token-356-14" pos="word" morph="none" start_char="21065" end_char="21068">will</TOKEN>
        <TOKEN id="token-356-15" pos="word" morph="none" start_char="21070" end_char="21073">like</TOKEN>
      </SEG>
      <SEG id="segment-357" start_char="21075" end_char="21149">
        <ORIGINAL_TEXT>the positive spin she puts on even the most negative world events: it is so</ORIGINAL_TEXT>
        <TOKEN id="token-357-0" pos="word" morph="none" start_char="21075" end_char="21077">the</TOKEN>
        <TOKEN id="token-357-1" pos="word" morph="none" start_char="21079" end_char="21086">positive</TOKEN>
        <TOKEN id="token-357-2" pos="word" morph="none" start_char="21088" end_char="21091">spin</TOKEN>
        <TOKEN id="token-357-3" pos="word" morph="none" start_char="21093" end_char="21095">she</TOKEN>
        <TOKEN id="token-357-4" pos="word" morph="none" start_char="21097" end_char="21100">puts</TOKEN>
        <TOKEN id="token-357-5" pos="word" morph="none" start_char="21102" end_char="21103">on</TOKEN>
        <TOKEN id="token-357-6" pos="word" morph="none" start_char="21105" end_char="21108">even</TOKEN>
        <TOKEN id="token-357-7" pos="word" morph="none" start_char="21110" end_char="21112">the</TOKEN>
        <TOKEN id="token-357-8" pos="word" morph="none" start_char="21114" end_char="21117">most</TOKEN>
        <TOKEN id="token-357-9" pos="word" morph="none" start_char="21119" end_char="21126">negative</TOKEN>
        <TOKEN id="token-357-10" pos="word" morph="none" start_char="21128" end_char="21132">world</TOKEN>
        <TOKEN id="token-357-11" pos="word" morph="none" start_char="21134" end_char="21139">events</TOKEN>
        <TOKEN id="token-357-12" pos="punct" morph="none" start_char="21140" end_char="21140">:</TOKEN>
        <TOKEN id="token-357-13" pos="word" morph="none" start_char="21142" end_char="21143">it</TOKEN>
        <TOKEN id="token-357-14" pos="word" morph="none" start_char="21145" end_char="21146">is</TOKEN>
        <TOKEN id="token-357-15" pos="word" morph="none" start_char="21148" end_char="21149">so</TOKEN>
      </SEG>
      <SEG id="segment-358" start_char="21151" end_char="21170">
        <ORIGINAL_TEXT>cheerful, so upbeat.</ORIGINAL_TEXT>
        <TOKEN id="token-358-0" pos="word" morph="none" start_char="21151" end_char="21158">cheerful</TOKEN>
        <TOKEN id="token-358-1" pos="punct" morph="none" start_char="21159" end_char="21159">,</TOKEN>
        <TOKEN id="token-358-2" pos="word" morph="none" start_char="21161" end_char="21162">so</TOKEN>
        <TOKEN id="token-358-3" pos="word" morph="none" start_char="21164" end_char="21169">upbeat</TOKEN>
        <TOKEN id="token-358-4" pos="punct" morph="none" start_char="21170" end_char="21170">.</TOKEN>
      </SEG>
      <SEG id="segment-359" start_char="21172" end_char="21175">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-359-0" pos="unknown" morph="none" start_char="21172" end_char="21175">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-360" start_char="21177" end_char="21179">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-360-0" pos="unknown" morph="none" start_char="21177" end_char="21179">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-361" start_char="21181" end_char="21255">
        <ORIGINAL_TEXT>Hard Choices is not remotely a book for the ages. It does not belong on the</ORIGINAL_TEXT>
        <TOKEN id="token-361-0" pos="word" morph="none" start_char="21181" end_char="21184">Hard</TOKEN>
        <TOKEN id="token-361-1" pos="word" morph="none" start_char="21186" end_char="21192">Choices</TOKEN>
        <TOKEN id="token-361-2" pos="word" morph="none" start_char="21194" end_char="21195">is</TOKEN>
        <TOKEN id="token-361-3" pos="word" morph="none" start_char="21197" end_char="21199">not</TOKEN>
        <TOKEN id="token-361-4" pos="word" morph="none" start_char="21201" end_char="21208">remotely</TOKEN>
        <TOKEN id="token-361-5" pos="word" morph="none" start_char="21210" end_char="21210">a</TOKEN>
        <TOKEN id="token-361-6" pos="word" morph="none" start_char="21212" end_char="21215">book</TOKEN>
        <TOKEN id="token-361-7" pos="word" morph="none" start_char="21217" end_char="21219">for</TOKEN>
        <TOKEN id="token-361-8" pos="word" morph="none" start_char="21221" end_char="21223">the</TOKEN>
        <TOKEN id="token-361-9" pos="word" morph="none" start_char="21225" end_char="21228">ages</TOKEN>
        <TOKEN id="token-361-10" pos="punct" morph="none" start_char="21229" end_char="21229">.</TOKEN>
        <TOKEN id="token-361-11" pos="word" morph="none" start_char="21231" end_char="21232">It</TOKEN>
        <TOKEN id="token-361-12" pos="word" morph="none" start_char="21234" end_char="21237">does</TOKEN>
        <TOKEN id="token-361-13" pos="word" morph="none" start_char="21239" end_char="21241">not</TOKEN>
        <TOKEN id="token-361-14" pos="word" morph="none" start_char="21243" end_char="21248">belong</TOKEN>
        <TOKEN id="token-361-15" pos="word" morph="none" start_char="21250" end_char="21251">on</TOKEN>
        <TOKEN id="token-361-16" pos="word" morph="none" start_char="21253" end_char="21255">the</TOKEN>
      </SEG>
      <SEG id="segment-362" start_char="21257" end_char="21326">
        <ORIGINAL_TEXT>same shelf as Dean Acheson’s memoir. But maybe it contains the winning</ORIGINAL_TEXT>
        <TOKEN id="token-362-0" pos="word" morph="none" start_char="21257" end_char="21260">same</TOKEN>
        <TOKEN id="token-362-1" pos="word" morph="none" start_char="21262" end_char="21266">shelf</TOKEN>
        <TOKEN id="token-362-2" pos="word" morph="none" start_char="21268" end_char="21269">as</TOKEN>
        <TOKEN id="token-362-3" pos="word" morph="none" start_char="21271" end_char="21274">Dean</TOKEN>
        <TOKEN id="token-362-4" pos="word" morph="none" start_char="21276" end_char="21282">Acheson</TOKEN>
        <TOKEN id="token-362-5" pos="punct" morph="none" start_char="21283" end_char="21283">’</TOKEN>
        <TOKEN id="token-362-6" pos="word" morph="none" start_char="21284" end_char="21284">s</TOKEN>
        <TOKEN id="token-362-7" pos="word" morph="none" start_char="21286" end_char="21291">memoir</TOKEN>
        <TOKEN id="token-362-8" pos="punct" morph="none" start_char="21292" end_char="21292">.</TOKEN>
        <TOKEN id="token-362-9" pos="word" morph="none" start_char="21294" end_char="21296">But</TOKEN>
        <TOKEN id="token-362-10" pos="word" morph="none" start_char="21298" end_char="21302">maybe</TOKEN>
        <TOKEN id="token-362-11" pos="word" morph="none" start_char="21304" end_char="21305">it</TOKEN>
        <TOKEN id="token-362-12" pos="word" morph="none" start_char="21307" end_char="21314">contains</TOKEN>
        <TOKEN id="token-362-13" pos="word" morph="none" start_char="21316" end_char="21318">the</TOKEN>
        <TOKEN id="token-362-14" pos="word" morph="none" start_char="21320" end_char="21326">winning</TOKEN>
      </SEG>
      <SEG id="segment-363" start_char="21328" end_char="21379">
        <ORIGINAL_TEXT>formula—and for this author, winning is what counts.</ORIGINAL_TEXT>
        <TOKEN id="token-363-0" pos="word" morph="none" start_char="21328" end_char="21334">formula</TOKEN>
        <TOKEN id="token-363-1" pos="punct" morph="none" start_char="21335" end_char="21335">—</TOKEN>
        <TOKEN id="token-363-2" pos="word" morph="none" start_char="21336" end_char="21338">and</TOKEN>
        <TOKEN id="token-363-3" pos="word" morph="none" start_char="21340" end_char="21342">for</TOKEN>
        <TOKEN id="token-363-4" pos="word" morph="none" start_char="21344" end_char="21347">this</TOKEN>
        <TOKEN id="token-363-5" pos="word" morph="none" start_char="21349" end_char="21354">author</TOKEN>
        <TOKEN id="token-363-6" pos="punct" morph="none" start_char="21355" end_char="21355">,</TOKEN>
        <TOKEN id="token-363-7" pos="word" morph="none" start_char="21357" end_char="21363">winning</TOKEN>
        <TOKEN id="token-363-8" pos="word" morph="none" start_char="21365" end_char="21366">is</TOKEN>
        <TOKEN id="token-363-9" pos="word" morph="none" start_char="21368" end_char="21371">what</TOKEN>
        <TOKEN id="token-363-10" pos="word" morph="none" start_char="21373" end_char="21378">counts</TOKEN>
        <TOKEN id="token-363-11" pos="punct" morph="none" start_char="21379" end_char="21379">.</TOKEN>
      </SEG>
      <SEG id="segment-364" start_char="21381" end_char="21384">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-364-0" pos="unknown" morph="none" start_char="21381" end_char="21384">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-365" start_char="21386" end_char="21392">
        <ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-365-0" pos="unknown" morph="none" start_char="21386" end_char="21392">&lt;/TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-366" start_char="21394" end_char="21399">
        <ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-366-0" pos="unknown" morph="none" start_char="21394" end_char="21399">&lt;/DOC&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
