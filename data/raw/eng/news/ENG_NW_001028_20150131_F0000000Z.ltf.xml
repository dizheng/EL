<?xml version="1.0" encoding="UTF-8"?>
<LCTL_TEXT>
  <DOC id="ENG_NW_001028_20150131_F0000000Z.xml" tokenization="tokenization_parameters" grammar="none" raw_text_char_length="3047" raw_text_md5="030376fa86de13c04715517be4ea5031">
    <TEXT>
      <SEG id="segment-0" start_char="0" end_char="37">
        <ORIGINAL_TEXT>&lt;?xml version="1.0" encoding="utf-8"?&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-0-0" pos="unknown" morph="none" start_char="0" end_char="4">&lt;?xml</TOKEN>
        <TOKEN id="token-0-1" pos="unknown" morph="none" start_char="6" end_char="18">version="1.0"</TOKEN>
        <TOKEN id="token-0-2" pos="unknown" morph="none" start_char="20" end_char="37">encoding="utf-8"?&gt;</TOKEN>
      </SEG>
      <SEG id="segment-1" start_char="39" end_char="81">
        <ORIGINAL_TEXT>&lt;DOC id="ENG_NW_001028_20150131_F0000000Z"&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-1-0" pos="unknown" morph="none" start_char="39" end_char="42">&lt;DOC</TOKEN>
        <TOKEN id="token-1-1" pos="unknown" morph="none" start_char="44" end_char="81">id="ENG_NW_001028_20150131_F0000000Z"&gt;</TOKEN>
      </SEG>
      <SEG id="segment-2" start_char="83" end_char="161">
        <ORIGINAL_TEXT>&lt;SOURCE&gt;http://www.kavkazcenter.com/eng/content/2015/01/31/19949.shtml&lt;/SOURCE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-2-0" pos="unknown" morph="none" start_char="83" end_char="161">&lt;SOURCE&gt;http://www.kavkazcenter.com/eng/content/2015/01/31/19949.shtml&lt;/SOURCE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-3" start_char="163" end_char="204">
        <ORIGINAL_TEXT>&lt;DATE_TIME&gt;2015-01-31T00:00:00&lt;/DATE_TIME&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-3-0" pos="unknown" morph="none" start_char="163" end_char="204">&lt;DATE_TIME&gt;2015-01-31T00:00:00&lt;/DATE_TIME&gt;</TOKEN>
      </SEG>
      <SEG id="segment-4" start_char="206" end_char="215">
        <ORIGINAL_TEXT>&lt;HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-4-0" pos="unknown" morph="none" start_char="206" end_char="215">&lt;HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-5" start_char="217" end_char="311">
        <ORIGINAL_TEXT>Journalists surprised by top secrecy surrounding "Tsarnaev's case". Is there something to hide?</ORIGINAL_TEXT>
        <TOKEN id="token-5-0" pos="word" morph="none" start_char="217" end_char="227">Journalists</TOKEN>
        <TOKEN id="token-5-1" pos="word" morph="none" start_char="229" end_char="237">surprised</TOKEN>
        <TOKEN id="token-5-2" pos="word" morph="none" start_char="239" end_char="240">by</TOKEN>
        <TOKEN id="token-5-3" pos="word" morph="none" start_char="242" end_char="244">top</TOKEN>
        <TOKEN id="token-5-4" pos="word" morph="none" start_char="246" end_char="252">secrecy</TOKEN>
        <TOKEN id="token-5-5" pos="word" morph="none" start_char="254" end_char="264">surrounding</TOKEN>
        <TOKEN id="token-5-6" pos="punct" morph="none" start_char="266" end_char="266">"</TOKEN>
        <TOKEN id="token-5-7" pos="word" morph="none" start_char="267" end_char="274">Tsarnaev</TOKEN>
        <TOKEN id="token-5-8" pos="punct" morph="none" start_char="275" end_char="275">'</TOKEN>
        <TOKEN id="token-5-9" pos="word" morph="none" start_char="276" end_char="276">s</TOKEN>
        <TOKEN id="token-5-10" pos="word" morph="none" start_char="278" end_char="281">case</TOKEN>
        <TOKEN id="token-5-11" pos="punct" morph="none" start_char="282" end_char="283">".</TOKEN>
        <TOKEN id="token-5-12" pos="word" morph="none" start_char="285" end_char="286">Is</TOKEN>
        <TOKEN id="token-5-13" pos="word" morph="none" start_char="288" end_char="292">there</TOKEN>
        <TOKEN id="token-5-14" pos="word" morph="none" start_char="294" end_char="302">something</TOKEN>
        <TOKEN id="token-5-15" pos="word" morph="none" start_char="304" end_char="305">to</TOKEN>
        <TOKEN id="token-5-16" pos="word" morph="none" start_char="307" end_char="310">hide</TOKEN>
        <TOKEN id="token-5-17" pos="punct" morph="none" start_char="311" end_char="311">?</TOKEN>
      </SEG>
      <SEG id="segment-6" start_char="313" end_char="323">
        <ORIGINAL_TEXT>&lt;/HEADLINE&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-6-0" pos="unknown" morph="none" start_char="313" end_char="323">&lt;/HEADLINE&gt;</TOKEN>
      </SEG>
      <SEG id="segment-7" start_char="325" end_char="330">
        <ORIGINAL_TEXT>&lt;TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-7-0" pos="unknown" morph="none" start_char="325" end_char="330">&lt;TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-8" start_char="332" end_char="334">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-8-0" pos="unknown" morph="none" start_char="332" end_char="334">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-9" start_char="336" end_char="410">
        <ORIGINAL_TEXT>American journalists are frustrated by the behavior of US District Court in</ORIGINAL_TEXT>
        <TOKEN id="token-9-0" pos="word" morph="none" start_char="336" end_char="343">American</TOKEN>
        <TOKEN id="token-9-1" pos="word" morph="none" start_char="345" end_char="355">journalists</TOKEN>
        <TOKEN id="token-9-2" pos="word" morph="none" start_char="357" end_char="359">are</TOKEN>
        <TOKEN id="token-9-3" pos="word" morph="none" start_char="361" end_char="370">frustrated</TOKEN>
        <TOKEN id="token-9-4" pos="word" morph="none" start_char="372" end_char="373">by</TOKEN>
        <TOKEN id="token-9-5" pos="word" morph="none" start_char="375" end_char="377">the</TOKEN>
        <TOKEN id="token-9-6" pos="word" morph="none" start_char="379" end_char="386">behavior</TOKEN>
        <TOKEN id="token-9-7" pos="word" morph="none" start_char="388" end_char="389">of</TOKEN>
        <TOKEN id="token-9-8" pos="word" morph="none" start_char="391" end_char="392">US</TOKEN>
        <TOKEN id="token-9-9" pos="word" morph="none" start_char="394" end_char="401">District</TOKEN>
        <TOKEN id="token-9-10" pos="word" morph="none" start_char="403" end_char="407">Court</TOKEN>
        <TOKEN id="token-9-11" pos="word" morph="none" start_char="409" end_char="410">in</TOKEN>
      </SEG>
      <SEG id="segment-10" start_char="412" end_char="482">
        <ORIGINAL_TEXT>Boston, writes The Washington Post, whose correspondent Gessen has been</ORIGINAL_TEXT>
        <TOKEN id="token-10-0" pos="word" morph="none" start_char="412" end_char="417">Boston</TOKEN>
        <TOKEN id="token-10-1" pos="punct" morph="none" start_char="418" end_char="418">,</TOKEN>
        <TOKEN id="token-10-2" pos="word" morph="none" start_char="420" end_char="425">writes</TOKEN>
        <TOKEN id="token-10-3" pos="word" morph="none" start_char="427" end_char="429">The</TOKEN>
        <TOKEN id="token-10-4" pos="word" morph="none" start_char="431" end_char="440">Washington</TOKEN>
        <TOKEN id="token-10-5" pos="word" morph="none" start_char="442" end_char="445">Post</TOKEN>
        <TOKEN id="token-10-6" pos="punct" morph="none" start_char="446" end_char="446">,</TOKEN>
        <TOKEN id="token-10-7" pos="word" morph="none" start_char="448" end_char="452">whose</TOKEN>
        <TOKEN id="token-10-8" pos="word" morph="none" start_char="454" end_char="466">correspondent</TOKEN>
        <TOKEN id="token-10-9" pos="word" morph="none" start_char="468" end_char="473">Gessen</TOKEN>
        <TOKEN id="token-10-10" pos="word" morph="none" start_char="475" end_char="477">has</TOKEN>
        <TOKEN id="token-10-11" pos="word" morph="none" start_char="479" end_char="482">been</TOKEN>
      </SEG>
      <SEG id="segment-11" start_char="484" end_char="523">
        <ORIGINAL_TEXT>covering the trial of Dzhokhar Tsarnaev.</ORIGINAL_TEXT>
        <TOKEN id="token-11-0" pos="word" morph="none" start_char="484" end_char="491">covering</TOKEN>
        <TOKEN id="token-11-1" pos="word" morph="none" start_char="493" end_char="495">the</TOKEN>
        <TOKEN id="token-11-2" pos="word" morph="none" start_char="497" end_char="501">trial</TOKEN>
        <TOKEN id="token-11-3" pos="word" morph="none" start_char="503" end_char="504">of</TOKEN>
        <TOKEN id="token-11-4" pos="word" morph="none" start_char="506" end_char="513">Dzhokhar</TOKEN>
        <TOKEN id="token-11-5" pos="word" morph="none" start_char="515" end_char="522">Tsarnaev</TOKEN>
        <TOKEN id="token-11-6" pos="punct" morph="none" start_char="523" end_char="523">.</TOKEN>
      </SEG>
      <SEG id="segment-12" start_char="525" end_char="528">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-12-0" pos="unknown" morph="none" start_char="525" end_char="528">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-13" start_char="530" end_char="532">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-13-0" pos="unknown" morph="none" start_char="530" end_char="532">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-14" start_char="535" end_char="538">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-14-0" pos="unknown" morph="none" start_char="535" end_char="538">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-15" start_char="540" end_char="542">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-15-0" pos="unknown" morph="none" start_char="540" end_char="542">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-16" start_char="544" end_char="621">
        <ORIGINAL_TEXT>In American courts, no video, or audio recording- or photos of the proceedings</ORIGINAL_TEXT>
        <TOKEN id="token-16-0" pos="word" morph="none" start_char="544" end_char="545">In</TOKEN>
        <TOKEN id="token-16-1" pos="word" morph="none" start_char="547" end_char="554">American</TOKEN>
        <TOKEN id="token-16-2" pos="word" morph="none" start_char="556" end_char="561">courts</TOKEN>
        <TOKEN id="token-16-3" pos="punct" morph="none" start_char="562" end_char="562">,</TOKEN>
        <TOKEN id="token-16-4" pos="word" morph="none" start_char="564" end_char="565">no</TOKEN>
        <TOKEN id="token-16-5" pos="word" morph="none" start_char="567" end_char="571">video</TOKEN>
        <TOKEN id="token-16-6" pos="punct" morph="none" start_char="572" end_char="572">,</TOKEN>
        <TOKEN id="token-16-7" pos="word" morph="none" start_char="574" end_char="575">or</TOKEN>
        <TOKEN id="token-16-8" pos="word" morph="none" start_char="577" end_char="581">audio</TOKEN>
        <TOKEN id="token-16-9" pos="word" morph="none" start_char="583" end_char="591">recording</TOKEN>
        <TOKEN id="token-16-10" pos="punct" morph="none" start_char="592" end_char="592">-</TOKEN>
        <TOKEN id="token-16-11" pos="word" morph="none" start_char="594" end_char="595">or</TOKEN>
        <TOKEN id="token-16-12" pos="word" morph="none" start_char="597" end_char="602">photos</TOKEN>
        <TOKEN id="token-16-13" pos="word" morph="none" start_char="604" end_char="605">of</TOKEN>
        <TOKEN id="token-16-14" pos="word" morph="none" start_char="607" end_char="609">the</TOKEN>
        <TOKEN id="token-16-15" pos="word" morph="none" start_char="611" end_char="621">proceedings</TOKEN>
      </SEG>
      <SEG id="segment-17" start_char="623" end_char="696">
        <ORIGINAL_TEXT>is ever allowed, and transcripts are quite difficult to get, the newspaper</ORIGINAL_TEXT>
        <TOKEN id="token-17-0" pos="word" morph="none" start_char="623" end_char="624">is</TOKEN>
        <TOKEN id="token-17-1" pos="word" morph="none" start_char="626" end_char="629">ever</TOKEN>
        <TOKEN id="token-17-2" pos="word" morph="none" start_char="631" end_char="637">allowed</TOKEN>
        <TOKEN id="token-17-3" pos="punct" morph="none" start_char="638" end_char="638">,</TOKEN>
        <TOKEN id="token-17-4" pos="word" morph="none" start_char="640" end_char="642">and</TOKEN>
        <TOKEN id="token-17-5" pos="word" morph="none" start_char="644" end_char="654">transcripts</TOKEN>
        <TOKEN id="token-17-6" pos="word" morph="none" start_char="656" end_char="658">are</TOKEN>
        <TOKEN id="token-17-7" pos="word" morph="none" start_char="660" end_char="664">quite</TOKEN>
        <TOKEN id="token-17-8" pos="word" morph="none" start_char="666" end_char="674">difficult</TOKEN>
        <TOKEN id="token-17-9" pos="word" morph="none" start_char="676" end_char="677">to</TOKEN>
        <TOKEN id="token-17-10" pos="word" morph="none" start_char="679" end_char="681">get</TOKEN>
        <TOKEN id="token-17-11" pos="punct" morph="none" start_char="682" end_char="682">,</TOKEN>
        <TOKEN id="token-17-12" pos="word" morph="none" start_char="684" end_char="686">the</TOKEN>
        <TOKEN id="token-17-13" pos="word" morph="none" start_char="688" end_char="696">newspaper</TOKEN>
      </SEG>
      <SEG id="segment-18" start_char="698" end_char="704">
        <ORIGINAL_TEXT>writes.</ORIGINAL_TEXT>
        <TOKEN id="token-18-0" pos="word" morph="none" start_char="698" end_char="703">writes</TOKEN>
        <TOKEN id="token-18-1" pos="punct" morph="none" start_char="704" end_char="704">.</TOKEN>
      </SEG>
      <SEG id="segment-19" start_char="706" end_char="709">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-19-0" pos="unknown" morph="none" start_char="706" end_char="709">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-20" start_char="711" end_char="713">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-20-0" pos="unknown" morph="none" start_char="711" end_char="713">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-21" start_char="716" end_char="719">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-21-0" pos="unknown" morph="none" start_char="716" end_char="719">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-22" start_char="721" end_char="723">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-22-0" pos="unknown" morph="none" start_char="721" end_char="723">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-23" start_char="725" end_char="801">
        <ORIGINAL_TEXT>"But local court reporters say they have never faced the sort of restrictions</ORIGINAL_TEXT>
        <TOKEN id="token-23-0" pos="punct" morph="none" start_char="725" end_char="725">"</TOKEN>
        <TOKEN id="token-23-1" pos="word" morph="none" start_char="726" end_char="728">But</TOKEN>
        <TOKEN id="token-23-2" pos="word" morph="none" start_char="730" end_char="734">local</TOKEN>
        <TOKEN id="token-23-3" pos="word" morph="none" start_char="736" end_char="740">court</TOKEN>
        <TOKEN id="token-23-4" pos="word" morph="none" start_char="742" end_char="750">reporters</TOKEN>
        <TOKEN id="token-23-5" pos="word" morph="none" start_char="752" end_char="754">say</TOKEN>
        <TOKEN id="token-23-6" pos="word" morph="none" start_char="756" end_char="759">they</TOKEN>
        <TOKEN id="token-23-7" pos="word" morph="none" start_char="761" end_char="764">have</TOKEN>
        <TOKEN id="token-23-8" pos="word" morph="none" start_char="766" end_char="770">never</TOKEN>
        <TOKEN id="token-23-9" pos="word" morph="none" start_char="772" end_char="776">faced</TOKEN>
        <TOKEN id="token-23-10" pos="word" morph="none" start_char="778" end_char="780">the</TOKEN>
        <TOKEN id="token-23-11" pos="word" morph="none" start_char="782" end_char="785">sort</TOKEN>
        <TOKEN id="token-23-12" pos="word" morph="none" start_char="787" end_char="788">of</TOKEN>
        <TOKEN id="token-23-13" pos="word" morph="none" start_char="790" end_char="801">restrictions</TOKEN>
      </SEG>
      <SEG id="segment-24" start_char="803" end_char="878">
        <ORIGINAL_TEXT>imposed by judge O’Toole in the case of Dzhokhar Tsarnaev. The bulk of files</ORIGINAL_TEXT>
        <TOKEN id="token-24-0" pos="word" morph="none" start_char="803" end_char="809">imposed</TOKEN>
        <TOKEN id="token-24-1" pos="word" morph="none" start_char="811" end_char="812">by</TOKEN>
        <TOKEN id="token-24-2" pos="word" morph="none" start_char="814" end_char="818">judge</TOKEN>
        <TOKEN id="token-24-3" pos="word" morph="none" start_char="820" end_char="820">O</TOKEN>
        <TOKEN id="token-24-4" pos="punct" morph="none" start_char="821" end_char="821">’</TOKEN>
        <TOKEN id="token-24-5" pos="word" morph="none" start_char="822" end_char="826">Toole</TOKEN>
        <TOKEN id="token-24-6" pos="word" morph="none" start_char="828" end_char="829">in</TOKEN>
        <TOKEN id="token-24-7" pos="word" morph="none" start_char="831" end_char="833">the</TOKEN>
        <TOKEN id="token-24-8" pos="word" morph="none" start_char="835" end_char="838">case</TOKEN>
        <TOKEN id="token-24-9" pos="word" morph="none" start_char="840" end_char="841">of</TOKEN>
        <TOKEN id="token-24-10" pos="word" morph="none" start_char="843" end_char="850">Dzhokhar</TOKEN>
        <TOKEN id="token-24-11" pos="word" morph="none" start_char="852" end_char="859">Tsarnaev</TOKEN>
        <TOKEN id="token-24-12" pos="punct" morph="none" start_char="860" end_char="860">.</TOKEN>
        <TOKEN id="token-24-13" pos="word" morph="none" start_char="862" end_char="864">The</TOKEN>
        <TOKEN id="token-24-14" pos="word" morph="none" start_char="866" end_char="869">bulk</TOKEN>
        <TOKEN id="token-24-15" pos="word" morph="none" start_char="871" end_char="872">of</TOKEN>
        <TOKEN id="token-24-16" pos="word" morph="none" start_char="874" end_char="878">files</TOKEN>
      </SEG>
      <SEG id="segment-25" start_char="880" end_char="954">
        <ORIGINAL_TEXT>in the case are under seal – including at least one defense motion that was</ORIGINAL_TEXT>
        <TOKEN id="token-25-0" pos="word" morph="none" start_char="880" end_char="881">in</TOKEN>
        <TOKEN id="token-25-1" pos="word" morph="none" start_char="883" end_char="885">the</TOKEN>
        <TOKEN id="token-25-2" pos="word" morph="none" start_char="887" end_char="890">case</TOKEN>
        <TOKEN id="token-25-3" pos="word" morph="none" start_char="892" end_char="894">are</TOKEN>
        <TOKEN id="token-25-4" pos="word" morph="none" start_char="896" end_char="900">under</TOKEN>
        <TOKEN id="token-25-5" pos="word" morph="none" start_char="902" end_char="905">seal</TOKEN>
        <TOKEN id="token-25-6" pos="unknown" morph="none" start_char="907" end_char="907">–</TOKEN>
        <TOKEN id="token-25-7" pos="word" morph="none" start_char="909" end_char="917">including</TOKEN>
        <TOKEN id="token-25-8" pos="word" morph="none" start_char="919" end_char="920">at</TOKEN>
        <TOKEN id="token-25-9" pos="word" morph="none" start_char="922" end_char="926">least</TOKEN>
        <TOKEN id="token-25-10" pos="word" morph="none" start_char="928" end_char="930">one</TOKEN>
        <TOKEN id="token-25-11" pos="word" morph="none" start_char="932" end_char="938">defense</TOKEN>
        <TOKEN id="token-25-12" pos="word" morph="none" start_char="940" end_char="945">motion</TOKEN>
        <TOKEN id="token-25-13" pos="word" morph="none" start_char="947" end_char="950">that</TOKEN>
        <TOKEN id="token-25-14" pos="word" morph="none" start_char="952" end_char="954">was</TOKEN>
      </SEG>
      <SEG id="segment-26" start_char="956" end_char="1031">
        <ORIGINAL_TEXT>excerpted at length by The Boston Globe before the judge sealed it last week</ORIGINAL_TEXT>
        <TOKEN id="token-26-0" pos="word" morph="none" start_char="956" end_char="964">excerpted</TOKEN>
        <TOKEN id="token-26-1" pos="word" morph="none" start_char="966" end_char="967">at</TOKEN>
        <TOKEN id="token-26-2" pos="word" morph="none" start_char="969" end_char="974">length</TOKEN>
        <TOKEN id="token-26-3" pos="word" morph="none" start_char="976" end_char="977">by</TOKEN>
        <TOKEN id="token-26-4" pos="word" morph="none" start_char="979" end_char="981">The</TOKEN>
        <TOKEN id="token-26-5" pos="word" morph="none" start_char="983" end_char="988">Boston</TOKEN>
        <TOKEN id="token-26-6" pos="word" morph="none" start_char="990" end_char="994">Globe</TOKEN>
        <TOKEN id="token-26-7" pos="word" morph="none" start_char="996" end_char="1001">before</TOKEN>
        <TOKEN id="token-26-8" pos="word" morph="none" start_char="1003" end_char="1005">the</TOKEN>
        <TOKEN id="token-26-9" pos="word" morph="none" start_char="1007" end_char="1011">judge</TOKEN>
        <TOKEN id="token-26-10" pos="word" morph="none" start_char="1013" end_char="1018">sealed</TOKEN>
        <TOKEN id="token-26-11" pos="word" morph="none" start_char="1020" end_char="1021">it</TOKEN>
        <TOKEN id="token-26-12" pos="word" morph="none" start_char="1023" end_char="1026">last</TOKEN>
        <TOKEN id="token-26-13" pos="word" morph="none" start_char="1028" end_char="1031">week</TOKEN>
      </SEG>
      <SEG id="segment-27" start_char="1033" end_char="1105">
        <ORIGINAL_TEXT>– and reporters are excluded from seeing or hearing much of the courtroom</ORIGINAL_TEXT>
        <TOKEN id="token-27-0" pos="unknown" morph="none" start_char="1033" end_char="1033">–</TOKEN>
        <TOKEN id="token-27-1" pos="word" morph="none" start_char="1035" end_char="1037">and</TOKEN>
        <TOKEN id="token-27-2" pos="word" morph="none" start_char="1039" end_char="1047">reporters</TOKEN>
        <TOKEN id="token-27-3" pos="word" morph="none" start_char="1049" end_char="1051">are</TOKEN>
        <TOKEN id="token-27-4" pos="word" morph="none" start_char="1053" end_char="1060">excluded</TOKEN>
        <TOKEN id="token-27-5" pos="word" morph="none" start_char="1062" end_char="1065">from</TOKEN>
        <TOKEN id="token-27-6" pos="word" morph="none" start_char="1067" end_char="1072">seeing</TOKEN>
        <TOKEN id="token-27-7" pos="word" morph="none" start_char="1074" end_char="1075">or</TOKEN>
        <TOKEN id="token-27-8" pos="word" morph="none" start_char="1077" end_char="1083">hearing</TOKEN>
        <TOKEN id="token-27-9" pos="word" morph="none" start_char="1085" end_char="1088">much</TOKEN>
        <TOKEN id="token-27-10" pos="word" morph="none" start_char="1090" end_char="1091">of</TOKEN>
        <TOKEN id="token-27-11" pos="word" morph="none" start_char="1093" end_char="1095">the</TOKEN>
        <TOKEN id="token-27-12" pos="word" morph="none" start_char="1097" end_char="1105">courtroom</TOKEN>
      </SEG>
      <SEG id="segment-28" start_char="1107" end_char="1169">
        <ORIGINAL_TEXT>discussions that would customarily be public", the article says</ORIGINAL_TEXT>
        <TOKEN id="token-28-0" pos="word" morph="none" start_char="1107" end_char="1117">discussions</TOKEN>
        <TOKEN id="token-28-1" pos="word" morph="none" start_char="1119" end_char="1122">that</TOKEN>
        <TOKEN id="token-28-2" pos="word" morph="none" start_char="1124" end_char="1128">would</TOKEN>
        <TOKEN id="token-28-3" pos="word" morph="none" start_char="1130" end_char="1140">customarily</TOKEN>
        <TOKEN id="token-28-4" pos="word" morph="none" start_char="1142" end_char="1143">be</TOKEN>
        <TOKEN id="token-28-5" pos="word" morph="none" start_char="1145" end_char="1150">public</TOKEN>
        <TOKEN id="token-28-6" pos="punct" morph="none" start_char="1151" end_char="1152">",</TOKEN>
        <TOKEN id="token-28-7" pos="word" morph="none" start_char="1154" end_char="1156">the</TOKEN>
        <TOKEN id="token-28-8" pos="word" morph="none" start_char="1158" end_char="1164">article</TOKEN>
        <TOKEN id="token-28-9" pos="word" morph="none" start_char="1166" end_char="1169">says</TOKEN>
      </SEG>
      <SEG id="segment-29" start_char="1171" end_char="1174">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-29-0" pos="unknown" morph="none" start_char="1171" end_char="1174">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-30" start_char="1176" end_char="1178">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-30-0" pos="unknown" morph="none" start_char="1176" end_char="1178">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-31" start_char="1181" end_char="1184">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-31-0" pos="unknown" morph="none" start_char="1181" end_char="1184">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-32" start_char="1186" end_char="1188">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-32-0" pos="unknown" morph="none" start_char="1186" end_char="1188">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-33" start_char="1190" end_char="1258">
        <ORIGINAL_TEXT>The trial is in the voir dire stage, the individual interview part of</ORIGINAL_TEXT>
        <TOKEN id="token-33-0" pos="word" morph="none" start_char="1190" end_char="1192">The</TOKEN>
        <TOKEN id="token-33-1" pos="word" morph="none" start_char="1194" end_char="1198">trial</TOKEN>
        <TOKEN id="token-33-2" pos="word" morph="none" start_char="1200" end_char="1201">is</TOKEN>
        <TOKEN id="token-33-3" pos="word" morph="none" start_char="1203" end_char="1204">in</TOKEN>
        <TOKEN id="token-33-4" pos="word" morph="none" start_char="1206" end_char="1208">the</TOKEN>
        <TOKEN id="token-33-5" pos="word" morph="none" start_char="1210" end_char="1213">voir</TOKEN>
        <TOKEN id="token-33-6" pos="word" morph="none" start_char="1215" end_char="1218">dire</TOKEN>
        <TOKEN id="token-33-7" pos="word" morph="none" start_char="1220" end_char="1224">stage</TOKEN>
        <TOKEN id="token-33-8" pos="punct" morph="none" start_char="1225" end_char="1225">,</TOKEN>
        <TOKEN id="token-33-9" pos="word" morph="none" start_char="1227" end_char="1229">the</TOKEN>
        <TOKEN id="token-33-10" pos="word" morph="none" start_char="1231" end_char="1240">individual</TOKEN>
        <TOKEN id="token-33-11" pos="word" morph="none" start_char="1242" end_char="1250">interview</TOKEN>
        <TOKEN id="token-33-12" pos="word" morph="none" start_char="1252" end_char="1255">part</TOKEN>
        <TOKEN id="token-33-13" pos="word" morph="none" start_char="1257" end_char="1258">of</TOKEN>
      </SEG>
      <SEG id="segment-34" start_char="1260" end_char="1333">
        <ORIGINAL_TEXT>selecting a jury. On Wednesday, The Boston Globe filed a motion requesting</ORIGINAL_TEXT>
        <TOKEN id="token-34-0" pos="word" morph="none" start_char="1260" end_char="1268">selecting</TOKEN>
        <TOKEN id="token-34-1" pos="word" morph="none" start_char="1270" end_char="1270">a</TOKEN>
        <TOKEN id="token-34-2" pos="word" morph="none" start_char="1272" end_char="1275">jury</TOKEN>
        <TOKEN id="token-34-3" pos="punct" morph="none" start_char="1276" end_char="1276">.</TOKEN>
        <TOKEN id="token-34-4" pos="word" morph="none" start_char="1278" end_char="1279">On</TOKEN>
        <TOKEN id="token-34-5" pos="word" morph="none" start_char="1281" end_char="1289">Wednesday</TOKEN>
        <TOKEN id="token-34-6" pos="punct" morph="none" start_char="1290" end_char="1290">,</TOKEN>
        <TOKEN id="token-34-7" pos="word" morph="none" start_char="1292" end_char="1294">The</TOKEN>
        <TOKEN id="token-34-8" pos="word" morph="none" start_char="1296" end_char="1301">Boston</TOKEN>
        <TOKEN id="token-34-9" pos="word" morph="none" start_char="1303" end_char="1307">Globe</TOKEN>
        <TOKEN id="token-34-10" pos="word" morph="none" start_char="1309" end_char="1313">filed</TOKEN>
        <TOKEN id="token-34-11" pos="word" morph="none" start_char="1315" end_char="1315">a</TOKEN>
        <TOKEN id="token-34-12" pos="word" morph="none" start_char="1317" end_char="1322">motion</TOKEN>
        <TOKEN id="token-34-13" pos="word" morph="none" start_char="1324" end_char="1333">requesting</TOKEN>
      </SEG>
      <SEG id="segment-35" start_char="1335" end_char="1405">
        <ORIGINAL_TEXT>public – meaning media – access to some of the challenges made to juror</ORIGINAL_TEXT>
        <TOKEN id="token-35-0" pos="word" morph="none" start_char="1335" end_char="1340">public</TOKEN>
        <TOKEN id="token-35-1" pos="unknown" morph="none" start_char="1342" end_char="1342">–</TOKEN>
        <TOKEN id="token-35-2" pos="word" morph="none" start_char="1344" end_char="1350">meaning</TOKEN>
        <TOKEN id="token-35-3" pos="word" morph="none" start_char="1352" end_char="1356">media</TOKEN>
        <TOKEN id="token-35-4" pos="unknown" morph="none" start_char="1358" end_char="1358">–</TOKEN>
        <TOKEN id="token-35-5" pos="word" morph="none" start_char="1360" end_char="1365">access</TOKEN>
        <TOKEN id="token-35-6" pos="word" morph="none" start_char="1367" end_char="1368">to</TOKEN>
        <TOKEN id="token-35-7" pos="word" morph="none" start_char="1370" end_char="1373">some</TOKEN>
        <TOKEN id="token-35-8" pos="word" morph="none" start_char="1375" end_char="1376">of</TOKEN>
        <TOKEN id="token-35-9" pos="word" morph="none" start_char="1378" end_char="1380">the</TOKEN>
        <TOKEN id="token-35-10" pos="word" morph="none" start_char="1382" end_char="1391">challenges</TOKEN>
        <TOKEN id="token-35-11" pos="word" morph="none" start_char="1393" end_char="1396">made</TOKEN>
        <TOKEN id="token-35-12" pos="word" morph="none" start_char="1398" end_char="1399">to</TOKEN>
        <TOKEN id="token-35-13" pos="word" morph="none" start_char="1401" end_char="1405">juror</TOKEN>
      </SEG>
      <SEG id="segment-36" start_char="1407" end_char="1479">
        <ORIGINAL_TEXT>candidates by the lawyers on either side and the judge’s rulings on these</ORIGINAL_TEXT>
        <TOKEN id="token-36-0" pos="word" morph="none" start_char="1407" end_char="1416">candidates</TOKEN>
        <TOKEN id="token-36-1" pos="word" morph="none" start_char="1418" end_char="1419">by</TOKEN>
        <TOKEN id="token-36-2" pos="word" morph="none" start_char="1421" end_char="1423">the</TOKEN>
        <TOKEN id="token-36-3" pos="word" morph="none" start_char="1425" end_char="1431">lawyers</TOKEN>
        <TOKEN id="token-36-4" pos="word" morph="none" start_char="1433" end_char="1434">on</TOKEN>
        <TOKEN id="token-36-5" pos="word" morph="none" start_char="1436" end_char="1441">either</TOKEN>
        <TOKEN id="token-36-6" pos="word" morph="none" start_char="1443" end_char="1446">side</TOKEN>
        <TOKEN id="token-36-7" pos="word" morph="none" start_char="1448" end_char="1450">and</TOKEN>
        <TOKEN id="token-36-8" pos="word" morph="none" start_char="1452" end_char="1454">the</TOKEN>
        <TOKEN id="token-36-9" pos="word" morph="none" start_char="1456" end_char="1460">judge</TOKEN>
        <TOKEN id="token-36-10" pos="punct" morph="none" start_char="1461" end_char="1461">’</TOKEN>
        <TOKEN id="token-36-11" pos="word" morph="none" start_char="1462" end_char="1462">s</TOKEN>
        <TOKEN id="token-36-12" pos="word" morph="none" start_char="1464" end_char="1470">rulings</TOKEN>
        <TOKEN id="token-36-13" pos="word" morph="none" start_char="1472" end_char="1473">on</TOKEN>
        <TOKEN id="token-36-14" pos="word" morph="none" start_char="1475" end_char="1479">these</TOKEN>
      </SEG>
      <SEG id="segment-37" start_char="1481" end_char="1491">
        <ORIGINAL_TEXT>challenges.</ORIGINAL_TEXT>
        <TOKEN id="token-37-0" pos="word" morph="none" start_char="1481" end_char="1490">challenges</TOKEN>
        <TOKEN id="token-37-1" pos="punct" morph="none" start_char="1491" end_char="1491">.</TOKEN>
      </SEG>
      <SEG id="segment-38" start_char="1493" end_char="1496">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-38-0" pos="unknown" morph="none" start_char="1493" end_char="1496">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-39" start_char="1498" end_char="1500">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-39-0" pos="unknown" morph="none" start_char="1498" end_char="1500">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-40" start_char="1503" end_char="1506">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-40-0" pos="unknown" morph="none" start_char="1503" end_char="1506">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-41" start_char="1508" end_char="1510">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-41-0" pos="unknown" morph="none" start_char="1508" end_char="1510">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-42" start_char="1512" end_char="1583">
        <ORIGINAL_TEXT>"If a juror is so obviously dead-set on voting for the death penalty or,</ORIGINAL_TEXT>
        <TOKEN id="token-42-0" pos="punct" morph="none" start_char="1512" end_char="1512">"</TOKEN>
        <TOKEN id="token-42-1" pos="word" morph="none" start_char="1513" end_char="1514">If</TOKEN>
        <TOKEN id="token-42-2" pos="word" morph="none" start_char="1516" end_char="1516">a</TOKEN>
        <TOKEN id="token-42-3" pos="word" morph="none" start_char="1518" end_char="1522">juror</TOKEN>
        <TOKEN id="token-42-4" pos="word" morph="none" start_char="1524" end_char="1525">is</TOKEN>
        <TOKEN id="token-42-5" pos="word" morph="none" start_char="1527" end_char="1528">so</TOKEN>
        <TOKEN id="token-42-6" pos="word" morph="none" start_char="1530" end_char="1538">obviously</TOKEN>
        <TOKEN id="token-42-7" pos="word" morph="none" start_char="1540" end_char="1543">dead</TOKEN>
        <TOKEN id="token-42-8" pos="punct" morph="none" start_char="1544" end_char="1544">-</TOKEN>
        <TOKEN id="token-42-9" pos="word" morph="none" start_char="1545" end_char="1547">set</TOKEN>
        <TOKEN id="token-42-10" pos="word" morph="none" start_char="1549" end_char="1550">on</TOKEN>
        <TOKEN id="token-42-11" pos="word" morph="none" start_char="1552" end_char="1557">voting</TOKEN>
        <TOKEN id="token-42-12" pos="word" morph="none" start_char="1559" end_char="1561">for</TOKEN>
        <TOKEN id="token-42-13" pos="word" morph="none" start_char="1563" end_char="1565">the</TOKEN>
        <TOKEN id="token-42-14" pos="word" morph="none" start_char="1567" end_char="1571">death</TOKEN>
        <TOKEN id="token-42-15" pos="word" morph="none" start_char="1573" end_char="1579">penalty</TOKEN>
        <TOKEN id="token-42-16" pos="word" morph="none" start_char="1581" end_char="1582">or</TOKEN>
        <TOKEN id="token-42-17" pos="punct" morph="none" start_char="1583" end_char="1583">,</TOKEN>
      </SEG>
      <SEG id="segment-43" start_char="1585" end_char="1658">
        <ORIGINAL_TEXT>conversely, if a juror is unequivocally opposed to the death penalty, both</ORIGINAL_TEXT>
        <TOKEN id="token-43-0" pos="word" morph="none" start_char="1585" end_char="1594">conversely</TOKEN>
        <TOKEN id="token-43-1" pos="punct" morph="none" start_char="1595" end_char="1595">,</TOKEN>
        <TOKEN id="token-43-2" pos="word" morph="none" start_char="1597" end_char="1598">if</TOKEN>
        <TOKEN id="token-43-3" pos="word" morph="none" start_char="1600" end_char="1600">a</TOKEN>
        <TOKEN id="token-43-4" pos="word" morph="none" start_char="1602" end_char="1606">juror</TOKEN>
        <TOKEN id="token-43-5" pos="word" morph="none" start_char="1608" end_char="1609">is</TOKEN>
        <TOKEN id="token-43-6" pos="word" morph="none" start_char="1611" end_char="1623">unequivocally</TOKEN>
        <TOKEN id="token-43-7" pos="word" morph="none" start_char="1625" end_char="1631">opposed</TOKEN>
        <TOKEN id="token-43-8" pos="word" morph="none" start_char="1633" end_char="1634">to</TOKEN>
        <TOKEN id="token-43-9" pos="word" morph="none" start_char="1636" end_char="1638">the</TOKEN>
        <TOKEN id="token-43-10" pos="word" morph="none" start_char="1640" end_char="1644">death</TOKEN>
        <TOKEN id="token-43-11" pos="word" morph="none" start_char="1646" end_char="1652">penalty</TOKEN>
        <TOKEN id="token-43-12" pos="punct" morph="none" start_char="1653" end_char="1653">,</TOKEN>
        <TOKEN id="token-43-13" pos="word" morph="none" start_char="1655" end_char="1658">both</TOKEN>
      </SEG>
      <SEG id="segment-44" start_char="1660" end_char="1737">
        <ORIGINAL_TEXT>sides may agree on the spot that the person cannot meaningfully participate in</ORIGINAL_TEXT>
        <TOKEN id="token-44-0" pos="word" morph="none" start_char="1660" end_char="1664">sides</TOKEN>
        <TOKEN id="token-44-1" pos="word" morph="none" start_char="1666" end_char="1668">may</TOKEN>
        <TOKEN id="token-44-2" pos="word" morph="none" start_char="1670" end_char="1674">agree</TOKEN>
        <TOKEN id="token-44-3" pos="word" morph="none" start_char="1676" end_char="1677">on</TOKEN>
        <TOKEN id="token-44-4" pos="word" morph="none" start_char="1679" end_char="1681">the</TOKEN>
        <TOKEN id="token-44-5" pos="word" morph="none" start_char="1683" end_char="1686">spot</TOKEN>
        <TOKEN id="token-44-6" pos="word" morph="none" start_char="1688" end_char="1691">that</TOKEN>
        <TOKEN id="token-44-7" pos="word" morph="none" start_char="1693" end_char="1695">the</TOKEN>
        <TOKEN id="token-44-8" pos="word" morph="none" start_char="1697" end_char="1702">person</TOKEN>
        <TOKEN id="token-44-9" pos="word" morph="none" start_char="1704" end_char="1709">cannot</TOKEN>
        <TOKEN id="token-44-10" pos="word" morph="none" start_char="1711" end_char="1722">meaningfully</TOKEN>
        <TOKEN id="token-44-11" pos="word" morph="none" start_char="1724" end_char="1734">participate</TOKEN>
        <TOKEN id="token-44-12" pos="word" morph="none" start_char="1736" end_char="1737">in</TOKEN>
      </SEG>
      <SEG id="segment-45" start_char="1739" end_char="1794">
        <ORIGINAL_TEXT>the penalty phase of the trial", the newspaper explains.</ORIGINAL_TEXT>
        <TOKEN id="token-45-0" pos="word" morph="none" start_char="1739" end_char="1741">the</TOKEN>
        <TOKEN id="token-45-1" pos="word" morph="none" start_char="1743" end_char="1749">penalty</TOKEN>
        <TOKEN id="token-45-2" pos="word" morph="none" start_char="1751" end_char="1755">phase</TOKEN>
        <TOKEN id="token-45-3" pos="word" morph="none" start_char="1757" end_char="1758">of</TOKEN>
        <TOKEN id="token-45-4" pos="word" morph="none" start_char="1760" end_char="1762">the</TOKEN>
        <TOKEN id="token-45-5" pos="word" morph="none" start_char="1764" end_char="1768">trial</TOKEN>
        <TOKEN id="token-45-6" pos="punct" morph="none" start_char="1769" end_char="1770">",</TOKEN>
        <TOKEN id="token-45-7" pos="word" morph="none" start_char="1772" end_char="1774">the</TOKEN>
        <TOKEN id="token-45-8" pos="word" morph="none" start_char="1776" end_char="1784">newspaper</TOKEN>
        <TOKEN id="token-45-9" pos="word" morph="none" start_char="1786" end_char="1793">explains</TOKEN>
        <TOKEN id="token-45-10" pos="punct" morph="none" start_char="1794" end_char="1794">.</TOKEN>
      </SEG>
      <SEG id="segment-46" start_char="1796" end_char="1799">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-46-0" pos="unknown" morph="none" start_char="1796" end_char="1799">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-47" start_char="1801" end_char="1803">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-47-0" pos="unknown" morph="none" start_char="1801" end_char="1803">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-48" start_char="1806" end_char="1809">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-48-0" pos="unknown" morph="none" start_char="1806" end_char="1809">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-49" start_char="1811" end_char="1813">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-49-0" pos="unknown" morph="none" start_char="1811" end_char="1813">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-50" start_char="1815" end_char="1892">
        <ORIGINAL_TEXT>The court has interviewed 98 people so far. "It would appear that most of them</ORIGINAL_TEXT>
        <TOKEN id="token-50-0" pos="word" morph="none" start_char="1815" end_char="1817">The</TOKEN>
        <TOKEN id="token-50-1" pos="word" morph="none" start_char="1819" end_char="1823">court</TOKEN>
        <TOKEN id="token-50-2" pos="word" morph="none" start_char="1825" end_char="1827">has</TOKEN>
        <TOKEN id="token-50-3" pos="word" morph="none" start_char="1829" end_char="1839">interviewed</TOKEN>
        <TOKEN id="token-50-4" pos="number" morph="none" start_char="1841" end_char="1842">98</TOKEN>
        <TOKEN id="token-50-5" pos="word" morph="none" start_char="1844" end_char="1849">people</TOKEN>
        <TOKEN id="token-50-6" pos="word" morph="none" start_char="1851" end_char="1852">so</TOKEN>
        <TOKEN id="token-50-7" pos="word" morph="none" start_char="1854" end_char="1856">far</TOKEN>
        <TOKEN id="token-50-8" pos="punct" morph="none" start_char="1857" end_char="1857">.</TOKEN>
        <TOKEN id="token-50-9" pos="punct" morph="none" start_char="1859" end_char="1859">"</TOKEN>
        <TOKEN id="token-50-10" pos="word" morph="none" start_char="1860" end_char="1861">It</TOKEN>
        <TOKEN id="token-50-11" pos="word" morph="none" start_char="1863" end_char="1867">would</TOKEN>
        <TOKEN id="token-50-12" pos="word" morph="none" start_char="1869" end_char="1874">appear</TOKEN>
        <TOKEN id="token-50-13" pos="word" morph="none" start_char="1876" end_char="1879">that</TOKEN>
        <TOKEN id="token-50-14" pos="word" morph="none" start_char="1881" end_char="1884">most</TOKEN>
        <TOKEN id="token-50-15" pos="word" morph="none" start_char="1886" end_char="1887">of</TOKEN>
        <TOKEN id="token-50-16" pos="word" morph="none" start_char="1889" end_char="1892">them</TOKEN>
      </SEG>
      <SEG id="segment-51" start_char="1894" end_char="1964">
        <ORIGINAL_TEXT>cannot serve on the jury, either because they hold strong beliefs about</ORIGINAL_TEXT>
        <TOKEN id="token-51-0" pos="word" morph="none" start_char="1894" end_char="1899">cannot</TOKEN>
        <TOKEN id="token-51-1" pos="word" morph="none" start_char="1901" end_char="1905">serve</TOKEN>
        <TOKEN id="token-51-2" pos="word" morph="none" start_char="1907" end_char="1908">on</TOKEN>
        <TOKEN id="token-51-3" pos="word" morph="none" start_char="1910" end_char="1912">the</TOKEN>
        <TOKEN id="token-51-4" pos="word" morph="none" start_char="1914" end_char="1917">jury</TOKEN>
        <TOKEN id="token-51-5" pos="punct" morph="none" start_char="1918" end_char="1918">,</TOKEN>
        <TOKEN id="token-51-6" pos="word" morph="none" start_char="1920" end_char="1925">either</TOKEN>
        <TOKEN id="token-51-7" pos="word" morph="none" start_char="1927" end_char="1933">because</TOKEN>
        <TOKEN id="token-51-8" pos="word" morph="none" start_char="1935" end_char="1938">they</TOKEN>
        <TOKEN id="token-51-9" pos="word" morph="none" start_char="1940" end_char="1943">hold</TOKEN>
        <TOKEN id="token-51-10" pos="word" morph="none" start_char="1945" end_char="1950">strong</TOKEN>
        <TOKEN id="token-51-11" pos="word" morph="none" start_char="1952" end_char="1958">beliefs</TOKEN>
        <TOKEN id="token-51-12" pos="word" morph="none" start_char="1960" end_char="1964">about</TOKEN>
      </SEG>
      <SEG id="segment-52" start_char="1966" end_char="2032">
        <ORIGINAL_TEXT>Tsarnaev’s guilt or about the death penalty", the newspaper writes.</ORIGINAL_TEXT>
        <TOKEN id="token-52-0" pos="word" morph="none" start_char="1966" end_char="1973">Tsarnaev</TOKEN>
        <TOKEN id="token-52-1" pos="punct" morph="none" start_char="1974" end_char="1974">’</TOKEN>
        <TOKEN id="token-52-2" pos="word" morph="none" start_char="1975" end_char="1975">s</TOKEN>
        <TOKEN id="token-52-3" pos="word" morph="none" start_char="1977" end_char="1981">guilt</TOKEN>
        <TOKEN id="token-52-4" pos="word" morph="none" start_char="1983" end_char="1984">or</TOKEN>
        <TOKEN id="token-52-5" pos="word" morph="none" start_char="1986" end_char="1990">about</TOKEN>
        <TOKEN id="token-52-6" pos="word" morph="none" start_char="1992" end_char="1994">the</TOKEN>
        <TOKEN id="token-52-7" pos="word" morph="none" start_char="1996" end_char="2000">death</TOKEN>
        <TOKEN id="token-52-8" pos="word" morph="none" start_char="2002" end_char="2008">penalty</TOKEN>
        <TOKEN id="token-52-9" pos="punct" morph="none" start_char="2009" end_char="2010">",</TOKEN>
        <TOKEN id="token-52-10" pos="word" morph="none" start_char="2012" end_char="2014">the</TOKEN>
        <TOKEN id="token-52-11" pos="word" morph="none" start_char="2016" end_char="2024">newspaper</TOKEN>
        <TOKEN id="token-52-12" pos="word" morph="none" start_char="2026" end_char="2031">writes</TOKEN>
        <TOKEN id="token-52-13" pos="punct" morph="none" start_char="2032" end_char="2032">.</TOKEN>
      </SEG>
      <SEG id="segment-53" start_char="2034" end_char="2037">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-53-0" pos="unknown" morph="none" start_char="2034" end_char="2037">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-54" start_char="2039" end_char="2041">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-54-0" pos="unknown" morph="none" start_char="2039" end_char="2041">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-55" start_char="2044" end_char="2047">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-55-0" pos="unknown" morph="none" start_char="2044" end_char="2047">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-56" start_char="2049" end_char="2051">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-56-0" pos="unknown" morph="none" start_char="2049" end_char="2051">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-57" start_char="2053" end_char="2121">
        <ORIGINAL_TEXT>In open court proceedings, O’Toole said he didn’t want to tell jurors</ORIGINAL_TEXT>
        <TOKEN id="token-57-0" pos="word" morph="none" start_char="2053" end_char="2054">In</TOKEN>
        <TOKEN id="token-57-1" pos="word" morph="none" start_char="2056" end_char="2059">open</TOKEN>
        <TOKEN id="token-57-2" pos="word" morph="none" start_char="2061" end_char="2065">court</TOKEN>
        <TOKEN id="token-57-3" pos="word" morph="none" start_char="2067" end_char="2077">proceedings</TOKEN>
        <TOKEN id="token-57-4" pos="punct" morph="none" start_char="2078" end_char="2078">,</TOKEN>
        <TOKEN id="token-57-5" pos="word" morph="none" start_char="2080" end_char="2080">O</TOKEN>
        <TOKEN id="token-57-6" pos="punct" morph="none" start_char="2081" end_char="2081">’</TOKEN>
        <TOKEN id="token-57-7" pos="word" morph="none" start_char="2082" end_char="2086">Toole</TOKEN>
        <TOKEN id="token-57-8" pos="word" morph="none" start_char="2088" end_char="2091">said</TOKEN>
        <TOKEN id="token-57-9" pos="word" morph="none" start_char="2093" end_char="2094">he</TOKEN>
        <TOKEN id="token-57-10" pos="word" morph="none" start_char="2096" end_char="2099">didn</TOKEN>
        <TOKEN id="token-57-11" pos="punct" morph="none" start_char="2100" end_char="2100">’</TOKEN>
        <TOKEN id="token-57-12" pos="word" morph="none" start_char="2101" end_char="2101">t</TOKEN>
        <TOKEN id="token-57-13" pos="word" morph="none" start_char="2103" end_char="2106">want</TOKEN>
        <TOKEN id="token-57-14" pos="word" morph="none" start_char="2108" end_char="2109">to</TOKEN>
        <TOKEN id="token-57-15" pos="word" morph="none" start_char="2111" end_char="2114">tell</TOKEN>
        <TOKEN id="token-57-16" pos="word" morph="none" start_char="2116" end_char="2121">jurors</TOKEN>
      </SEG>
      <SEG id="segment-58" start_char="2123" end_char="2193">
        <ORIGINAL_TEXT>directly that they have been excused because he doesn’t want to “coach”</ORIGINAL_TEXT>
        <TOKEN id="token-58-0" pos="word" morph="none" start_char="2123" end_char="2130">directly</TOKEN>
        <TOKEN id="token-58-1" pos="word" morph="none" start_char="2132" end_char="2135">that</TOKEN>
        <TOKEN id="token-58-2" pos="word" morph="none" start_char="2137" end_char="2140">they</TOKEN>
        <TOKEN id="token-58-3" pos="word" morph="none" start_char="2142" end_char="2145">have</TOKEN>
        <TOKEN id="token-58-4" pos="word" morph="none" start_char="2147" end_char="2150">been</TOKEN>
        <TOKEN id="token-58-5" pos="word" morph="none" start_char="2152" end_char="2158">excused</TOKEN>
        <TOKEN id="token-58-6" pos="word" morph="none" start_char="2160" end_char="2166">because</TOKEN>
        <TOKEN id="token-58-7" pos="word" morph="none" start_char="2168" end_char="2169">he</TOKEN>
        <TOKEN id="token-58-8" pos="word" morph="none" start_char="2171" end_char="2175">doesn</TOKEN>
        <TOKEN id="token-58-9" pos="punct" morph="none" start_char="2176" end_char="2176">’</TOKEN>
        <TOKEN id="token-58-10" pos="word" morph="none" start_char="2177" end_char="2177">t</TOKEN>
        <TOKEN id="token-58-11" pos="word" morph="none" start_char="2179" end_char="2182">want</TOKEN>
        <TOKEN id="token-58-12" pos="word" morph="none" start_char="2184" end_char="2185">to</TOKEN>
        <TOKEN id="token-58-13" pos="punct" morph="none" start_char="2187" end_char="2187">“</TOKEN>
        <TOKEN id="token-58-14" pos="word" morph="none" start_char="2188" end_char="2192">coach</TOKEN>
        <TOKEN id="token-58-15" pos="punct" morph="none" start_char="2193" end_char="2193">”</TOKEN>
      </SEG>
      <SEG id="segment-59" start_char="2195" end_char="2270">
        <ORIGINAL_TEXT>other candidates on how to get out of jury duty in this case. "That may be a</ORIGINAL_TEXT>
        <TOKEN id="token-59-0" pos="word" morph="none" start_char="2195" end_char="2199">other</TOKEN>
        <TOKEN id="token-59-1" pos="word" morph="none" start_char="2201" end_char="2210">candidates</TOKEN>
        <TOKEN id="token-59-2" pos="word" morph="none" start_char="2212" end_char="2213">on</TOKEN>
        <TOKEN id="token-59-3" pos="word" morph="none" start_char="2215" end_char="2217">how</TOKEN>
        <TOKEN id="token-59-4" pos="word" morph="none" start_char="2219" end_char="2220">to</TOKEN>
        <TOKEN id="token-59-5" pos="word" morph="none" start_char="2222" end_char="2224">get</TOKEN>
        <TOKEN id="token-59-6" pos="word" morph="none" start_char="2226" end_char="2228">out</TOKEN>
        <TOKEN id="token-59-7" pos="word" morph="none" start_char="2230" end_char="2231">of</TOKEN>
        <TOKEN id="token-59-8" pos="word" morph="none" start_char="2233" end_char="2236">jury</TOKEN>
        <TOKEN id="token-59-9" pos="word" morph="none" start_char="2238" end_char="2241">duty</TOKEN>
        <TOKEN id="token-59-10" pos="word" morph="none" start_char="2243" end_char="2244">in</TOKEN>
        <TOKEN id="token-59-11" pos="word" morph="none" start_char="2246" end_char="2249">this</TOKEN>
        <TOKEN id="token-59-12" pos="word" morph="none" start_char="2251" end_char="2254">case</TOKEN>
        <TOKEN id="token-59-13" pos="punct" morph="none" start_char="2255" end_char="2255">.</TOKEN>
        <TOKEN id="token-59-14" pos="punct" morph="none" start_char="2257" end_char="2257">"</TOKEN>
        <TOKEN id="token-59-15" pos="word" morph="none" start_char="2258" end_char="2261">That</TOKEN>
        <TOKEN id="token-59-16" pos="word" morph="none" start_char="2263" end_char="2265">may</TOKEN>
        <TOKEN id="token-59-17" pos="word" morph="none" start_char="2267" end_char="2268">be</TOKEN>
        <TOKEN id="token-59-18" pos="word" morph="none" start_char="2270" end_char="2270">a</TOKEN>
      </SEG>
      <SEG id="segment-60" start_char="2272" end_char="2344">
        <ORIGINAL_TEXT>part of the reason he has closed the afternoon discussions to the press –</ORIGINAL_TEXT>
        <TOKEN id="token-60-0" pos="word" morph="none" start_char="2272" end_char="2275">part</TOKEN>
        <TOKEN id="token-60-1" pos="word" morph="none" start_char="2277" end_char="2278">of</TOKEN>
        <TOKEN id="token-60-2" pos="word" morph="none" start_char="2280" end_char="2282">the</TOKEN>
        <TOKEN id="token-60-3" pos="word" morph="none" start_char="2284" end_char="2289">reason</TOKEN>
        <TOKEN id="token-60-4" pos="word" morph="none" start_char="2291" end_char="2292">he</TOKEN>
        <TOKEN id="token-60-5" pos="word" morph="none" start_char="2294" end_char="2296">has</TOKEN>
        <TOKEN id="token-60-6" pos="word" morph="none" start_char="2298" end_char="2303">closed</TOKEN>
        <TOKEN id="token-60-7" pos="word" morph="none" start_char="2305" end_char="2307">the</TOKEN>
        <TOKEN id="token-60-8" pos="word" morph="none" start_char="2309" end_char="2317">afternoon</TOKEN>
        <TOKEN id="token-60-9" pos="word" morph="none" start_char="2319" end_char="2329">discussions</TOKEN>
        <TOKEN id="token-60-10" pos="word" morph="none" start_char="2331" end_char="2332">to</TOKEN>
        <TOKEN id="token-60-11" pos="word" morph="none" start_char="2334" end_char="2336">the</TOKEN>
        <TOKEN id="token-60-12" pos="word" morph="none" start_char="2338" end_char="2342">press</TOKEN>
        <TOKEN id="token-60-13" pos="unknown" morph="none" start_char="2344" end_char="2344">–</TOKEN>
      </SEG>
      <SEG id="segment-61" start_char="2346" end_char="2421">
        <ORIGINAL_TEXT>though he has not explained this decision. Nor has he explained the decision</ORIGINAL_TEXT>
        <TOKEN id="token-61-0" pos="word" morph="none" start_char="2346" end_char="2351">though</TOKEN>
        <TOKEN id="token-61-1" pos="word" morph="none" start_char="2353" end_char="2354">he</TOKEN>
        <TOKEN id="token-61-2" pos="word" morph="none" start_char="2356" end_char="2358">has</TOKEN>
        <TOKEN id="token-61-3" pos="word" morph="none" start_char="2360" end_char="2362">not</TOKEN>
        <TOKEN id="token-61-4" pos="word" morph="none" start_char="2364" end_char="2372">explained</TOKEN>
        <TOKEN id="token-61-5" pos="word" morph="none" start_char="2374" end_char="2377">this</TOKEN>
        <TOKEN id="token-61-6" pos="word" morph="none" start_char="2379" end_char="2386">decision</TOKEN>
        <TOKEN id="token-61-7" pos="punct" morph="none" start_char="2387" end_char="2387">.</TOKEN>
        <TOKEN id="token-61-8" pos="word" morph="none" start_char="2389" end_char="2391">Nor</TOKEN>
        <TOKEN id="token-61-9" pos="word" morph="none" start_char="2393" end_char="2395">has</TOKEN>
        <TOKEN id="token-61-10" pos="word" morph="none" start_char="2397" end_char="2398">he</TOKEN>
        <TOKEN id="token-61-11" pos="word" morph="none" start_char="2400" end_char="2408">explained</TOKEN>
        <TOKEN id="token-61-12" pos="word" morph="none" start_char="2410" end_char="2412">the</TOKEN>
        <TOKEN id="token-61-13" pos="word" morph="none" start_char="2414" end_char="2421">decision</TOKEN>
      </SEG>
      <SEG id="segment-62" start_char="2423" end_char="2494">
        <ORIGINAL_TEXT>to exclude journalists physically from the courtroom", the article says.</ORIGINAL_TEXT>
        <TOKEN id="token-62-0" pos="word" morph="none" start_char="2423" end_char="2424">to</TOKEN>
        <TOKEN id="token-62-1" pos="word" morph="none" start_char="2426" end_char="2432">exclude</TOKEN>
        <TOKEN id="token-62-2" pos="word" morph="none" start_char="2434" end_char="2444">journalists</TOKEN>
        <TOKEN id="token-62-3" pos="word" morph="none" start_char="2446" end_char="2455">physically</TOKEN>
        <TOKEN id="token-62-4" pos="word" morph="none" start_char="2457" end_char="2460">from</TOKEN>
        <TOKEN id="token-62-5" pos="word" morph="none" start_char="2462" end_char="2464">the</TOKEN>
        <TOKEN id="token-62-6" pos="word" morph="none" start_char="2466" end_char="2474">courtroom</TOKEN>
        <TOKEN id="token-62-7" pos="punct" morph="none" start_char="2475" end_char="2476">",</TOKEN>
        <TOKEN id="token-62-8" pos="word" morph="none" start_char="2478" end_char="2480">the</TOKEN>
        <TOKEN id="token-62-9" pos="word" morph="none" start_char="2482" end_char="2488">article</TOKEN>
        <TOKEN id="token-62-10" pos="word" morph="none" start_char="2490" end_char="2493">says</TOKEN>
        <TOKEN id="token-62-11" pos="punct" morph="none" start_char="2494" end_char="2494">.</TOKEN>
      </SEG>
      <SEG id="segment-63" start_char="2496" end_char="2499">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-63-0" pos="unknown" morph="none" start_char="2496" end_char="2499">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-64" start_char="2501" end_char="2503">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-64-0" pos="unknown" morph="none" start_char="2501" end_char="2503">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-65" start_char="2506" end_char="2509">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-65-0" pos="unknown" morph="none" start_char="2506" end_char="2509">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-66" start_char="2511" end_char="2513">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-66-0" pos="unknown" morph="none" start_char="2511" end_char="2513">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-67" start_char="2515" end_char="2592">
        <ORIGINAL_TEXT>Such restrictions in this court have not even been seen during the last year's</ORIGINAL_TEXT>
        <TOKEN id="token-67-0" pos="word" morph="none" start_char="2515" end_char="2518">Such</TOKEN>
        <TOKEN id="token-67-1" pos="word" morph="none" start_char="2520" end_char="2531">restrictions</TOKEN>
        <TOKEN id="token-67-2" pos="word" morph="none" start_char="2533" end_char="2534">in</TOKEN>
        <TOKEN id="token-67-3" pos="word" morph="none" start_char="2536" end_char="2539">this</TOKEN>
        <TOKEN id="token-67-4" pos="word" morph="none" start_char="2541" end_char="2545">court</TOKEN>
        <TOKEN id="token-67-5" pos="word" morph="none" start_char="2547" end_char="2550">have</TOKEN>
        <TOKEN id="token-67-6" pos="word" morph="none" start_char="2552" end_char="2554">not</TOKEN>
        <TOKEN id="token-67-7" pos="word" morph="none" start_char="2556" end_char="2559">even</TOKEN>
        <TOKEN id="token-67-8" pos="word" morph="none" start_char="2561" end_char="2564">been</TOKEN>
        <TOKEN id="token-67-9" pos="word" morph="none" start_char="2566" end_char="2569">seen</TOKEN>
        <TOKEN id="token-67-10" pos="word" morph="none" start_char="2571" end_char="2576">during</TOKEN>
        <TOKEN id="token-67-11" pos="word" morph="none" start_char="2578" end_char="2580">the</TOKEN>
        <TOKEN id="token-67-12" pos="word" morph="none" start_char="2582" end_char="2585">last</TOKEN>
        <TOKEN id="token-67-13" pos="word" morph="none" start_char="2587" end_char="2590">year</TOKEN>
        <TOKEN id="token-67-14" pos="punct" morph="none" start_char="2591" end_char="2591">'</TOKEN>
        <TOKEN id="token-67-15" pos="word" morph="none" start_char="2592" end_char="2592">s</TOKEN>
      </SEG>
      <SEG id="segment-68" start_char="2594" end_char="2645">
        <ORIGINAL_TEXT>trial of a notorious Boston gangster, Whitey Bulger.</ORIGINAL_TEXT>
        <TOKEN id="token-68-0" pos="word" morph="none" start_char="2594" end_char="2598">trial</TOKEN>
        <TOKEN id="token-68-1" pos="word" morph="none" start_char="2600" end_char="2601">of</TOKEN>
        <TOKEN id="token-68-2" pos="word" morph="none" start_char="2603" end_char="2603">a</TOKEN>
        <TOKEN id="token-68-3" pos="word" morph="none" start_char="2605" end_char="2613">notorious</TOKEN>
        <TOKEN id="token-68-4" pos="word" morph="none" start_char="2615" end_char="2620">Boston</TOKEN>
        <TOKEN id="token-68-5" pos="word" morph="none" start_char="2622" end_char="2629">gangster</TOKEN>
        <TOKEN id="token-68-6" pos="punct" morph="none" start_char="2630" end_char="2630">,</TOKEN>
        <TOKEN id="token-68-7" pos="word" morph="none" start_char="2632" end_char="2637">Whitey</TOKEN>
        <TOKEN id="token-68-8" pos="word" morph="none" start_char="2639" end_char="2644">Bulger</TOKEN>
        <TOKEN id="token-68-9" pos="punct" morph="none" start_char="2645" end_char="2645">.</TOKEN>
      </SEG>
      <SEG id="segment-69" start_char="2647" end_char="2650">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-69-0" pos="unknown" morph="none" start_char="2647" end_char="2650">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-70" start_char="2652" end_char="2654">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-70-0" pos="unknown" morph="none" start_char="2652" end_char="2654">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-71" start_char="2657" end_char="2660">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-71-0" pos="unknown" morph="none" start_char="2657" end_char="2660">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-72" start_char="2662" end_char="2664">
        <ORIGINAL_TEXT>&lt;P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-72-0" pos="unknown" morph="none" start_char="2662" end_char="2664">&lt;P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-73" start_char="2666" end_char="2740">
        <ORIGINAL_TEXT>As a result, they agreed the access to the courtroom for three journalists.</ORIGINAL_TEXT>
        <TOKEN id="token-73-0" pos="word" morph="none" start_char="2666" end_char="2667">As</TOKEN>
        <TOKEN id="token-73-1" pos="word" morph="none" start_char="2669" end_char="2669">a</TOKEN>
        <TOKEN id="token-73-2" pos="word" morph="none" start_char="2671" end_char="2676">result</TOKEN>
        <TOKEN id="token-73-3" pos="punct" morph="none" start_char="2677" end_char="2677">,</TOKEN>
        <TOKEN id="token-73-4" pos="word" morph="none" start_char="2679" end_char="2682">they</TOKEN>
        <TOKEN id="token-73-5" pos="word" morph="none" start_char="2684" end_char="2689">agreed</TOKEN>
        <TOKEN id="token-73-6" pos="word" morph="none" start_char="2691" end_char="2693">the</TOKEN>
        <TOKEN id="token-73-7" pos="word" morph="none" start_char="2695" end_char="2700">access</TOKEN>
        <TOKEN id="token-73-8" pos="word" morph="none" start_char="2702" end_char="2703">to</TOKEN>
        <TOKEN id="token-73-9" pos="word" morph="none" start_char="2705" end_char="2707">the</TOKEN>
        <TOKEN id="token-73-10" pos="word" morph="none" start_char="2709" end_char="2717">courtroom</TOKEN>
        <TOKEN id="token-73-11" pos="word" morph="none" start_char="2719" end_char="2721">for</TOKEN>
        <TOKEN id="token-73-12" pos="word" morph="none" start_char="2723" end_char="2727">three</TOKEN>
        <TOKEN id="token-73-13" pos="word" morph="none" start_char="2729" end_char="2739">journalists</TOKEN>
        <TOKEN id="token-73-14" pos="punct" morph="none" start_char="2740" end_char="2740">.</TOKEN>
      </SEG>
      <SEG id="segment-74" start_char="2742" end_char="2818">
        <ORIGINAL_TEXT>The time at which the court mutes the microphone, has been slowly shortening,</ORIGINAL_TEXT>
        <TOKEN id="token-74-0" pos="word" morph="none" start_char="2742" end_char="2744">The</TOKEN>
        <TOKEN id="token-74-1" pos="word" morph="none" start_char="2746" end_char="2749">time</TOKEN>
        <TOKEN id="token-74-2" pos="word" morph="none" start_char="2751" end_char="2752">at</TOKEN>
        <TOKEN id="token-74-3" pos="word" morph="none" start_char="2754" end_char="2758">which</TOKEN>
        <TOKEN id="token-74-4" pos="word" morph="none" start_char="2760" end_char="2762">the</TOKEN>
        <TOKEN id="token-74-5" pos="word" morph="none" start_char="2764" end_char="2768">court</TOKEN>
        <TOKEN id="token-74-6" pos="word" morph="none" start_char="2770" end_char="2774">mutes</TOKEN>
        <TOKEN id="token-74-7" pos="word" morph="none" start_char="2776" end_char="2778">the</TOKEN>
        <TOKEN id="token-74-8" pos="word" morph="none" start_char="2780" end_char="2789">microphone</TOKEN>
        <TOKEN id="token-74-9" pos="punct" morph="none" start_char="2790" end_char="2790">,</TOKEN>
        <TOKEN id="token-74-10" pos="word" morph="none" start_char="2792" end_char="2794">has</TOKEN>
        <TOKEN id="token-74-11" pos="word" morph="none" start_char="2796" end_char="2799">been</TOKEN>
        <TOKEN id="token-74-12" pos="word" morph="none" start_char="2801" end_char="2806">slowly</TOKEN>
        <TOKEN id="token-74-13" pos="word" morph="none" start_char="2808" end_char="2817">shortening</TOKEN>
        <TOKEN id="token-74-14" pos="punct" morph="none" start_char="2818" end_char="2818">,</TOKEN>
      </SEG>
      <SEG id="segment-75" start_char="2820" end_char="2895">
        <ORIGINAL_TEXT>too, and journalists can hear a little more. "Still, no one has been able to</ORIGINAL_TEXT>
        <TOKEN id="token-75-0" pos="word" morph="none" start_char="2820" end_char="2822">too</TOKEN>
        <TOKEN id="token-75-1" pos="punct" morph="none" start_char="2823" end_char="2823">,</TOKEN>
        <TOKEN id="token-75-2" pos="word" morph="none" start_char="2825" end_char="2827">and</TOKEN>
        <TOKEN id="token-75-3" pos="word" morph="none" start_char="2829" end_char="2839">journalists</TOKEN>
        <TOKEN id="token-75-4" pos="word" morph="none" start_char="2841" end_char="2843">can</TOKEN>
        <TOKEN id="token-75-5" pos="word" morph="none" start_char="2845" end_char="2848">hear</TOKEN>
        <TOKEN id="token-75-6" pos="word" morph="none" start_char="2850" end_char="2850">a</TOKEN>
        <TOKEN id="token-75-7" pos="word" morph="none" start_char="2852" end_char="2857">little</TOKEN>
        <TOKEN id="token-75-8" pos="word" morph="none" start_char="2859" end_char="2862">more</TOKEN>
        <TOKEN id="token-75-9" pos="punct" morph="none" start_char="2863" end_char="2863">.</TOKEN>
        <TOKEN id="token-75-10" pos="punct" morph="none" start_char="2865" end_char="2865">"</TOKEN>
        <TOKEN id="token-75-11" pos="word" morph="none" start_char="2866" end_char="2870">Still</TOKEN>
        <TOKEN id="token-75-12" pos="punct" morph="none" start_char="2871" end_char="2871">,</TOKEN>
        <TOKEN id="token-75-13" pos="word" morph="none" start_char="2873" end_char="2874">no</TOKEN>
        <TOKEN id="token-75-14" pos="word" morph="none" start_char="2876" end_char="2878">one</TOKEN>
        <TOKEN id="token-75-15" pos="word" morph="none" start_char="2880" end_char="2882">has</TOKEN>
        <TOKEN id="token-75-16" pos="word" morph="none" start_char="2884" end_char="2887">been</TOKEN>
        <TOKEN id="token-75-17" pos="word" morph="none" start_char="2889" end_char="2892">able</TOKEN>
        <TOKEN id="token-75-18" pos="word" morph="none" start_char="2894" end_char="2895">to</TOKEN>
      </SEG>
      <SEG id="segment-76" start_char="2897" end_char="2972">
        <ORIGINAL_TEXT>hear any of the chats that go on between Tsarnaev and public defender Miriam</ORIGINAL_TEXT>
        <TOKEN id="token-76-0" pos="word" morph="none" start_char="2897" end_char="2900">hear</TOKEN>
        <TOKEN id="token-76-1" pos="word" morph="none" start_char="2902" end_char="2904">any</TOKEN>
        <TOKEN id="token-76-2" pos="word" morph="none" start_char="2906" end_char="2907">of</TOKEN>
        <TOKEN id="token-76-3" pos="word" morph="none" start_char="2909" end_char="2911">the</TOKEN>
        <TOKEN id="token-76-4" pos="word" morph="none" start_char="2913" end_char="2917">chats</TOKEN>
        <TOKEN id="token-76-5" pos="word" morph="none" start_char="2919" end_char="2922">that</TOKEN>
        <TOKEN id="token-76-6" pos="word" morph="none" start_char="2924" end_char="2925">go</TOKEN>
        <TOKEN id="token-76-7" pos="word" morph="none" start_char="2927" end_char="2928">on</TOKEN>
        <TOKEN id="token-76-8" pos="word" morph="none" start_char="2930" end_char="2936">between</TOKEN>
        <TOKEN id="token-76-9" pos="word" morph="none" start_char="2938" end_char="2945">Tsarnaev</TOKEN>
        <TOKEN id="token-76-10" pos="word" morph="none" start_char="2947" end_char="2949">and</TOKEN>
        <TOKEN id="token-76-11" pos="word" morph="none" start_char="2951" end_char="2956">public</TOKEN>
        <TOKEN id="token-76-12" pos="word" morph="none" start_char="2958" end_char="2965">defender</TOKEN>
        <TOKEN id="token-76-13" pos="word" morph="none" start_char="2967" end_char="2972">Miriam</TOKEN>
      </SEG>
      <SEG id="segment-77" start_char="2974" end_char="3025">
        <ORIGINAL_TEXT>Conrad, who sits to his right", notes the newspaper.</ORIGINAL_TEXT>
        <TOKEN id="token-77-0" pos="word" morph="none" start_char="2974" end_char="2979">Conrad</TOKEN>
        <TOKEN id="token-77-1" pos="punct" morph="none" start_char="2980" end_char="2980">,</TOKEN>
        <TOKEN id="token-77-2" pos="word" morph="none" start_char="2982" end_char="2984">who</TOKEN>
        <TOKEN id="token-77-3" pos="word" morph="none" start_char="2986" end_char="2989">sits</TOKEN>
        <TOKEN id="token-77-4" pos="word" morph="none" start_char="2991" end_char="2992">to</TOKEN>
        <TOKEN id="token-77-5" pos="word" morph="none" start_char="2994" end_char="2996">his</TOKEN>
        <TOKEN id="token-77-6" pos="word" morph="none" start_char="2998" end_char="3002">right</TOKEN>
        <TOKEN id="token-77-7" pos="punct" morph="none" start_char="3003" end_char="3004">",</TOKEN>
        <TOKEN id="token-77-8" pos="word" morph="none" start_char="3006" end_char="3010">notes</TOKEN>
        <TOKEN id="token-77-9" pos="word" morph="none" start_char="3012" end_char="3014">the</TOKEN>
        <TOKEN id="token-77-10" pos="word" morph="none" start_char="3016" end_char="3024">newspaper</TOKEN>
        <TOKEN id="token-77-11" pos="punct" morph="none" start_char="3025" end_char="3025">.</TOKEN>
      </SEG>
      <SEG id="segment-78" start_char="3027" end_char="3030">
        <ORIGINAL_TEXT>&lt;/P&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-78-0" pos="unknown" morph="none" start_char="3027" end_char="3030">&lt;/P&gt;</TOKEN>
      </SEG>
      <SEG id="segment-79" start_char="3032" end_char="3038">
        <ORIGINAL_TEXT>&lt;/TEXT&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-79-0" pos="unknown" morph="none" start_char="3032" end_char="3038">&lt;/TEXT&gt;</TOKEN>
      </SEG>
      <SEG id="segment-80" start_char="3040" end_char="3045">
        <ORIGINAL_TEXT>&lt;/DOC&gt;</ORIGINAL_TEXT>
        <TOKEN id="token-80-0" pos="unknown" morph="none" start_char="3040" end_char="3045">&lt;/DOC&gt;</TOKEN>
      </SEG>
    </TEXT>
  </DOC>
</LCTL_TEXT>
